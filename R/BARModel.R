

fast_ifelse <- function(test, yes, no) {
  out <- rep(NA, length(test))
  out[test] <- yes[test]
  out[!test] <- no[!test]

  out
}


fast_ifint_elsevec <- function(test, yes, no) {
  out <- rep(NA, length(test))
  out[test] <- yes
  out[!test] <- no[!test]

  out
}

mybart2dbart_tree <- function(mybarttree,
                              treeNums, # probably unnecessary
                              chainNums, # probably unnecessary
                              sampleNums # probably unnecessary
){

  # print("mybarttree = ")
  # print(mybarttree)

  ### dbarts getTrees returns a matrix with columns:
  ### sample, tree, n, var. and value

  # columns ofmybart are
  # c('terminal',
  #   'child_left',
  #   'child_right',
  #   'parent',
  #   'split_variable',
  #   'split_value',
  #   'mu',
  #   'node_size')

  # the first 3 lines are probably unnecessary, can replace with NA

  outtree <- cbind(#rep(chainNums, nrow(mybarttree)),
    rep(sampleNums, nrow(mybarttree)),
    rep(treeNums, nrow(mybarttree)),
    mybarttree[, 'node_size'],
    # mybarttree[,'split_variable'],
    ifelse(is.na(mybarttree[,'split_variable']) ,
           -1,
           mybarttree[,'split_variable']),
    ifelse(is.na(mybarttree[,'split_variable']) ,
           mybarttree[,'mu'],
           mybarttree[,'split_value']))

  return(outtree)

}


#' @export
fastnormdens <- function(x, mean = 0, sd = 0){
  (1/(sd*sqrt(2*pi)))*exp(-0.5*((x-mean)/sd)^2)
}

#' @export
fastlognormdens <- function(x, mean = 0, sd = 0){
  -log(sd*sqrt(2*pi)) + (-0.5*((x-mean)/sd)^2)
}


rebuildTree2 <- function(tree) {
  # Define a worker function that will be recursively called on every node.
  tree1 <- tree
  tree <- cbind(tree,
                rep(NA, nrow(tree)),
                rep(NA, nrow(tree)))

  colnames(tree) <- c(colnames(tree1), "lower", "upper")

  lower <- -Inf
  upper <- Inf
  rebuildTreeRecurse <- function(tree1, lower1, upper1, rowind) {
    # print('rowind = ')
    # print(rowind)
    node <- list(
      # value = tree1$value[1],
      # n = tree1$n[1],
      # lower = lower1,
      # upper = upper1,
      rowindtemp = rowind
    )
    # Check node if is a leaf, and if so return early.
    if (tree1$var[1] == -1) {
      node$n_nodes <- 1


      # node$lower <- lower1
      # node$upper <- upper1

      # tree$lower[rowind] <- lower1
      # tree$upper[rowind] <- upper1
      # print("adding lower and upper")

      tree[rowind,6] <<- lower1
      tree[rowind,7] <<- upper1

      # print(tree)

      return(node)
    }
    # node$var <- variableNames[tree1$var[1]]

    leftlower <- lower1

    # print("tree1$var[1]= ")
    # print(tree1$var[1])

    if(tree1$var[1] ==1){

      leftupper <- tree1$value[1]
      # print("in if statement leftupper = ")
      # print(leftupper)
    }else{
      leftupper <- upper1
    }

    # By removing the current row, we can recurse down the left branch.
    headOfLeftBranch <- tree1[-1,]

    # print("leftupper = ")
    # print(leftupper)
    #
    # print("enter left branch function")

    left <- rebuildTreeRecurse(headOfLeftBranch, leftlower, leftupper, node$rowindtemp +1)
    n_nodes.left <- left$n_nodes
    # left$n_nodes <- NULL
    # node$left <- left



    if(tree1$var[1] ==1){
      rightlower <- tree1$value[1]
    }else{
      rightlower <- lower1
    }
    rightupper <- upper1

    # The right branch is obtained by advancing past the left nodes.
    headOfRightBranch <- tree1[seq.int(2 + n_nodes.left, nrow(tree1)),]
    # print("enter right branch function")
    # print("rightlower = ")
    # print(rightlower)
    # print("rightupper = ")
    # print(rightupper)

    right <- rebuildTreeRecurse(headOfRightBranch, rightlower, rightupper, left$rowindtemp + 1)
    n_nodes.right <- right$n_nodes
    # right$n_nodes <- NULL
    # node$right <- right
    node$n_nodes <- 1L + n_nodes.left + n_nodes.right
    node$rowindtemp <- right$rowindtemp
    return(node)
  }
  # variableNames <- colnames(object$data@x)
  rowind <- 1
  result <- rebuildTreeRecurse(tree1, lower, upper, rowind)
  result$n_nodes <- NULL
  return(tree)
  # return(result)
}


##////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



getPredictionsRangesForTree3 <- function(tree, x) {
  # predictions <- rep(NA_real_, nrow(x))
  outputmat <-cbind(rep(NA_real_, nrow(x)),
                    rep(NA_real_, nrow(x)),
                    rep(NA_real_, nrow(x)))
  indices <- c(1)

  tree1 <- tree

  getPredictionsForTreeRecursive <- function(tree, go_bool) {
    # if (tree$var[1] == -1) {
    # print("tree = ")
    # print(tree)

    if (tree[1,4] == -1) {
      # Assigns in the calling environment by using <<-

      # print("tree$var[1] == -1, indices = ")
      # print(indices)
      #
      # print("outputmat = ")
      # print(outputmat)
      #
      # print("length(indices) = ")
      # print(length(indices))

      if(go_bool){
        # outputmat[indices,1] <<- tree$value[1]
        # outputmat[indices,2] <<- tree$lower[1]
        # outputmat[indices,3] <<- tree$upper[1]
        outputmat[indices,1] <<- tree[1,5]
        outputmat[indices,2] <<- tree[1,6]
        outputmat[indices,3] <<- tree[1,7]
        tempindices <- indices[1] + 1
        # print("tempindices = ")
        # print(tempindices)
        # print("indices[1] = ")
        # print(indices[1])
        indices[1] <<- tempindices

      }

      # print("indices = ")
      # print(indices)
      #
      # print("outputmat = ")
      # print(outputmat)

      return(1)
    }

    # print("tree = ")
    # print(tree)

    # if(tree$var[1] == 1){
    if (tree[1,4] == 1) {
      # add a row because there are two possible values of the latent variable lag

      # print("tree$var[1] == 1, indices = ")
      # print(indices)

      if(go_bool ){
        outputmat <<- rbind(outputmat,
                            c(NA,NA,NA))
      }

      # goesLeft <- x[indices, tree$var[1]] <= tree$value[1]
      headOfLeftBranch <- tree[-1, , drop = FALSE]

      # print("indices = ")
      #
      # print(indices)
      #
      # print("nrow(outputmat)) = ")
      #
      # print(nrow(outputmat))
      #
      # print("headOfLeftBranch = ")
      #
      # print(headOfLeftBranch)

      n_nodes.left <- getPredictionsForTreeRecursive(
        headOfLeftBranch, go_bool)

      # print("n_nodes.left = ")
      #
      # print(n_nodes.left)
      #
      # print("nrow(tree) = ")
      #
      # print(nrow(tree))

      headOfRightBranch <- tree[seq.int(2 + n_nodes.left, nrow(tree)), , drop = FALSE]


      # print("headOfRightBranch = ")
      #
      # print(headOfRightBranch)
      #
      # print("indices = ")
      #
      # print(indices)
      #
      #
      # print(" outputmat = ")
      #
      # print( outputmat)
      #
      # print("nrow(outputmat)) = ")
      #
      # print(nrow(outputmat))


      n_nodes.right <- getPredictionsForTreeRecursive(
        headOfRightBranch, go_bool)

      # if(length(indices) >0 ){
      #   n_nodes.right <- getPredictionsForTreeRecursive(
      #     headOfRightBranch, nrow(outputmat))
      # }else{
      #   n_nodes.right <- getPredictionsForTreeRecursive(
      #     headOfRightBranch, indices)
      # }

      return(1 + n_nodes.left + n_nodes.right)

    }
    # if(tree$var[1] > 1){
    # print("tree = ")
    # print(tree)

    if (tree[1,4] > 1) {
      # print("tree$var[1] > 1, indices = ")
      # print(indices)

      # goesLeft <- x[indices, tree$var[1]] <= tree$value[1]
      # goesLeft <- x[1, tree$var[1]] <= tree$value[1]

      # goesLeft <- x[1, tree$var[1]] <= tree$value[1]
      goesLeft <- x[1, tree[1,4] ]<= tree[1,5]
      headOfLeftBranch <- tree[-1, , drop = FALSE]


      # print("goesLeft & go_bool = ")
      #
      # print(goesLeft  & go_bool)

      n_nodes.left <- getPredictionsForTreeRecursive(
        headOfLeftBranch, goesLeft & go_bool)

      headOfRightBranch <- tree[seq.int(2 + n_nodes.left, nrow(tree)), , drop = FALSE]



      #
      # print("!goesLeft = ")
      #
      # print(!goesLeft)
      #
      # print("outputmat = ")
      # print(outputmat)
      #
      # print("headOfRightBranch = ")
      # print(headOfRightBranch)

      n_nodes.right <- getPredictionsForTreeRecursive(
        headOfRightBranch, (!goesLeft)& go_bool)
    }


    return(1 + n_nodes.left + n_nodes.right)
  }


  # print("nrow(x) = ")
  # print(nrow(x))

  getPredictionsForTreeRecursive(tree, TRUE)

  # getPredictionsForTreeRecursive(tree, seq_len(nrow(x)))

  return(outputmat)
}



##///////////////////////////////////////////////////////////////////////////////////////////////////////////



# All preds and Zlag intervals for one row of covariates ##########

getPredictionsRangesForTree2 <- function(tree, x) {
  # predictions <- rep(NA_real_, nrow(x))
  outputmat <-cbind(rep(NA_real_, nrow(x)),
                    rep(NA_real_, nrow(x)),
                    rep(NA_real_, nrow(x)))

  tree1 <- tree

  getPredictionsForTreeRecursive <- function(tree, indices) {
    if (tree$var[1] == -1) {
      # Assigns in the calling environment by using <<-

      # print("outputmat = ")
      # print(outputmat)
      #
      # print("length(indices) = ")
      # print(length(indices))

      if(length(indices)>0){
        outputmat[indices,1] <<- tree$value[1]
        outputmat[indices,2] <<- tree$lower[1]
        outputmat[indices,3] <<- tree$upper[1]
      }

      # print("indices = ")
      # print(indices)
      #
      # print("outputmat = ")
      # print(outputmat)

      return(1)
    }

    if(tree$var[1] == 1){
      # add a row because there are two possible values of the latent variable lag

      # print("tree$var[1] == 1, indices = ")
      # print(indices)

      if(length(indices) >0 ){
        outputmat <<- rbind(outputmat,
                            c(NA,NA,NA))
      }
      # goesLeft <- x[indices, tree$var[1]] <= tree$value[1]
      headOfLeftBranch <- tree[-1,]

      # print("indices = ")
      #
      # print(indices)
      #
      # print("nrow(outputmat)) = ")
      #
      # print(nrow(outputmat))

      n_nodes.left <- getPredictionsForTreeRecursive(
        headOfLeftBranch, indices)

      headOfRightBranch <- tree[seq.int(2 + n_nodes.left, nrow(tree)),]


      # print("indices = ")
      #
      # print(indices)
      #
      #
      # print(" nrow(outputmat) = ")
      #
      # print( nrow(outputmat))
      #
      # print("nrow(outputmat)) = ")
      #
      # print(nrow(outputmat))

      if(length(indices) >0 ){
        n_nodes.right <- getPredictionsForTreeRecursive(
          headOfRightBranch, nrow(outputmat))
      }else{
        n_nodes.right <- getPredictionsForTreeRecursive(
          headOfRightBranch, indices)
      }

      return(1 + n_nodes.left + n_nodes.right)

    }
    if(tree$var[1] > 1){
      # goesLeft <- x[indices, tree$var[1]] <= tree$value[1]
      goesLeft <- x[1, tree$var[1]] <= tree$value[1]
      headOfLeftBranch <- tree[-1,]


      # print("indices[goesLeft] = ")
      #
      # print(indices[goesLeft])

      n_nodes.left <- getPredictionsForTreeRecursive(
        headOfLeftBranch, indices[goesLeft])

      headOfRightBranch <- tree[seq.int(2 + n_nodes.left, nrow(tree)),]




      # print("indices[!goesLeft] = ")
      #
      # print(indices[!goesLeft])
      #
      # print("outputmat = ")
      # print(outputmat)
      #
      # print("headOfRightBranch = ")
      # print(headOfRightBranch)

      n_nodes.right <- getPredictionsForTreeRecursive(
        headOfRightBranch, indices[!goesLeft])
    }


    return(1 + n_nodes.left + n_nodes.right)
  }


  # print("nrow(x) = ")
  # print(nrow(x))

  getPredictionsForTreeRecursive(tree, seq_len(nrow(x)))
  return(outputmat)
}


inter2treesa <- function(intermat1, intermat2){


  #create a step function

  x1 <- c(-Inf, intermat1[,3])
  x2 <- c(-Inf, intermat2[,3])

  xs <- collapse::funique(c(x1, x2), sort = TRUE)

  y1 <- intermat1[,1]
  y2 <- intermat2[,1]



  ypredvec <- rep(NA, length(xs)-1)
  for(i in 2:length(xs)){

    tempval <- xs[i]
    tempinds <- which((x1 <tempval ))
    temp_ind1 <- tempinds[length(tempinds)]

    tempinds <- which((x2 <tempval ))

    temp_ind2 <- tempinds[length(tempinds)]

    ypredvec[i-1] <- y1[temp_ind1] + y2[temp_ind2]

  }

  newmat <- matrix(NA, nrow = length(xs)-1, ncol = 3)

  newmat[,1] <- ypredvec
  newmat[,2] <- xs[1:(length(xs) - 1)]
  newmat[,3] <- xs[2:(length(xs))]

  return(newmat)

}




interNtreesA <- function(inter_list){

  temp_mat <- inter_list[[1]]
  for(i in 2:length(inter_list)){

    temp_mat <- inter2treesa(temp_mat,inter_list[[i]] )

  }

  return(temp_mat)

}



interNtreesB <- function(inter_list){


  #create a step function
  xlist <- list()
  for(i in 1:length(inter_list)){
    xlist[[i]] <- c(-Inf, (inter_list[[i]])[,3])
  }

  # x1 <- c(-Inf, intermat1[,3])
  # x2 <- c(-Inf, intermat2[,3])

  xs <- collapse::funique(unlist(xlist), sort = TRUE)


  ylist <- list()

  for(i in 1:length(inter_list)){
    ylist[[i]] <-  (inter_list[[i]])[,1]
  }

  # y1 <- intermat1[,1]
  # y2 <- intermat2[,1]

  ypredvec <- rep(NA, length(xs)-1)

  # tempindvec <- rep(NA, length(inter_list))

  for(i in 2:length(xs)){


    tempval <- xs[i]

    ypredvec[i-1] <- 0
    for(j in 1:length(inter_list)){
      tempinds <- which((xlist[[j]] <tempval ))

      temp_ind <- tempinds[length(tempinds)]

      ypredvec[i-1] <- ypredvec[i-1] + (ylist[[j]])[temp_ind]
    }

    # tempinds <- which((x1 <tempval ))
    # temp_ind1 <- tempinds[length(tempinds)]
    #
    # tempinds <- which((x2 <tempval ))
    #
    # temp_ind2 <- tempinds[length(tempinds)]

    # ypredvec[i-1] <- y1[temp_ind1] + y2[temp_ind2]

  }

  newmat <- matrix(NA, nrow = length(xs)-1, ncol = 3)

  newmat[,1] <- ypredvec
  newmat[,2] <- xs[1:(length(xs) - 1)]
  newmat[,3] <- xs[2:(length(xs))]


  return(newmat)

}




##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data without  Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and without covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @export
ARRObartNOCovars_fullcond_partial <- function(pair.comp.ten,
                                      # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                      # X.test = matrix(NA, nrow =0, ncol = 0),
                                      # tau2.alpha = 5^2,
                                      # nu.alpha = 3,
                                      # tau2.beta = 5^2,
                                      # nu.beta = 3,
                                      n.item = dim(pair.comp.ten)[1],
                                      n.rankerbytime = dim(pair.comp.ten)[3],
                                      n.ranker,
                                      n.time,
                                      # p.cov = ncol(X.train),
                                      iter.max = 5000,
                                      para.expan = TRUE,
                                      print.opt = 100,
                                      initial.list = NULL,
                                      n.trees = 50L,
                                      n.burn = 0L,
                                      n.samples = 1L,
                                      n.thin = 1L,
                                      n.chains = 1,
                                      n.threads = 1L,#guessNumCores(),
                                      printEvery = 100L,
                                      printCutoffs = 0L,
                                      rngKind = "default",
                                      rngNormalKind = "default",
                                      rngSeed = NA_integer_,
                                      updateState = TRUE,
                                      num_lags = 1,
                                      diff_num_test_rankers = 0,
                                      keep_zmat = FALSE,
                                      noise_in_pred = 0,
                                      seq_z_draws = 1,
                                      N_hdr = 100,
                                      rho_hdr = 0.5,
                                      smoothing_method = "AR",
                                      num_horizon = 1,
                                      num_z_iters = 10,
                                      tree_power = 2,
                                      tree_base = 0.95,
                                      n.burnin = floor(dim(pair.comp.ten)[1]/2),
                                      sparse = TRUE,
                                      alpha_a_y = 0.5,
                                      alpha_b_y = 1,
                                      alpha_split_prior = TRUE){


  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  # length_mu_test <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  # ranks_mat <- matrix(NA,
  #                     ncol = n.ranker*n.time,
  #                     nrow = n.item )
  #
  #
  # #n.item by n.item
  #
  # for(t in 1:n.time){
  #
  #   for(indiv in 1:n.ranker){
  #     pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]
  #
  #     # 1 corresponding to "highest rank" . i.e. highest utility ite,
  #     # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1
  #
  #     # 1 corresponding to "lowest rank". i.e. lowest utility item
  #
  #     up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
  #
  #
  #     ranks_mat[, (t-1)*n.ranker + indiv] <- up.order
  #
  #   }
  # }
  #
  #
  # # it might be more efficient to create and save all rank constraint matrices at this stage
  #
  #
  # rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))
  #
  # for(indiv in 1:n.ranker){
  #
  #   for(t in 1:n.time){
  #
  #     rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
  #
  #
  #     rankconstraint_t <- matrix(0,
  #                                nrow = n.item - 1,
  #                                ncol = n.item)
  #
  #     # note: ordering of rows is unimportant
  #     # as long as ordering agrees with the ordering of the mean vector
  #
  #     # so can begin by filling in first row
  #
  #     #MUST BE EDITED IF ALLOW FOR TIES
  #     for(rankind in 1:(length(rankvec_t)-1)){
  #
  #       rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
  #       rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1
  #
  #       # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
  #       # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1
  #
  #     }
  #
  #     rank_cons_arr[, , indiv, t] <- rankconstraint_t
  #
  #   }
  # }
  # # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  boundconstraints <- matrix(NA,
                             nrow = 2*n.item,
                             ncol = n.item)

  # use kroenecker product
  # there is probably a more efficient way of doing this

  boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))


      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }



    # print("Line 799.")

    df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )

    p_y <- ncol(df_for_dbart) - 1 # subtracting 1. outcome is a column of df_for_dbart

    if(sparse){
      s_y <- rep(1 / p_y, p_y) # probability vector to be used during the growing process for DART feature weighting
      rho_y <- p_y # For DART

      if(alpha_split_prior){
        alpha_s_y <- p_y
      }else{
        alpha_s_y <- 1
      }
      alpha_scale_y <- p_y


      var_count_y <- rep(0, p_y)

      draw$alpha_s_y_store <- rep(NA, iter.max)
      draw$var_count_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
      draw$s_prob_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
    }

    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")


    # if(nrow(X.test )==0){
    sampler <- dbarts(y ~ .,
                      data = df_for_dbart,
                      #test = Xmat.test,
                      control = control,
                      resid.prior = fixed(1),
                      tree.prior = dbarts:::cgm(power = tree_power, base =  tree_base,  split.probs = rep(1 / p_y, p_y)),
                      sigma=1 #check if this is the correct approach for setting the variance to 1
    )

    # }else{
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    #                     sigma=1 #
    #   )
    #
    # }

    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    min_resp <- min(as.vector(Z.mat))
    max_resp <- max(as.vector(Z.mat))

    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }
    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)

    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()


    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y <- rep(0, p_y)
      var_count_y[tempcounts$x] <- tempcounts$N
    }

    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    mu <- mutemp

    #
    # if(nrow(X.train)==n.item){
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #   stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #   # if(mutemp[1]!= mutemp[n.item+1]){
    #   if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
    #     print("initiating mu")
    #     print("Xmat.train = ")
    #     print(Xmat.train)
    #     print("Z.mat = ")
    #     print(Z.mat)
    #
    #     print("samplestemp$sigma = ")
    #     print(samplestemp$sigma)
    #     print("samplestemp$varcount = ")
    #     print(samplestemp$varcount)
    #
    #     print("samplestemp$train[,1] = ")
    #     print(samplestemp$train[,1])
    #
    #     print("n.item = ")
    #     print(n.item)
    #     print("mutemp = ")
    #     print(mutemp)
    #
    #     # print("mupreds= ")
    #     # print(mupreds)
    #
    #     stop("mutemp[1]!= mutemp[n.item+1]")
    #   }
    #
    #   #mu = mutemp[(1:n.item)]
    #   mu = mutemp[n.item+(1:n.item)]
    #
    #   #mu = mutemp[(1:n.item)*n.ranker]
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     mu <- mutemp
    #   }else{
    #     stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    #
    # }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  # print("Line 954")


  df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    temp_test_mat <- data.frame(x = as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      testpredvec <- sampler$predict(temp_test_mat)

      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker), ] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),] )))

      }

      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration

  iter <- 2
  breakcount <- 0
  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############



    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA

    # create vector of indices for ranker indiv in time period 1

    # # this part is not really necessary
    # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
    # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
    # obs_indices <- ind_start:ind_end

    # obs_indices[1] could jsut be replaced by [1] below\
    # because the only variable is zlag, so the other covariates are not used


    list_inter_mats <- list()

    for(i in 1:n.trees){

      treeexample1 <- sampler$getTrees(treeNums = i,
                                       chainNums = 1,
                                       sampleNums = 1)

      # rebuilt_tree <- rebuildTree2(treeexample1)
      rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))


      #must use covariates for individual indiv at time period t

      # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )

      # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
      list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree[,4] == -1 , 5:7, drop = FALSE]


    }

    intersectmat <- interNtreesB(list_inter_mats)

    # print("Line 1146")

    intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

    # print("Line 1150")


    # calculate one dimensional integrals
    for(rowind in 1:nrow(intersectmat)){
      # ktemp <- nkt_mat[rowind,k_index]
      # tempmean <- intersectmat[ktemp,1]
      templower <- intersectmat[rowind,2]
      tempupper <- intersectmat[rowind,3]

      # ASSUMING PRIOR MEAN ALL ZEROS

      # These are the q0 integrals
      intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
      # tempintegralval <- tempintegralval*onedim_int
    }

    intersectmat_tmin1 <- intersectmat



    num_regions <- nrow(intersectmat)

    # print("Line 1169")


    for(z_iter_ind in 1:num_z_iters){


      for(indiv in 1:n.ranker){

        # print("indiv = ")
        # print(indiv)
        ########### calculate qkt  ########################################

        ########### calculate qkt   for t = 1 ########################################


        ### calculate qkt integrals for time period t = 1  ################

        # These integrals are already calculated and saved as intersectmat[ktemp,4]

        for(item_ind in 1:n.item){


          #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

          # loop over items

          # Now loop over time periods

          # special case for t=1

          # probability matrix for sampling elements

          # let rows be period zero, and columns be period 1 (2?)

          # probmattemp <- matrix(0,
          #                       nrow = num_regions,
          #                       ncol = num_regions)

          logprobmattemp <- matrix(0,
                                   nrow = num_regions,
                                   ncol = num_regions)

          # loop over period 2 regions into which z_1 can fall


          tempbounds <- matrix(NA,
                               nrow = num_regions,
                               ncol = 2)

          # Trunc norm prob of next periods latent value conditional on region

          # Create intervals from interval t+1 latent values

          # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]
          #
          # # inds for j ranked below i in t+1
          #
          #
          #
          # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in t+1
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower <- -Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    belowrank_ind]
          # }
          #
          # # inds for j ranked above i in t+1
          #
          # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period t+1
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper <- Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #
          #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    aboverank_ind]
          # }


          temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                          n.item*(indiv - 1) +
                                          item_ind]

          temppaircomps <- pair.comp.ten[, , (1-1)*n.ranker + indiv]

          tempz <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                      n.item*(indiv - 1) +
                                      1:n.item]

          set1 = which( temppaircomps[item_ind, ] == 1)
          set0 = which( temppaircomps[item_ind, ] == 0)

          if(length(set1) > 0){
            temp_upper3 = min(tempz[set1])
          }else{
            temp_upper3 = Inf
          }

          if(length(set0) > 0){
            temp_lower3 = max(tempz[set0])
          }else{
            temp_lower3 = -Inf
          }

          # rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]
          #
          # # if(any(order(rankvec_t) !=
          # #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                           n.item*(indiv-1) +
          # #                           1:n.item])) ){
          # #
          # #   # print("order(rankvec_t) = ")
          # #   # print(order(rankvec_t))
          # #   #
          # #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #   #                         n.item*(indiv - 1) +
          # #   #                         1:n.item])  = ")
          # #
          # #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                                  n.item*(indiv - 1) +
          # #                                  1:n.item]) )
          # #
          # #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #   #                                n.item*(indiv - 1) +
          # #   #                                1:n.item] = ")
          # #
          # #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                            n.item*(indiv - 1) +
          # #                            1:n.item])
          # #
          # # }
          #
          # # inds for j ranked below i in t
          #
          # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in t
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower3 <- -Inf
          # }else{
          #   temp_lower3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     belowrank_ind]
          # }
          #
          # # inds for j ranked above i in t
          #
          # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period t
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper3 <- Inf
          # }else{
          #   temp_upper3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     aboverank_ind]
          # }



          tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp

          bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

          logprobmattemp[, bad_regions] <- -Inf #rep(-Inf,num_regions)
          tempbounds[bad_regions, 1] <- NA
          tempbounds[bad_regions, 2] <- NA

          good_regions <- setdiff(1:num_regions, bad_regions)


          temp_tnorm_logprobvec <- rep(NA, num_regions)
          temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                 mean = tempmeanfordens[good_regions],
                                                                 sd = 1)


          # logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprobvec[k_ind] +
          #   log(intersectmat[1:num_regions,4])

          logprobmattemp[1:num_regions, good_regions] <- outer(log(intersectmat[1:num_regions,4]),
                                                               temp_tnorm_logprobvec[good_regions],
                                                               FUN = "+")


          tempbounds[good_regions,1] <- pmax(intersectmat[good_regions, 2], temp_lower3)
          tempbounds[good_regions,2] <- pmin(intersectmat[good_regions, 3], temp_upper3)

          if(any(tempbounds[good_regions,1] >= tempbounds[good_regions,2])){
            stop(" line 1868 bounds badly defined")
          }

          # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
          #                                    mean = tempmeanfordens,
          #                                    sd = 1)



          # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
          #                                 mean = intersectmat[1:num_regions, 1],
          #                                 sd = 1)

          # for(k_ind in 1:num_regions){
          #   # obtain mean for truncated normal distribution
          #   # temp_mean <- intersectmat[k_ind, 1]
          #
          #   # want trunc norm probability of latent variable value for item_ind
          #   # in period t+1
          #
          #
          #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
          #   #                               a=temp_lower,
          #   #                               b=Inf,
          #   #                               mean = temp_mean,
          #   #                               sd = 1)
          #
          #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
          #   #                          mean = temp_mean,
          #   #                          sd = 1)
          #
          #   temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
          #
          #   # temp_mean <- intersectmat[k_ind, 1]
          #
          #
          #
          #   # now second term
          #
          #
          #   temp_lower2 <- intersectmat[k_ind, 2]
          #   temp_upper2 <- intersectmat[k_ind, 3]
          #
          #
          #
          #
          #   # print("temp_lower2 = ")
          #   # print(temp_lower2)
          #   #
          #   # print("temp_lower3 = ")
          #   # print(temp_lower3)
          #   #
          #   # print("temp_upper2 = ")
          #   # print(temp_upper2)
          #   #
          #   # print("temp_upper3 = ")
          #   # print(temp_upper3)
          #
          #
          #   if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
          #     # intervals do not overlap, therefore assign probability zero
          #     # and skip to next iteration
          #
          #
          #     # print("k_ind = ")
          #     # print(k_ind)
          #
          #     # print("ncol(temp_region_probs) = ")
          #     # print(ncol(temp_region_probs))
          #
          #     # print("nrow(temp_region_probs) = ")
          #     # print(nrow(temp_region_probs))
          #
          #
          #     # these three lines are technically unnecessary
          #     probmattemp[, k_ind] <- rep(0,num_regions)
          #     tempbounds[k_ind, 1] <- NA
          #     tempbounds[k_ind, 2] <- NA
          #
          #     next
          #
          #   }
          #
          #
          #   temp_lower2 <- max(temp_lower2, temp_lower3)
          #   temp_upper2 <- min(temp_upper2, temp_upper3)
          #
          #   if(temp_lower2 > temp_upper2){
          #
          #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     1:n.item]")
          #
          #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                              n.item*(indiv - 1) +
          #                              1:n.item])
          #
          #     print("item_ind = ")
          #     print(item_ind)
          #
          #     # print("rankvec_t = ")
          #     # print(rankvec_t)
          #
          #     stop("Line 1581 temp_lower2 > temp_upper2")
          #   }
          #
          #
          #   for(k0_ind in 1:num_regions){
          #
          #     #loop over all possible means
          #     temp_mean2 <- intersectmat[k0_ind,1]
          #
          #     # probability of being in intersection region
          #
          #     # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
          #
          #
          #     # probmattemp[k0_ind, k_ind] <- prob_t_region*
          #     #   temp_tnorm_prob *
          #     #   intersectmat[k0_ind,4]
          #
          #     probmattemp[k0_ind, k_ind] <- temp_tnorm_prob * intersectmat[k0_ind,4]
          #
          #     if(probmattemp[k0_ind, k_ind] <0){
          #       print("probmattemp[k0_ind, k_ind] = ")
          #       print(probmattemp[k0_ind, k_ind])
          #
          #       # print("prob_t_region = ")
          #       # print(prob_t_region)
          #
          #       print("temp_tnorm_prob = ")
          #       print(temp_tnorm_prob)
          #
          #       print("intersectmat[k0_ind,4] = ")
          #       print(intersectmat[k0_ind,4])
          #
          #       print("temp_upper2 = ")
          #       print(temp_upper2)
          #
          #       print("temp_lower2 = ")
          #       print(temp_lower2)
          #
          #       print("temp_mean2 = ")
          #       print(temp_mean2)
          #
          #
          #     }
          #
          #
          #   } # end loop over k0
          #
          #   # save upper and lower bounds (mean saved in intersectmat)
          #   # or just obtain again later
          #
          #   tempbounds[k_ind,1] <- temp_lower2
          #   tempbounds[k_ind,2] <- temp_upper2
          #
          #
          # } # end loop over k1


          #sample a combination of k0 and k1
          # if necessary can use column sums to sample k1, then k0
          # however, this is probably unnecessary


          # print("Line 1621 before sample")

          # region_ind <- sample.int((num_regions^2),
          #                          size = 1,
          #                          replace = TRUE,
          #                          prob = as.vector(probmattemp))

          logprobstemp <- as.vector(logprobmattemp)
          max_ll <- max(logprobstemp)
          logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
          probstemp <- exp(logprobstemp - logsumexps)

          region_ind <- sample.int((num_regions^2),
                                   size = 1,
                                   replace = TRUE,
                                   prob = probstemp)


          # print("Line 1629 after sample")

          # k0 region is sampled number modulo number of regions
          k0_region_ind <- (region_ind - 1) %% num_regions + 1
          # if(k0_region_ind ==0){
          #   k0_region_ind <- num_regions
          # }

          # k1 region is the ceiling of sampled number divided by number of regions
          # k1_region_ind <- ceiling(region_ind/num_regions)
          k1_region_ind <- (region_ind - 1) %/% num_regions + 1


          # print("k1_region_ind = ")
          # print(k1_region_ind)

          temp_lower2 <- tempbounds[k1_region_ind,1]
          temp_upper2 <- tempbounds[k1_region_ind,2]

          # print("num_regions = ")
          # print(num_regions)
          #
          # print("region_ind = ")
          # print(region_ind)
          #
          # print("k0_region_ind = ")
          # print(k0_region_ind)

          temp_mean0 <- intersectmat[k0_region_ind, 1]
          temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

          # print("temp_mean0 = ")
          # print(temp_mean0)
          #
          # print("temp_lower2 = ")
          # print(temp_lower2)
          #
          # print("temp_upper2 = ")
          # print(temp_upper2)

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = temp_lower2,
                                   b = temp_upper2,
                                   mean = temp_mean0,
                                   sd = 1)


          Z.mat[item_ind,  indiv ] <- zdraw_temp


          # loop over time periods for general case 1 < t < T

          for(t in 2:(n.time - 1)){

            temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # or first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat[, 3]) )[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat[ktemp_tmin1,1]

            # print("temp_mean2 = ")
            # print(temp_mean2)
            #
            # print("ktemp_tmin1 = ")
            # print(ktemp_tmin1)



            # Calculate the probabilities for each region in this time period
            # the regions being looped over are actually period t+1 regions

            # Same regions for all time periods if there are no time varying covariates

            # However, the weights are individual and time period specific

            # loop through regions


            # first column is the probabilities
            # second column is the lower bounds
            # third column is the upper bounds
            # temp_region_probs <- matrix(0,
            #                             nrow = nrow(intersectmat),
            #                             ncol = 3)


            temp_region_logprobs <- matrix(-Inf,
                                           nrow = nrow(intersectmat),
                                           ncol = 3)


            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]
            #
            # # inds for j ranked below i in t+1
            #
            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            # want trunc norm probability of latent variable value for item_ind
            # in period t+1

            temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]


            temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

            tempz <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                        n.item*(indiv - 1) +
                                        1:n.item]

            set1 = which( temppaircomps[item_ind, ] == 1)
            set0 = which( temppaircomps[item_ind, ] == 0)

            if(length(set1) > 0){
              temp_upper3 = min(tempz[set1])
            }else{
              temp_upper3 = Inf
            }

            if(length(set0) > 0){
              temp_lower3 = max(tempz[set0])
            }else{
              temp_lower3 = -Inf
            }



            # rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
            #
            #
            #
            # # if(any(order(rankvec_t) !=
            # #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                           n.item*(indiv - 1) +
            # #                           1:n.item]) )){
            # #
            # #   print("order(rankvec_t) = ")
            # #   print(order(rankvec_t))
            # #
            # #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                         n.item*(indiv - 1) +
            # #                         1:n.item])  = ")
            # #
            # #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                                  n.item*(indiv - 1) +
            # #                                  1:n.item]) )
            # #
            # #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                                n.item*(indiv - 1) +
            # #                                1:n.item] = ")
            # #
            # #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                            n.item*(indiv - 1) +
            # #                            1:n.item])
            # #
            # #
            # # }
            #
            #
            #
            #
            #
            # # inds for j ranked below i in t
            #
            # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower3 <- -Inf
            # }else{
            #   temp_lower3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                     n.item*(indiv - 1) +
            #                                     belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t
            #
            # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper3 <- Inf
            # }else{
            #   temp_upper3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                     n.item*(indiv - 1) +
            #                                     aboverank_ind]
            # }

            tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                    mean = tempmeanfordens,
            #                                    sd = 1)

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                 mean = intersectmat[1:num_regions, 1],
            #                                 sd = 1)
            bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

            temp_region_logprobs[bad_regions, 1] <- -Inf
            temp_region_logprobs[bad_regions, 2] <- NA
            temp_region_logprobs[bad_regions, 3] <- NA

            good_regions <- setdiff(1:num_regions, bad_regions)

            temp_tnorm_logprobvec <- rep(NA, num_regions)
            temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                   mean = tempmeanfordens[good_regions],
                                                                   sd = 1)


            temp_region_logprobs[good_regions, 1] <- temp_tnorm_logprobvec[good_regions]
            temp_region_logprobs[good_regions, 2] <- pmax(intersectmat[good_regions, 2], temp_lower3)
            temp_region_logprobs[good_regions, 3] <- pmin(intersectmat[good_regions, 3], temp_upper3)


            # for(k_ind in 1:num_regions){
            #   # obtain mean for truncated normal distribution
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #   #                               a=temp_lower,
            #   #                               b=Inf,
            #   #                               mean = temp_mean,
            #   #                               sd = 1)
            #
            #
            #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #   #                          mean = temp_mean,
            #   #                          sd = 1)
            #
            #   temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
            #
            #   # Probability of z_t in intersection of
            #   # region k_ind (for period t+1)
            #   # and region defined by period t latent variables for other individuals
            #   # and rank for period t
            #
            #
            #   # tildeC_ktminl corresponds to
            #   # period t+1 k_ind region intereval
            #
            #   temp_lower2 <- intersectmat[k_ind, 2]
            #   temp_upper2 <- intersectmat[k_ind, 3]
            #
            #
            #
            #   # print("temp_lower2 = ")
            #   # print(temp_lower2)
            #   #
            #   # print("temp_upper2 = ")
            #   # print(temp_upper2)
            #   #
            #   # print("temp_lower3 = ")
            #   # print(temp_lower3)
            #   #
            #   # print("temp_upper3 = ")
            #   # print(temp_upper3)
            #
            #
            #   if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
            #     # intervals do not overlap, therefore assign probability zero
            #     # and skip to next iteration
            #
            #     # print("k_ind = ")
            #     # print(k_ind)
            #
            #     # print("ncol(temp_region_probs) = ")
            #     # print(ncol(temp_region_probs))
            #
            #     # print("nrow(temp_region_probs) = ")
            #     # print(nrow(temp_region_probs))
            #
            #     temp_region_probs[k_ind, 1] <- 0
            #     temp_region_probs[k_ind, 2] <- NA
            #     temp_region_probs[k_ind, 3] <- NA
            #
            #
            #     next
            #   }
            #
            #
            #
            #   temp_lower2 <- max(temp_lower2, temp_lower3)
            #   temp_upper2 <- min(temp_upper2, temp_upper3)
            #
            #
            #   if(temp_lower2 > temp_upper2){
            #
            #     print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                   n.item*(indiv - 1) +
            #                                   1:n.item]")
            #     print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #
            #     print("temp_lower2 = ")
            #     print(temp_lower2)
            #
            #     print("temp_upper2 = ")
            #     print(temp_upper2)
            #
            #     stop("Line 1917. temp_lower2 > temp_upper2")
            #   }
            #
            #
            #
            #   # probability of being in intersection region
            #
            #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
            #
            #
            #   # print("temp_upper2 = ")
            #   # print(temp_upper2)
            #   # print("temp_lower2 = ")
            #   # print(temp_lower2)
            #   #
            #   # print("temp_mean2 = ")
            #   # print(temp_mean2)
            #   #
            #   #
            #   # print("prob_t_region = ")
            #   # print(prob_t_region)
            #   #
            #   # print("temp_tnorm_prob = ")
            #   # print(temp_tnorm_prob)
            #
            #   # prob_t_region <- prob_t_region*temp_tnorm_prob
            #   prob_t_region <- temp_tnorm_prob
            #
            #   # save region probability
            #
            #   # and save region bounds (or maybe more memory efficient to obtain the region again)
            #
            #   # must multiply by other previously obtained probabilities
            #
            #   # print("prob_t_region = ")
            #   # print(prob_t_region)
            #
            #   temp_region_probs[k_ind, 1] <- prob_t_region
            #   temp_region_probs[k_ind, 2] <- temp_lower2
            #   temp_region_probs[k_ind, 3] <- temp_upper2
            #
            #
            # }


            # sample a region using probabilities obtained above

            # print("Line 1903 before sample")

            # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])

            if(length(good_regions)==1){
              region_ind <- good_regions[1]
            }else{
              logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
              max_ll <- max(logprobstemp)
              logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
              probstemp <- exp(logprobstemp - logsumexps)

              region_ind <- sample(x = (1:num_regions)[good_regions], size = 1, replace = TRUE, prob = probstemp)
            }

            temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
            #
            # print("line 2102 temp_mean2_debug from predict = ")
            # print(temp_mean2_debug)
            #
            # print("line 2105 temp_mean2_origscale = ")
            # print(temp_mean2_origscale)
            #
            # print("line 2108 temp_mean2 = ")
            # print(temp_mean2)

            # tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/100
            #
            # if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
            #   upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
            #   lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer
            #
            # }else{
            #   upper_buffered <- temp_region_logprobs[region_ind, 3]
            #   lower_buffered <- temp_region_logprobs[region_ind, 2]
            #
            #
            #   if(temp_region_logprobs[region_ind, 3] != Inf){
            #     upper_buffered <- temp_region_logprobs[region_ind, 3] - 0.00001
            #   }
            #
            #   if(temp_region_logprobs[region_ind, 2] != -Inf){
            #     lower_buffered <- temp_region_logprobs[region_ind, 2] + 0.00001
            #   }
            #
            # }


            zdraw_temp <- rtruncnorm(n = 1,
                                     a=temp_region_logprobs[region_ind, 2],
                                     b=temp_region_logprobs[region_ind, 3],
                                     mean = temp_mean2_origscale,
                                     sd = 1)


            # print("Line 1914 after sample")

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a=temp_region_probs[region_ind, 2],
            #                          b=temp_region_probs[region_ind, 3],
            #                          mean = temp_mean2,
            #                          sd = 1)



            Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



          } # end loop over time periods

          # check for special cases for n.time - 1, n.time - 2, n.time - 3

          # special case for t = n.time


          temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             item_ind]


          # must find mean corresponding to z in period t-1
          # This will be used in and after the loop over regions.
          # can directly obtain from dbarts
          # or find region
          # and use already saved region mean values


          # must find last lower bound that temp_ztpmin1 is greater than
          # for first upper bound that temp_ztpmin1 is below
          ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat[, 3])[1]
          # Then obtain the corresponding region mean value
          temp_mean2 <- intersectmat[ktemp_tmin1,1]

          # now find interval


          # tildeC_ktminl corresponds to
          # period t+1 k_ind region intereval

          temppaircomps <- pair.comp.ten[, , (n.time-1)*n.ranker + indiv]

          tempz <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                      n.item*(indiv - 1) +
                                      1:n.item]

          set1 = which( temppaircomps[item_ind, ] == 1)
          set0 = which( temppaircomps[item_ind, ] == 0)

          if(length(set1) > 0){
            temp_upper3 = min(tempz[set1])
          }else{
            temp_upper3 = Inf
          }

          if(length(set0) > 0){
            temp_lower3 = max(tempz[set0])
          }else{
            temp_lower3 = -Inf
          }

          # rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]
          #
          # # inds for j ranked below i in T
          #
          # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in T
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower3 <- -Inf
          # }else{
          #   temp_lower3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     belowrank_ind]
          # }
          #
          # # inds for j ranked above i in T
          #
          # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period T
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper3 <- Inf
          # }else{
          #
          #   temp_upper3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     aboverank_ind]
          # }


          temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

          # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
          #
          # print("line 2202 temp_mean2_debug from predict = ")
          # print(temp_mean2_debug)
          #
          # print("line 2205 temp_mean2_origscale = ")
          # print(temp_mean2_origscale)
          #
          # print("line 2208 temp_mean2 = ")
          # print(temp_mean2)

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = temp_lower3,
                                   b = temp_upper3,
                                   mean = temp_mean2_origscale,
                                   sd = 1)


          # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

          # zdraw_temp <- rtruncnorm(n = 1,
          #                          a = temp_lower3,
          #                          b = temp_upper3,
          #                          mean = temp_mean2,
          #                          sd = 1)


          Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





        } # end loop over items



      } # end loop over individuals indiv in 1:n.ranker

    }




    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{

    temp_break <- 0
    for(j in 1:num_lags){
      # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)

      while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {

        if(seq_z_draws==1){
          stop("updates still not consistent with tree structure")
        }
        print("new z values not consistent with tree structure, must draw again")

        # If this error message occurs
        # Check the conditions in the dbart package for setPredictor == FALSE
        # And if this is hypothetically possible, even with draws from the smoothing distribution,
        # and if it is not a bug
        # then need to go back to beginning of this iteration of the Gibbs sampler
        # and sample Zmat again


        temp_break <- 1
        break
        # stop("new z values not consistent with tree structure, must draw again")


        # #perhaps this can be rewritten to just re-draw the relevant column?
        # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                           Z.mat = Z.mat,
        #                                           mu = mu,
        #                                           weight.vec = rep(1, n.ranker*n.time),
        #                                           n.ranker = n.ranker*n.time,
        #                                           n.item = n.item )
        #
        # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
        #
        # for(t in 1:num_lags){
        #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
        #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
        #
        #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
        #
        # }
        #
        # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j

      }

      if(temp_break==1){
        break
      }
    }

    # if need to draw z values again, go back to start of loop
    if(temp_break==1){
      if(breakcount == 10){
        Z.mat <- Z.matold
        Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

        for(t in 1:num_lags){
          init_Z_t0 <- rep(0, t*n.item*n.ranker)
          # init_Z_t0 <- rnorm(t*n.item*n.ranker)

          Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

        }

      }else{
        breakcount <- breakcount +1
        next
      }

    }

    breakcount <- 0


    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)

    min_resp <- min(as.vector(Z.mat))
    max_resp <- max(as.vector(Z.mat))

    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }
    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples
    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y[tempcounts$x] <- tempcounts$N
    }
    # mutemp <- sampler$predict(df_for_dbart)
    # print("sigma = ")
    # print(samplestemp$sigma)

    mu = mutemp


    if (sparse & (iter > floor(n.burnin * 0.5))) {
      # s_update_z <- update_s(var_count_z, p_z, alpha_s_z)
      # s_z <- s_update_z[[1]]

      s_update_y <- update_s(var_count_y, p_y, alpha_s_y)
      s_y <- s_update_y[[1]]

      if(alpha_split_prior){
        # alpha_s_z <- update_alpha(s_z, alpha_scale_z, alpha_a_z, alpha_b_z, p_z, s_update_z[[2]])
        alpha_s_y <- update_alpha(s_y, alpha_scale_y, alpha_a_y, alpha_b_y, p_y, s_update_y[[2]])
      }
    }
    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta




    # if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(df_for_dbart)

    # Xmat.test[,1:num_lags] <-  Zlag.mat.test


    temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))

    for(t  in 1:num_lags){
      if(noise_in_pred ==1){
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
      }else{
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]

      }

    }

    # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #                                                                      (num_lags+1):ncol(Xmat.test)])

    temp_test_mat <- data.frame(x = temp_test_mat)
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # print("Line 5488")


    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )


    # if(iter < 5){
    #   print("temp_test_mat = " )
    #   print(temp_test_mat)
    # }

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # must use original column names to prevent an error in the predict function
      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      testpredvec <- sampler$predict(temp_test_mat)

      #fill in temp_test_preds with noise
      if(noise_in_pred ==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
      }


      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

      if(t1 != num_test_periods){


        if(num_lags ==1){
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }else{
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                    temp_test_mat[,1:(num_lags-1)] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }
      }

      # colnames(temp_test_mat) <- colnames(Xmat.test)


      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?

    # print("Line 5545")


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }


    draw$mu_test[,iter] <- temp_mu_test
    # draw$mu_test[,iter] <- samplestemp$test[,1]

    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }


    if(sparse){
      draw$alpha_s_y_store[iter] <- alpha_s_y
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_y_store[iter,] <- var_count_y
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_y_store[iter,] <- s_y
      # draw$s_prob_z_store[iter,] <- s_z
    }

    # draw$mu_test[,1] <- samplestemp$test[,1]

    # }else{
    #   draw$mu_test[,1] <- initial.list$mu_test
    # }




    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

    iter <- iter+1
  } # end loop over MCMC iterations


  return(draw)
}



##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and with covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.train An \eqn{N} by \eqn{L} training covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param X.test An \eqn{N} by \eqn{L} test covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param n.item Number of entities/items being ranked.
#' @param n.rankerbytime Number of rankers multiplied by number of time periods
#' @param n.ranker Number of rankers
#' @param n.time Number of time periods
#' @param p.cov Number of covariates.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @param itemcovars Set equal to TRUE if covariates vary across items, and FALSE otherwise.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @useDynLib ROBART2, .registration = TRUE
#' @export
ARRObartWithCovars_fullcond_partial <- function(pair.comp.ten,
                                        X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                        X.test = matrix(NA, nrow =0, ncol = 0),
                                        # tau2.alpha = 5^2,
                                        # nu.alpha = 3,
                                        # tau2.beta = 5^2,
                                        # nu.beta = 3,
                                        n.item = dim(pair.comp.ten)[1],
                                        n.rankerbytime = dim(pair.comp.ten)[3],
                                        n.ranker,
                                        n.time,
                                        p.cov = ncol(X.train),
                                        iter.max = 5000,
                                        para.expan = TRUE,
                                        print.opt = 100,
                                        initial.list = NULL,
                                        n.trees = 50L,
                                        n.burn = 0L,
                                        n.samples = 1L,
                                        n.thin = 1L,
                                        n.chains = 1,
                                        n.threads = 1L,#guessNumCores(),
                                        printEvery = 100L,
                                        printCutoffs = 0L,
                                        rngKind = "default",
                                        rngNormalKind = "default",
                                        rngSeed = NA_integer_,
                                        updateState = FALSE,
                                        num_lags = 1,
                                        diff_num_test_rankers = 0,
                                        keep_zmat = FALSE,
                                        noise_in_pred = 0,
                                        seq_z_draws = 1,
                                        N_hdr = 100,
                                        rho_hdr = 0.5,
                                        smoothing_method = "AR",
                                        num_horizon = 1,
                                        num_z_iters = 10,
                                        itemcovars = FALSE,
                                        tree_power = 2,
                                        tree_base = 0.95,
                                        n.burnin = floor(dim(pair.comp.ten)[1]/2),
                                        sparse = TRUE,
                                        alpha_a_y = 0.5,
                                        alpha_b_y = 1,
                                        alpha_split_prior = TRUE){


  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)

      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  # ranks_mat <- matrix(NA,
  #                     ncol = n.ranker*n.time,
  #                     nrow = n.item )
  #
  #
  # #n.item by n.item
  #
  # for(t in 1:n.time){
  #
  #   for(indiv in 1:n.ranker){
  #     pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]
  #
  #     # 1 corresponding to "highest rank" . i.e. highest utility ite,
  #     # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1
  #
  #     # 1 corresponding to "lowest rank". i.e. lowest utility item
  #
  #     up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
  #
  #
  #     ranks_mat[, (t-1)*n.ranker + indiv] <- up.order
  #
  #   }
  # }
  #
  #
  # # it might be more efficient to create and save all rank constraint matrices at this stage
  #
  #
  # rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))
  #
  # for(indiv in 1:n.ranker){
  #
  #   for(t in 1:n.time){
  #
  #     rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
  #
  #
  #     rankconstraint_t <- matrix(0,
  #                                nrow = n.item - 1,
  #                                ncol = n.item)
  #
  #     # note: ordering of rows is unimportant
  #     # as long as ordering agrees with the ordering of the mean vector
  #
  #     # so can begin by filling in first row
  #
  #     #MUST BE EDITED IF ALLOW FOR TIES
  #     for(rankind in 1:(length(rankvec_t)-1)){
  #
  #       rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
  #       rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1
  #
  #       # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
  #       # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1
  #
  #     }
  #
  #     rank_cons_arr[, , indiv, t] <- rankconstraint_t
  #
  #   }
  # }
  # # create array of rank constraint matrices


  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  boundconstraints <- matrix(NA,
                             nrow = 2*n.item,
                             ncol = n.item)

  # use kroenecker product
  # there is probably a more efficient way of doing this

  boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))


      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }



    print("Line 799.")

    # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )


      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")





        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }


    p_y <- ncol(Xmat.train) - 1 # subtracting 1. Outcome is a column of Xmat.train

    if(sparse){
      s_y <- rep(1 / p_y, p_y) # probability vector to be used during the growing process for DART feature weighting
      rho_y <- p_y # For DART

      if(alpha_split_prior){
        alpha_s_y <- p_y
      }else{
        alpha_s_y <- 1
      }
      alpha_scale_y <- p_y


      var_count_y <- rep(0, p_y)

      draw$alpha_s_y_store <- rep(NA, iter.max)
      draw$var_count_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
      draw$s_prob_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
    }

    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")


    if(nrow(X.test )==0){
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        #test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1),
                        tree.prior = dbarts:::cgm(power = tree_power, base =  tree_base,  split.probs = rep(1 / p_y, p_y)),
                        sigma=1 #check if this is the correct approach for setting the variance to 1
      )

    }else{
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
                        tree.prior = dbarts:::cgm(power = tree_power, base =  tree_base,  split.probs = rep(1 / p_y, p_y)),
                        sigma=1 #
      )

    }


    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    min_resp <- min(as.vector(Z.mat))
    max_resp <- max(as.vector(Z.mat))

    #sampler$setPredictor(x= Xmat.train$x, column = 1, forceUpdate = TRUE)
    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }
    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples
    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y <- rep(0, p_y)
      var_count_y[tempcounts$x] <- tempcounts$N
    }
    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    # mu <- mutemp

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train = ")
        print(Xmat.train)
        print("Z.mat = ")
        print(Z.mat)

        print("samplestemp$sigma = ")
        print(samplestemp$sigma)
        print("samplestemp$varcount = ")
        print(samplestemp$varcount)

        print("samplestemp$train[,1] = ")
        print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  print("Line 954")


  # df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    # temp_test_mat <- as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_mat <- data.frame( x = as.matrix(Xmat.test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(Xmat.test)



    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    temp_mu_test <- rep(NA,  nrow(Xmat.test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      testpredvec <- sampler$predict(temp_test_mat)

      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }

      colnames(temp_test_mat) <- colnames(Xmat.test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  iter <- 2
  breakcount <- 0

  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############



    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA



    # num_regions <- nrow(intersectmat)

    # print("Line 1169")


    for(z_iter_ind in 1:num_z_iters){

      # print("z_iter_ind = ")
      # print(z_iter_ind)

      for(indiv in 1:n.ranker){

        # print("indiv = ")
        # print(indiv)

        ########### calculate qkt   for t = 1 ########################################

        Biglist_list_item_intersectmats <- list()
        Biglist_intersectmats <- list()


        ######## Period 1 Intersection Matrix #########################

        # create vector of indices for ranker indiv in time period 1
        ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        # print("Begin Period 1 intersection matrices = ")
        # print(indiv)

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            treeexample1 <- sampler$getTrees(treeNums = i,
                                             chainNums = 1,
                                             sampleNums = 1)

            # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))


            # print("rebuilt_tree = ")
            # print(rebuilt_tree)

            #must use covariates for individual indiv at time period t

            # print("Xmat.train$x[obs_indices[1],, drop = FALSE] = ")
            # print(Xmat.train$x[obs_indices[1],, drop = FALSE])
            #
            #
            # print("Xmat.train$x[obs_indices[1],] = ")
            # print(Xmat.train$x[obs_indices[1],])
            #
            #
            # print("obs_indices[1] = ")
            # print(obs_indices[1])
            #
            #
            # print("Xmat.train = ")
            # print(Xmat.train)



            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )
            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train[obs_indices[1],-1, drop = FALSE]) )


          }

          intersectmat_tmin1 <- interNtreesB(list_inter_mats)


          intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat_tmin1)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat_tmin1[ktemp,1]
            templower <- intersectmat_tmin1[rowind,2]
            tempupper <- intersectmat_tmin1[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[1]] <- intersectmat_tmin1


        }else{ # itemcovars == TRUE


          list_item_intersectmats_tmin1 <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              treeexample1 <- sampler$getTrees(treeNums = i,
                                               chainNums = 1,
                                               sampleNums = 1)

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train[obs_one_ind,-1, drop = FALSE]) )


            } #end loop over trees

            intersectmat_tmin1 <- interNtreesB(list_inter_mats)

            intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat_tmin1)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat_tmin1[ktemp,1]
              templower <- intersectmat_tmin1[rowind,2]
              tempupper <- intersectmat_tmin1[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats_tmin1[[index_item]] <- intersectmat_tmin1


          } #end loop over items

          Biglist_list_item_intersectmats[[1]] <- list_item_intersectmats_tmin1

        } # end else itemcovars == TRUE


        ################ period 2 intersection matrix #################################################

        # create vector of indices for ranker indiv in time period 2
        ind_start <- (2 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (2 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            treeexample1 <- sampler$getTrees(treeNums = i,
                                             chainNums = 1,
                                             sampleNums = 1)

            # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

            #must use covariates for individual indiv at time period t

            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train[obs_indices[1],-1, drop = FALSE]) )

          }

          intersectmat <- interNtreesB(list_inter_mats)


          intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat[ktemp,1]
            templower <- intersectmat[rowind,2]
            tempupper <- intersectmat[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[2]] <- intersectmat


        }else{ # itemcovars == TRUE


          list_item_intersectmats <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              treeexample1 <- sampler$getTrees(treeNums = i,
                                               chainNums = 1,
                                               sampleNums = 1)

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train[obs_one_ind,-1, drop = FALSE]) )

            } #end loop over trees

            intersectmat <- interNtreesB(list_inter_mats)

            intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat[ktemp,1]
              templower <- intersectmat[rowind,2]
              tempupper <- intersectmat[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats[[index_item]] <- intersectmat


          } #end loop over items

          Biglist_list_item_intersectmats[[2]] <- list_item_intersectmats

        } # end else itemcovars == TRUE


        # print("End Period 1 intersection matrices = ")


        ##### t = 3 to T intersect matrices ######################

        # print("Begin loop for intersection matrices = ")

        for(t in 3:n.time){

          #### obtain intersection matrices for time period t ###############
          # print("t = ")
          # print(t)

          # create vector of indices for ranker indiv in time period 1
          ind_start <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          ind_end <- (t - 1)*n.ranker*n.item+n.item*indiv
          obs_indices <- ind_start:ind_end

          if(itemcovars == FALSE){


            list_inter_mats <- list()

            for(i in 1:n.trees){

              treeexample1 <- sampler$getTrees(treeNums = i,
                                               chainNums = 1,
                                               sampleNums = 1)

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train[obs_indices[1],-1, drop = FALSE]) )

            }

            intersectmat <- interNtreesB(list_inter_mats)

            Biglist_intersectmats[[t]] <- intersectmat


          }else{ # itemcovars == TRUE


            list_item_intersectmats <- list()

            for(index_item in 1:n.item){

              obs_one_ind <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

              list_inter_mats <- list()

              for(i in 1:n.trees){

                treeexample1 <- sampler$getTrees(treeNums = i,
                                                 chainNums = 1,
                                                 sampleNums = 1)

                # rebuilt_tree <- rebuildTree2(treeexample1)

                rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

                #must use covariates for individual indiv at time period t

                # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

                list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                         as.matrix(Xmat.train[obs_one_ind,-1, drop = FALSE]) )


              } #end loop over trees

              intersectmat <- interNtreesB(list_inter_mats)

              list_item_intersectmats[[index_item]] <- intersectmat


            } #end loop over items


            Biglist_list_item_intersectmats[[t]] <- list_item_intersectmats


          } # end else itemcovars == TRUE

        }


        # print("End loop for intersection matrices = ")


        ######## Begin loop over items ################################

        # print("Begin loop for over items = ")

        for(item_ind in 1:n.item){

          # print("item_ind = ")
          # print(item_ind)

          if(itemcovars == TRUE){
            list_item_intersectmats <- Biglist_list_item_intersectmats[[2]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[1]]


            intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            intersectmat <- Biglist_intersectmats[[2]]
            intersectmat_tmin1 <- Biglist_intersectmats[[1]]
          }

          num_regions <- nrow(intersectmat)
          num_regions_tmin1 <- nrow(intersectmat_tmin1)

          # ########### begin create intersectmat t = 1 ############
          #
          # # define intersections inside item loop
          # # to allow covariates can be item specific
          #
          # # create vector of indices for ranker indiv in time period 1
          #
          # # this part is not really necessary
          # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
          # obs_indices <- ind_start:ind_end
          #
          # # obs_indices[1] could jsut be replaced by [1] below\
          # # because the only variable is zlag, so the other covariates are not used
          #
          #
          # list_inter_mats <- list()
          #
          # for(i in 1:n.trees){
          #
          #   treeexample1 <- sampler$getTrees(treeNums = i,
          #                                    chainNums = 1,
          #                                    sampleNums = 1)
          #
          #   rebuilt_tree <- rebuildTree2(treeexample1, sampler)
          #
          #
          #   #must use covariates for individual indiv at time period t
          #
          #   list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )
          #   # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
          #
          #
          # }
          #
          # intersectmat <- interNtreesB(list_inter_mats)
          #
          # # print("Line 1146")
          #
          # intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))
          #
          # # print("Line 1150")
          #
          #
          # # calculate one dimensional integrals
          # for(rowind in 1:nrow(intersectmat)){
          #   # ktemp <- nkt_mat[rowind,k_index]
          #   # tempmean <- intersectmat[ktemp,1]
          #   templower <- intersectmat[rowind,2]
          #   tempupper <- intersectmat[rowind,3]
          #
          #   # ASSUMING PRIOR MEAN ALL ZEROS
          #
          #   # These are the q0 integrals
          #   intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
          #   # tempintegralval <- tempintegralval*onedim_int
          # }
          #
          # # intersectmat_tmin1 <- intersectmat
          #
          #
          #
          # ########### end create intersectmat t = 1 ############
          #





          #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

          # loop over items

          # Now loop over time periods

          # special case for t=1

          # probability matrix for sampling elements

          # let rows be period zero, and columns be period 1 (2?)

          # probmattemp <- matrix(0,
          #                       nrow = num_regions_tmin1,
          #                       ncol = num_regions)

          logprobmattemp <- matrix(0,
                                   nrow = num_regions_tmin1,
                                   ncol = num_regions)

          # loop over period 2 regions into which z_1 can fall


          tempbounds <- matrix(NA,
                               nrow = num_regions,
                               ncol = 2)

          # Trunc norm prob of next periods latent value conditional on region

          # Create intervals from interval t+1 latent values

          # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]
          #
          # # inds for j ranked below i in t+1
          #
          #
          #
          # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in t+1
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower <- -Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    belowrank_ind]
          # }
          #
          # # inds for j ranked above i in t+1
          #
          # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period t+1
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper <- Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #
          #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    aboverank_ind]
          # }


          temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                          n.item*(indiv - 1) +
                                          item_ind]

          temppaircomps <- pair.comp.ten[, , (1-1)*n.ranker + indiv]

          tempz <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                      n.item*(indiv - 1) +
                                      1:n.item]

          set1 = which( temppaircomps[item_ind, ] == 1)
          set0 = which( temppaircomps[item_ind, ] == 0)

          if(length(set1) > 0){
            temp_upper3 = min(tempz[set1])
          }else{
            temp_upper3 = Inf
          }

          if(length(set0) > 0){
            temp_lower3 = max(tempz[set0])
          }else{
            temp_lower3 = -Inf
          }

          # rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]
          #
          # # if(any(order(rankvec_t) !=
          # #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                           n.item*(indiv-1) +
          # #                           1:n.item])) ){
          # #
          # #   # print("order(rankvec_t) = ")
          # #   # print(order(rankvec_t))
          # #   #
          # #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #   #                         n.item*(indiv - 1) +
          # #   #                         1:n.item])  = ")
          # #
          # #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                                  n.item*(indiv - 1) +
          # #                                  1:n.item]) )
          # #
          # #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #   #                                n.item*(indiv - 1) +
          # #   #                                1:n.item] = ")
          # #
          # #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                            n.item*(indiv - 1) +
          # #                            1:n.item])
          # #
          # # }
          #
          # # inds for j ranked below i in t
          #
          # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in t
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower3 <- -Inf
          # }else{
          #   temp_lower3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     belowrank_ind]
          # }
          #
          # # inds for j ranked above i in t
          #
          # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period t
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper3 <- Inf
          # }else{
          #   temp_upper3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     aboverank_ind]
          # }

          temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
                                                   mean = intersectmat[1:num_regions, 1],
                                                   sd = 1)


          for(k_ind in 1:num_regions){




            # # obtain mean for truncated normal distribution
            # temp_mean <- intersectmat[k_ind, 1]
            #
            # # want trunc norm probability of latent variable value for item_ind
            # # in period t+1
            #
            #
            # # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            # #                               a=temp_lower,
            # #                               b=Inf,
            # #                               mean = temp_mean,
            # #                               sd = 1)
            #
            # tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp
            #
            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                                 mean = tempmeanfordens,
            #                                 sd = 1)
            #
            # # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            # #                          mean = temp_mean,
            # #                          sd = 1)
            #
            # temp_mean <- intersectmat[k_ind, 1]


            temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]

            # now second term


            temp_lower2 <- intersectmat[k_ind, 2]
            temp_upper2 <- intersectmat[k_ind, 3]




            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_lower3 = ")
            # print(temp_lower3)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)
            #
            # print("temp_upper3 = ")
            # print(temp_upper3)


            if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
              # intervals do not overlap, therefore assign probability zero
              # and skip to next iteration


              # print("k_ind = ")
              # print(k_ind)

              # print("ncol(temp_region_probs) = ")
              # print(ncol(temp_region_probs))

              # print("nrow(temp_region_probs) = ")
              # print(nrow(temp_region_probs))


              # these three lines are technically unnecessary
              # probmattemp[, k_ind] <- rep(0,num_regions_tmin1)
              logprobmattemp[, k_ind] <- rep(-Inf,num_regions_tmin1)
              tempbounds[k_ind, 1] <- NA
              tempbounds[k_ind, 2] <- NA

              next

            }


            temp_lower2 <- max(temp_lower2, temp_lower3)
            temp_upper2 <- min(temp_upper2, temp_upper3)

            if(temp_lower2 > temp_upper2){

              print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

              print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                       n.item*(indiv - 1) +
                                       1:n.item])

              print("item_ind = ")
              print(item_ind)

              # print("rankvec_t = ")
              # print(rankvec_t)

              stop("Line 1581 temp_lower2 > temp_upper2")
            }


            for(k0_ind in 1:num_regions_tmin1){

              #loop over all possible means
              temp_mean2 <- intersectmat_tmin1[k0_ind,1]

              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # probmattemp[k0_ind, k_ind] <- prob_t_region*
              #   temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob +
                log(intersectmat_tmin1[k0_ind,4])

              # if(probmattemp[k0_ind, k_ind] <0){
              #   print("probmattemp[k0_ind, k_ind] = ")
              #   print(probmattemp[k0_ind, k_ind])
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   print("temp_tnorm_prob = ")
              #   print(temp_tnorm_prob)
              #
              #   print("intersectmat[k0_ind,4] = ")
              #   print(intersectmat[k0_ind,4])
              #
              #   print("temp_upper2 = ")
              #   print(temp_upper2)
              #
              #   print("temp_lower2 = ")
              #   print(temp_lower2)
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #
              # }


            } # end loop over k0

            # save upper and lower bounds (mean saved in intersectmat)
            # or just obtain again later

            tempbounds[k_ind,1] <- temp_lower2
            tempbounds[k_ind,2] <- temp_upper2


          } # end loop over k1


          #sample a combination of k0 and k1
          # if necessary can use column sums to sample k1, then k0
          # however, this is probably unnecessary


          # print("Line 1621 before sample")

          # region_ind <- sample.int(num_regions_tmin1*num_regions,
          #                          size = 1,
          #                          replace = TRUE,
          #                          prob = as.vector(probmattemp))

          logprobstemp <- as.vector(logprobmattemp)
          max_ll <- max(logprobstemp)
          logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
          probstemp <- exp(logprobstemp - logsumexps)

          region_ind <- sample.int(num_regions_tmin1*num_regions,
                                   size = 1,
                                   replace = TRUE,
                                   prob = as.vector(probstemp))

          # print("Line 1629 after sample")

          # k0 region is sampled number modulo number of regions in period 1
          k0_region_ind <- ((region_ind -1) %% num_regions_tmin1 ) + 1
          # if(k0_region_ind ==0){
          #   k0_region_ind <- num_regions
          # }

          # k1 region is the ceiling of sampled number divided by number of regions in period 1
          # k1_region_ind <- ceiling(region_ind/num_regions)
          k1_region_ind <- (region_ind -1) %/% num_regions_tmin1 + 1


          # print("k1_region_ind = ")
          # print(k1_region_ind)

          temp_lower2 <- tempbounds[k1_region_ind,1]
          temp_upper2 <- tempbounds[k1_region_ind,2]

          # print("num_regions = ")
          # print(num_regions)
          #
          # print("region_ind = ")
          # print(region_ind)
          #
          # print("k0_region_ind = ")
          # print(k0_region_ind)

          temp_mean0 <- intersectmat_tmin1[k0_region_ind, 1]
          temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

          # print("temp_mean0 = ")
          # print(temp_mean0)
          #
          # print("temp_lower2 = ")
          # print(temp_lower2)
          #
          # print("temp_upper2 = ")
          # print(temp_upper2)

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = temp_lower2,
                                   b = temp_upper2,
                                   mean = temp_mean0,
                                   sd = 1)


          Z.mat[item_ind,  indiv ] <- zdraw_temp


          #### Begin Loop over time ###################

          # loop over time periods for general case 1 < t < T

          for(t in 2:(n.time - 1)){


            if(itemcovars == TRUE){
              list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
              list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[t]]


              intersectmat <- list_item_intersectmats[[index_item]]
              intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
            }else{
              intersectmat <- Biglist_intersectmats[[t+1]]
              intersectmat_tmin1 <- Biglist_intersectmats[[t]]
            }

            num_regions <- nrow(intersectmat)

            temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # or first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat_tmin1[, 3]) )[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

            # print("temp_mean2 = ")
            # print(temp_mean2)
            #
            # print("ktemp_tmin1 = ")
            # print(ktemp_tmin1)



            # Calculate the probabilities for each region in this time period
            # the regions being looped over are actually period t+1 regions

            # Same regions for all time periods if there are no time varying covariates

            # However, the weights are individual and time period specific

            # loop through regions


            # first column is the probabilities
            # second column is the lower bounds
            # third column is the upper bounds
            # temp_region_probs <- matrix(0,
            #                             nrow = nrow(intersectmat),
            #                             ncol = 3)

            temp_region_logprobs <- matrix(-Inf,
                                           nrow = nrow(intersectmat),
                                           ncol = 3)


            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]
            #
            # # inds for j ranked below i in t+1
            #
            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            # want trunc norm probability of latent variable value for item_ind
            # in period t+1

            temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]

            temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

            tempz <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                        n.item*(indiv - 1) +
                                        1:n.item]

            set1 = which( temppaircomps[item_ind, ] == 1)
            set0 = which( temppaircomps[item_ind, ] == 0)

            if(length(set1) > 0){
              temp_upper3 = min(tempz[set1])
            }else{
              temp_upper3 = Inf
            }

            if(length(set0) > 0){
              temp_lower3 = max(tempz[set0])
            }else{
              temp_lower3 = -Inf
            }


            # rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
            #
            # # if(any(order(rankvec_t) !=
            # #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                           n.item*(indiv - 1) +
            # #                           1:n.item]) )){
            # #
            # #   print("order(rankvec_t) = ")
            # #   print(order(rankvec_t))
            # #
            # #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                         n.item*(indiv - 1) +
            # #                         1:n.item])  = ")
            # #
            # #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                                  n.item*(indiv - 1) +
            # #                                  1:n.item]) )
            # #
            # #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                                n.item*(indiv - 1) +
            # #                                1:n.item] = ")
            # #
            # #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                            n.item*(indiv - 1) +
            # #                            1:n.item])
            # #
            # #
            # # }
            #
            #
            #
            #
            #
            # # inds for j ranked below i in t
            #
            # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower3 <- -Inf
            # }else{
            #   temp_lower3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                     n.item*(indiv - 1) +
            #                                     belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t
            #
            # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper3 <- Inf
            # }else{
            #   temp_upper3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                     n.item*(indiv - 1) +
            #                                     aboverank_ind]
            # }


            temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
                                                     mean = intersectmat[1:num_regions, 1],
                                                     sd = 1)

            for(k_ind in 1:num_regions){



              # # obtain mean for truncated normal distribution
              # temp_mean <- intersectmat[k_ind, 1]
              #
              #
              #
              # # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              # #                               a=temp_lower,
              # #                               b=Inf,
              # #                               mean = temp_mean,
              # #                               sd = 1)
              #
              # tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp
              #
              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                                 mean = tempmeanfordens,
              #                                 sd = 1)
              #
              # # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              # #                          mean = temp_mean,
              # #                          sd = 1)

              temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]

              # Probability of z_t in intersection of
              # region k_ind (for period t+1)
              # and region defined by period t latent variables for other individuals
              # and rank for period t


              # tildeC_ktminl corresponds to
              # period t+1 k_ind region intereval

              temp_lower2 <- intersectmat[k_ind, 2]
              temp_upper2 <- intersectmat[k_ind, 3]



              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_upper2 = ")
              # print(temp_upper2)
              #
              # print("temp_lower3 = ")
              # print(temp_lower3)
              #
              # print("temp_upper3 = ")
              # print(temp_upper3)


              if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
                # intervals do not overlap, therefore assign probability zero
                # and skip to next iteration

                # print("k_ind = ")
                # print(k_ind)

                # print("ncol(temp_region_probs) = ")
                # print(ncol(temp_region_probs))

                # print("nrow(temp_region_probs) = ")
                # print(nrow(temp_region_probs))

                # temp_region_probs[k_ind, 1] <- 0
                # temp_region_probs[k_ind, 2] <- NA
                # temp_region_probs[k_ind, 3] <- NA

                temp_region_logprobs[k_ind, 1] <- -Inf
                temp_region_logprobs[k_ind, 2] <- NA
                temp_region_logprobs[k_ind, 3] <- NA

                next
              }



              temp_lower2 <- max(temp_lower2, temp_lower3)
              temp_upper2 <- min(temp_upper2, temp_upper3)


              if(temp_lower2 > temp_upper2){

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")
                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])
                print("item_ind = ")
                print(item_ind)

                print("rankvec_t = ")
                print(rankvec_t)


                print("temp_lower2 = ")
                print(temp_lower2)

                print("temp_upper2 = ")
                print(temp_upper2)

                stop("Line 1917. temp_lower2 > temp_upper2")
              }



              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # print("temp_upper2 = ")
              # print(temp_upper2)
              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              #
              # print("prob_t_region = ")
              # print(prob_t_region)
              #
              # print("temp_tnorm_prob = ")
              # print(temp_tnorm_prob)

              # prob_t_region <- prob_t_region*temp_tnorm_prob
              # prob_t_region <- temp_tnorm_prob
              logprob_t_region <- temp_tnorm_logprob

              # save region probability

              # and save region bounds (or maybe more memory efficient to obtain the region again)

              # must multiply by other previously obtained probabilities

              # print("prob_t_region = ")
              # print(prob_t_region)

              # temp_region_probs[k_ind, 1] <- prob_t_region
              # temp_region_probs[k_ind, 2] <- temp_lower2
              # temp_region_probs[k_ind, 3] <- temp_upper2

              temp_region_logprobs[k_ind, 1] <- logprob_t_region
              temp_region_logprobs[k_ind, 2] <- temp_lower2
              temp_region_logprobs[k_ind, 3] <- temp_upper2

            }


            # sample a region using probabilities obtained above

            # print("Line 1903 before sample")
            logprobstemp <- as.vector(temp_region_logprobs[,1])
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int(num_regions, 1, replace = TRUE,
                                     prob = probstemp)

            # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])

            # print("Line 1914 after sample")

            temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            zdraw_temp <- rtruncnorm(n = 1,
                                     a=temp_region_logprobs[region_ind, 2],
                                     b=temp_region_logprobs[region_ind, 3],
                                     mean = temp_mean2_origscale,
                                     sd = 1)

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a=temp_region_probs[region_ind, 2],
            #                          b=temp_region_probs[region_ind, 3],
            #                          mean = temp_mean2_origscale,
            #                          sd = 1)

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a=temp_region_probs[region_ind, 2],
            #                          b=temp_region_probs[region_ind, 3],
            #                          mean = temp_mean2,
            #                          sd = 1)



            Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



          } # end loop over time periods

          # check for special cases for n.time - 1, n.time - 2, n.time - 3

          # special case for t = n.time


          if(itemcovars == TRUE){
            # list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[n.time]]


            # intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            # intersectmat <- Biglist_intersectmats[[t+1]]
            intersectmat_tmin1 <- Biglist_intersectmats[[n.time]]
          }

          num_regions <- nrow(intersectmat)

          temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             item_ind]


          # must find mean corresponding to z in period t-1
          # This will be used in and after the loop over regions.
          # can directly obtain from dbarts
          # or find region
          # and use already saved region mean values


          # must find last lower bound that temp_ztpmin1 is greater than
          # for first upper bound that temp_ztpmin1 is below
          ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat_tmin1[, 3])[1]
          # Then obtain the corresponding region mean value
          temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

          # now find interval


          # tildeC_ktminl corresponds to
          # period t+1 k_ind region intereval


          temppaircomps <- pair.comp.ten[, , (n.time-1)*n.ranker + indiv]

          tempz <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                      n.item*(indiv - 1) +
                                      1:n.item]

          set1 = which( temppaircomps[item_ind, ] == 1)
          set0 = which( temppaircomps[item_ind, ] == 0)

          if(length(set1) > 0){
            temp_upper3 = min(tempz[set1])
          }else{
            temp_upper3 = Inf
          }

          if(length(set0) > 0){
            temp_lower3 = max(tempz[set0])
          }else{
            temp_lower3 = -Inf
          }


          # rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]
          #
          # # inds for j ranked below i in T
          #
          # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in T
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower3 <- -Inf
          # }else{
          #   temp_lower3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     belowrank_ind]
          # }
          #
          # # inds for j ranked above i in T
          #
          # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period T
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper3 <- Inf
          # }else{
          #
          #   temp_upper3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
          #                                     n.item*(indiv - 1) +
          #                                     aboverank_ind]
          # }


          temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

          # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = temp_lower3,
                                   b = temp_upper3,
                                   mean = temp_mean2_origscale,
                                   sd = 1)

          # zdraw_temp <- rtruncnorm(n = 1,
          #                          a = temp_lower3,
          #                          b = temp_upper3,
          #                          mean = temp_mean2,
          #                          sd = 1)


          Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





        } # end loop over items



      } # end loop over individuals indiv in 1:n.ranker

    }




    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{
    temp_break <- 0
    for(j in 1:num_lags){
      # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)

      while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {

        if(seq_z_draws==1){
          stop("updates still not consistent with tree structure")
        }
        print("new z values not consistent with tree structure, must draw again")

        # If this error message occurs
        # Check the conditions in the dbart package for setPredictor == FALSE
        # And if this is hypothetically possible, even with draws from the smoothing distribution,
        # and if it is not a bug
        # then need to go back to beginning of this iteration of the Gibbs sampler
        # and sample Zmat again


        temp_break <- 1
        break
        # stop("new z values not consistent with tree structure, must draw again")


        # #perhaps this can be rewritten to just re-draw the relevant column?
        # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                           Z.mat = Z.mat,
        #                                           mu = mu,
        #                                           weight.vec = rep(1, n.ranker*n.time),
        #                                           n.ranker = n.ranker*n.time,
        #                                           n.item = n.item )
        #
        # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
        #
        # for(t in 1:num_lags){
        #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
        #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
        #
        #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
        #
        # }
        #
        # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j

      }

      if(temp_break==1){
        break
      }
    }

    # if need to draw z values again, go back to start of loop
    if(temp_break==1){
      if(breakcount == 10){
        Z.mat <- Z.matold
        Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

        for(t in 1:num_lags){
          init_Z_t0 <- rep(0, t*n.item*n.ranker)
          # init_Z_t0 <- rnorm(t*n.item*n.ranker)

          Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

        }

      }else{
        breakcount <- breakcount +1
        next
      }

    }

    breakcount <- 0
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)

    min_resp <- min(as.vector(Z.mat))
    max_resp <- max(as.vector(Z.mat))
    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }
    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples
    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y[tempcounts$x] <- tempcounts$N
    }
    # mutemp <- sampler$predict(df_for_dbart)
    # print("sigma = ")
    # print(samplestemp$sigma)

    # mu = mutemp

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]




      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("iteration number")
        print(iter)
        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)
        stop("mutemp[1]!= mutemp[n.item+1]")
      }


      #mu = mutemp[(1:n.item)*n.ranker]
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu = mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    if (sparse & (iter > floor(n.burnin * 0.5))) {
      # s_update_z <- update_s(var_count_z, p_z, alpha_s_z)
      # s_z <- s_update_z[[1]]

      s_update_y <- update_s(var_count_y, p_y, alpha_s_y)
      s_y <- s_update_y[[1]]

      if(alpha_split_prior){
        # alpha_s_z <- update_alpha(s_z, alpha_scale_z, alpha_a_z, alpha_b_z, p_z, s_update_z[[2]])
        alpha_s_y <- update_alpha(s_y, alpha_scale_y, alpha_a_y, alpha_b_y, p_y, s_update_y[[2]])
      }
    }


    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta



    #
    #     # if(is.null(initial.list)){
    #     # print("samplestemp$test[,1] = ")
    #     # print(samplestemp$test[,1])
    #
    #     # mupreds <- sampler$predict(df_for_dbart)
    #
    #     # Xmat.test[,1:num_lags] <-  Zlag.mat.test
    #
    #
    #     temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))
    #
    #     for(t  in 1:num_lags){
    #       if(noise_in_pred ==1){
    #         temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
    #       }else{
    #         temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
    #       }
    #
    #     }
    #
    #     # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #     #                                                                      (num_lags+1):ncol(Xmat.test)])
    #
    #     temp_test_mat <- data.frame(x = temp_test_mat)
    #     colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #     # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    #     temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    #     print("Line 5488")
    #
    #
    #     temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    #
    #
    #     # if(iter < 5){
    #     #   print("temp_test_mat = " )
    #     #   print(temp_test_mat)
    #     # }
    #
    #     for(t1 in 1:num_test_periods){
    #       #produce a prediction
    #
    #       # must use original column names to prevent an error in the predict function
    #       colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #       testpredvec <- sampler$predict(temp_test_mat)
    #
    #       #fill in temp_test_preds with noise
    #       if(noise_in_pred ==1){
    #         temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #       }else{
    #         temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
    #       }
    #
    #
    #       #update temp_test_mat
    #       #shift z columns to the right and fill in leftmost column
    #
    #       #need to rewrite this if want to allow for no observed covariates
    #
    #       # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )
    #
    #       if(t1 != num_test_periods){
    #
    #
    #         if(num_lags ==1){
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }else{
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
    #                                                  temp_test_mat[,1:(num_lags-1)] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }
    #       }
    #
    #       # colnames(temp_test_mat) <- colnames(Xmat.test)
    #
    #
    #       #fill in temp_mu_test without noise
    #       temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    #     }
    #
    #     #also update Zlag.mat.test ?
    #     #perhaps this is unnecessary here?
    #
    #     print("Line 5545")
    #
    #
    #     Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    #     # if(nrow(X.test) >0 ){
    #     for(t in 1:num_lags){
    #       # if(t==1){
    #       #   #repeating the last period values
    #       #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #       #
    #       #   #other option is to set all unobservable values to zero
    #       #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #       #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #       #
    #       #
    #       # }else{
    #
    #       if(num_test_periods > t ){
    #         #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #       }else{
    #         #nothing to fill in if num_test_periods <= t
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #       }
    #
    #
    #       # }
    #     }
    #     # }
    #
    #     # if(nrow(X.test)>0){
    #     #
    #     #
    #     #   for(j in 1:num_lags){
    #     #
    #     #     #perhaps this should be removed for when Z is updated properly below
    #     #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #     #
    #     #   }
    #     #
    #     # }
    #
    #
    #     draw$mu_test[,iter] <- temp_mu_test
    #     # draw$mu_test[,iter] <- samplestemp$test[,1]
    #
    #     if(keep_zmat==TRUE){
    #       draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    #     }
    #
    #     # draw$mu_test[,1] <- samplestemp$test[,1]
    #
    #     # }else{
    #     #   draw$mu_test[,1] <- initial.list$mu_test
    #     # }
    #


    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        if(noise_in_pred ==1){
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }

      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      temp_test_mat <- data.frame(x = temp_test_mat)
      colnames(temp_test_mat) <- colnames(Xmat.test)

      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )


      # if(iter < 5){
      #   print("temp_test_mat = " )
      #   print(temp_test_mat)
      # }

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }


        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){


          if(num_lags ==1){
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }else{
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      temp_test_mat[,1:(num_lags-1)] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }
        }

        colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }

      # if(nrow(X.test)>0){
      #
      #
      #   for(j in 1:num_lags){
      #
      #     #perhaps this should be removed for when Z is updated properly below
      #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
      #
      #   }
      #
      # }


      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    if(sparse){
      draw$alpha_s_y_store[iter] <- alpha_s_y
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_y_store[iter,] <- var_count_y
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_y_store[iter,] <- s_y
      # draw$s_prob_z_store[iter,] <- s_z
    }


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }


    iter <- iter+1
  }


  return(draw)
}







##////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with partial ranks and without Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and without covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @import collapse
#' @importFrom MCMCpack 'rdirichlet'
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @export
ARRObartNOCovars_fullcond_EmpN_partial <- function(pair.comp.ten,
                                                   # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                                   # X.test = matrix(NA, nrow =0, ncol = 0),
                                                   # tau2.alpha = 5^2,
                                                   # nu.alpha = 3,
                                                   # tau2.beta = 5^2,
                                                   # nu.beta = 3,
                                                   n.item = dim(pair.comp.ten)[1],
                                                   n.rankerbytime = dim(pair.comp.ten)[3],
                                                   n.ranker,
                                                   n.time,
                                                # p.cov = ncol(X.train),
                                                iter.max = 5000,
                                                para.expan = TRUE,
                                                print.opt = 100,
                                                initial.list = NULL,
                                                n.trees = 50L,
                                                n.burn = 0L,
                                                n.samples = 1L,
                                                n.thin = 1L,
                                                trans_prob = c(2.5, 2.5, 4) / 9, # Probabilities to grow, prune or change, respectively
                                                n.chains = 1,
                                                n.threads = 1L,#guessNumCores(),
                                                printEvery = 100L,
                                                printCutoffs = 0L,
                                                rngKind = "default",
                                                rngNormalKind = "default",
                                                rngSeed = NA_integer_,
                                                updateState = FALSE,
                                                num_lags = 1,
                                                diff_num_test_rankers = 0,
                                                keep_zmat = FALSE,
                                                noise_in_pred = 0,
                                                seq_z_draws = 1,
                                                N_hdr = 100,
                                                rho_hdr = 0.5,
                                                smoothing_method = "AR",
                                                num_horizon = 1,
                                                num_z_iters = 10,
                                                node_min_size = 5,
                                                k = 2,
                                                sigquant = .90,
                                                alpha = 0.95,
                                                beta = 2,
                                                nu = 3,
                                                lambda = 0.1,
                                                no_empty_proposals = FALSE,
                                                alpha_prior = FALSE,
                                                sigma_mu_prior = FALSE,
                                                splitting_rules = "discrete",
                                                loop_order = "time_in_item",
                                                max_bad_trees = 10,
                                                sparse = TRUE,
                                                alpha_a_y = 0.5,
                                                alpha_b_y = 1,
                                                alpha_split_prior = TRUE){


  if(!(loop_order %in% c("time_in_item", "item_in_time"))){
    stop("loop_order must be 'time_in_item' or 'item_in_time'.")
  }


  if(!(splitting_rules %in% c("discrete", "continuous"))){
    stop("splitting_rules must be 'discrete' or 'continuous'.")
  }

  ######### set up things for myBART implementation ####################

  # Extract control parameters
  # we only have to allow for empty nodes when updating Z (and therefore Zlag is updated and splits on Zlag are affected)
  # Therefore there is still a minimum node size criterion for the purpose of proposing new splits
  node_min_size = node_min_size

  # Storage containers
  store_size = iter.max # npost # code currently written to save all output, so no nburnin or npost
  tree_store = vector('list', store_size)
  sigma2_store = rep(NA, store_size)
  # y_hat_store = matrix(NA, ncol = length(y), nrow = store_size)
  # var_count = rep(0, ncol(x))
  # var_count_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # s_prob_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # tree_fits_store = matrix(0, ncol = n.trees, nrow = length(y))

  sigma2 <- 1 # keep sigma2 set to 1


  ########## beginning of original code ############################

  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  # length_mu_test <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  # ranks_mat <- matrix(NA,
  #                     ncol = n.ranker*n.time,
  #                     nrow = n.item )
  #
  #
  # #n.item by n.item
  #
  # for(t in 1:n.time){
  #
  #   for(indiv in 1:n.ranker){
  #     pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]
  #
  #     # 1 corresponding to "highest rank" . i.e. highest utility ite,
  #     # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1
  #
  #     # 1 corresponding to "lowest rank". i.e. lowest utility item
  #
  #     # up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
  #     up.order = -rowSums( pair.comp, na.rm = TRUE ) + n.item
  #
  #     ranks_mat[, (t-1)*n.ranker + indiv] <- up.order
  #
  #   }
  # }


  # # it might be more efficient to create and save all rank constraint matrices at this stage
  #
  #
  # rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))
  #
  # for(indiv in 1:n.ranker){
  #
  #   for(t in 1:n.time){
  #
  #     rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
  #
  #
  #     rankconstraint_t <- matrix(0,
  #                                nrow = n.item - 1,
  #                                ncol = n.item)
  #
  #     # note: ordering of rows is unimportant
  #     # as long as ordering agrees with the ordering of the mean vector
  #
  #     # so can begin by filling in first row
  #
  #     #MUST BE EDITED IF ALLOW FOR TIES
  #     for(rankind in 1:(length(rankvec_t)-1)){
  #
  #       rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
  #       rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1
  #
  #       # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
  #       # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1
  #
  #     }
  #
  #     rank_cons_arr[, , indiv, t] <- rankconstraint_t
  #
  #   }
  # }
  # # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  # boundconstraints <- matrix(NA,
  #                            nrow = 2*n.item,
  #                            ncol = n.item)
  #
  # # use kroenecker product
  # # there is probably a more efficient way of doing this
  #
  # boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      # pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))
      # ranks_mat[,j] <-
      #   Z.mat[,j]

      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
        (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))


      # tempsort <- sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE )
      #
      # Z.mat[ tempsort$ix , j] <-
      #   qnorm(  tempsort$x   /(n.item+1)) +
      #   rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues
      # # if separate noise for each item, then would need to preserve ranks

      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   qnorm(c(n.item : 1)/(n.item+1)) +
      #   rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues
      # # if separate noise for each item, then would need to preserve ranks


      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j]/5

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(n =  t*n.item*n.ranker, mean = 0, sd = 0.005) #maybe add some noise to avoid splitting issues?
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }

    ##### old dbarts initialization ###############

    # # print("Line 799.")
    #
    # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )
    #
    #
    # control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
    #                          keepTrees = TRUE,
    #                          n.trees = n.trees,
    #                          n.burn = n.burn,
    #                          n.samples = n.samples,
    #                          n.thin = n.thin,
    #                          n.chains = n.chains,
    #                          n.threads = n.threads,
    #                          printEvery = printEvery,
    #                          printCutoffs = printCutoffs,
    #                          rngKind = rngKind,
    #                          rngNormalKind = rngNormalKind,
    #                          rngSeed = rngSeed)
    #
    #
    # # print(colnames(Xmat.train))
    # # print(colnames(Xmat.test))
    #
    # # print("begin dbarts")
    #
    #
    # # if(nrow(X.test )==0){
    # sampler <- dbarts(y ~ .,
    #                   data = df_for_dbart,
    #                   #test = Xmat.test,
    #                   control = control,
    #                   resid.prior = fixed(1),
    #                   sigma=1 #check if this is the correct approach for setting the variance to 1
    # )
    #
    # # }else{
    # #   sampler <- dbarts(y ~ .,
    # #                     data = Xmat.train,
    # #                     test = Xmat.test,
    # #                     control = control,
    # #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    # #                     sigma=1 #
    # #   )
    # #
    # # }
    #
    # # print("error after dbarts")
    #
    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    #
    # #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # sampler$sampleTreesFromPrior()
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mupreds <- sampler$predict(Xmat.train)
    #
    # mu <- mutemp


    y_hat_store = matrix(NA, ncol = length(as.vector(Z.mat)), nrow = store_size)
    var_count = rep(0, ncol(Zlag.mat))
    var_count_store = matrix(0, ncol = ncol(Zlag.mat), nrow = store_size)
    s_prob_store = matrix(0, ncol = ncol(Zlag.mat), nrow = store_size)
    tree_fits_store = matrix(0, ncol = n.trees, nrow = length(as.vector(Z.mat)))
    s = rep(1/ncol(Zlag.mat), ncol(Zlag.mat))

    p <- ncol(Zlag.mat)
    rho <- p # For DART

    alpha_s <- 1 # p

    alpha_scale <- p

    ###### new myBART initialization ######################

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }
    }

    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }

    # maybe (max(as.vector(Z.mat))-min(as.vector(Z.mat)))
    # can be replaced by something else
    # sigma2_mu <- (max(as.vector(Z.mat))-min(as.vector(Z.mat)))/((2 * k * sqrt(n.trees))^2)
    sigma2_mu <- ((max(as.vector(Z.mat))-min(as.vector(Z.mat)))/(2 * k * sqrt(n.trees)))^2

    # sigma2_mu <- 1/n.trees

    # Create a list of trees for the initial stump
    curr_trees = create_stump(num_trees = n.trees,
                              y = as.vector(Z.mat),
                              X = Zlag.mat)
    # Initialise the new trees as current one
    new_trees = curr_trees

    # Initialise the predicted values to zero
    mutemp = get_predictions(curr_trees, Zlag.mat, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))



  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  # print("Line 954")


  df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    temp_test_mat <- data.frame(x = as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      # testpredvec <- sampler$predict(temp_test_mat)

      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)



      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker), ] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),] )))

      }

      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  if(any(is.na(Z.mat))){
    print("Z.mat = ")
    print(Z.mat)
    stop("NA values in initial Z.mat")

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration

  iter <- 2
  breakcount <- 0
  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    # Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############


    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }


    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }

      # tempsort <- sort(tempcol)
      #
      # tempdiffs <- tempsort[-1] - tempsort[-(length(tempsort))]

      # if( any( abs(tempdiffs) < 0.001 )   ){
      #
      #   print("tempsort =")
      #   print(tempsort)
      #   print("tempdiffs =")
      #   print(tempdiffs)
      #   print("j = ")
      #   print(j)
      #   print("tempcol =")
      #   print(tempcol)
      #   print("Z.mat =")
      #   print(Z.mat)
      #   print(" some differences in Z vector very small")
      # }

    }


    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA

    # create vector of indices for ranker indiv in time period 1

    # # this part is not really necessary
    # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
    # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
    # obs_indices <- ind_start:ind_end

    # obs_indices[1] could jsut be replaced by [1] below\
    # because the only variable is zlag, so the other covariates are not used


    list_inter_mats <- list()

    emptynodecount <- 0

    for(i in 1:n.trees){



      ####### new tree structures, so need new functions to rebuild trees, create intersections etc

      ### dbarts getTrees returns a matrix with columns:
      ### sample, tree, n, var. and value

      ### simplest, but not most efficient, thing to do is to convert the tree structure
      ### from myBart format to dbarts format.




      # treeexample1_db <- sampler$getTrees(treeNums = i,
      #                                     chainNums = 1,
      #                                     sampleNums = 1)


      # print("curr_trees[[i]]$tree_matrix = ")
      # print(curr_trees[[i]]$tree_matrix)

      temptree <- curr_trees[[i]]$tree_matrix

      # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
      #                                   treeNums = i,
      #                                   chainNums = 1,
      #                                   sampleNums = 1)

      emptynodecount <- emptynodecount + sum(temptree[, 'node_size'] == 0)

      treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

      temp_na_inds <- is.na(temptree[,'split_variable'])
      treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

      # temp_nainds <- is.na(temptree[,'split_variable'])
      # treeexample1[temp_nainds, ] <- cbind(1, i, temptree[, 'node_size'], -1, temptree[,'mu'] )
      # treeexample1[!temp_nainds, ] <- cbind(1, i, temptree[, c('node_size','mu', 'split_variable' )])
      #
      # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
      #   1,#rep(sampleNums, nrow(temptree)),
      #   i,#rep(treeNums, nrow(temptree)),
      #   temptree[, 'node_size'],
      #   # mybarttree[,'split_variable'],
      #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
      #          -1,
      #          temptree[,'split_variable']),
      #   fast_ifelse(is.na(temptree[,'split_variable']) ,
      #          temptree[,'mu'],
      #          temptree[,'split_value']))


      # print("treeexample1 = ")
      # print(treeexample1)

      # rebuilt_tree <- rebuildTree2(treeexample1)
      rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

      # print("rebuilt_tree = ")
      # print(rebuilt_tree)

      #must use covariates for individual indiv at time period t

      # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )

      # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
      list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree[,4] == -1 , 5:7, drop = FALSE]


      # print("list_inter_mats[[i]] = ")
      # print(list_inter_mats[[i]])
    }

    # print("line 1468")

    intersectmat <- interNtreesB(list_inter_mats)

    # print("Line 1146")

    intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))


    # print(" emptynodecount = ")
    # print(emptynodecount)

    if(nrow(intersectmat) > 350){

      print("nrow(intersectmat) > 350")
      print("intersectmat = ")
      print(intersectmat)


    }

    # print("Line 1150")

    # print("line 1478")

    # calculate one dimensional integrals
    for(rowind in 1:nrow(intersectmat)){
      # ktemp <- nkt_mat[rowind,k_index]
      # tempmean <- intersectmat[ktemp,1]
      templower <- intersectmat[rowind,2]
      tempupper <- intersectmat[rowind,3]

      # ASSUMING PRIOR MEAN ALL ZEROS

      # These are the q0 integrals
      intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
      # tempintegralval <- tempintegralval*onedim_int
    }

    intersectmat_tmin1 <- intersectmat



    num_regions <- nrow(intersectmat)

    # print("Line 1169")

    # print("nrow(intersectmat) = ")
    # print(nrow(intersectmat))

    if(loop_order == "time_in_item"){
      for(z_iter_ind in 1:num_z_iters){


        for(indiv in 1:n.ranker){

          # print("indiv = ")
          # print(indiv)
          ########### calculate qkt  ########################################

          ########### calculate qkt   for t = 1 ########################################


          ### calculate qkt integrals for time period t = 1  ################

          # These integrals are already calculated and saved as intersectmat[ktemp,4]

          for(item_ind in 1:n.item){


            #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

            # loop over items

            # Now loop over time periods

            # special case for t=1

            # probability matrix for sampling elements

            # let rows be period zero, and columns be period 1 (2?)

            # probmattemp <- matrix(0,
            #                       nrow = num_regions,
            #                       ncol = num_regions)

            logprobmattemp <- matrix(0,
                                     nrow = num_regions,
                                     ncol = num_regions)

            # loop over period 2 regions into which z_1 can fall


            tempbounds <- matrix(NA,
                                 nrow = num_regions,
                                 ncol = 2)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

            # inds for j ranked below i in t+1



            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]





            temppaircomps <- pair.comp.ten[, , (1-1)*n.ranker + indiv]

            tempz <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                        n.item*(indiv - 1) +
                                        1:n.item]

            set1 = which( temppaircomps[item_ind, ] == 1)
            set0 = which( temppaircomps[item_ind, ] == 0)

            if(length(set1) > 0){
              temp_upper3 = min(tempz[set1])
            }else{
              temp_upper3 = Inf
            }

            if(length(set0) > 0){
              temp_lower3 = max(tempz[set0])
            }else{
              temp_lower3 = -Inf
            }


            # rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]
            #
            # # if(any(order(rankvec_t) !=
            # #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                           n.item*(indiv-1) +
            # #                           1:n.item])) ){
            # #
            # #   # print("order(rankvec_t) = ")
            # #   # print(order(rankvec_t))
            # #   #
            # #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #   #                         n.item*(indiv - 1) +
            # #   #                         1:n.item])  = ")
            # #
            # #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                                  n.item*(indiv - 1) +
            # #                                  1:n.item]) )
            # #
            # #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #   #                                n.item*(indiv - 1) +
            # #   #                                1:n.item] = ")
            # #
            # #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                            n.item*(indiv - 1) +
            # #                            1:n.item])
            # #
            # # }
            #
            # # inds for j ranked below i in t
            #
            # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower3 <- -Inf
            # }else{
            #   temp_lower3 <- max(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         belowrank_ind])
            # }
            #
            # # inds for j ranked above i in t
            #
            # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper3 <- Inf
            # }else{
            #   temp_upper3 <- min(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         aboverank_ind])
            # }

            # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
            tempmeanfordens <- intersectmat[1:num_regions, 1]

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                    mean = tempmeanfordens,
            #                                    sd = 1)


            if(temp_lower3 >= temp_upper3){
              print(" temp_lower3 = ")
              print(temp_lower3)

              print(" temp_upper3 = ")
              print(temp_upper3)

              stop("Line 1844. temp_lower3 >= temp_upper3")
            }


            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                 mean = intersectmat[1:num_regions, 1],
            #                                 sd = 1)

            # find intervals that do not overlap

            bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

            logprobmattemp[, bad_regions] <- -Inf #rep(-Inf,num_regions)
            tempbounds[bad_regions, 1] <- NA
            tempbounds[bad_regions, 2] <- NA

            good_regions <- setdiff(1:num_regions, bad_regions)


            temp_tnorm_logprobvec <- rep(NA, num_regions)
            temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                   mean = tempmeanfordens[good_regions],
                                                                   sd = 1)


            # logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprobvec[k_ind] +
            #   log(intersectmat[1:num_regions,4])

            logprobmattemp[1:num_regions, good_regions] <- outer(log(intersectmat[1:num_regions,4]),
                                                                 temp_tnorm_logprobvec[good_regions],
                                                                 FUN = "+")


            tempbounds[good_regions,1] <- pmax(intersectmat[good_regions, 2], temp_lower3)
            tempbounds[good_regions,2] <- pmin(intersectmat[good_regions, 3], temp_upper3)

            if(any(tempbounds[good_regions,1] >= tempbounds[good_regions,2])){
              stop(" line 1868 bounds badly defined")
            }

            # CAN VECTORIZE THIS EVEN MORE

            # # for(k_ind in 1:num_regions){
            # for(k_ind in good_regions){
            #     # obtain mean for truncated normal distribution
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # want trunc norm probability of latent variable value for item_ind
            #   # in period t+1
            #
            #
            #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #   #                               a=temp_lower,
            #   #                               b=Inf,
            #   #                               mean = temp_mean,
            #   #                               sd = 1)
            #
            #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #   #                          mean = temp_mean,
            #   #                          sd = 1)
            #
            #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
            #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
            #
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # now second term
            #
            #   temp_lower2 <- intersectmat[k_ind, 2]
            #   temp_upper2 <- intersectmat[k_ind, 3]
            #
            #
            #   # print(" line 1697 ")
            #   #
            #   # print("temp_lower2 = ")
            #   # print(temp_lower2)
            #   #
            #   # print("temp_lower3 = ")
            #   # print(temp_lower3)
            #   #
            #   # print("temp_upper2 = ")
            #   # print(temp_upper2)
            #   #
            #   # print("temp_upper3 = ")
            #   # print(temp_upper3)
            #
            #
            #   # if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
            #   #   # if((temp_lower2 - temp_upper3) > -0.001 | (temp_lower3 - temp_upper2 > -0.001)){
            #   #   # intervals do not overlap, therefore assign probability zero
            #   #   # and skip to next iteration
            #   #
            #   #
            #   #   # print("k_ind = ")
            #   #   # print(k_ind)
            #   #
            #   #   # print("ncol(temp_region_probs) = ")
            #   #   # print(ncol(temp_region_probs))
            #   #
            #   #   # print("nrow(temp_region_probs) = ")
            #   #   # print(nrow(temp_region_probs))
            #   #
            #   #
            #   #   # these three lines are technically unnecessary
            #   #   # probmattemp[, k_ind] <- rep(0,num_regions)
            #   #   logprobmattemp[, k_ind] <- rep(-Inf,num_regions)
            #   #   tempbounds[k_ind, 1] <- NA
            #   #   tempbounds[k_ind, 2] <- NA
            #   #
            #   #   next
            #   #
            #   # }
            #
            #
            #   temp_lower2 <- max(temp_lower2, temp_lower3)
            #   temp_upper2 <- min(temp_upper2, temp_upper3)
            #
            #   if(temp_lower2 >= temp_upper2){
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                     n.item*(indiv - 1) +
            #                                     1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("Line 1763 temp_lower2 >= temp_upper2")
            #   }
            #
            #   # if(all( intersectmat[,4] == 0 ) |all( is.na(intersectmat[,4])  ) ){
            #   #
            #   #   print("(1-1)*n.item*n.ranker +
            #   #                            n.item*(indiv - 1) +
            #   #                            1:n.item] = ")
            #   #
            #   #   print((1-1)*n.item*n.ranker +
            #   #           n.item*(indiv - 1) +
            #   #           1:n.item)
            #   #
            #   #   print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                                   n.item*(indiv - 1) +
            #   #                                   1:n.item]")
            #   #
            #   #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                            n.item*(indiv - 1) +
            #   #                            1:n.item])
            #   #
            #   #   print("item_ind = ")
            #   #   print(item_ind)
            #   #
            #   #   print("rankvec_t = ")
            #   #   print(rankvec_t)
            #   #
            #   #   print("intersectmat = ")
            #   #   print(intersectmat)
            #   #
            #   #   print("k_ind = ")
            #   #   print(k_ind)
            #   #
            #   #   stop("all( intersectmat[,4] == 0 )")
            #   #
            #   # }
            #
            #   logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprob +
            #     log(intersectmat[1:num_regions,4])
            #
            #
            #   # for(k0_ind in 1:num_regions){
            #   #
            #   #   #loop over all possible means
            #   #   # temp_mean2 <- intersectmat[k0_ind,1]
            #   #
            #   #   # probability of being in intersection region
            #   #
            #   #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
            #   #
            #   #
            #   #   # probmattemp[k0_ind, k_ind] <- prob_t_region*
            #   #   #   temp_tnorm_prob *
            #   #   #   intersectmat[k0_ind,4]
            #   #
            #   #   # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob * intersectmat[k0_ind,4]
            #   #   logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob + log(intersectmat[k0_ind,4])
            #   #
            #   #   # if(probmattemp[k0_ind, k_ind] < 0){
            #   #   #   print("probmattemp[k0_ind, k_ind] = ")
            #   #   #   print(probmattemp[k0_ind, k_ind])
            #   #   #
            #   #   #   # print("prob_t_region = ")
            #   #   #   # print(prob_t_region)
            #   #   #
            #   #   #   print("temp_tnorm_prob = ")
            #   #   #   print(temp_tnorm_prob)
            #   #   #
            #   #   #   print("intersectmat[k0_ind,4] = ")
            #   #   #   print(intersectmat[k0_ind,4])
            #   #   #
            #   #   #   print("temp_upper2 = ")
            #   #   #   print(temp_upper2)
            #   #   #
            #   #   #   print("temp_lower2 = ")
            #   #   #   print(temp_lower2)
            #   #   #
            #   #   #   print("temp_mean2 = ")
            #   #   #   print(temp_mean2)
            #   #   #
            #   #   #
            #   #   # }
            #   #
            #   #
            #   # } # end loop over k0
            #
            #   # save upper and lower bounds (mean saved in intersectmat)
            #   # or just obtain again later
            #
            #   tempbounds[k_ind,1] <- temp_lower2
            #   tempbounds[k_ind,2] <- temp_upper2
            #
            #
            # } # end loop over k1


            #sample a combination of k0 and k1
            # if necessary can use column sums to sample k1, then k0
            # however, this is probably unnecessary


            # print("Line 1621 before sample")

            # if(all(probmattemp ==0)){
            if(all(logprobmattemp == -Inf)){

              print("iter = ")
              print(iter)

              print("tempbounds = ")
              print(tempbounds)

              print("intersectmat = ")
              print(intersectmat)



              stop("line 1880 all(probmattemp ==0)")
            }




            # region_ind <- sample.int((num_regions^2),
            #                          size = 1,
            #                          replace = TRUE,
            #                          prob = as.vector(probmattemp))


            logprobstemp <- as.vector(logprobmattemp)
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int((num_regions^2),
                                     size = 1,
                                     replace = TRUE,
                                     prob = probstemp)

            # print("Line 1629 after sample")

            # k0 region is sampled number modulo number of regions
            k0_region_ind <- (region_ind - 1) %% num_regions + 1
            # if(k0_region_ind ==0){
            #   k0_region_ind <- num_regions
            # }

            # k1 region is the ceiling of sampled number divided by number of regions
            # k1_region_ind <- ceiling(region_ind/num_regions)
            k1_region_ind <- (region_ind - 1) %/% num_regions + 1


            # print("k1_region_ind = ")
            # print(k1_region_ind)

            temp_lower2 <- tempbounds[k1_region_ind,1]
            temp_upper2 <- tempbounds[k1_region_ind,2]

            # print("num_regions = ")
            # print(num_regions)
            #
            # print("region_ind = ")
            # print(region_ind)
            #
            # print("k0_region_ind = ")
            # print(k0_region_ind)

            temp_mean0 <- intersectmat[k0_region_ind, 1]
            # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

            # print("temp_mean0 = ")
            # print(temp_mean0)
            #
            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)

            # if(temp_upper2 - temp_lower2 < 0.000001 ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("very small difference in limits")
            # }


            # if(temp_upper2 - temp_lower2 < 0.001 ){
            #   stop("line 1980.  Very small range")
            #
            # }

            # if(temp_lower2 + 0.00005  >  temp_upper2 - 0.00005 ){
            #   print("line 1985 Very small range")
            #
            # }

            tempbuffer <- (temp_upper2 - temp_lower2)/100

            if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
              upper_buffered <- temp_upper2 - tempbuffer
              lower_buffered <- temp_lower2 + tempbuffer

            }else{


              upper_buffered <- temp_upper2
              lower_buffered <- temp_lower2

              if(temp_upper2 != Inf){
                upper_buffered <- temp_upper2 - 0.00001
              }

              if(temp_lower2 != -Inf){
                lower_buffered <- temp_lower2 + 0.00001
              }

            }


            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean0,
                                     sd = 1)



            # if( (zdraw_temp - temp_lower2 < 0.00001 ) | (temp_upper2 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_mean0 = ")
            #   print(temp_mean0)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   print("line 1988. draw very close to limit")
            # }

            if(is.na(zdraw_temp)){
              print("line 1881")

              print("temp_lower2 = ")
              print(temp_lower2)

              print("temp_upper2 = ")
              print(temp_upper2)

              print("temp_mean0 = ")
              print(temp_mean0)


              stop("NA zdraw_temp")

            }


            Z.mat[item_ind,  indiv ] <- zdraw_temp


            # loop over time periods for general case 1 < t < T

            for(t in 2:(n.time - 1)){

              # print("z time t = ")
              # print(t)

              temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker +
                                                 n.item*(indiv - 1) +
                                                 item_ind]

              if(is.na(temp_ztpmin1)){

                print("line 1895")

                print("Z.mat = ")
                print(Z.mat)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("item_ind = ")
                print(item_ind)

                stop("NA temp_ztpmin1")
              }

              # must find mean corresponding to z in period t-1
              # This will be used in and after the loop over regions.
              # can directly obtain from dbarts
              # or find region
              # and use already saved region mean values


              # must find last lower bound that temp_ztpmin1 is greater than
              # or first upper bound that temp_ztpmin1 is below
              ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat[, 3]) )[1]
              # Then obtain the corresponding region mean value
              temp_mean2 <- intersectmat[ktemp_tmin1,1]


              if(is.na(temp_mean2)){
                print("line 1908")

                print("ktemp_tmin1 = ")
                print(ktemp_tmin1)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_ztpmin1 = ")
                print(temp_ztpmin1)

                stop("temp_mean2 NA")


              }



              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              # print("ktemp_tmin1 = ")
              # print(ktemp_tmin1)



              # Calculate the probabilities for each region in this time period
              # the regions being looped over are actually period t+1 regions

              # Same regions for all time periods if there are no time varying covariates

              # However, the weights are individual and time period specific

              # loop through regions


              # first column is the probabilities
              # second column is the lower bounds
              # third column is the upper bounds
              # temp_region_probs <- matrix(0,
              #                             nrow = nrow(intersectmat),
              #                             ncol = 3)


              temp_region_logprobs <- matrix(-Inf,
                                             nrow = nrow(intersectmat),
                                             ncol = 3)

              # Trunc norm prob of next periods latent value conditional on region

              # Create intervals from interval t+1 latent values

              # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

              # inds for j ranked below i in t+1

              # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
              #
              # #max of latent variables for j ranked below i in t+1
              # # Z.mat
              #
              # if(length(belowrank_ind) ==0){
              #   temp_lower <- -Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    belowrank_ind]
              # }
              #
              # # inds for j ranked above i in t+1
              #
              # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
              #
              # #min of latent variables for j ranked below i in period t+1
              #
              # if(length(aboverank_ind) ==0){
              #   temp_upper <- Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #
              #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    aboverank_ind]
              # }


              # want trunc norm probability of latent variable value for item_ind
              # in period t+1

              temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                              n.item*(indiv - 1) +
                                              item_ind]


              temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

              tempz <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                          n.item*(indiv - 1) +
                                          1:n.item]

              set1 = which( temppaircomps[item_ind, ] == 1)
              set0 = which( temppaircomps[item_ind, ] == 0)

              if(length(set1) > 0){
                temp_upper3 = min(tempz[set1])
              }else{
                temp_upper3 = Inf
              }

              if(length(set0) > 0){
                temp_lower3 = max(tempz[set0])
              }else{
                temp_lower3 = -Inf
              }


              # rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
              #
              #
              #
              # # if(any(order(rankvec_t) !=
              # #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              # #                           n.item*(indiv - 1) +
              # #                           1:n.item]) )){
              # #
              # #   print("order(rankvec_t) = ")
              # #   print(order(rankvec_t))
              # #
              # #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
              # #                         n.item*(indiv - 1) +
              # #                         1:n.item])  = ")
              # #
              # #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              # #                                  n.item*(indiv - 1) +
              # #                                  1:n.item]) )
              # #
              # #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              # #                                n.item*(indiv - 1) +
              # #                                1:n.item] = ")
              # #
              # #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              # #                            n.item*(indiv - 1) +
              # #                            1:n.item])
              # #
              # #
              # # }
              #
              #
              #
              #
              #
              # # inds for j ranked below i in t
              #
              # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
              #
              # #max of latent variables for j ranked below i in t
              # # Z.mat
              #
              # if(length(belowrank_ind) ==0){
              #   temp_lower3 <- -Inf
              # }else{
              #   temp_lower3 <- max(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                         n.item*(indiv - 1) +
              #                                         belowrank_ind])
              # }
              #
              # if(is.na(temp_lower3)){
              #   print("NA temp_lower3")
              #
              #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                   n.item*(indiv - 1) +
              #                                   belowrank_ind] = ")
              #
              #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                            n.item*(indiv - 1) +
              #                            belowrank_ind])
              #
              #   print(" t = ")
              #   print(t)
              #
              #   print(" n.item = ")
              #   print(n.item)
              #
              #   print(" n.ranker = ")
              #   print(n.ranker)
              #
              #   print(" indiv = ")
              #   print(indiv)
              #
              #   print(" belowrank_ind = ")
              #   print(belowrank_ind)
              #
              #   print(" Z.mat = ")
              #   print(Z.mat)
              #
              #   stop("NA temp_lower3")
              #
              # }
              #
              #
              #
              # # inds for j ranked above i in t
              #
              #
              # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
              #
              # #min of latent variables for j ranked below i in period t
              #
              # if(length(aboverank_ind) ==0){
              #   temp_upper3 <- Inf
              # }else{
              #   temp_upper3 <- min(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                         n.item*(indiv - 1) +
              #                                         aboverank_ind])
              # }
              #
              # if(temp_lower3 >= temp_upper3){
              #   print(" temp_lower3 = ")
              #   print(temp_lower3)
              #
              #   print(" temp_upper3 = ")
              #   print(temp_upper3)
              #
              #   stop("Line 2495. temp_lower3 >= temp_upper3")
              # }


              # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
              tempmeanfordens <- intersectmat[1:num_regions, 1]

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                    mean = tempmeanfordens,
              #                                    sd = 1)

              # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
              #                                          mean = tempmeanfordens,
              #                                          sd = 1)


              # find intervals that do not overlap

              bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

              temp_region_logprobs[bad_regions, 1] <- -Inf
              temp_region_logprobs[bad_regions, 2] <- NA
              temp_region_logprobs[bad_regions, 3] <- NA

              good_regions <- setdiff(1:num_regions, bad_regions)

              temp_tnorm_logprobvec <- rep(NA, num_regions)
              temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                     mean = tempmeanfordens[good_regions],
                                                                     sd = 1)


              temp_region_logprobs[good_regions, 1] <- temp_tnorm_logprobvec[good_regions]
              temp_region_logprobs[good_regions, 2] <- pmax(intersectmat[good_regions, 2], temp_lower3)
              temp_region_logprobs[good_regions, 3] <- pmin(intersectmat[good_regions, 3], temp_upper3)


              if(any(temp_region_logprobs[good_regions, 2] >= temp_region_logprobs[good_regions, 3])){
                print("good_regions = ")
                print(good_regions)

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                stop(" line 2525 bounds badly defined")
              }
              # CAN VECTORIZE THIS EVEN MORE


              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                 mean = intersectmat[1:num_regions, 1],
              #                                 sd = 1)

              # for(k_ind in 1:num_regions){
              # for(k_ind in good_regions){
              #   # obtain mean for truncated normal distribution
              #   # temp_mean <- intersectmat[k_ind, 1]
              #
              #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #   #                               a=temp_lower,
              #   #                               b=Inf,
              #   #                               mean = temp_mean,
              #   #                               sd = 1)
              #
              #
              #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #   #                          mean = temp_mean,
              #   #                          sd = 1)
              #
              #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
              #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
              #
              #   # Probability of z_t in intersection of
              #   # region k_ind (for period t+1)
              #   # and region defined by period t latent variables for other individuals
              #   # and rank for period t
              #
              #
              #   # tildeC_ktminl corresponds to
              #   # period t+1 k_ind region intereval
              #
              #   temp_lower2 <- intersectmat[k_ind, 2]
              #   temp_upper2 <- intersectmat[k_ind, 3]
              #
              #
              #
              #   # print(" line 2075 ")
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   #
              #   # print("temp_lower3 = ")
              #   # print(temp_lower3)
              #   #
              #   # print("temp_upper3 = ")
              #   # print(temp_upper3)
              #
              #
              #   # if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
              #   #   # if((temp_lower2 - temp_upper3 > -0.0001) | (temp_lower3 - temp_upper2 > -0.0001)){
              #   #   # intervals do not overlap, therefore assign probability zero
              #   #   # and skip to next iteration
              #   #
              #   #   # print("k_ind = ")
              #   #   # print(k_ind)
              #   #
              #   #   # print("ncol(temp_region_probs) = ")
              #   #   # print(ncol(temp_region_probs))
              #   #
              #   #   # print("nrow(temp_region_probs) = ")
              #   #   # print(nrow(temp_region_probs))
              #   #
              #   #   # temp_region_probs[k_ind, 1] <- 0
              #   #   # temp_region_probs[k_ind, 2] <- NA
              #   #   # temp_region_probs[k_ind, 3] <- NA
              #   #
              #   #   temp_region_logprobs[k_ind, 1] <- -Inf
              #   #   temp_region_logprobs[k_ind, 2] <- NA
              #   #   temp_region_logprobs[k_ind, 3] <- NA
              #   #
              #   #
              #   #   next
              #   # }
              #
              #
              #
              #   temp_lower2 <- max(temp_lower2, temp_lower3)
              #   temp_upper2 <- min(temp_upper2, temp_upper3)
              #
              #
              #   if(temp_lower2 >= temp_upper2){
              #
              #     print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                   n.item*(indiv - 1) +
              #                                   1:n.item]")
              #     print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                              n.item*(indiv - 1) +
              #                              1:n.item])
              #     print("item_ind = ")
              #     print(item_ind)
              #
              #     print("t = ")
              #     print(t)
              #
              #     print("indiv = ")
              #     print(indiv)
              #
              #
              #     print("rankvec_t = ")
              #     print(rankvec_t)
              #
              #
              #     print("temp_lower2 = ")
              #     print(temp_lower2)
              #
              #     print("temp_upper2 = ")
              #     print(temp_upper2)
              #
              #     print("temp_lower3 = ")
              #     print(temp_lower3)
              #
              #     print("temp_upper3 = ")
              #     print(temp_upper3)
              #
              #
              #
              #     print("intersectmat[k_ind, 2] = ")
              #     print(intersectmat[k_ind, 2])
              #
              #     print("intersectmat[k_ind, 3] = ")
              #     print(intersectmat[k_ind, 3])
              #
              #     print("k_ind = ")
              #     print(k_ind)
              #
              #
              #
              #     stop("Line 1917. temp_lower2 >= temp_upper2")
              #   }
              #
              #
              #
              #   # probability of being in intersection region
              #
              #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
              #
              #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_mean2 = ")
              #   # print(temp_mean2)
              #   #
              #   #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #   #
              #   # print("temp_tnorm_prob = ")
              #   # print(temp_tnorm_prob)
              #
              #   # prob_t_region <- prob_t_region*temp_tnorm_prob
              #   # prob_t_region <- temp_tnorm_prob
              #   logprob_t_region <- temp_tnorm_logprob
              #
              #   # if(temp_tnorm_prob ==0){
              #   if(temp_tnorm_logprob == -Inf){
              #     print("temp_tnorm_prob = ")
              #     print(temp_tnorm_prob)
              #
              #     print("temp_tnorm_probvec =")
              #     print(temp_tnorm_probvec)
              #
              #     print("tempmeanfordens =")
              #     print(tempmeanfordens)
              #
              #     print("temp_ztp1 =")
              #     print(temp_ztp1)
              #
              #   }
              #
              #   # save region probability
              #
              #   # and save region bounds (or maybe more memory efficient to obtain the region again)
              #
              #   # must multiply by other previously obtained probabilities
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   # temp_region_probs[k_ind, 1] <- prob_t_region
              #   # temp_region_probs[k_ind, 2] <- temp_lower2
              #   # temp_region_probs[k_ind, 3] <- temp_upper2
              #
              #   temp_region_logprobs[k_ind, 1] <- logprob_t_region
              #   temp_region_logprobs[k_ind, 2] <- temp_lower2
              #   temp_region_logprobs[k_ind, 3] <- temp_upper2
              #
              # }


              # sample a region using probabilities obtained above

              # print("Line 1903 before sample")


              # if(sum(temp_region_probs[,1] > 0) ==0){
              if(sum(temp_region_logprobs[,1] > -Inf) ==0){

                print("temp_tnorm_probvec =")
                print(temp_tnorm_probvec)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_region_probs = ")
                print(temp_region_probs)

                print("item_ind = ")
                print(item_ind)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("rankvec_t = ")
                print(rankvec_t)

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])

                stop(" Line 2590 sum(temp_region_probs[,1] >0) == 0")
              }



              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])

              # logprobstemp <- as.vector(temp_region_logprobs[,1])
              # max_ll <- max(logprobstemp)
              # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
              # probstemp <- exp(logprobstemp - logsumexps)
              #
              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = probstemp)

              if(length(good_regions)==1){
                region_ind <- good_regions[1]
              }else{
                logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
                max_ll <- max(logprobstemp)
                logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
                probstemp <- exp(logprobstemp - logsumexps)

                region_ind <- sample(x = (1:num_regions)[good_regions], size = 1, replace = TRUE, prob = probstemp)
              }


              # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

              # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
              #
              # print("line 2102 temp_mean2_debug from predict = ")
              # print(temp_mean2_debug)
              #
              # print("line 2105 temp_mean2_origscale = ")
              # print(temp_mean2_origscale)
              #
              # print("line 2108 temp_mean2 = ")
              # print(temp_mean2)


              # if(temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2] < 0.000001 ){
              #
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #
              #
              #   stop("very small difference in limits")
              # }

              # if(temp_region_probs[region_ind, 3] -temp_region_probs[region_ind, 2] < 0.001 ){
              #   stop("line 2456. Very small range")
              #
              # }

              # if(temp_region_probs[region_ind, 2] + 0.00005  >  temp_region_probs[region_ind, 3] - 0.00005 ){
              #
              #   print("iter  = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   stop("line 2467 Very small range")
              #
              # }


              # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
              #
              # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
              #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
              #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
              #
              # }else{
              #   upper_buffered <- temp_region_probs[region_ind, 3]
              #   lower_buffered <- temp_region_probs[region_ind, 2]
              #
              # }

              tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/100

              if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
                upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
                lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer

              }else{
                upper_buffered <- temp_region_logprobs[region_ind, 3]
                lower_buffered <- temp_region_logprobs[region_ind, 2]


                if(temp_region_logprobs[region_ind, 3] != Inf){
                  upper_buffered <- temp_region_logprobs[region_ind, 3] - 0.00001
                }

                if(temp_region_logprobs[region_ind, 2] != -Inf){
                  lower_buffered <- temp_region_logprobs[region_ind, 2] + 0.00001
                }

              }


              if(abs( temp_mean2/ (upper_buffered - lower_buffered ) ) > 10^15){
                # this is a quick fix for when the bounds are close or very far from the mean
                # this does not really address any potential underlying issue
                zdraw_temp <- (lower_buffered + upper_buffered)/2
              }else{
                zdraw_temp <- rtruncnorm(n = 1,
                                         a=lower_buffered,
                                         b=upper_buffered,
                                         mean = temp_mean2, #temp_mean2_origscale,
                                         sd = 1)
              }


              if(is.na(zdraw_temp)){
                print(" line 2883")

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                print("zdraw_temp = ")
                print(zdraw_temp)


                stop("NA zdraw_temp")
              }


              # if( (zdraw_temp - temp_region_probs[region_ind, 2] < 0.00001 ) | (temp_region_probs[region_ind, 3] - zdraw_temp  < 0.00001 ) ){
              #
              #   print("iter = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #   print("zdraw_temp = ")
              #   print(zdraw_temp)
              #
              #   stop("line 2470 draw very close to limit")
              # }



              # print("Line 1914 after sample")

              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=temp_region_probs[region_ind, 2],
              #                          b=temp_region_probs[region_ind, 3],
              #                          mean = temp_mean2,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs= ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                stop("NA zdraw_temp")
              }

              Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



            } # end loop over time periods

            # check for special cases for n.time - 1, n.time - 2, n.time - 3

            # special case for t = n.time


            temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # for first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat[, 3])[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat[ktemp_tmin1,1]

            # now find interval


            # tildeC_ktminl corresponds to
            # period t+1 k_ind region intereval

            temppaircomps <- pair.comp.ten[, , (n.time-1)*n.ranker + indiv]

            tempz <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                        n.item*(indiv - 1) +
                                        1:n.item]

            set1 = which( temppaircomps[item_ind, ] == 1)
            set0 = which( temppaircomps[item_ind, ] == 0)

            if(length(set1) > 0){
              temp_upper3 = min(tempz[set1])
            }else{
              temp_upper3 = Inf
            }

            if(length(set0) > 0){
              temp_lower3 = max(tempz[set0])
            }else{
              temp_lower3 = -Inf
            }


            # rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]
            #
            # # inds for j ranked below i in T
            #
            # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in T
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower3 <- -Inf
            # }else{
            #   temp_lower3 <- max(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         belowrank_ind])
            # }
            #
            # # inds for j ranked above i in T
            #
            # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period T
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper3 <- Inf
            # }else{
            #   temp_upper3 <- min(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         aboverank_ind])
            # }


            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
            #
            # print("line 2202 temp_mean2_debug from predict = ")
            # print(temp_mean2_debug)
            #
            # print("line 2205 temp_mean2_origscale = ")
            # print(temp_mean2_origscale)
            #
            # print("line 2208 temp_mean2 = ")
            # print(temp_mean2)

            # if(temp_upper3 -temp_lower3 < 0.000001 ){
            #
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   stop("very small difference in limits")
            # }


            # if(temp_upper3 - temp_lower3 < 0.001 ){
            #   stop("line 2613.  Very small range")
            #
            # }

            # if(temp_lower3 + 0.00005  >  temp_upper3 - 0.00005 ){
            #   print("line 2623 Very small range")
            #
            # }

            tempbuffer <- (temp_upper3 - temp_lower3)/100

            if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
              upper_buffered <- temp_upper3 - tempbuffer
              lower_buffered <- temp_lower3 + tempbuffer

            }else{
              upper_buffered <- temp_upper3
              lower_buffered <- temp_lower3

              # if(temp_upper3 != Inf){
              #   upper_buffered <- temp_upper3 - 0.00001
              # }
              #
              # if(temp_upper3 != -Inf){
              #   lower_buffered <- temp_lower3 + 0.00001
              # }
            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean2, #temp_mean2_origscale,
                                     sd = 1)

            # if( (zdraw_temp - temp_lower3 < 0.00001 ) | (temp_upper3 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("temp_lower3 = ")
            #   print(temp_lower3)
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   stop("line 2612 draw very close to limit")
            # }

            # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a = temp_lower3,
            #                          b = temp_upper3,
            #                          mean = temp_mean2,
            #                          sd = 1)

            if(is.na(zdraw_temp)){
              print(" line 2367")
              print("temp_lower3] = ")
              print(temp_lower3)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_mean2 = ")
              print(temp_mean2)

              stop("NA zdraw_temp")
            }

            Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





          } # end loop over items



        } # end loop over individuals indiv in 1:n.ranker

      }
    }else{ # loop over items and rankers within each time period
      for(z_iter_ind in 1:num_z_iters){


        for(indiv in 1:n.ranker){

          # print("indiv = ")
          # print(indiv)
          ########### calculate qkt  ########################################

          ########### calculate qkt   for t = 1 ########################################


          ### calculate qkt integrals for time period t = 1  ################

          # These integrals are already calculated and saved as intersectmat[ktemp,4]

          for(item_ind in 1:n.item){


            #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

            # loop over items

            # Now loop over time periods

            # special case for t=1

            # probability matrix for sampling elements

            # let rows be period zero, and columns be period 1 (2?)

            # probmattemp <- matrix(0,
            #                       nrow = num_regions,
            #                       ncol = num_regions)

            logprobmattemp <- matrix(0,
                                     nrow = num_regions,
                                     ncol = num_regions)

            # loop over period 2 regions into which z_1 can fall


            tempbounds <- matrix(NA,
                                 nrow = num_regions,
                                 ncol = 2)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

            # inds for j ranked below i in t+1



            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]




            temppaircomps <- pair.comp.ten[, , (1-1)*n.ranker + indiv]

            tempz <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                        n.item*(indiv - 1) +
                                        1:n.item]

            set1 = which( temppaircomps[item_ind, ] == 1)
            set0 = which( temppaircomps[item_ind, ] == 0)

            if(length(set1) > 0){
              temp_upper3 = min(tempz[set1])
            }else{
              temp_upper3 = Inf
            }

            if(length(set0) > 0){
              temp_lower3 = max(tempz[set0])
            }else{
              temp_lower3 = -Inf
            }


            # rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]
            #
            # # if(any(order(rankvec_t) !=
            # #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                           n.item*(indiv-1) +
            # #                           1:n.item])) ){
            # #
            # #   # print("order(rankvec_t) = ")
            # #   # print(order(rankvec_t))
            # #   #
            # #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #   #                         n.item*(indiv - 1) +
            # #   #                         1:n.item])  = ")
            # #
            # #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                                  n.item*(indiv - 1) +
            # #                                  1:n.item]) )
            # #
            # #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #   #                                n.item*(indiv - 1) +
            # #   #                                1:n.item] = ")
            # #
            # #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                            n.item*(indiv - 1) +
            # #                            1:n.item])
            # #
            # # }
            #
            # # inds for j ranked below i in t
            #
            # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower3 <- -Inf
            # }else{
            #   temp_lower3 <- max(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         belowrank_ind])
            # }
            #
            # # inds for j ranked above i in t
            #
            # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper3 <- Inf
            # }else{
            #   temp_upper3 <- min(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         aboverank_ind])
            # }

            # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
            tempmeanfordens <- intersectmat[1:num_regions, 1]

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                    mean = tempmeanfordens,
            #                                    sd = 1)

            # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
            #                                          mean = tempmeanfordens,
            #                                          sd = 1)

            if(temp_lower3 >= temp_upper3){
              print(" temp_lower3 = ")
              print(temp_lower3)

              print(" temp_upper3 = ")
              print(temp_upper3)

              stop("Line 3328. temp_lower3 >= temp_upper3")
            }

            bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

            logprobmattemp[, bad_regions] <- -Inf #rep(-Inf,num_regions)
            tempbounds[bad_regions, 1] <- NA
            tempbounds[bad_regions, 2] <- NA

            good_regions <- setdiff(1:num_regions, bad_regions)


            temp_tnorm_logprobvec <- rep(NA, num_regions)
            temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                   mean = tempmeanfordens[good_regions],
                                                                   sd = 1)


            # logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprobvec[k_ind] +
            #   log(intersectmat[1:num_regions,4])

            logprobmattemp[1:num_regions, good_regions] <- outer(log(intersectmat[1:num_regions,4]),
                                                                 temp_tnorm_logprobvec[good_regions],
                                                                 FUN = "+")


            tempbounds[good_regions,1] <- pmax(intersectmat[good_regions, 2], temp_lower3)
            tempbounds[good_regions,2] <- pmin(intersectmat[good_regions, 3], temp_upper3)

            if(any(tempbounds[good_regions,1] >= tempbounds[good_regions,2])){
              print("intersectmat = ")
              print(intersectmat)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_lower3 = ")
              print(temp_lower3)

              print("good_regions = ")
              print(good_regions)

              print("tempbounds = ")
              print(tempbounds)
              stop(" line 3305 bounds badly defined")
            }

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                 mean = intersectmat[1:num_regions, 1],
            #                                 sd = 1)

            # for(k_ind in 1:num_regions){
            #   # obtain mean for truncated normal distribution
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # want trunc norm probability of latent variable value for item_ind
            #   # in period t+1
            #
            #
            #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #   #                               a=temp_lower,
            #   #                               b=Inf,
            #   #                               mean = temp_mean,
            #   #                               sd = 1)
            #
            #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #   #                          mean = temp_mean,
            #   #                          sd = 1)
            #
            #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
            #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
            #
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #
            #
            #   # now second term
            #
            #
            #   temp_lower2 <- intersectmat[k_ind, 2]
            #   temp_upper2 <- intersectmat[k_ind, 3]
            #
            #
            #   # print(" line 1697 ")
            #   #
            #   # print("temp_lower2 = ")
            #   # print(temp_lower2)
            #   #
            #   # print("temp_lower3 = ")
            #   # print(temp_lower3)
            #   #
            #   # print("temp_upper2 = ")
            #   # print(temp_upper2)
            #   #
            #   # print("temp_upper3 = ")
            #   # print(temp_upper3)
            #
            #
            #   if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
            #     # if((temp_lower2 - temp_upper3) > -0.001 | (temp_lower3 - temp_upper2 > -0.001)){
            #     # intervals do not overlap, therefore assign probability zero
            #     # and skip to next iteration
            #
            #
            #     # print("k_ind = ")
            #     # print(k_ind)
            #
            #     # print("ncol(temp_region_probs) = ")
            #     # print(ncol(temp_region_probs))
            #
            #     # print("nrow(temp_region_probs) = ")
            #     # print(nrow(temp_region_probs))
            #
            #
            #     # these three lines are technically unnecessary
            #     # probmattemp[, k_ind] <- rep(0,num_regions)
            #     logprobmattemp[, k_ind] <- rep(-Inf,num_regions)
            #     tempbounds[k_ind, 1] <- NA
            #     tempbounds[k_ind, 2] <- NA
            #
            #     next
            #
            #   }
            #
            #
            #   temp_lower2 <- max(temp_lower2, temp_lower3)
            #   temp_upper2 <- min(temp_upper2, temp_upper3)
            #
            #   if(temp_lower2 >= temp_upper2){
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                   n.item*(indiv - 1) +
            #                                   1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("Line 1763 temp_lower2 >= temp_upper2")
            #   }
            #
            #   if(all( intersectmat[,4] == 0 ) |all( is.na(intersectmat[,4])  ) ){
            #
            #     print("(1-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item] = ")
            #
            #     print((1-1)*n.item*n.ranker +
            #             n.item*(indiv - 1) +
            #             1:n.item)
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                   n.item*(indiv - 1) +
            #                                   1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("all( intersectmat[,4] == 0 )")
            #
            #   }
            #
            #
            #   for(k0_ind in 1:num_regions){
            #
            #     #loop over all possible means
            #     temp_mean2 <- intersectmat[k0_ind,1]
            #
            #     # probability of being in intersection region
            #
            #     # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
            #
            #
            #     # probmattemp[k0_ind, k_ind] <- prob_t_region*
            #     #   temp_tnorm_prob *
            #     #   intersectmat[k0_ind,4]
            #
            #     # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob * intersectmat[k0_ind,4]
            #     logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob + log(intersectmat[k0_ind,4])
            #
            #     # if(probmattemp[k0_ind, k_ind] < 0){
            #     #   print("probmattemp[k0_ind, k_ind] = ")
            #     #   print(probmattemp[k0_ind, k_ind])
            #     #
            #     #   # print("prob_t_region = ")
            #     #   # print(prob_t_region)
            #     #
            #     #   print("temp_tnorm_prob = ")
            #     #   print(temp_tnorm_prob)
            #     #
            #     #   print("intersectmat[k0_ind,4] = ")
            #     #   print(intersectmat[k0_ind,4])
            #     #
            #     #   print("temp_upper2 = ")
            #     #   print(temp_upper2)
            #     #
            #     #   print("temp_lower2 = ")
            #     #   print(temp_lower2)
            #     #
            #     #   print("temp_mean2 = ")
            #     #   print(temp_mean2)
            #     #
            #     #
            #     # }
            #
            #
            #   } # end loop over k0
            #
            #   # save upper and lower bounds (mean saved in intersectmat)
            #   # or just obtain again later
            #
            #   tempbounds[k_ind,1] <- temp_lower2
            #   tempbounds[k_ind,2] <- temp_upper2
            #
            #
            # } # end loop over k1


            #sample a combination of k0 and k1
            # if necessary can use column sums to sample k1, then k0
            # however, this is probably unnecessary


            # print("Line 1621 before sample")

            # if(all(probmattemp ==0)){
            if(all(logprobmattemp == -Inf)){

              print("iter = ")
              print(iter)

              print("tempbounds = ")
              print(tempbounds)

              print("intersectmat = ")
              print(intersectmat)



              stop("line 1880 all(probmattemp ==0)")
            }




            # region_ind <- sample.int((num_regions^2),
            #                          size = 1,
            #                          replace = TRUE,
            #                          prob = as.vector(probmattemp))


            logprobstemp <- as.vector(logprobmattemp)
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int((num_regions^2),
                                     size = 1,
                                     replace = TRUE,
                                     prob = probstemp)



            # logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
            # max_ll <- max(logprobstemp)
            # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            # probstemp <- exp(logprobstemp - logsumexps)
            # region_ind <- sample((1:num_regions)[good_regions], 1, replace = TRUE, prob = probstemp)


            # print("Line 1629 after sample")

            # k0 region is sampled number modulo number of regions
            k0_region_ind <- (region_ind - 1) %% num_regions + 1
            # if(k0_region_ind ==0){
            #   k0_region_ind <- num_regions
            # }

            # k1 region is the ceiling of sampled number divided by number of regions
            # k1_region_ind <- ceiling(region_ind/num_regions)
            k1_region_ind <- (region_ind - 1) %/% num_regions + 1


            # print("k1_region_ind = ")
            # print(k1_region_ind)

            temp_lower2 <- tempbounds[k1_region_ind,1]
            temp_upper2 <- tempbounds[k1_region_ind,2]

            # print("num_regions = ")
            # print(num_regions)
            #
            # print("region_ind = ")
            # print(region_ind)
            #
            # print("k0_region_ind = ")
            # print(k0_region_ind)

            temp_mean0 <- intersectmat[k0_region_ind, 1]
            # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

            # print("temp_mean0 = ")
            # print(temp_mean0)
            #
            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)

            # if(temp_upper2 - temp_lower2 < 0.000001 ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("very small difference in limits")
            # }


            # if(temp_upper2 - temp_lower2 < 0.001 ){
            #   stop("line 1980.  Very small range")
            #
            # }

            # if(temp_lower2 + 0.00005  >  temp_upper2 - 0.00005 ){
            #   print("line 1985 Very small range")
            #
            # }

            tempbuffer <- (temp_upper2 - temp_lower2)/100

            if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
              upper_buffered <- temp_upper2 - tempbuffer
              lower_buffered <- temp_lower2 + tempbuffer

            }else{
              upper_buffered <- temp_upper2
              lower_buffered <- temp_lower2

              if(temp_upper2 != Inf){
                upper_buffered <- temp_upper2 - 0.00001
              }

              if(temp_lower2 != -Inf){
                lower_buffered <- temp_lower2 + 0.00001
              }

            }


            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean0,
                                     sd = 1)



            # if( (zdraw_temp - temp_lower2 < 0.00001 ) | (temp_upper2 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_mean0 = ")
            #   print(temp_mean0)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   print("line 1988. draw very close to limit")
            # }

            if(is.na(zdraw_temp)){
              print("line 1881")

              print("temp_lower2 = ")
              print(temp_lower2)

              print("temp_upper2 = ")
              print(temp_upper2)

              print("temp_mean0 = ")
              print(temp_mean0)


              stop("NA zdraw_temp")

            }


            Z.mat[item_ind,  indiv ] <- zdraw_temp

          } # end loop over items

        } # end loop over individuals indiv in 1:n.ranker



        # loop over time periods for general case 1 < t < T

        for(t in 2:(n.time - 1)){

          # print("z time t = ")
          # print(t)

          for(indiv in 1:n.ranker){
            # print("z indiv = ")
            # print(indiv)

            for(item_ind in 1:n.item){

              # print("item_ind = ")
              # print(item_ind)

              temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker +
                                                 n.item*(indiv - 1) +
                                                 item_ind]

              if(is.na(temp_ztpmin1)){

                print("line 1895")

                print("Z.mat = ")
                print(Z.mat)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("item_ind = ")
                print(item_ind)

                stop("NA temp_ztpmin1")
              }

              # must find mean corresponding to z in period t-1
              # This will be used in and after the loop over regions.
              # can directly obtain from dbarts
              # or find region
              # and use already saved region mean values


              # must find last lower bound that temp_ztpmin1 is greater than
              # or first upper bound that temp_ztpmin1 is below
              ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat[, 3]) )[1]
              # Then obtain the corresponding region mean value
              temp_mean2 <- intersectmat[ktemp_tmin1,1]


              if(is.na(temp_mean2)){
                print("line 1908")

                print("ktemp_tmin1 = ")
                print(ktemp_tmin1)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_ztpmin1 = ")
                print(temp_ztpmin1)

                stop("temp_mean2 NA")
              }

              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              # print("ktemp_tmin1 = ")
              # print(ktemp_tmin1)

              # Calculate the probabilities for each region in this time period
              # the regions being looped over are actually period t+1 regions

              # Same regions for all time periods if there are no time varying covariates

              # However, the weights are individual and time period specific

              # loop through regions


              # first column is the probabilities
              # second column is the lower bounds
              # third column is the upper bounds
              # temp_region_probs <- matrix(0,
              #                             nrow = nrow(intersectmat),
              #                             ncol = 3)


              temp_region_logprobs <- matrix(-Inf,
                                             nrow = nrow(intersectmat),
                                             ncol = 3)

              # Trunc norm prob of next periods latent value conditional on region

              # Create intervals from interval t+1 latent values

              # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

              # inds for j ranked below i in t+1

              # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
              #
              # #max of latent variables for j ranked below i in t+1
              # # Z.mat
              #
              # if(length(belowrank_ind) ==0){
              #   temp_lower <- -Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    belowrank_ind]
              # }
              #
              # # inds for j ranked above i in t+1
              #
              # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
              #
              # #min of latent variables for j ranked below i in period t+1
              #
              # if(length(aboverank_ind) ==0){
              #   temp_upper <- Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #
              #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    aboverank_ind]
              # }


              # want trunc norm probability of latent variable value for item_ind
              # in period t+1

              temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                              n.item*(indiv - 1) +
                                              item_ind]


              temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

              tempz <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                          n.item*(indiv - 1) +
                                          1:n.item]

              set1 = which( temppaircomps[item_ind, ] == 1)
              set0 = which( temppaircomps[item_ind, ] == 0)

              if(length(set1) > 0){
                temp_upper3 = min(tempz[set1])
              }else{
                temp_upper3 = Inf
              }

              if(length(set0) > 0){
                temp_lower3 = max(tempz[set0])
              }else{
                temp_lower3 = -Inf
              }




              # rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
              #
              #
              # # if(any(order(rankvec_t) !=
              # #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              # #                           n.item*(indiv - 1) +
              # #                           1:n.item]) )){
              # #
              # #   print("order(rankvec_t) = ")
              # #   print(order(rankvec_t))
              # #
              # #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
              # #                         n.item*(indiv - 1) +
              # #                         1:n.item])  = ")
              # #
              # #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              # #                                  n.item*(indiv - 1) +
              # #                                  1:n.item]) )
              # #
              # #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              # #                                n.item*(indiv - 1) +
              # #                                1:n.item] = ")
              # #
              # #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              # #                            n.item*(indiv - 1) +
              # #                            1:n.item])
              # #
              # #
              # # }
              #
              #
              # # inds for j ranked below i in t
              #
              # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
              #
              # #max of latent variables for j ranked below i in t
              # # Z.mat
              #
              # if(length(belowrank_ind) ==0){
              #   temp_lower3 <- -Inf
              # }else{
              #   temp_lower3 <- max(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                         n.item*(indiv - 1) +
              #                                         belowrank_ind])
              # }
              #
              # if(is.na(temp_lower3)){
              #   print("NA temp_lower3")
              #
              #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                       n.item*(indiv - 1) +
              #                                       belowrank_ind] = ")
              #
              #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                            n.item*(indiv - 1) +
              #                            belowrank_ind])
              #
              #   print(" t = ")
              #   print(t)
              #
              #   print(" n.item = ")
              #   print(n.item)
              #
              #   print(" n.ranker = ")
              #   print(n.ranker)
              #
              #   print(" indiv = ")
              #   print(indiv)
              #
              #   print(" belowrank_ind = ")
              #   print(belowrank_ind)
              #
              #   print(" Z.mat = ")
              #   print(Z.mat)
              #
              #   stop("NA temp_lower3")
              #
              # }
              #
              # # inds for j ranked above i in t
              #
              # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
              #
              # #min of latent variables for j ranked below i in period t
              #
              # if(length(aboverank_ind) ==0){
              #   temp_upper3 <- Inf
              # }else{
              #   temp_upper3 <- min(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                         n.item*(indiv - 1) +
              #                                         aboverank_ind])
              # }

              # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
              tempmeanfordens <- intersectmat[1:num_regions, 1]

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                    mean = tempmeanfordens,
              #                                    sd = 1)

              # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
              #                                          mean = tempmeanfordens,
              #                                          sd = 1)

              if(temp_lower3 >= temp_upper3){
                print(" temp_lower3 = ")
                print(temp_lower3)

                print(" temp_upper3 = ")
                print(temp_upper3)

                stop("Line 4016 temp_lower3 >= temp_upper3")
              }

              bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))


              # print("length(bad_regions) = ")
              # print(length(bad_regions))

              temp_region_logprobs[bad_regions, 1] <- -Inf
              temp_region_logprobs[bad_regions, 2] <- NA
              temp_region_logprobs[bad_regions, 3] <- NA

              good_regions <- setdiff(1:num_regions, bad_regions)

              if(length(good_regions) == 0){
                stop("Line 3969. No good regions.")
              }

              if(length(good_regions) > num_regions){
                stop("Line 3973 length(good_regions) > num_regionss.")
              }
              if(length(temp_tnorm_logprobvec) > num_regions){
                stop("Line 3973 length(temp_tnorm_logprobvec) > num_regionss.")
              }
              if(length(tempmeanfordens) > num_regions){
                stop("Line 3979 length(tempmeanfordens) > num_regionss.")
              }
              if(length(temp_ztp1) > 1){
                stop("Line 3979 length(temp_ztp1) > 1")
              }


              temp_tnorm_logprobvec <- rep(NA, num_regions)
              temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                     mean = tempmeanfordens[good_regions],
                                                                     sd = 1)


              temp_region_logprobs[good_regions, 1] <- temp_tnorm_logprobvec[good_regions]
              temp_region_logprobs[good_regions, 2] <- pmax(intersectmat[good_regions, 2], temp_lower3)
              temp_region_logprobs[good_regions, 3] <- pmin(intersectmat[good_regions, 3], temp_upper3)

              if(any(temp_region_logprobs[good_regions, 2] >= temp_region_logprobs[good_regions, 3])){
                stop(" line 3954 bounds badly defined")
              }

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                 mean = intersectmat[1:num_regions, 1],
              #                                 sd = 1)

              # for(k_ind in 1:num_regions){
              #   # obtain mean for truncated normal distribution
              #   # temp_mean <- intersectmat[k_ind, 1]
              #
              #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #   #                               a=temp_lower,
              #   #                               b=Inf,
              #   #                               mean = temp_mean,
              #   #                               sd = 1)
              #
              #
              #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #   #                          mean = temp_mean,
              #   #                          sd = 1)
              #
              #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
              #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
              #
              #   # Probability of z_t in intersection of
              #   # region k_ind (for period t+1)
              #   # and region defined by period t latent variables for other individuals
              #   # and rank for period t
              #
              #
              #   # tildeC_ktminl corresponds to
              #   # period t+1 k_ind region intereval
              #
              #   temp_lower2 <- intersectmat[k_ind, 2]
              #   temp_upper2 <- intersectmat[k_ind, 3]
              #
              #
              #
              #   # print(" line 2075 ")
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   #
              #   # print("temp_lower3 = ")
              #   # print(temp_lower3)
              #   #
              #   # print("temp_upper3 = ")
              #   # print(temp_upper3)
              #
              #
              #   if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
              #     # if((temp_lower2 - temp_upper3 > -0.0001) | (temp_lower3 - temp_upper2 > -0.0001)){
              #     # intervals do not overlap, therefore assign probability zero
              #     # and skip to next iteration
              #
              #     # print("k_ind = ")
              #     # print(k_ind)
              #
              #     # print("ncol(temp_region_probs) = ")
              #     # print(ncol(temp_region_probs))
              #
              #     # print("nrow(temp_region_probs) = ")
              #     # print(nrow(temp_region_probs))
              #
              #     # temp_region_probs[k_ind, 1] <- 0
              #     # temp_region_probs[k_ind, 2] <- NA
              #     # temp_region_probs[k_ind, 3] <- NA
              #
              #     temp_region_logprobs[k_ind, 1] <- -Inf
              #     temp_region_logprobs[k_ind, 2] <- NA
              #     temp_region_logprobs[k_ind, 3] <- NA
              #
              #
              #     next
              #   }
              #
              #
              #
              #   temp_lower2 <- max(temp_lower2, temp_lower3)
              #   temp_upper2 <- min(temp_upper2, temp_upper3)
              #
              #
              #   if(temp_lower2 >= temp_upper2){
              #
              #     print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                 n.item*(indiv - 1) +
              #                                 1:n.item]")
              #     print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                              n.item*(indiv - 1) +
              #                              1:n.item])
              #     print("item_ind = ")
              #     print(item_ind)
              #
              #     print("t = ")
              #     print(t)
              #
              #     print("indiv = ")
              #     print(indiv)
              #
              #
              #     print("rankvec_t = ")
              #     print(rankvec_t)
              #
              #
              #     print("temp_lower2 = ")
              #     print(temp_lower2)
              #
              #     print("temp_upper2 = ")
              #     print(temp_upper2)
              #
              #     print("temp_lower3 = ")
              #     print(temp_lower3)
              #
              #     print("temp_upper3 = ")
              #     print(temp_upper3)
              #
              #
              #
              #     print("intersectmat[k_ind, 2] = ")
              #     print(intersectmat[k_ind, 2])
              #
              #     print("intersectmat[k_ind, 3] = ")
              #     print(intersectmat[k_ind, 3])
              #
              #     print("k_ind = ")
              #     print(k_ind)
              #
              #
              #
              #     stop("Line 1917. temp_lower2 >= temp_upper2")
              #   }
              #
              #
              #
              #   # probability of being in intersection region
              #
              #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
              #
              #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_mean2 = ")
              #   # print(temp_mean2)
              #   #
              #   #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #   #
              #   # print("temp_tnorm_prob = ")
              #   # print(temp_tnorm_prob)
              #
              #   # prob_t_region <- prob_t_region*temp_tnorm_prob
              #   # prob_t_region <- temp_tnorm_prob
              #   logprob_t_region <- temp_tnorm_logprob
              #
              #   # if(temp_tnorm_prob ==0){
              #   if(temp_tnorm_logprob == -Inf){
              #     print("temp_tnorm_prob = ")
              #     print(temp_tnorm_prob)
              #
              #     print("temp_tnorm_probvec =")
              #     print(temp_tnorm_probvec)
              #
              #     print("tempmeanfordens =")
              #     print(tempmeanfordens)
              #
              #     print("temp_ztp1 =")
              #     print(temp_ztp1)
              #
              #   }
              #
              #   # save region probability
              #
              #   # and save region bounds (or maybe more memory efficient to obtain the region again)
              #
              #   # must multiply by other previously obtained probabilities
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   # temp_region_probs[k_ind, 1] <- prob_t_region
              #   # temp_region_probs[k_ind, 2] <- temp_lower2
              #   # temp_region_probs[k_ind, 3] <- temp_upper2
              #
              #   temp_region_logprobs[k_ind, 1] <- logprob_t_region
              #   temp_region_logprobs[k_ind, 2] <- temp_lower2
              #   temp_region_logprobs[k_ind, 3] <- temp_upper2
              #
              # }


              # sample a region using probabilities obtained above

              # print("Line 1903 before sample")


              # if(sum(temp_region_probs[,1] > 0) ==0){
              if(sum(temp_region_logprobs[,1] > -Inf) ==0){

                print("temp_tnorm_probvec =")
                print(temp_tnorm_probvec)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_region_probs = ")
                print(temp_region_probs)

                print("item_ind = ")
                print(item_ind)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("rankvec_t = ")
                print(rankvec_t)

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  1:n.item]")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])

                stop(" Line 2590 sum(temp_region_probs[,1] >0) == 0")
              }



              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])
              # print("line 4219")
              # print("length(temp_region_logprobs) = ")
              # print(length(temp_region_logprobs))
              # logprobstemp <- as.vector(temp_region_logprobs[,1])
              # max_ll <- max(logprobstemp)
              # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
              # probstemp <- exp(logprobstemp - logsumexps)
              #
              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = probstemp)
              if(length(good_regions)==1){
                region_ind <- good_regions[1]
              }else{
                logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
                max_ll <- max(logprobstemp)
                logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
                probstemp <- exp(logprobstemp - logsumexps)

                region_ind <- sample(x = (1:num_regions)[good_regions], size = 1, replace = TRUE, prob = probstemp)
              }

              # print("line 4229")

              # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

              # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
              #
              # print("line 2102 temp_mean2_debug from predict = ")
              # print(temp_mean2_debug)
              #
              # print("line 2105 temp_mean2_origscale = ")
              # print(temp_mean2_origscale)
              #
              # print("line 2108 temp_mean2 = ")
              # print(temp_mean2)


              # if(temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2] < 0.000001 ){
              #
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #
              #
              #   stop("very small difference in limits")
              # }

              # if(temp_region_probs[region_ind, 3] -temp_region_probs[region_ind, 2] < 0.001 ){
              #   stop("line 2456. Very small range")
              #
              # }

              # if(temp_region_probs[region_ind, 2] + 0.00005  >  temp_region_probs[region_ind, 3] - 0.00005 ){
              #
              #   print("iter  = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   stop("line 2467 Very small range")
              #
              # }


              # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
              #
              # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
              #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
              #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
              #
              # }else{
              #   upper_buffered <- temp_region_probs[region_ind, 3]
              #   lower_buffered <- temp_region_probs[region_ind, 2]
              #
              # }

              tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/100

              if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
                upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
                lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer
              }else{
                upper_buffered <- temp_region_logprobs[region_ind, 3]
                lower_buffered <- temp_region_logprobs[region_ind, 2]

                if(temp_region_logprobs[region_ind, 3] != Inf){
                  upper_buffered <- temp_region_logprobs[region_ind, 3] - 0.00001
                }

                if(temp_region_logprobs[region_ind, 2] != -Inf){
                  lower_buffered <- temp_region_logprobs[region_ind, 2] + 0.00001
                }


              }

              if(abs( temp_mean2/ (upper_buffered - lower_buffered ) ) > 10^15){
                # this is a quick fix for when the bounds are close or very far from the mean
                # this does not really address any potential underlying issue
                zdraw_temp <- (lower_buffered + upper_buffered)/2
              }else{
                zdraw_temp <- rtruncnorm(n = 1,
                                         a=lower_buffered,
                                         b=upper_buffered,
                                         mean = temp_mean2, #temp_mean2_origscale,
                                         sd = 1)
              }


              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=lower_buffered,
              #                          b=upper_buffered,
              #                          mean = temp_mean2, #temp_mean2_origscale,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                print("zdraw_temp = ")
                print(zdraw_temp)

                stop("NA zdraw_temp")
              }


              # if( (zdraw_temp - temp_region_probs[region_ind, 2] < 0.00001 ) | (temp_region_probs[region_ind, 3] - zdraw_temp  < 0.00001 ) ){
              #
              #   print("iter = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #   print("zdraw_temp = ")
              #   print(zdraw_temp)
              #
              #   stop("line 2470 draw very close to limit")
              # }



              # print("Line 1914 after sample")

              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=temp_region_probs[region_ind, 2],
              #                          b=temp_region_probs[region_ind, 3],
              #                          mean = temp_mean2,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs= ")
                print(temp_region_logprobs)

                # print("temp_region_logprobs = ")
                # print(temp_region_logprobs)

                print("temp_mean2 = ")
                print(temp_mean2)

                stop("NA zdraw_temp")
              }

              Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp

            } # end loop over items
          } # end loop over rankers


        } # end loop over time periods

        # check for special cases for n.time - 1, n.time - 2, n.time - 3

        # special case for t = n.time

        for(indiv in 1:n.ranker){
          for(item_ind in 1:n.item){
            temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # for first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat[, 3])[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat[ktemp_tmin1,1]

            # now find interval


            # tildeC_ktminl corresponds to
            # period t+1 k_ind region intereval


            temppaircomps <- pair.comp.ten[, , (n.time-1)*n.ranker + indiv]

            tempz <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                        n.item*(indiv - 1) +
                                        1:n.item]

            set1 = which( temppaircomps[item_ind, ] == 1)
            set0 = which( temppaircomps[item_ind, ] == 0)

            if(length(set1) > 0){
              temp_upper3 = min(tempz[set1])
            }else{
              temp_upper3 = Inf
            }

            if(length(set0) > 0){
              temp_lower3 = max(tempz[set0])
            }else{
              temp_lower3 = -Inf
            }



            # rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]
            #
            # # inds for j ranked below i in T
            #
            # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in T
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower3 <- -Inf
            # }else{
            #   temp_lower3 <- max(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         belowrank_ind])
            # }
            #
            # # inds for j ranked above i in T
            #
            # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period T
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper3 <- Inf
            # }else{
            #   temp_upper3 <- min(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         aboverank_ind])
            # }


            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
            #
            # print("line 2202 temp_mean2_debug from predict = ")
            # print(temp_mean2_debug)
            #
            # print("line 2205 temp_mean2_origscale = ")
            # print(temp_mean2_origscale)
            #
            # print("line 2208 temp_mean2 = ")
            # print(temp_mean2)

            # if(temp_upper3 -temp_lower3 < 0.000001 ){
            #
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   stop("very small difference in limits")
            # }


            # if(temp_upper3 - temp_lower3 < 0.001 ){
            #   stop("line 2613.  Very small range")
            #
            # }

            # if(temp_lower3 + 0.00005  >  temp_upper3 - 0.00005 ){
            #   print("line 2623 Very small range")
            #
            # }

            tempbuffer <- (temp_upper3 - temp_lower3)/100

            if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
              upper_buffered <- temp_upper3 - tempbuffer
              lower_buffered <- temp_lower3 + tempbuffer

            }else{
              upper_buffered <- temp_upper3
              lower_buffered <- temp_lower3

              # if(temp_upper3 != Inf){
              #   upper_buffered <- temp_upper3 - 0.00001
              # }
              #
              # if(temp_lower3 != -Inf){
              #   lower_buffered <- temp_lower3 + 0.00001
              # }


            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean2, #temp_mean2_origscale,
                                     sd = 1)

            # if( (zdraw_temp - temp_lower3 < 0.00001 ) | (temp_upper3 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("temp_lower3 = ")
            #   print(temp_lower3)
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   stop("line 2612 draw very close to limit")
            # }

            # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a = temp_lower3,
            #                          b = temp_upper3,
            #                          mean = temp_mean2,
            #                          sd = 1)

            if(is.na(zdraw_temp)){
              print(" line 2367")
              print("temp_lower3] = ")
              print(temp_lower3)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_mean2 = ")
              print(temp_mean2)

              stop("NA zdraw_temp")
            }

            Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp

          } # end loop over items
        } # end loop over rankers

        #   } # end loop over items
        #
        # } # end loop over individuals indiv in 1:n.ranker

      } # end loop over z iters
    } # end else statement

    # print("end z draws ")



    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{

    # temp_break <- 0
    # for(j in 1:num_lags){
    #   # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #
    #   while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {
    #
    #     if(seq_z_draws==1){
    #       stop("updates still not consistent with tree structure")
    #     }
    #     print("new z values not consistent with tree structure, must draw again")
    #
    #     # If this error message occurs
    #     # Check the conditions in the dbart package for setPredictor == FALSE
    #     # And if this is hypothetically possible, even with draws from the smoothing distribution,
    #     # and if it is not a bug
    #     # then need to go back to beginning of this iteration of the Gibbs sampler
    #     # and sample Zmat again
    #
    #
    #     temp_break <- 1
    #     break
    #     # stop("new z values not consistent with tree structure, must draw again")
    #
    #
    #     # #perhaps this can be rewritten to just re-draw the relevant column?
    #     # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #     #                                           Z.mat = Z.mat,
    #     #                                           mu = mu,
    #     #                                           weight.vec = rep(1, n.ranker*n.time),
    #     #                                           n.ranker = n.ranker*n.time,
    #     #                                           n.item = n.item )
    #     #
    #     # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #     #
    #     # for(t in 1:num_lags){
    #     #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #     #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #     #
    #     #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #     #
    #     # }
    #     #
    #     # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j
    #
    #   }
    #
    #   if(temp_break==1){
    #     break
    #   }
    # }
    #
    # # if need to draw z values again, go back to start of loop
    # if(temp_break==1){
    #   if(breakcount == 10){
    #     Z.mat <- Z.matold
    #     Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #     for(t in 1:num_lags){
    #       init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #       # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #       Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #
    #     }
    #
    #   }else{
    #     breakcount <- breakcount +1
    #     next
    #   }
    #
    # }
    #
    # breakcount <- 0


    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }




    ##################### Sample sum-of-trees ##################################################


    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    # #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # mutemp <- sampler$predict(df_for_dbart)
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # mu = mutemp


    # print("line 2768")



    # Must update node sizes for original tree
    # update all node sizes before new proposal

    # Must update node sizes for original tree
    # update all node sizes before new proposal

    for (j in 1:n.trees) {
      # print("curr_trees[[j]] = ")
      # print(curr_trees[[j]] )

      curr_trees[[j]] <- fill_tree_details(curr_trees[[j]],
                                           Zlag.mat)

      # print("line 2785, curr_trees[[j]] = ")
      # print(curr_trees[[j]] )
      # must also update individual tree predictions for calcualtion of partial residuals
      tree_fits_store[,j]  = get_predictions(curr_trees[[j]], Zlag.mat, single_tree = TRUE)

    }

    # option: prune all empty nodes from current trees before proposal?
    # must create new function for this
    # perhaps an issue is that there would not be a (umique) mu value
    # associated with a parent of an empty node
    # print("line 2791")

    # must update mu before and after trees updated because covariates have been updated

    mutemp = get_predictions(curr_trees, Zlag.mat, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))

    # print("line 2801")

    # Start looping through trees
    for (j in 1:n.trees) {

      current_partial_residuals = as.vector(Z.mat) - mu + tree_fits_store[,j]

      # Propose a new tree via grow/change/prune/swap
      type = sample_move(curr_trees[[j]], iter, 0, # nburn # no burnin number, so setting to 100, maybe this is not optimal
                         trans_prob)



      # option: edit the proposal step so that any proposed tree does not contain empty nodes?
      # must create new function for this

      # Generate a new tree based on the current
      if(no_empty_proposals == TRUE){

        new_trees[[j]] = noempty_update_tree(y = as.vector(Z.mat),
                                             X = Zlag.mat,
                                             type = type,
                                             curr_tree = curr_trees[[j]],
                                             node_min_size = node_min_size,
                                             s = s,
                                             splitting_rules = splitting_rules,
                                             max_bad_trees = max_bad_trees)

      }else{
        new_trees[[j]] = update_tree(y = as.vector(Z.mat),
                                     X = Zlag.mat,
                                     type = type,
                                     curr_tree = curr_trees[[j]],
                                     node_min_size = node_min_size,
                                     s = s,
                                     splitting_rules = splitting_rules,
                                     max_bad_trees = max_bad_trees)

      }




      # print("line 2825")


      # CURRENT TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_old = tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(curr_trees[[j]], alpha, beta)

      # print("line 2825")
      #
      # print("new_trees[[j]]")
      # print(new_trees[[j]])

      # NEW TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_new = tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(new_trees[[j]], alpha, beta)

      # Exponentiate and multiply by the transition probabilities

      if(type == 'grow'){
        a = exp(l_new - l_old)*ratio_grow(new_trees[[j]], curr_trees[[j]])
      } else if(type == 'prune'){
        a = exp(l_new - l_old)*ratio_prune(new_trees[[j]], curr_trees[[j]])
      } else{
        a = exp(l_new - l_old)
      }

      vars_empty_pruned <- c()

      if(is.na(a)){
        print("current_partial_residuals = ")
        print(current_partial_residuals)

        print("get_tree_prior(new_trees[[j]], alpha, beta) = ")
        print(get_tree_prior(new_trees[[j]], alpha, beta))

        print("get_tree_prior(curr_trees[[j]], alpha, beta) = ")
        print(get_tree_prior(curr_trees[[j]], alpha, beta))

        print("tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) = ")
        print(tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu))

        print("tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)  = ")
        print(tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) )

        print("new_trees[[j]] = ")
        print(new_trees[[j]])
        print("curr_trees[[j]] = ")
        print(curr_trees[[j]])

        print("l_new = ")
        print(l_new)

        print("l_old = ")
        print(l_old)

        print("ratio_prune(new_trees[[j]], curr_trees[[j]]) = ")
        print(ratio_prune(new_trees[[j]], curr_trees[[j]]))

        print("ratio_grow(new_trees[[j]], curr_trees[[j]]) = ")
        print(ratio_grow(new_trees[[j]], curr_trees[[j]]))

        print("exp(l_new - l_old) = ")
        print(exp(l_new - l_old))

        print("type = ")
        print(type)

        print("is.na(a)")
      }


      if(a > runif(1)) {
        curr_trees[[j]] = new_trees[[j]]
        # only account for pruning if  accept
        vars_empty_pruned <- new_trees[[j]]$vars_empty_pruned

        for(var_ind in vars_empty_pruned){
          var_count[var_ind ] = var_count[var_ind ] - 1
        }


        if (type =='change'){
          var_count[curr_trees[[j]]$var[1] ] = var_count[curr_trees[[j]]$var[1] ] - 1
          var_count[curr_trees[[j]]$var[2] ] = var_count[curr_trees[[j]]$var[2] ] + 1
        }

        if (type=='grow'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] + 1
        } # -1 because of the intercept in X

        if (type=='prune'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] - 1
        } # -1 because of the intercept in X

      }


      ### might need to edit simulate_mu to find right terminal nodes #########

      # Update mu whether tree accepted or not
      curr_trees[[j]] = simulate_mu(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)
      # Updating BART predictions
      current_fit = get_predictions(curr_trees[[j]], Zlag.mat, single_tree = TRUE)
      mu = mu - tree_fits_store[,j] # subtract the old fit
      mu = mu + current_fit # add the new fit
      tree_fits_store[,j] = current_fit # update the new fit

    } # End loop through trees



    # sum_of_squares = sum((y_scale - y_hat)^2)

    # Update sigma2 (variance of the residuals)
    # sigma2 = update_sigma2(sum_of_squares, n = length(y_scale), nu, lambda)
    # variance kept equal to 1, do not update

    # # Update s = (s_1, ..., s_p), where s_p is the probability that predictor p is used to create new terminal nodes
    # if (sparse == 'TRUE' & i > floor(iter.max*0.1)){
    #   s = update_s(var_count, ncol(Zlag.mat), 1)
    # }

    # Update s = (s_1, ..., s_p), where s_p is the probability that predictor q in 1:p is used to create new terminal nodes
    if (sparse & i > floor(iter.max * 0.25)) {
      s <- update_s(var_count, p, alpha_s)
      if(alpha_prior){
        alpha_s <- update_alpha_par(s, alpha_scale, alpha_a, alpha_b)
      }
    }

    if(sigma_mu_prior){
      sigma2_mu <-  update_sigma_mu_par(curr_trees, sigma2_mu)
    }


    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta




    # if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(df_for_dbart)

    # Xmat.test[,1:num_lags] <-  Zlag.mat.test


    temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))

    for(t  in 1:num_lags){
      if(noise_in_pred ==1){
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
      }else{
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]

      }

    }

    # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #                                                                      (num_lags+1):ncol(Xmat.test)])

    temp_test_mat <- data.frame(x = temp_test_mat)
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # print("Line 5488")


    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )


    # if(iter < 5){
    #   print("temp_test_mat = " )
    #   print(temp_test_mat)
    # }

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # must use original column names to prevent an error in the predict function
      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      # testpredvec <- sampler$predict(temp_test_mat)
      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

      #fill in temp_test_preds with noise
      if(noise_in_pred ==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
      }


      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

      if(t1 != num_test_periods){


        if(num_lags ==1){
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }else{
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                    temp_test_mat[,1:(num_lags-1)] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }
      }

      # colnames(temp_test_mat) <- colnames(Xmat.test)


      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?

    # print("Line 5545")


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }


    draw$mu_test[,iter] <- temp_mu_test
    # draw$mu_test[,iter] <- samplestemp$test[,1]

    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

    # draw$mu_test[,1] <- samplestemp$test[,1]

    # }else{
    #   draw$mu_test[,1] <- initial.list$mu_test
    # }




    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

    iter <- iter+1
  } # end loop over MCMC iterations


  return(draw)
}




##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////





#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with partial ranks and with Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and with covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.train An \eqn{N} by \eqn{L} training covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param X.test An \eqn{N} by \eqn{L} test covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param n.item Number of entities/items being ranked.
#' @param n.rankerbytime Number of rankers multiplied by number of time periods
#' @param n.ranker Number of rankers
#' @param n.time Number of time periods
#' @param p.cov Number of covariates.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @param itemcovars Set equal to TRUE if covariates vary across items, and FALSE otherwise.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @useDynLib ROBART2, .registration = TRUE
#' @export
ARRObartWithCovars_fullcond_EmpN_partial <- function(pair.comp.ten,
                                                     X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                                     X.test = matrix(NA, nrow =0, ncol = 0),
                                                     # tau2.alpha = 5^2,
                                                     # nu.alpha = 3,
                                                     # tau2.beta = 5^2,
                                                     # nu.beta = 3,
                                                     n.item = dim(pair.comp.ten)[1],
                                                     n.rankerbytime = dim(pair.comp.ten)[3],
                                                     n.ranker,
                                                     n.time,
                                                  p.cov = ncol(X.train),
                                                  iter.max = 5000,
                                                  para.expan = TRUE,
                                                  print.opt = 100,
                                                  initial.list = NULL,
                                                  n.trees = 50L,
                                                  n.burn = 0L,
                                                  n.samples = 1L,
                                                  n.thin = 1L,
                                                  trans_prob = c(2.5, 2.5, 4) / 9, # Probabilities to grow, prune or change, respectively
                                                  n.chains = 1,
                                                  n.threads = 1L,#guessNumCores(),
                                                  printEvery = 100L,
                                                  printCutoffs = 0L,
                                                  rngKind = "default",
                                                  rngNormalKind = "default",
                                                  rngSeed = NA_integer_,
                                                  updateState = FALSE,
                                                  num_lags = 1,
                                                  diff_num_test_rankers = 0,
                                                  keep_zmat = FALSE,
                                                  noise_in_pred = 0,
                                                  seq_z_draws = 1,
                                                  N_hdr = 100,
                                                  rho_hdr = 0.5,
                                                  smoothing_method = "AR",
                                                  num_horizon = 1,
                                                  num_z_iters = 10,
                                                  itemcovars = FALSE,
                                                  node_min_size = 5,
                                                  k = 2,
                                                  sigquant = .90,
                                                  alpha = 0.95,
                                                  beta = 2,
                                                  nu = 3,
                                                  lambda = 0.1,
                                                  no_empty_proposals = FALSE,
                                                  alpha_prior = TRUE,
                                                  sigma_mu_prior = FALSE,
                                                  splitting_rules = "discrete",
                                                  max_bad_trees = 10,
                                                  sparse = TRUE,
                                                  alpha_a_y = 0.5,
                                                  alpha_b_y = 1,
                                                  alpha_split_prior = TRUE){


  if(!(splitting_rules %in% c("discrete", "continuous"))){
    stop("splitting_rules must be 'discrete' or 'continuous'.")
  }

  X.train <- as.matrix(X.train)
  X.test <- as.matrix(X.test)

  ######### set up things for myBART implementation ####################

  # Extract control parameters
  # we only have to allow for empty nodes when updating Z (and therefore Zlag is updated and splits on Zlag are affected)
  # Therefore there is still a minimum node size criterion for the purpose of proposing new splits
  # node_min_size = node_min_size

  # Storage containers
  store_size = iter.max # npost # code currently written to save all output, so no nburnin or npost
  tree_store = vector('list', store_size)
  sigma2_store = rep(NA, store_size)
  # y_hat_store = matrix(NA, ncol = length(y), nrow = store_size)
  # var_count = rep(0, ncol(x))
  # var_count_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # s_prob_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # tree_fits_store = matrix(0, ncol = n.trees, nrow = length(y))

  sigma2 <- 1 # keep sigma2 set to 1


  ########## beginning of original code ############################


  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)

      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  # ranks_mat <- matrix(NA,
  #                     ncol = n.ranker*n.time,
  #                     nrow = n.item )
  #
  #
  # #n.item by n.item
  #
  # for(t in 1:n.time){
  #
  #   for(indiv in 1:n.ranker){
  #     pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]
  #
  #     # 1 corresponding to "highest rank" . i.e. highest utility ite,
  #     # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1
  #
  #     # 1 corresponding to "lowest rank". i.e. lowest utility item
  #
  #     up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
  #
  #
  #     ranks_mat[, (t-1)*n.ranker + indiv] <- up.order
  #
  #   }
  # }


  # it might be more efficient to create and save all rank constraint matrices at this stage


  # rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))
  #
  # for(indiv in 1:n.ranker){
  #
  #   for(t in 1:n.time){
  #
  #     rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
  #
  #
  #     rankconstraint_t <- matrix(0,
  #                                nrow = n.item - 1,
  #                                ncol = n.item)
  #
  #     # note: ordering of rows is unimportant
  #     # as long as ordering agrees with the ordering of the mean vector
  #
  #     # so can begin by filling in first row
  #
  #     #MUST BE EDITED IF ALLOW FOR TIES
  #     for(rankind in 1:(length(rankvec_t)-1)){
  #
  #       rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
  #       rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1
  #
  #       # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
  #       # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1
  #
  #     }
  #
  #     rank_cons_arr[, , indiv, t] <- rankconstraint_t
  #
  #   }
  # }
  # # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  # boundconstraints <- matrix(NA,
  #                            nrow = 2*n.item,
  #                            ncol = n.item)
  #
  # # use kroenecker product
  # # there is probably a more efficient way of doing this
  #
  # boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      # pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))


      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))

      # tempsort <- sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE )
      #
      # Z.mat[ tempsort$ix , j] <-
      #   qnorm(  tempsort$x   /(n.item+1)) +
      #   rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   qnorm(c(n.item : 1)/(n.item+1)) +
      #   rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }



    print("Line 799.")

    # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )

      Xmat.train.no.y <- cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                  ncol =  ncol(X.train) + num_lags ,
                                                  byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")

        Xmat.test.no.y <- cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                       ncol =  ncol(X.test) , byrow = TRUE ) )




        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        Xmat.train.no.y <- cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          Xmat.test.no.y <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }



    # ##### old dbarts initialization ###############
    #
    # control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
    #                          keepTrees = TRUE,
    #                          n.trees = n.trees,
    #                          n.burn = n.burn,
    #                          n.samples = n.samples,
    #                          n.thin = n.thin,
    #                          n.chains = n.chains,
    #                          n.threads = n.threads,
    #                          printEvery = printEvery,
    #                          printCutoffs = printCutoffs,
    #                          rngKind = rngKind,
    #                          rngNormalKind = rngNormalKind,
    #                          rngSeed = rngSeed)
    #
    #
    # # print(colnames(Xmat.train))
    # # print(colnames(Xmat.test))
    #
    # # print("begin dbarts")
    #
    #
    # if(nrow(X.test )==0){
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     #test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1),
    #                     sigma=1 #check if this is the correct approach for setting the variance to 1
    #   )
    #
    # }else{
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    #                     sigma=1 #
    #   )
    #
    # }
    #
    #
    # # print("error after dbarts")
    #
    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    # #sampler$setPredictor(x= Xmat.train$x, column = 1, forceUpdate = TRUE)
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # sampler$sampleTreesFromPrior()
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mupreds <- sampler$predict(Xmat.train)
    #
    # # mu <- mutemp





    y_hat_store = matrix(NA, ncol = length(as.vector(Z.mat)), nrow = store_size)
    var_count = rep(0, ncol(Xmat.train.no.y))
    var_count_store = matrix(0, ncol = ncol(Xmat.train.no.y), nrow = store_size)
    s_prob_store = matrix(0, ncol = ncol(Xmat.train.no.y), nrow = store_size)
    tree_fits_store = matrix(0, ncol = n.trees, nrow = length(as.vector(Z.mat)))
    s = rep(1/ncol(Xmat.train.no.y), ncol(Xmat.train.no.y))


    p <- ncol(Xmat.train.no.y)
    rho <- p # For DART

    if(alpha_prior){
      alpha_s <- p
    }else{
      alpha_s <- 1
    }
    alpha_scale <- p
    # s <- rep(1 / p, p) # probability vector to be used during the growing process for DART feature weighting


    if(sparse){
      draw$alpha_s_store <- rep(NA, iter.max)
      draw$var_count_store <- matrix(0, ncol = p, nrow = iter.max)
      draw$s_prob_store <- matrix(0, ncol = p, nrow = iter.max)
    }



    ###### new myBART initialization ######################

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }
    }

    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }

    # maybe (max(as.vector(Z.mat))-min(as.vector(Z.mat)))
    # can be replaced by something else
    # sigma2_mu <- (max(as.vector(Z.mat))-min(as.vector(Z.mat)))/((2 * k * sqrt(n.trees))^2)
    sigma2_mu <- ((max(as.vector(Z.mat))-min(as.vector(Z.mat)))/(2 * k * sqrt(n.trees)))^2


    # Create a list of trees for the initial stump
    curr_trees = create_stump(num_trees = n.trees,
                              y = as.vector(Z.mat),
                              X = Xmat.train.no.y)
    # Initialise the new trees as current one
    new_trees = curr_trees

    # Initialise the predicted values to zero
    mutemp = get_predictions(curr_trees, Xmat.train.no.y, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))












    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train.no.y = ")
        print(Xmat.train.no.y)
        print("Z.mat = ")
        print(Z.mat)

        # print("samplestemp$sigma = ")
        # print(samplestemp$sigma)
        # print("samplestemp$varcount = ")
        # print(samplestemp$varcount)
        #
        # print("samplestemp$train[,1] = ")
        # print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  print("Line 954")


  # df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    # temp_test_mat <- as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_mat <- data.frame( x = as.matrix(Xmat.test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(Xmat.test)



    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    temp_mu_test <- rep(NA,  nrow(Xmat.test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      # testpredvec <- sampler$predict(temp_test_mat)
      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }

      colnames(temp_test_mat) <- colnames(Xmat.test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  iter <- 2
  breakcount <- 0

  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    # Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }

      # tempsort <- sort(tempcol)
      #
      # tempdiffs <- tempsort[-1] - tempsort[-(length(tempsort))]

      # if( any( abs(tempdiffs) < 0.001 )   ){
      #
      #   print("tempsort =")
      #   print(tempsort)
      #   print("tempdiffs =")
      #   print(tempdiffs)
      #   print("j = ")
      #   print(j)
      #   print("tempcol =")
      #   print(tempcol)
      #   print("Z.mat =")
      #   print(Z.mat)
      #   print(" some differences in Z vector very small")
      # }

    }

    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA



    # num_regions <- nrow(intersectmat)

    # print("Line 1169")


    for(z_iter_ind in 1:num_z_iters){

      # print("z_iter_ind = ")
      # print(z_iter_ind)

      for(indiv in 1:n.ranker){

        # print("indiv = ")
        # print(indiv)

        ########### calculate qkt   for t = 1 ########################################

        Biglist_list_item_intersectmats <- list()
        Biglist_intersectmats <- list()


        ######## Period 1 Intersection Matrix #########################

        # create vector of indices for ranker indiv in time period 1
        ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        # print("Begin Period 1 intersection matrices = ")
        # print(indiv)

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            # treeexample1 <- sampler$getTrees(treeNums = i,
            #                                  chainNums = 1,
            #                                  sampleNums = 1)
            #
            # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
            #                                   treeNums = i,
            #                                   chainNums = 1,
            #                                   sampleNums = 1)

            temptree <- curr_trees[[i]]$tree_matrix

            treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

            temp_na_inds <- is.na(temptree[,'split_variable'])
            # print("temp_na_inds = ")
            # print(temp_na_inds)
            #
            # print("treeexample1 = ")
            # print(treeexample1)
            #
            # print("temptree[temp_na_inds,'mu'] = ")
            # print(temptree[temp_na_inds,'mu'])

            treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

            # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
            #   1,#rep(sampleNums, nrow(temptree)),
            #   i,#rep(treeNums, nrow(temptree)),
            #   temptree[, 'node_size'],
            #   # mybarttree[,'split_variable'],
            #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
            #          -1,
            #          temptree[,'split_variable']),
            #   fast_ifelse(is.na(temptree[,'split_variable']) ,
            #          temptree[,'mu'],
            #          temptree[,'split_value']))

            # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))


            # print("rebuilt_tree = ")
            # print(rebuilt_tree)

            #must use covariates for individual indiv at time period t

            # print("Xmat.train$x[obs_indices[1],, drop = FALSE] = ")
            # print(Xmat.train$x[obs_indices[1],, drop = FALSE])
            #
            #
            # print("Xmat.train$x[obs_indices[1],] = ")
            # print(Xmat.train$x[obs_indices[1],])
            #
            #
            # print("obs_indices[1] = ")
            # print(obs_indices[1])
            #
            #
            # print("Xmat.train = ")
            # print(Xmat.train)



            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )
            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )


          }

          intersectmat_tmin1 <- interNtreesB(list_inter_mats)


          intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat_tmin1)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat_tmin1[ktemp,1]
            templower <- intersectmat_tmin1[rowind,2]
            tempupper <- intersectmat_tmin1[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[1]] <- intersectmat_tmin1


        }else{ # itemcovars == TRUE


          list_item_intersectmats_tmin1 <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)

              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])

              # print("temp_na_inds = ")
              # print(temp_na_inds)
              #
              # print("treeexample1 = ")
              # print(treeexample1)
              #
              # print("temptree[temp_na_inds,'mu'] = ")
              # print(temptree[temp_na_inds,'mu'])

              treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))
              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )


            } #end loop over trees

            intersectmat_tmin1 <- interNtreesB(list_inter_mats)

            intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat_tmin1)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat_tmin1[ktemp,1]
              templower <- intersectmat_tmin1[rowind,2]
              tempupper <- intersectmat_tmin1[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats_tmin1[[index_item]] <- intersectmat_tmin1


          } #end loop over items

          Biglist_list_item_intersectmats[[1]] <- list_item_intersectmats_tmin1

        } # end else itemcovars == TRUE


        ################ period 2 intersection matrix #################################################

        # create vector of indices for ranker indiv in time period 2
        ind_start <- (2 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (2 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            # treeexample1 <- sampler$getTrees(treeNums = i,
            #                                  chainNums = 1,
            #                                  sampleNums = 1)

            # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
            #                                   treeNums = i,
            #                                   chainNums = 1,
            #                                   sampleNums = 1)

            temptree <- curr_trees[[i]]$tree_matrix

            treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

            temp_na_inds <- is.na(temptree[,'split_variable'])
            treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

            # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
            #   1,#rep(sampleNums, nrow(temptree)),
            #   i,#rep(treeNums, nrow(temptree)),
            #   temptree[, 'node_size'],
            #   # mybarttree[,'split_variable'],
            #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
            #          -1,
            #          temptree[,'split_variable']),
            #   fast_ifelse(is.na(temptree[,'split_variable']) ,
            #          temptree[,'mu'],
            #          temptree[,'split_value']))
            # # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

            #must use covariates for individual indiv at time period t

            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )

          }

          intersectmat <- interNtreesB(list_inter_mats)


          intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat[ktemp,1]
            templower <- intersectmat[rowind,2]
            tempupper <- intersectmat[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[2]] <- intersectmat


        }else{ # itemcovars == TRUE


          list_item_intersectmats <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)


              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])
              treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))
              # # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )

            } #end loop over trees

            intersectmat <- interNtreesB(list_inter_mats)

            intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat[ktemp,1]
              templower <- intersectmat[rowind,2]
              tempupper <- intersectmat[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats[[index_item]] <- intersectmat


          } #end loop over items

          Biglist_list_item_intersectmats[[2]] <- list_item_intersectmats

        } # end else itemcovars == TRUE


        # print("End Period 1 intersection matrices = ")


        ##### t = 3 to T intersect matrices ######################

        # print("Begin loop for intersection matrices = ")

        for(t in 3:n.time){

          #### obtain intersection matrices for time period t ###############
          # print("t = ")
          # print(t)

          # create vector of indices for ranker indiv in time period 1
          ind_start <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          ind_end <- (t - 1)*n.ranker*n.item+n.item*indiv
          obs_indices <- ind_start:ind_end

          if(itemcovars == FALSE){


            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)

              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])
              treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )

            }

            intersectmat <- interNtreesB(list_inter_mats)

            Biglist_intersectmats[[t]] <- intersectmat


          }else{ # itemcovars == TRUE


            list_item_intersectmats <- list()

            for(index_item in 1:n.item){

              obs_one_ind <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

              list_inter_mats <- list()

              for(i in 1:n.trees){

                # treeexample1 <- sampler$getTrees(treeNums = i,
                #                                  chainNums = 1,
                #                                  sampleNums = 1)

                # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
                #                                   treeNums = i,
                #                                   chainNums = 1,
                #                                   sampleNums = 1)

                temptree <- curr_trees[[i]]$tree_matrix

                treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

                temp_na_inds <- is.na(temptree[,'split_variable'])
                treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

                # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
                #   1,#rep(sampleNums, nrow(temptree)),
                #   i,#rep(treeNums, nrow(temptree)),
                #   temptree[, 'node_size'],
                #   # mybarttree[,'split_variable'],
                #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
                #          -1,
                #          temptree[,'split_variable']),
                #   fast_ifelse(is.na(temptree[,'split_variable']) ,
                #          temptree[,'mu'],
                #          temptree[,'split_value']))
                # # rebuilt_tree <- rebuildTree2(treeexample1)

                rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

                #must use covariates for individual indiv at time period t

                # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

                list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                         as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )


              } #end loop over trees

              intersectmat <- interNtreesB(list_inter_mats)

              list_item_intersectmats[[index_item]] <- intersectmat


            } #end loop over items


            Biglist_list_item_intersectmats[[t]] <- list_item_intersectmats


          } # end else itemcovars == TRUE

        }


        # print("End loop for intersection matrices = ")


        ######## Begin loop over items ################################

        # print("Begin loop for over items = ")

        for(item_ind in 1:n.item){

          # print("item_ind = ")
          # print(item_ind)

          if(itemcovars == TRUE){
            list_item_intersectmats <- Biglist_list_item_intersectmats[[2]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[1]]


            intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            intersectmat <- Biglist_intersectmats[[2]]
            intersectmat_tmin1 <- Biglist_intersectmats[[1]]
          }

          num_regions <- nrow(intersectmat)
          num_regions_tmin1 <- nrow(intersectmat_tmin1)

          # ########### begin create intersectmat t = 1 ############
          #
          # # define intersections inside item loop
          # # to allow covariates can be item specific
          #
          # # create vector of indices for ranker indiv in time period 1
          #
          # # this part is not really necessary
          # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
          # obs_indices <- ind_start:ind_end
          #
          # # obs_indices[1] could jsut be replaced by [1] below\
          # # because the only variable is zlag, so the other covariates are not used
          #
          #
          # list_inter_mats <- list()
          #
          # for(i in 1:n.trees){
          #
          #   treeexample1 <- sampler$getTrees(treeNums = i,
          #                                    chainNums = 1,
          #                                    sampleNums = 1)
          #
          #   rebuilt_tree <- rebuildTree2(treeexample1, sampler)
          #
          #
          #   #must use covariates for individual indiv at time period t
          #
          #   list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )
          #   # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
          #
          #
          # }
          #
          # intersectmat <- interNtreesB(list_inter_mats)
          #
          # # print("Line 1146")
          #
          # intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))
          #
          # # print("Line 1150")
          #
          #
          # # calculate one dimensional integrals
          # for(rowind in 1:nrow(intersectmat)){
          #   # ktemp <- nkt_mat[rowind,k_index]
          #   # tempmean <- intersectmat[ktemp,1]
          #   templower <- intersectmat[rowind,2]
          #   tempupper <- intersectmat[rowind,3]
          #
          #   # ASSUMING PRIOR MEAN ALL ZEROS
          #
          #   # These are the q0 integrals
          #   intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
          #   # tempintegralval <- tempintegralval*onedim_int
          # }
          #
          # # intersectmat_tmin1 <- intersectmat
          #
          #
          #
          # ########### end create intersectmat t = 1 ############
          #





          #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

          # loop over items

          # Now loop over time periods

          # special case for t=1

          # probability matrix for sampling elements

          # let rows be period zero, and columns be period 1 (2?)

          # probmattemp <- matrix(0,
          #                       nrow = num_regions_tmin1,
          #                       ncol = num_regions)

          logprobmattemp <- matrix(0,
                                   nrow = num_regions_tmin1,
                                   ncol = num_regions)

          # loop over period 2 regions into which z_1 can fall


          tempbounds <- matrix(NA,
                               nrow = num_regions,
                               ncol = 2)

          # Trunc norm prob of next periods latent value conditional on region

          # Create intervals from interval t+1 latent values

          # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

          # inds for j ranked below i in t+1



          # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in t+1
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower <- -Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    belowrank_ind]
          # }
          #
          # # inds for j ranked above i in t+1
          #
          # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period t+1
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper <- Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #
          #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    aboverank_ind]
          # }


          temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                          n.item*(indiv - 1) +
                                          item_ind]

          temppaircomps <- pair.comp.ten[, , (1-1)*n.ranker + indiv]

          tempz <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                      n.item*(indiv - 1) +
                                      1:n.item]

          set1 = which( temppaircomps[item_ind, ] == 1)
          set0 = which( temppaircomps[item_ind, ] == 0)

          if(length(set1) > 0){
            temp_upper3 = min(tempz[set1])
          }else{
            temp_upper3 = Inf
          }

          if(length(set0) > 0){
            temp_lower3 = max(tempz[set0])
          }else{
            temp_lower3 = -Inf
          }

          # rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]
          #
          # # if(any(order(rankvec_t) !=
          # #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                           n.item*(indiv-1) +
          # #                           1:n.item])) ){
          # #
          # #   # print("order(rankvec_t) = ")
          # #   # print(order(rankvec_t))
          # #   #
          # #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #   #                         n.item*(indiv - 1) +
          # #   #                         1:n.item])  = ")
          # #
          # #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                                  n.item*(indiv - 1) +
          # #                                  1:n.item]) )
          # #
          # #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #   #                                n.item*(indiv - 1) +
          # #   #                                1:n.item] = ")
          # #
          # #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          # #                            n.item*(indiv - 1) +
          # #                            1:n.item])
          # #
          # # }
          #
          # # inds for j ranked below i in t
          #
          # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in t
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower3 <- -Inf
          # }else{
          #   temp_lower3 <- max(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                         n.item*(indiv - 1) +
          #                                         belowrank_ind])
          # }
          #
          # # inds for j ranked above i in t
          #
          # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period t
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper3 <- Inf
          # }else{
          #   temp_upper3 <- min(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                         n.item*(indiv - 1) +
          #                                         aboverank_ind])
          # }


          temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
                                                   mean = intersectmat[1:num_regions, 1],
                                                   sd = 1)

          for(k_ind in 1:num_regions){




            # obtain mean for truncated normal distribution
            # temp_mean <- intersectmat[k_ind, 1]

            # want trunc norm probability of latent variable value for item_ind
            # in period t+1


            # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #                               a=temp_lower,
            #                               b=Inf,
            #                               mean = temp_mean,
            #                               sd = 1)

            # tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp

            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                                 mean = temp_mean,
            #                                 sd = 1)

            # temp_tnorm_logprob <- fastlognormdens(temp_ztp1,
            #                                          mean = tempmeanfordens,
            #                                          sd = 1)

            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                          mean = temp_mean,
            #                          sd = 1)

            # temp_mean <- intersectmat[k_ind, 1]

            temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]


            # now second term


            temp_lower2 <- intersectmat[k_ind, 2]
            temp_upper2 <- intersectmat[k_ind, 3]




            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_lower3 = ")
            # print(temp_lower3)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)
            #
            # print("temp_upper3 = ")
            # print(temp_upper3)


            if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
              # intervals do not overlap, therefore assign probability zero
              # and skip to next iteration


              # print("k_ind = ")
              # print(k_ind)

              # print("ncol(temp_region_probs) = ")
              # print(ncol(temp_region_probs))

              # print("nrow(temp_region_probs) = ")
              # print(nrow(temp_region_probs))


              # these three lines are technically unnecessary
              # probmattemp[, k_ind] <- rep(0,num_regions_tmin1)
              logprobmattemp[, k_ind] <- rep(-Inf,num_regions_tmin1)
              tempbounds[k_ind, 1] <- NA
              tempbounds[k_ind, 2] <- NA

              next

            }


            temp_lower2 <- max(temp_lower2, temp_lower3)
            temp_upper2 <- min(temp_upper2, temp_upper3)

            if(temp_lower2 > temp_upper2){

              print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

              print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                       n.item*(indiv - 1) +
                                       1:n.item])

              print("item_ind = ")
              print(item_ind)

              print("rankvec_t = ")
              print(rankvec_t)

              stop("Line 1581 temp_lower2 > temp_upper2")
            }


            for(k0_ind in 1:num_regions_tmin1){

              #loop over all possible means
              temp_mean2 <- intersectmat_tmin1[k0_ind,1]

              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # probmattemp[k0_ind, k_ind] <- prob_t_region*
              #   temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob +
                log(intersectmat_tmin1[k0_ind,4])

              # if(probmattemp[k0_ind, k_ind] < 0){
              #   print("probmattemp[k0_ind, k_ind] = ")
              #   print(probmattemp[k0_ind, k_ind])
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   print("temp_tnorm_prob = ")
              #   print(temp_tnorm_prob)
              #
              #   print("intersectmat[k0_ind,4] = ")
              #   print(intersectmat[k0_ind,4])
              #
              #   print("temp_upper2 = ")
              #   print(temp_upper2)
              #
              #   print("temp_lower2 = ")
              #   print(temp_lower2)
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #
              # }


            } # end loop over k0

            # save upper and lower bounds (mean saved in intersectmat)
            # or just obtain again later

            tempbounds[k_ind,1] <- temp_lower2
            tempbounds[k_ind,2] <- temp_upper2


          } # end loop over k1


          #sample a combination of k0 and k1
          # if necessary can use column sums to sample k1, then k0
          # however, this is probably unnecessary


          # print("Line 1621 before sample")

          # region_ind <- sample.int(num_regions_tmin1*num_regions,
          #                          size = 1,
          #                          replace = TRUE,
          #                          prob = as.vector(probmattemp))


          logprobstemp <- as.vector(logprobmattemp)
          max_ll <- max(logprobstemp)
          logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
          probstemp <- exp(logprobstemp - logsumexps)

          region_ind <- sample.int(num_regions_tmin1*num_regions,
                                   size = 1,
                                   replace = TRUE,
                                   prob = as.vector(probstemp))


          # print("Line 1629 after sample")

          # k0 region is sampled number modulo number of regions in period 1
          k0_region_ind <- ((region_ind -1) %% num_regions_tmin1 ) + 1
          # if(k0_region_ind ==0){
          #   k0_region_ind <- num_regions
          # }

          # k1 region is the ceiling of sampled number divided by number of regions in period 1
          # k1_region_ind <- ceiling(region_ind/num_regions)
          k1_region_ind <- (region_ind -1) %/% num_regions_tmin1 + 1


          # print("k1_region_ind = ")
          # print(k1_region_ind)

          temp_lower2 <- tempbounds[k1_region_ind,1]
          temp_upper2 <- tempbounds[k1_region_ind,2]

          # print("num_regions = ")
          # print(num_regions)
          #
          # print("region_ind = ")
          # print(region_ind)
          #
          # print("k0_region_ind = ")
          # print(k0_region_ind)

          temp_mean0 <- intersectmat_tmin1[k0_region_ind, 1]
          # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

          # print("temp_mean0 = ")
          # print(temp_mean0)
          #
          # print("temp_lower2 = ")
          # print(temp_lower2)
          #
          # print("temp_upper2 = ")
          # print(temp_upper2)

          tempbuffer <- (temp_upper2 - temp_lower2)/100

          if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
            upper_buffered <- temp_upper2 - tempbuffer
            lower_buffered <- temp_lower2 + tempbuffer

          }else{
            upper_buffered <- temp_upper2
            lower_buffered <- temp_lower2

          }


          zdraw_temp <- rtruncnorm(n = 1,
                                   a = lower_buffered,
                                   b = upper_buffered,
                                   mean = temp_mean0,
                                   sd = 1)


          Z.mat[item_ind,  indiv ] <- zdraw_temp


          #### Begin Loop over time ###################

          # loop over time periods for general case 1 < t < T

          for(t in 2:(n.time - 1)){


            if(itemcovars == TRUE){
              list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
              list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[t]]


              intersectmat <- list_item_intersectmats[[index_item]]
              intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
            }else{
              intersectmat <- Biglist_intersectmats[[t+1]]
              intersectmat_tmin1 <- Biglist_intersectmats[[t]]
            }

            num_regions <- nrow(intersectmat)

            temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # or first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat_tmin1[, 3]) )[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

            # print("temp_mean2 = ")
            # print(temp_mean2)
            #
            # print("ktemp_tmin1 = ")
            # print(ktemp_tmin1)



            # Calculate the probabilities for each region in this time period
            # the regions being looped over are actually period t+1 regions

            # Same regions for all time periods if there are no time varying covariates

            # However, the weights are individual and time period specific

            # loop through regions


            # first column is the probabilities
            # second column is the lower bounds
            # third column is the upper bounds
            # temp_region_probs <- matrix(0,
            #                             nrow = nrow(intersectmat),
            #                             ncol = 3)

            temp_region_logprobs <- matrix(0,
                                           nrow = nrow(intersectmat),
                                           ncol = 3)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

            # inds for j ranked below i in t+1

            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            # want trunc norm probability of latent variable value for item_ind
            # in period t+1

            temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]


            temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

            tempz <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                        n.item*(indiv - 1) +
                                        1:n.item]

            set1 = which( temppaircomps[item_ind, ] == 1)
            set0 = which( temppaircomps[item_ind, ] == 0)

            if(length(set1) > 0){
              temp_upper3 = min(tempz[set1])
            }else{
              temp_upper3 = Inf
            }

            if(length(set0) > 0){
              temp_lower3 = max(tempz[set0])
            }else{
              temp_lower3 = -Inf
            }




            # rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
            #
            #
            #
            # # if(any(order(rankvec_t) !=
            # #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                           n.item*(indiv - 1) +
            # #                           1:n.item]) )){
            # #
            # #   print("order(rankvec_t) = ")
            # #   print(order(rankvec_t))
            # #
            # #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            # #                         n.item*(indiv - 1) +
            # #                         1:n.item])  = ")
            # #
            # #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                                  n.item*(indiv - 1) +
            # #                                  1:n.item]) )
            # #
            # #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                                n.item*(indiv - 1) +
            # #                                1:n.item] = ")
            # #
            # #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            # #                            n.item*(indiv - 1) +
            # #                            1:n.item])
            # #
            # #
            # # }
            #
            #
            #
            #
            #
            # # inds for j ranked below i in t
            #
            # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower3 <- -Inf
            # }else{
            #   temp_lower3 <- max(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         belowrank_ind])
            # }
            #
            # # inds for j ranked above i in t
            #
            # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper3 <- Inf
            # }else{
            #   temp_upper3 <- min(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                         n.item*(indiv - 1) +
            #                                         aboverank_ind])
            # }



            temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
                                                     mean = intersectmat[1:num_regions, 1],
                                                     sd = 1)


            for(k_ind in 1:num_regions){



              # obtain mean for truncated normal distribution
              # temp_mean <- intersectmat[k_ind, 1]



              # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #                               a=temp_lower,
              #                               b=Inf,
              #                               mean = temp_mean,
              #                               sd = 1)

              # tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp

              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                                 mean = temp_mean,
              #                                 sd = 1)

              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                          mean = temp_mean,
              #                          sd = 1)

              temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]


              # Probability of z_t in intersection of
              # region k_ind (for period t+1)
              # and region defined by period t latent variables for other individuals
              # and rank for period t


              # tildeC_ktminl corresponds to
              # period t+1 k_ind region intereval

              temp_lower2 <- intersectmat[k_ind, 2]
              temp_upper2 <- intersectmat[k_ind, 3]



              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_upper2 = ")
              # print(temp_upper2)
              #
              # print("temp_lower3 = ")
              # print(temp_lower3)
              #
              # print("temp_upper3 = ")
              # print(temp_upper3)


              if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
                # intervals do not overlap, therefore assign probability zero
                # and skip to next iteration

                # print("k_ind = ")
                # print(k_ind)

                # print("ncol(temp_region_probs) = ")
                # print(ncol(temp_region_probs))

                # print("nrow(temp_region_probs) = ")
                # print(nrow(temp_region_probs))

                # temp_region_probs[k_ind, 1] <- 0
                # temp_region_probs[k_ind, 2] <- NA
                # temp_region_probs[k_ind, 3] <- NA

                temp_region_logprobs[k_ind, 1] <- -Inf
                temp_region_logprobs[k_ind, 2] <- NA
                temp_region_logprobs[k_ind, 3] <- NA

                next
              }

              temp_lower2 <- max(temp_lower2, temp_lower3)
              temp_upper2 <- min(temp_upper2, temp_upper3)


              if(temp_lower2 > temp_upper2){

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")
                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])
                print("item_ind = ")
                print(item_ind)

                print("rankvec_t = ")
                print(rankvec_t)


                print("temp_lower2 = ")
                print(temp_lower2)

                print("temp_upper2 = ")
                print(temp_upper2)

                stop("Line 1917. temp_lower2 > temp_upper2")
              }



              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # print("temp_upper2 = ")
              # print(temp_upper2)
              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              #
              # print("prob_t_region = ")
              # print(prob_t_region)
              #
              # print("temp_tnorm_prob = ")
              # print(temp_tnorm_prob)

              # prob_t_region <- prob_t_region*temp_tnorm_prob
              # prob_t_region <- temp_tnorm_prob
              logprob_t_region <- temp_tnorm_logprob

              # save region probability

              # and save region bounds (or maybe more memory efficient to obtain the region again)

              # must multiply by other previously obtained probabilities

              # print("prob_t_region = ")
              # print(prob_t_region)

              # temp_region_probs[k_ind, 1] <- prob_t_region
              # temp_region_probs[k_ind, 2] <- temp_lower2
              # temp_region_probs[k_ind, 3] <- temp_upper2

              temp_region_logprobs[k_ind, 1] <- logprob_t_region
              temp_region_logprobs[k_ind, 2] <- temp_lower2
              temp_region_logprobs[k_ind, 3] <- temp_upper2


            }


            # sample a region using probabilities obtained above

            # print("Line 1903 before sample")

            # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])


            logprobstemp <- as.vector(temp_region_logprobs[,1])
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int(num_regions, 1, replace = TRUE,
                                     prob = probstemp)


            # print("Line 1914 after sample")

            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
            #
            # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
            #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
            #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
            #
            # }else{
            #   upper_buffered <- temp_region_probs[region_ind, 3]
            #   lower_buffered <- temp_region_probs[region_ind, 2]
            #
            # }

            tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/50

            if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
              upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
              lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer

            }else{
              upper_buffered <- temp_region_logprobs[region_ind, 3]
              lower_buffered <- temp_region_logprobs[region_ind, 2]

            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a=lower_buffered,
                                     b=upper_buffered,
                                     mean = temp_mean2,
                                     sd = 1)

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a=temp_region_probs[region_ind, 2],
            #                          b=temp_region_probs[region_ind, 3],
            #                          mean = temp_mean2,
            #                          sd = 1)



            Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



          } # end loop over time periods

          # check for special cases for n.time - 1, n.time - 2, n.time - 3

          # special case for t = n.time


          if(itemcovars == TRUE){
            # list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[n.time]]


            # intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            # intersectmat <- Biglist_intersectmats[[t+1]]
            intersectmat_tmin1 <- Biglist_intersectmats[[n.time]]
          }

          num_regions <- nrow(intersectmat)

          temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             item_ind]


          # must find mean corresponding to z in period t-1
          # This will be used in and after the loop over regions.
          # can directly obtain from dbarts
          # or find region
          # and use already saved region mean values


          # must find last lower bound that temp_ztpmin1 is greater than
          # for first upper bound that temp_ztpmin1 is below
          ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat_tmin1[, 3])[1]
          # Then obtain the corresponding region mean value
          temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

          # now find interval

          # tildeC_ktminl corresponds to
          # period t+1 k_ind region intereval



          temppaircomps <- pair.comp.ten[, , (n.time-1)*n.ranker + indiv]

          tempz <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                                     n.item*(indiv - 1) +
                                                                     1:n.item]

          set1 = which( temppaircomps[item_ind, ] == 1)
          set0 = which( temppaircomps[item_ind, ] == 0)

          if(length(set1) > 0){
            temp_upper3 = min(tempz[set1])
          }else{
            temp_upper3 = Inf
          }

          if(length(set0) > 0){
            temp_lower3 = max(tempz[set0])
          }else{
            temp_lower3 = -Inf
          }

          # rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]
          #
          # # inds for j ranked below i in T
          #
          # belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in T
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower3 <- -Inf
          # }else{
          #   temp_lower3 <- max(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
          #                                         n.item*(indiv - 1) +
          #                                         belowrank_ind])
          # }
          #
          # # inds for j ranked above i in T
          #
          # aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period T
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper3 <- Inf
          # }else{
          #
          #   temp_upper3 <- min(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
          #                                         n.item*(indiv - 1) +
          #                                         aboverank_ind])
          # }


          # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

          # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED
          tempbuffer <- (temp_upper3 - temp_lower3)/100

          if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
            upper_buffered <- temp_upper3 - tempbuffer
            lower_buffered <- temp_lower3 + tempbuffer

          }else{
            upper_buffered <- temp_upper3
            lower_buffered <- temp_lower3

          }

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = lower_buffered,
                                   b = upper_buffered,
                                   mean = temp_mean2,
                                   sd = 1)

          # zdraw_temp <- rtruncnorm(n = 1,
          #                          a = temp_lower3,
          #                          b = temp_upper3,
          #                          mean = temp_mean2,
          #                          sd = 1)

          if(is.na(zdraw_temp)){
            print(" line 2367")
            print("temp_lower3] = ")
            print(temp_lower3)

            print("temp_upper3 = ")
            print(temp_upper3)

            print("temp_mean2 = ")
            print(temp_mean2)

            stop("NA zdraw_temp")
          }

          Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





        } # end loop over items



      } # end loop over individuals indiv in 1:n.ranker

    }




    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    # #THEN use SetPredictor
    #
    # # if (i <= n_warmup) {
    # #   for(j in 1:num_lags){
    # #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    # #     }
    # # } else{
    # temp_break <- 0
    # for(j in 1:num_lags){
    #   # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #
    #   while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {
    #
    #     if(seq_z_draws==1){
    #       stop("updates still not consistent with tree structure")
    #     }
    #     print("new z values not consistent with tree structure, must draw again")
    #
    #     # If this error message occurs
    #     # Check the conditions in the dbart package for setPredictor == FALSE
    #     # And if this is hypothetically possible, even with draws from the smoothing distribution,
    #     # and if it is not a bug
    #     # then need to go back to beginning of this iteration of the Gibbs sampler
    #     # and sample Zmat again
    #
    #
    #     temp_break <- 1
    #     break
    #     # stop("new z values not consistent with tree structure, must draw again")
    #
    #
    #     # #perhaps this can be rewritten to just re-draw the relevant column?
    #     # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #     #                                           Z.mat = Z.mat,
    #     #                                           mu = mu,
    #     #                                           weight.vec = rep(1, n.ranker*n.time),
    #     #                                           n.ranker = n.ranker*n.time,
    #     #                                           n.item = n.item )
    #     #
    #     # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #     #
    #     # for(t in 1:num_lags){
    #     #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #     #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #     #
    #     #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #     #
    #     # }
    #     #
    #     # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j
    #
    #   }
    #
    #   if(temp_break==1){
    #     break
    #   }
    # }
    #
    # # if need to draw z values again, go back to start of loop
    # if(temp_break==1){
    #   if(breakcount == 10){
    #     Z.mat <- Z.matold
    #     Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #     for(t in 1:num_lags){
    #       init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #       # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #       Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #
    #     }
    #
    #   }else{
    #     breakcount <- breakcount +1
    #     next
    #   }
    #
    # }
    #
    # breakcount <- 0
    # # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    # #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # mutemp <- sampler$predict(df_for_dbart)
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mu = mutemp
    #
    # if(nrow(X.train)==n.item){
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #
    #   #mu = mutemp[(1:n.item)]
    #   mu = mutemp[n.item+(1:n.item)]
    #
    #
    #
    #
    #   # if(mutemp[1]!= mutemp[n.item+1]){
    #   if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
    #     print("iteration number")
    #     print(iter)
    #     print("n.item = ")
    #     print(n.item)
    #     print("mutemp = ")
    #     print(mutemp)
    #     stop("mutemp[1]!= mutemp[n.item+1]")
    #   }
    #
    #
    #   #mu = mutemp[(1:n.item)*n.ranker]
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     mu = mutemp
    #   }else{
    #     stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    #
    # }



    ########

    # update training data matrix #

    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )

      Xmat.train.no.y <- cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                  ncol =  ncol(X.train) + num_lags ,
                                                  byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")

        Xmat.test.no.y <- cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                       ncol =  ncol(X.test) , byrow = TRUE ) )




        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        Xmat.train.no.y <- cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          Xmat.test.no.y <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }




    # Must update node sizes for original tree
    # update all node sizes before new proposal

    # Must update node sizes for original tree
    # update all node sizes before new proposal

    for (j in 1:n.trees) {
      # print("curr_trees[[j]] = ")
      # print(curr_trees[[j]] )

      curr_trees[[j]] <- fill_tree_details(curr_trees[[j]],
                                           Xmat.train.no.y)

      # print("line 2785, curr_trees[[j]] = ")
      # print(curr_trees[[j]] )
      # must also update individual tree predictions for calcualtion of partial residuals
      tree_fits_store[,j]  = get_predictions(curr_trees[[j]], Xmat.train.no.y, single_tree = TRUE)

    }

    # option: prune all empty nodes from current trees before proposal?
    # must create new function for this
    # perhaps an issue is that there would not be a (umique) mu value
    # associated with a parent of an empty node
    # print("line 2791")

    # must update mu before and after trees updated because covariates have been updated

    mutemp = get_predictions(curr_trees, Xmat.train.no.y, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))

    # print("line 2801")

    # Start looping through trees
    for (j in 1:n.trees) {

      current_partial_residuals = as.vector(Z.mat) - mu + tree_fits_store[,j]

      # Propose a new tree via grow/change/prune/swap
      type = sample_move(curr_trees[[j]], iter, 0, # nburn # no burnin number, so setting to 100, maybe this is not optimal
                         trans_prob)


      # option: edit the proposal step so that any proposed tree does not contain empty nodes?
      # must create new function for this

      # Generate a new tree based on the current
      if(no_empty_proposals == TRUE){

        new_trees[[j]] = noempty_update_tree(y = as.vector(Z.mat),
                                             X = Xmat.train.no.y,
                                             type = type,
                                             curr_tree = curr_trees[[j]],
                                             node_min_size = node_min_size,
                                             s = s,
                                             splitting_rules = splitting_rules,
                                             max_bad_trees = max_bad_trees)

      }else{
        new_trees[[j]] = update_tree(y = as.vector(Z.mat),
                                     X = Xmat.train.no.y,
                                     type = type,
                                     curr_tree = curr_trees[[j]],
                                     node_min_size = node_min_size,
                                     s = s,
                                     splitting_rules = splitting_rules,
                                     max_bad_trees = max_bad_trees)

      }




      # print("line 2825")


      # CURRENT TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_old = tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(curr_trees[[j]], alpha, beta)

      # print("line 2825")
      #
      # print("new_trees[[j]]")
      # print(new_trees[[j]])

      # NEW TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_new = tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(new_trees[[j]], alpha, beta)

      # Exponentiate and multiply by the transition probabilities

      if(type == 'grow'){
        a = exp(l_new - l_old)*ratio_grow(new_trees[[j]], curr_trees[[j]])
      } else if(type == 'prune'){
        a = exp(l_new - l_old)*ratio_prune(new_trees[[j]], curr_trees[[j]])
      } else{
        a = exp(l_new - l_old)
      }

      vars_empty_pruned <- c()

      if(a > runif(1)) {
        curr_trees[[j]] = new_trees[[j]]
        # only account for pruning if  accept
        vars_empty_pruned <- new_trees[[j]]$vars_empty_pruned

        for(var_ind in vars_empty_pruned){
          var_count[var_ind ] = var_count[var_ind ] - 1
        }


        if (type =='change'){
          var_count[curr_trees[[j]]$var[1] ] = var_count[curr_trees[[j]]$var[1] ] - 1
          var_count[curr_trees[[j]]$var[2] ] = var_count[curr_trees[[j]]$var[2] ] + 1
        }

        if (type=='grow'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] + 1
        } # -1 because of the intercept in X

        if (type=='prune'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] - 1
        } # -1 because of the intercept in X

      }


      ### might need to edit simulate_mu to find right terminal nodes #########

      # Update mu whether tree accepted or not
      curr_trees[[j]] = simulate_mu(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)
      # Updating BART predictions
      current_fit = get_predictions(curr_trees[[j]], Xmat.train.no.y, single_tree = TRUE)
      mu = mu - tree_fits_store[,j] # subtract the old fit
      mu = mu + current_fit # add the new fit
      tree_fits_store[,j] = current_fit # update the new fit

    } # End loop through trees



    # sum_of_squares = sum((y_scale - y_hat)^2)

    # Update sigma2 (variance of the residuals)
    # sigma2 = update_sigma2(sum_of_squares, n = length(y_scale), nu, lambda)
    # variance kept equal to 1, do not update

    # # Update s = (s_1, ..., s_p), where s_p is the probability that predictor p is used to create new terminal nodes
    # if (sparse == 'TRUE' & i > floor(iter.max*0.1)){
    #   s = update_s(var_count, ncol(Xmat.train.no.y), 1)
    # }


    # Update s = (s_1, ..., s_p), where s_p is the probability that predictor q in 1:p is used to create new terminal nodes
    if (sparse & i > floor(iter.max * 0.25)) {
      s_update <- update_s(var_count, p, alpha_s)
      s <- s_update[[1]]

      if(alpha_prior){
        alpha_s <- update_alpha(s, alpha_scale, alpha_a, alpha_b, p, s_update[[2]])
      }
    }

    if(sigma_mu_prior){
      sigma2_mu <-  update_sigma_mu_par(curr_trees, sigma2_mu)
    }




    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta



    #
    #     # if(is.null(initial.list)){
    #     # print("samplestemp$test[,1] = ")
    #     # print(samplestemp$test[,1])
    #
    #     # mupreds <- sampler$predict(df_for_dbart)
    #
    #     # Xmat.test[,1:num_lags] <-  Zlag.mat.test
    #
    #
    #     temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))
    #
    #     for(t  in 1:num_lags){
    #       if(noise_in_pred ==1){
    #         temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
    #       }else{
    #         temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
    #       }
    #
    #     }
    #
    #     # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #     #                                                                      (num_lags+1):ncol(Xmat.test)])
    #
    #     temp_test_mat <- data.frame(x = temp_test_mat)
    #     colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #     # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    #     temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    #     print("Line 5488")
    #
    #
    #     temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    #
    #
    #     # if(iter < 5){
    #     #   print("temp_test_mat = " )
    #     #   print(temp_test_mat)
    #     # }
    #
    #     for(t1 in 1:num_test_periods){
    #       #produce a prediction
    #
    #       # must use original column names to prevent an error in the predict function
    #       colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #       testpredvec <- sampler$predict(temp_test_mat)
    #
    #       #fill in temp_test_preds with noise
    #       if(noise_in_pred ==1){
    #         temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #       }else{
    #         temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
    #       }
    #
    #
    #       #update temp_test_mat
    #       #shift z columns to the right and fill in leftmost column
    #
    #       #need to rewrite this if want to allow for no observed covariates
    #
    #       # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )
    #
    #       if(t1 != num_test_periods){
    #
    #
    #         if(num_lags ==1){
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }else{
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
    #                                                  temp_test_mat[,1:(num_lags-1)] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }
    #       }
    #
    #       # colnames(temp_test_mat) <- colnames(Xmat.test)
    #
    #
    #       #fill in temp_mu_test without noise
    #       temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    #     }
    #
    #     #also update Zlag.mat.test ?
    #     #perhaps this is unnecessary here?
    #
    #     print("Line 5545")
    #
    #
    #     Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    #     # if(nrow(X.test) >0 ){
    #     for(t in 1:num_lags){
    #       # if(t==1){
    #       #   #repeating the last period values
    #       #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #       #
    #       #   #other option is to set all unobservable values to zero
    #       #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #       #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #       #
    #       #
    #       # }else{
    #
    #       if(num_test_periods > t ){
    #         #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #       }else{
    #         #nothing to fill in if num_test_periods <= t
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #       }
    #
    #
    #       # }
    #     }
    #     # }
    #
    #     # if(nrow(X.test)>0){
    #     #
    #     #
    #     #   for(j in 1:num_lags){
    #     #
    #     #     #perhaps this should be removed for when Z is updated properly below
    #     #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #     #
    #     #   }
    #     #
    #     # }
    #
    #
    #     draw$mu_test[,iter] <- temp_mu_test
    #     # draw$mu_test[,iter] <- samplestemp$test[,1]
    #
    #     if(keep_zmat==TRUE){
    #       draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    #     }
    #
    #     # draw$mu_test[,1] <- samplestemp$test[,1]
    #
    #     # }else{
    #     #   draw$mu_test[,1] <- initial.list$mu_test
    #     # }
    #


    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        if(noise_in_pred ==1){
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }

      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      temp_test_mat <- data.frame(x = temp_test_mat)
      colnames(temp_test_mat) <- colnames(Xmat.test)

      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )


      # if(iter < 5){
      #   print("temp_test_mat = " )
      #   print(temp_test_mat)
      # }

      for(t1 in 1:num_test_periods){
        #produce a prediction
        # testpredvec <- sampler$predict(temp_test_mat)
        testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }


        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){


          if(num_lags ==1){
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }else{
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      temp_test_mat[,1:(num_lags-1)] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }
        }

        colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }

      # if(nrow(X.test)>0){
      #
      #
      #   for(j in 1:num_lags){
      #
      #     #perhaps this should be removed for when Z is updated properly below
      #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
      #
      #   }
      #
      # }


      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }
    if(sparse){
      draw$alpha_s_store[iter] <- alpha_s
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_store[iter,] <- var_count
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_store[iter,] <- s
      # draw$s_prob_z_store[iter,] <- s_z
    }

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }


    iter <- iter+1
  }


  return(draw)
}









##////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with partial ranks and without Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and without covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @import collapse
#' @importFrom MCMCpack 'rdirichlet'
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @export
ARRObartNOCovars_fullcond_EmpN_topk <- function(ranks_mat, # pair.comp.ten,
                                                 # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                                 # X.test = matrix(NA, nrow =0, ncol = 0),
                                                 # tau2.alpha = 5^2,
                                                 # nu.alpha = 3,
                                                 # tau2.beta = 5^2,
                                                 # nu.beta = 3,
                                                 n.item,# = dim(pair.comp.ten)[1],
                                                 n.rankerbytime, # = dim(pair.comp.ten)[3],
                                                 n.ranker,
                                                 n.time,
                                                 # p.cov = ncol(X.train),
                                                 iter.max = 5000,
                                                 para.expan = TRUE,
                                                 print.opt = 100,
                                                 initial.list = NULL,
                                                 n.trees = 50L,
                                                 n.burn = 0L,
                                                 n.samples = 1L,
                                                 n.thin = 1L,
                                                 trans_prob = c(2.5, 2.5, 4) / 9, # Probabilities to grow, prune or change, respectively
                                                 n.chains = 1,
                                                 n.threads = 1L,#guessNumCores(),
                                                 printEvery = 100L,
                                                 printCutoffs = 0L,
                                                 rngKind = "default",
                                                 rngNormalKind = "default",
                                                 rngSeed = NA_integer_,
                                                 updateState = FALSE,
                                                 num_lags = 1,
                                                 diff_num_test_rankers = 0,
                                                 keep_zmat = FALSE,
                                                 noise_in_pred = 0,
                                                 seq_z_draws = 1,
                                                 N_hdr = 100,
                                                 rho_hdr = 0.5,
                                                 smoothing_method = "AR",
                                                 num_horizon = 1,
                                                 num_z_iters = 10,
                                                 node_min_size = 5,
                                                 k = 2,
                                                 sigquant = .90,
                                                 alpha = 0.95,
                                                 beta = 2,
                                                 nu = 3,
                                                 lambda = 0.1,
                                                 no_empty_proposals = FALSE,
                                                 alpha_prior = FALSE,
                                                 sigma_mu_prior = FALSE,
                                                 splitting_rules = "discrete",
                                                 loop_order = "time_in_item",
                                                 max_bad_trees = 10,
                                                sparse = FALSE,
                                                alpha_a_y = 0.5,
                                                alpha_b_y = 1,
                                                alpha_split_prior = TRUE){


  if(!(loop_order %in% c("time_in_item", "item_in_time"))){
    stop("loop_order must be 'time_in_item' or 'item_in_time'.")
  }


  if(!(splitting_rules %in% c("discrete", "continuous"))){
    stop("splitting_rules must be 'discrete' or 'continuous'.")
  }

  ######### set up things for myBART implementation ####################

  # Extract control parameters
  # we only have to allow for empty nodes when updating Z (and therefore Zlag is updated and splits on Zlag are affected)
  # Therefore there is still a minimum node size criterion for the purpose of proposing new splits
  node_min_size = node_min_size

  # Storage containers
  store_size = iter.max # npost # code currently written to save all output, so no nburnin or npost
  tree_store = vector('list', store_size)
  sigma2_store = rep(NA, store_size)
  # y_hat_store = matrix(NA, ncol = length(y), nrow = store_size)
  # var_count = rep(0, ncol(x))
  # var_count_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # s_prob_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # tree_fits_store = matrix(0, ncol = n.trees, nrow = length(y))

  sigma2 <- 1 # keep sigma2 set to 1


  ########## beginning of original code ############################

  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  # length_mu_test <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  # ranks_mat <- matrix(NA,
  #                     ncol = n.ranker*n.time,
  #                     nrow = n.item )
  #
  #
  # #n.item by n.item
  #
  # for(t in 1:n.time){
  #
  #   for(indiv in 1:n.ranker){
  #     pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]
  #
  #     # 1 corresponding to "highest rank" . i.e. highest utility ite,
  #     # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1
  #
  #     # 1 corresponding to "lowest rank". i.e. lowest utility item
  #
  #     # up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
  #     up.order = -rowSums( pair.comp, na.rm = TRUE ) + n.item
  #
  #     ranks_mat[, (t-1)*n.ranker + indiv] <- up.order
  #
  #   }
  # }


  # # it might be more efficient to create and save all rank constraint matrices at this stage
  #
  #
  # rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))
  #
  # for(indiv in 1:n.ranker){
  #
  #   for(t in 1:n.time){
  #
  #     rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
  #
  #
  #     rankconstraint_t <- matrix(0,
  #                                nrow = n.item - 1,
  #                                ncol = n.item)
  #
  #     # note: ordering of rows is unimportant
  #     # as long as ordering agrees with the ordering of the mean vector
  #
  #     # so can begin by filling in first row
  #
  #     #MUST BE EDITED IF ALLOW FOR TIES
  #     for(rankind in 1:(length(rankvec_t)-1)){
  #
  #       rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
  #       rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1
  #
  #       # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
  #       # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1
  #
  #     }
  #
  #     rank_cons_arr[, , indiv, t] <- rankconstraint_t
  #
  #   }
  # }
  # # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  # boundconstraints <- matrix(NA,
  #                            nrow = 2*n.item,
  #                            ncol = n.item)
  #
  # # use kroenecker product
  # # there is probably a more efficient way of doing this
  #
  # boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      # pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))
      # ranks_mat[,j] <-
      #   Z.mat[,j]

      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))


      tempsort <- sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE )

      Z.mat[ tempsort$ix , j] <-
        qnorm(  tempsort$x   /(n.item+1)) +
        rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues
      # if separate noise for each item, then would need to preserve ranks

      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   qnorm(c(n.item : 1)/(n.item+1)) +
      #   rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues
      # # if separate noise for each item, then would need to preserve ranks


      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j]/5

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(n =  t*n.item*n.ranker, mean = 0, sd = 0.005) #maybe add some noise to avoid splitting issues?
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }

    ##### old dbarts initialization ###############

    # # print("Line 799.")
    #
    # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )
    #
    #
    # control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
    #                          keepTrees = TRUE,
    #                          n.trees = n.trees,
    #                          n.burn = n.burn,
    #                          n.samples = n.samples,
    #                          n.thin = n.thin,
    #                          n.chains = n.chains,
    #                          n.threads = n.threads,
    #                          printEvery = printEvery,
    #                          printCutoffs = printCutoffs,
    #                          rngKind = rngKind,
    #                          rngNormalKind = rngNormalKind,
    #                          rngSeed = rngSeed)
    #
    #
    # # print(colnames(Xmat.train))
    # # print(colnames(Xmat.test))
    #
    # # print("begin dbarts")
    #
    #
    # # if(nrow(X.test )==0){
    # sampler <- dbarts(y ~ .,
    #                   data = df_for_dbart,
    #                   #test = Xmat.test,
    #                   control = control,
    #                   resid.prior = fixed(1),
    #                   sigma=1 #check if this is the correct approach for setting the variance to 1
    # )
    #
    # # }else{
    # #   sampler <- dbarts(y ~ .,
    # #                     data = Xmat.train,
    # #                     test = Xmat.test,
    # #                     control = control,
    # #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    # #                     sigma=1 #
    # #   )
    # #
    # # }
    #
    # # print("error after dbarts")
    #
    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    #
    # #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # sampler$sampleTreesFromPrior()
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mupreds <- sampler$predict(Xmat.train)
    #
    # mu <- mutemp


    y_hat_store = matrix(NA, ncol = length(as.vector(Z.mat)), nrow = store_size)
    var_count = rep(0, ncol(Zlag.mat))
    var_count_store = matrix(0, ncol = ncol(Zlag.mat), nrow = store_size)
    s_prob_store = matrix(0, ncol = ncol(Zlag.mat), nrow = store_size)
    tree_fits_store = matrix(0, ncol = n.trees, nrow = length(as.vector(Z.mat)))
    s = rep(1/ncol(Zlag.mat), ncol(Zlag.mat))

    p <- ncol(Zlag.mat)
    rho <- p # For DART

    alpha_s <- 1 # p

    alpha_scale <- p

    ###### new myBART initialization ######################

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }
    }

    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }

    # maybe (max(as.vector(Z.mat))-min(as.vector(Z.mat)))
    # can be replaced by something else
    # sigma2_mu <- (max(as.vector(Z.mat))-min(as.vector(Z.mat)))/((2 * k * sqrt(n.trees))^2)
    sigma2_mu <- ((max(as.vector(Z.mat))-min(as.vector(Z.mat)))/(2 * k * sqrt(n.trees)))^2

    # sigma2_mu <- 1/n.trees

    # Create a list of trees for the initial stump
    curr_trees = create_stump(num_trees = n.trees,
                              y = as.vector(Z.mat),
                              X = Zlag.mat)
    # Initialise the new trees as current one
    new_trees = curr_trees

    # Initialise the predicted values to zero
    mutemp = get_predictions(curr_trees, Zlag.mat, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))



  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  # print("Line 954")


  df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    temp_test_mat <- data.frame(x = as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      # testpredvec <- sampler$predict(temp_test_mat)

      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)



      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker), ] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),] )))

      }

      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  if(any(is.na(Z.mat))){
    print("Z.mat = ")
    print(Z.mat)
    stop("NA values in initial Z.mat")

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration

  iter <- 2
  breakcount <- 0
  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    # Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############


    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }


    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }

      # tempsort <- sort(tempcol)
      #
      # tempdiffs <- tempsort[-1] - tempsort[-(length(tempsort))]

      # if( any( abs(tempdiffs) < 0.001 )   ){
      #
      #   print("tempsort =")
      #   print(tempsort)
      #   print("tempdiffs =")
      #   print(tempdiffs)
      #   print("j = ")
      #   print(j)
      #   print("tempcol =")
      #   print(tempcol)
      #   print("Z.mat =")
      #   print(Z.mat)
      #   print(" some differences in Z vector very small")
      # }

    }


    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA

    # create vector of indices for ranker indiv in time period 1

    # # this part is not really necessary
    # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
    # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
    # obs_indices <- ind_start:ind_end

    # obs_indices[1] could jsut be replaced by [1] below\
    # because the only variable is zlag, so the other covariates are not used


    list_inter_mats <- list()

    emptynodecount <- 0

    for(i in 1:n.trees){



      ####### new tree structures, so need new functions to rebuild trees, create intersections etc

      ### dbarts getTrees returns a matrix with columns:
      ### sample, tree, n, var. and value

      ### simplest, but not most efficient, thing to do is to convert the tree structure
      ### from myBart format to dbarts format.




      # treeexample1_db <- sampler$getTrees(treeNums = i,
      #                                     chainNums = 1,
      #                                     sampleNums = 1)


      # print("curr_trees[[i]]$tree_matrix = ")
      # print(curr_trees[[i]]$tree_matrix)

      temptree <- curr_trees[[i]]$tree_matrix

      # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
      #                                   treeNums = i,
      #                                   chainNums = 1,
      #                                   sampleNums = 1)

      emptynodecount <- emptynodecount + sum(temptree[, 'node_size'] == 0)

      treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

      temp_na_inds <- is.na(temptree[,'split_variable'])
      treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

      # temp_nainds <- is.na(temptree[,'split_variable'])
      # treeexample1[temp_nainds, ] <- cbind(1, i, temptree[, 'node_size'], -1, temptree[,'mu'] )
      # treeexample1[!temp_nainds, ] <- cbind(1, i, temptree[, c('node_size','mu', 'split_variable' )])
      #
      # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
      #   1,#rep(sampleNums, nrow(temptree)),
      #   i,#rep(treeNums, nrow(temptree)),
      #   temptree[, 'node_size'],
      #   # mybarttree[,'split_variable'],
      #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
      #          -1,
      #          temptree[,'split_variable']),
      #   fast_ifelse(is.na(temptree[,'split_variable']) ,
      #          temptree[,'mu'],
      #          temptree[,'split_value']))


      # print("treeexample1 = ")
      # print(treeexample1)

      # rebuilt_tree <- rebuildTree2(treeexample1)
      rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

      # print("rebuilt_tree = ")
      # print(rebuilt_tree)

      #must use covariates for individual indiv at time period t

      # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )

      # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
      list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree[,4] == -1 , 5:7, drop = FALSE]


      # print("list_inter_mats[[i]] = ")
      # print(list_inter_mats[[i]])
    }

    # print("line 1468")

    intersectmat <- interNtreesB(list_inter_mats)

    # print("Line 1146")

    intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))


    # print(" emptynodecount = ")
    # print(emptynodecount)

    if(nrow(intersectmat) > 350){

      print("nrow(intersectmat) > 350")
      print("intersectmat = ")
      print(intersectmat)


    }

    # print("Line 1150")

    # print("line 1478")

    # calculate one dimensional integrals
    for(rowind in 1:nrow(intersectmat)){
      # ktemp <- nkt_mat[rowind,k_index]
      # tempmean <- intersectmat[ktemp,1]
      templower <- intersectmat[rowind,2]
      tempupper <- intersectmat[rowind,3]

      # ASSUMING PRIOR MEAN ALL ZEROS

      # These are the q0 integrals
      intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
      # tempintegralval <- tempintegralval*onedim_int
    }

    intersectmat_tmin1 <- intersectmat



    num_regions <- nrow(intersectmat)

    # print("Line 1169")

    # print("nrow(intersectmat) = ")
    # print(nrow(intersectmat))

    if(loop_order == "time_in_item"){
      for(z_iter_ind in 1:num_z_iters){


        for(indiv in 1:n.ranker){

          # print("indiv = ")
          # print(indiv)
          ########### calculate qkt  ########################################

          ########### calculate qkt   for t = 1 ########################################


          ### calculate qkt integrals for time period t = 1  ################

          # These integrals are already calculated and saved as intersectmat[ktemp,4]

          for(item_ind in 1:n.item){


            #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

            # loop over items

            # Now loop over time periods

            # special case for t=1

            # probability matrix for sampling elements

            # let rows be period zero, and columns be period 1 (2?)

            # probmattemp <- matrix(0,
            #                       nrow = num_regions,
            #                       ncol = num_regions)

            logprobmattemp <- matrix(0,
                                     nrow = num_regions,
                                     ncol = num_regions)

            # loop over period 2 regions into which z_1 can fall


            tempbounds <- matrix(NA,
                                 nrow = num_regions,
                                 ncol = 2)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

            # inds for j ranked below i in t+1



            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]



            rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]

            # if(any(order(rankvec_t) !=
            #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                           n.item*(indiv-1) +
            #                           1:n.item])) ){
            #
            #   # print("order(rankvec_t) = ")
            #   # print(order(rankvec_t))
            #   #
            #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                         n.item*(indiv - 1) +
            #   #                         1:n.item])  = ")
            #
            #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                  n.item*(indiv - 1) +
            #                                  1:n.item]) )
            #
            #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                                n.item*(indiv - 1) +
            #   #                                1:n.item] = ")
            #
            #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item])
            #
            # }

            # inds for j ranked below i in t

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in t
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- max(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind])
            }

            # inds for j ranked above i in t

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period t

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- min(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind])
            }

            # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
            tempmeanfordens <- intersectmat[1:num_regions, 1]

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                    mean = tempmeanfordens,
            #                                    sd = 1)


            if(temp_lower3 >= temp_upper3){
              print(" temp_lower3 = ")
              print(temp_lower3)

              print(" temp_upper3 = ")
              print(temp_upper3)

              stop("Line 1844. temp_lower3 >= temp_upper3")
            }


            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                 mean = intersectmat[1:num_regions, 1],
            #                                 sd = 1)

            # find intervals that do not overlap

            bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

            logprobmattemp[, bad_regions] <- -Inf #rep(-Inf,num_regions)
            tempbounds[bad_regions, 1] <- NA
            tempbounds[bad_regions, 2] <- NA

            good_regions <- setdiff(1:num_regions, bad_regions)


            temp_tnorm_logprobvec <- rep(NA, num_regions)
            temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                   mean = tempmeanfordens[good_regions],
                                                                   sd = 1)


            # logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprobvec[k_ind] +
            #   log(intersectmat[1:num_regions,4])

            logprobmattemp[1:num_regions, good_regions] <- outer(log(intersectmat[1:num_regions,4]),
                                                                 temp_tnorm_logprobvec[good_regions],
                                                                 FUN = "+")


            tempbounds[good_regions,1] <- pmax(intersectmat[good_regions, 2], temp_lower3)
            tempbounds[good_regions,2] <- pmin(intersectmat[good_regions, 3], temp_upper3)

            if(any(tempbounds[good_regions,1] >= tempbounds[good_regions,2])){
              stop(" line 1868 bounds badly defined")
            }

            # CAN VECTORIZE THIS EVEN MORE

            # # for(k_ind in 1:num_regions){
            # for(k_ind in good_regions){
            #     # obtain mean for truncated normal distribution
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # want trunc norm probability of latent variable value for item_ind
            #   # in period t+1
            #
            #
            #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #   #                               a=temp_lower,
            #   #                               b=Inf,
            #   #                               mean = temp_mean,
            #   #                               sd = 1)
            #
            #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #   #                          mean = temp_mean,
            #   #                          sd = 1)
            #
            #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
            #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
            #
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # now second term
            #
            #   temp_lower2 <- intersectmat[k_ind, 2]
            #   temp_upper2 <- intersectmat[k_ind, 3]
            #
            #
            #   # print(" line 1697 ")
            #   #
            #   # print("temp_lower2 = ")
            #   # print(temp_lower2)
            #   #
            #   # print("temp_lower3 = ")
            #   # print(temp_lower3)
            #   #
            #   # print("temp_upper2 = ")
            #   # print(temp_upper2)
            #   #
            #   # print("temp_upper3 = ")
            #   # print(temp_upper3)
            #
            #
            #   # if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
            #   #   # if((temp_lower2 - temp_upper3) > -0.001 | (temp_lower3 - temp_upper2 > -0.001)){
            #   #   # intervals do not overlap, therefore assign probability zero
            #   #   # and skip to next iteration
            #   #
            #   #
            #   #   # print("k_ind = ")
            #   #   # print(k_ind)
            #   #
            #   #   # print("ncol(temp_region_probs) = ")
            #   #   # print(ncol(temp_region_probs))
            #   #
            #   #   # print("nrow(temp_region_probs) = ")
            #   #   # print(nrow(temp_region_probs))
            #   #
            #   #
            #   #   # these three lines are technically unnecessary
            #   #   # probmattemp[, k_ind] <- rep(0,num_regions)
            #   #   logprobmattemp[, k_ind] <- rep(-Inf,num_regions)
            #   #   tempbounds[k_ind, 1] <- NA
            #   #   tempbounds[k_ind, 2] <- NA
            #   #
            #   #   next
            #   #
            #   # }
            #
            #
            #   temp_lower2 <- max(temp_lower2, temp_lower3)
            #   temp_upper2 <- min(temp_upper2, temp_upper3)
            #
            #   if(temp_lower2 >= temp_upper2){
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                     n.item*(indiv - 1) +
            #                                     1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("Line 1763 temp_lower2 >= temp_upper2")
            #   }
            #
            #   # if(all( intersectmat[,4] == 0 ) |all( is.na(intersectmat[,4])  ) ){
            #   #
            #   #   print("(1-1)*n.item*n.ranker +
            #   #                            n.item*(indiv - 1) +
            #   #                            1:n.item] = ")
            #   #
            #   #   print((1-1)*n.item*n.ranker +
            #   #           n.item*(indiv - 1) +
            #   #           1:n.item)
            #   #
            #   #   print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                                   n.item*(indiv - 1) +
            #   #                                   1:n.item]")
            #   #
            #   #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                            n.item*(indiv - 1) +
            #   #                            1:n.item])
            #   #
            #   #   print("item_ind = ")
            #   #   print(item_ind)
            #   #
            #   #   print("rankvec_t = ")
            #   #   print(rankvec_t)
            #   #
            #   #   print("intersectmat = ")
            #   #   print(intersectmat)
            #   #
            #   #   print("k_ind = ")
            #   #   print(k_ind)
            #   #
            #   #   stop("all( intersectmat[,4] == 0 )")
            #   #
            #   # }
            #
            #   logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprob +
            #     log(intersectmat[1:num_regions,4])
            #
            #
            #   # for(k0_ind in 1:num_regions){
            #   #
            #   #   #loop over all possible means
            #   #   # temp_mean2 <- intersectmat[k0_ind,1]
            #   #
            #   #   # probability of being in intersection region
            #   #
            #   #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
            #   #
            #   #
            #   #   # probmattemp[k0_ind, k_ind] <- prob_t_region*
            #   #   #   temp_tnorm_prob *
            #   #   #   intersectmat[k0_ind,4]
            #   #
            #   #   # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob * intersectmat[k0_ind,4]
            #   #   logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob + log(intersectmat[k0_ind,4])
            #   #
            #   #   # if(probmattemp[k0_ind, k_ind] < 0){
            #   #   #   print("probmattemp[k0_ind, k_ind] = ")
            #   #   #   print(probmattemp[k0_ind, k_ind])
            #   #   #
            #   #   #   # print("prob_t_region = ")
            #   #   #   # print(prob_t_region)
            #   #   #
            #   #   #   print("temp_tnorm_prob = ")
            #   #   #   print(temp_tnorm_prob)
            #   #   #
            #   #   #   print("intersectmat[k0_ind,4] = ")
            #   #   #   print(intersectmat[k0_ind,4])
            #   #   #
            #   #   #   print("temp_upper2 = ")
            #   #   #   print(temp_upper2)
            #   #   #
            #   #   #   print("temp_lower2 = ")
            #   #   #   print(temp_lower2)
            #   #   #
            #   #   #   print("temp_mean2 = ")
            #   #   #   print(temp_mean2)
            #   #   #
            #   #   #
            #   #   # }
            #   #
            #   #
            #   # } # end loop over k0
            #
            #   # save upper and lower bounds (mean saved in intersectmat)
            #   # or just obtain again later
            #
            #   tempbounds[k_ind,1] <- temp_lower2
            #   tempbounds[k_ind,2] <- temp_upper2
            #
            #
            # } # end loop over k1


            #sample a combination of k0 and k1
            # if necessary can use column sums to sample k1, then k0
            # however, this is probably unnecessary


            # print("Line 1621 before sample")

            # if(all(probmattemp ==0)){
            if(all(logprobmattemp == -Inf)){

              print("iter = ")
              print(iter)

              print("tempbounds = ")
              print(tempbounds)

              print("intersectmat = ")
              print(intersectmat)



              stop("line 1880 all(probmattemp ==0)")
            }




            # region_ind <- sample.int((num_regions^2),
            #                          size = 1,
            #                          replace = TRUE,
            #                          prob = as.vector(probmattemp))


            logprobstemp <- as.vector(logprobmattemp)
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int((num_regions^2),
                                     size = 1,
                                     replace = TRUE,
                                     prob = probstemp)

            # print("Line 1629 after sample")

            # k0 region is sampled number modulo number of regions
            k0_region_ind <- (region_ind - 1) %% num_regions + 1
            # if(k0_region_ind ==0){
            #   k0_region_ind <- num_regions
            # }

            # k1 region is the ceiling of sampled number divided by number of regions
            # k1_region_ind <- ceiling(region_ind/num_regions)
            k1_region_ind <- (region_ind - 1) %/% num_regions + 1


            # print("k1_region_ind = ")
            # print(k1_region_ind)

            temp_lower2 <- tempbounds[k1_region_ind,1]
            temp_upper2 <- tempbounds[k1_region_ind,2]

            # print("num_regions = ")
            # print(num_regions)
            #
            # print("region_ind = ")
            # print(region_ind)
            #
            # print("k0_region_ind = ")
            # print(k0_region_ind)

            temp_mean0 <- intersectmat[k0_region_ind, 1]
            # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

            # print("temp_mean0 = ")
            # print(temp_mean0)
            #
            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)

            # if(temp_upper2 - temp_lower2 < 0.000001 ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("very small difference in limits")
            # }


            # if(temp_upper2 - temp_lower2 < 0.001 ){
            #   stop("line 1980.  Very small range")
            #
            # }

            # if(temp_lower2 + 0.00005  >  temp_upper2 - 0.00005 ){
            #   print("line 1985 Very small range")
            #
            # }

            tempbuffer <- (temp_upper2 - temp_lower2)/100

            if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
              upper_buffered <- temp_upper2 - tempbuffer
              lower_buffered <- temp_lower2 + tempbuffer

            }else{


              upper_buffered <- temp_upper2
              lower_buffered <- temp_lower2

              if(temp_upper2 != Inf){
                upper_buffered <- temp_upper2 - 0.00001
              }

              if(temp_lower2 != -Inf){
                lower_buffered <- temp_lower2 + 0.00001
              }

            }


            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean0,
                                     sd = 1)



            # if( (zdraw_temp - temp_lower2 < 0.00001 ) | (temp_upper2 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_mean0 = ")
            #   print(temp_mean0)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   print("line 1988. draw very close to limit")
            # }

            if(is.na(zdraw_temp)){
              print("line 1881")

              print("temp_lower2 = ")
              print(temp_lower2)

              print("temp_upper2 = ")
              print(temp_upper2)

              print("temp_mean0 = ")
              print(temp_mean0)


              stop("NA zdraw_temp")

            }


            Z.mat[item_ind,  indiv ] <- zdraw_temp


            # loop over time periods for general case 1 < t < T

            for(t in 2:(n.time - 1)){

              # print("z time t = ")
              # print(t)

              temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker +
                                                 n.item*(indiv - 1) +
                                                 item_ind]

              if(is.na(temp_ztpmin1)){

                print("line 1895")

                print("Z.mat = ")
                print(Z.mat)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("item_ind = ")
                print(item_ind)

                stop("NA temp_ztpmin1")
              }

              # must find mean corresponding to z in period t-1
              # This will be used in and after the loop over regions.
              # can directly obtain from dbarts
              # or find region
              # and use already saved region mean values


              # must find last lower bound that temp_ztpmin1 is greater than
              # or first upper bound that temp_ztpmin1 is below
              ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat[, 3]) )[1]
              # Then obtain the corresponding region mean value
              temp_mean2 <- intersectmat[ktemp_tmin1,1]


              if(is.na(temp_mean2)){
                print("line 1908")

                print("ktemp_tmin1 = ")
                print(ktemp_tmin1)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_ztpmin1 = ")
                print(temp_ztpmin1)

                stop("temp_mean2 NA")


              }



              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              # print("ktemp_tmin1 = ")
              # print(ktemp_tmin1)



              # Calculate the probabilities for each region in this time period
              # the regions being looped over are actually period t+1 regions

              # Same regions for all time periods if there are no time varying covariates

              # However, the weights are individual and time period specific

              # loop through regions


              # first column is the probabilities
              # second column is the lower bounds
              # third column is the upper bounds
              # temp_region_probs <- matrix(0,
              #                             nrow = nrow(intersectmat),
              #                             ncol = 3)


              temp_region_logprobs <- matrix(-Inf,
                                             nrow = nrow(intersectmat),
                                             ncol = 3)

              # Trunc norm prob of next periods latent value conditional on region

              # Create intervals from interval t+1 latent values

              # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

              # inds for j ranked below i in t+1

              # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
              #
              # #max of latent variables for j ranked below i in t+1
              # # Z.mat
              #
              # if(length(belowrank_ind) ==0){
              #   temp_lower <- -Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    belowrank_ind]
              # }
              #
              # # inds for j ranked above i in t+1
              #
              # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
              #
              # #min of latent variables for j ranked below i in period t+1
              #
              # if(length(aboverank_ind) ==0){
              #   temp_upper <- Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #
              #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    aboverank_ind]
              # }


              # want trunc norm probability of latent variable value for item_ind
              # in period t+1

              temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                              n.item*(indiv - 1) +
                                              item_ind]

              rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]



              # if(any(order(rankvec_t) !=
              #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                           n.item*(indiv - 1) +
              #                           1:n.item]) )){
              #
              #   print("order(rankvec_t) = ")
              #   print(order(rankvec_t))
              #
              #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
              #                         n.item*(indiv - 1) +
              #                         1:n.item])  = ")
              #
              #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                  n.item*(indiv - 1) +
              #                                  1:n.item]) )
              #
              #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                n.item*(indiv - 1) +
              #                                1:n.item] = ")
              #
              #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                            n.item*(indiv - 1) +
              #                            1:n.item])
              #
              #
              # }





              # inds for j ranked below i in t

              belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

              #max of latent variables for j ranked below i in t
              # Z.mat

              if(length(belowrank_ind) ==0){
                temp_lower3 <- -Inf
              }else{
                temp_lower3 <- max(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  belowrank_ind])
              }

              if(is.na(temp_lower3)){
                print("NA temp_lower3")

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind] = ")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         belowrank_ind])

                print(" t = ")
                print(t)

                print(" n.item = ")
                print(n.item)

                print(" n.ranker = ")
                print(n.ranker)

                print(" indiv = ")
                print(indiv)

                print(" belowrank_ind = ")
                print(belowrank_ind)

                print(" Z.mat = ")
                print(Z.mat)

                stop("NA temp_lower3")

              }



              # inds for j ranked above i in t


              aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

              #min of latent variables for j ranked below i in period t

              if(length(aboverank_ind) ==0){
                temp_upper3 <- Inf
              }else{
                temp_upper3 <- min(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  aboverank_ind])
              }

              if(temp_lower3 >= temp_upper3){
                print(" temp_lower3 = ")
                print(temp_lower3)

                print(" temp_upper3 = ")
                print(temp_upper3)

                stop("Line 2495. temp_lower3 >= temp_upper3")
              }


              # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
              tempmeanfordens <- intersectmat[1:num_regions, 1]

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                    mean = tempmeanfordens,
              #                                    sd = 1)

              # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
              #                                          mean = tempmeanfordens,
              #                                          sd = 1)


              # find intervals that do not overlap

              bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

              temp_region_logprobs[bad_regions, 1] <- -Inf
              temp_region_logprobs[bad_regions, 2] <- NA
              temp_region_logprobs[bad_regions, 3] <- NA

              good_regions <- setdiff(1:num_regions, bad_regions)

              temp_tnorm_logprobvec <- rep(NA, num_regions)
              temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                     mean = tempmeanfordens[good_regions],
                                                                     sd = 1)


              temp_region_logprobs[good_regions, 1] <- temp_tnorm_logprobvec[good_regions]
              temp_region_logprobs[good_regions, 2] <- pmax(intersectmat[good_regions, 2], temp_lower3)
              temp_region_logprobs[good_regions, 3] <- pmin(intersectmat[good_regions, 3], temp_upper3)


              if(any(temp_region_logprobs[good_regions, 2] >= temp_region_logprobs[good_regions, 3])){
                print("good_regions = ")
                print(good_regions)

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                stop(" line 2525 bounds badly defined")
              }
              # CAN VECTORIZE THIS EVEN MORE


              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                 mean = intersectmat[1:num_regions, 1],
              #                                 sd = 1)

              # for(k_ind in 1:num_regions){
              # for(k_ind in good_regions){
              #   # obtain mean for truncated normal distribution
              #   # temp_mean <- intersectmat[k_ind, 1]
              #
              #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #   #                               a=temp_lower,
              #   #                               b=Inf,
              #   #                               mean = temp_mean,
              #   #                               sd = 1)
              #
              #
              #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #   #                          mean = temp_mean,
              #   #                          sd = 1)
              #
              #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
              #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
              #
              #   # Probability of z_t in intersection of
              #   # region k_ind (for period t+1)
              #   # and region defined by period t latent variables for other individuals
              #   # and rank for period t
              #
              #
              #   # tildeC_ktminl corresponds to
              #   # period t+1 k_ind region intereval
              #
              #   temp_lower2 <- intersectmat[k_ind, 2]
              #   temp_upper2 <- intersectmat[k_ind, 3]
              #
              #
              #
              #   # print(" line 2075 ")
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   #
              #   # print("temp_lower3 = ")
              #   # print(temp_lower3)
              #   #
              #   # print("temp_upper3 = ")
              #   # print(temp_upper3)
              #
              #
              #   # if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
              #   #   # if((temp_lower2 - temp_upper3 > -0.0001) | (temp_lower3 - temp_upper2 > -0.0001)){
              #   #   # intervals do not overlap, therefore assign probability zero
              #   #   # and skip to next iteration
              #   #
              #   #   # print("k_ind = ")
              #   #   # print(k_ind)
              #   #
              #   #   # print("ncol(temp_region_probs) = ")
              #   #   # print(ncol(temp_region_probs))
              #   #
              #   #   # print("nrow(temp_region_probs) = ")
              #   #   # print(nrow(temp_region_probs))
              #   #
              #   #   # temp_region_probs[k_ind, 1] <- 0
              #   #   # temp_region_probs[k_ind, 2] <- NA
              #   #   # temp_region_probs[k_ind, 3] <- NA
              #   #
              #   #   temp_region_logprobs[k_ind, 1] <- -Inf
              #   #   temp_region_logprobs[k_ind, 2] <- NA
              #   #   temp_region_logprobs[k_ind, 3] <- NA
              #   #
              #   #
              #   #   next
              #   # }
              #
              #
              #
              #   temp_lower2 <- max(temp_lower2, temp_lower3)
              #   temp_upper2 <- min(temp_upper2, temp_upper3)
              #
              #
              #   if(temp_lower2 >= temp_upper2){
              #
              #     print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                   n.item*(indiv - 1) +
              #                                   1:n.item]")
              #     print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                              n.item*(indiv - 1) +
              #                              1:n.item])
              #     print("item_ind = ")
              #     print(item_ind)
              #
              #     print("t = ")
              #     print(t)
              #
              #     print("indiv = ")
              #     print(indiv)
              #
              #
              #     print("rankvec_t = ")
              #     print(rankvec_t)
              #
              #
              #     print("temp_lower2 = ")
              #     print(temp_lower2)
              #
              #     print("temp_upper2 = ")
              #     print(temp_upper2)
              #
              #     print("temp_lower3 = ")
              #     print(temp_lower3)
              #
              #     print("temp_upper3 = ")
              #     print(temp_upper3)
              #
              #
              #
              #     print("intersectmat[k_ind, 2] = ")
              #     print(intersectmat[k_ind, 2])
              #
              #     print("intersectmat[k_ind, 3] = ")
              #     print(intersectmat[k_ind, 3])
              #
              #     print("k_ind = ")
              #     print(k_ind)
              #
              #
              #
              #     stop("Line 1917. temp_lower2 >= temp_upper2")
              #   }
              #
              #
              #
              #   # probability of being in intersection region
              #
              #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
              #
              #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_mean2 = ")
              #   # print(temp_mean2)
              #   #
              #   #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #   #
              #   # print("temp_tnorm_prob = ")
              #   # print(temp_tnorm_prob)
              #
              #   # prob_t_region <- prob_t_region*temp_tnorm_prob
              #   # prob_t_region <- temp_tnorm_prob
              #   logprob_t_region <- temp_tnorm_logprob
              #
              #   # if(temp_tnorm_prob ==0){
              #   if(temp_tnorm_logprob == -Inf){
              #     print("temp_tnorm_prob = ")
              #     print(temp_tnorm_prob)
              #
              #     print("temp_tnorm_probvec =")
              #     print(temp_tnorm_probvec)
              #
              #     print("tempmeanfordens =")
              #     print(tempmeanfordens)
              #
              #     print("temp_ztp1 =")
              #     print(temp_ztp1)
              #
              #   }
              #
              #   # save region probability
              #
              #   # and save region bounds (or maybe more memory efficient to obtain the region again)
              #
              #   # must multiply by other previously obtained probabilities
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   # temp_region_probs[k_ind, 1] <- prob_t_region
              #   # temp_region_probs[k_ind, 2] <- temp_lower2
              #   # temp_region_probs[k_ind, 3] <- temp_upper2
              #
              #   temp_region_logprobs[k_ind, 1] <- logprob_t_region
              #   temp_region_logprobs[k_ind, 2] <- temp_lower2
              #   temp_region_logprobs[k_ind, 3] <- temp_upper2
              #
              # }


              # sample a region using probabilities obtained above

              # print("Line 1903 before sample")


              # if(sum(temp_region_probs[,1] > 0) ==0){
              if(sum(temp_region_logprobs[,1] > -Inf) ==0){

                print("temp_tnorm_probvec =")
                print(temp_tnorm_probvec)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_region_probs = ")
                print(temp_region_probs)

                print("item_ind = ")
                print(item_ind)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("rankvec_t = ")
                print(rankvec_t)

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])

                stop(" Line 2590 sum(temp_region_probs[,1] >0) == 0")
              }



              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])

              # logprobstemp <- as.vector(temp_region_logprobs[,1])
              # max_ll <- max(logprobstemp)
              # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
              # probstemp <- exp(logprobstemp - logsumexps)
              #
              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = probstemp)

              if(length(good_regions)==1){
                region_ind <- good_regions[1]
              }else{
                logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
                max_ll <- max(logprobstemp)
                logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
                probstemp <- exp(logprobstemp - logsumexps)

                region_ind <- sample(x = (1:num_regions)[good_regions], size = 1, replace = TRUE, prob = probstemp)
              }


              # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

              # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
              #
              # print("line 2102 temp_mean2_debug from predict = ")
              # print(temp_mean2_debug)
              #
              # print("line 2105 temp_mean2_origscale = ")
              # print(temp_mean2_origscale)
              #
              # print("line 2108 temp_mean2 = ")
              # print(temp_mean2)


              # if(temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2] < 0.000001 ){
              #
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #
              #
              #   stop("very small difference in limits")
              # }

              # if(temp_region_probs[region_ind, 3] -temp_region_probs[region_ind, 2] < 0.001 ){
              #   stop("line 2456. Very small range")
              #
              # }

              # if(temp_region_probs[region_ind, 2] + 0.00005  >  temp_region_probs[region_ind, 3] - 0.00005 ){
              #
              #   print("iter  = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   stop("line 2467 Very small range")
              #
              # }


              # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
              #
              # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
              #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
              #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
              #
              # }else{
              #   upper_buffered <- temp_region_probs[region_ind, 3]
              #   lower_buffered <- temp_region_probs[region_ind, 2]
              #
              # }

              tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/100

              if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
                upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
                lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer

              }else{
                upper_buffered <- temp_region_logprobs[region_ind, 3]
                lower_buffered <- temp_region_logprobs[region_ind, 2]


                if(temp_region_logprobs[region_ind, 3] != Inf){
                  upper_buffered <- temp_region_logprobs[region_ind, 3] - 0.00001
                }

                if(temp_region_logprobs[region_ind, 2] != -Inf){
                  lower_buffered <- temp_region_logprobs[region_ind, 2] + 0.00001
                }

              }


              if(abs( temp_mean2/ (upper_buffered - lower_buffered ) ) > 10^15){
                # this is a quick fix for when the bounds are close or very far from the mean
                # this does not really address any potential underlying issue
                zdraw_temp <- (lower_buffered + upper_buffered)/2
              }else{
                zdraw_temp <- rtruncnorm(n = 1,
                                         a=lower_buffered,
                                         b=upper_buffered,
                                         mean = temp_mean2, #temp_mean2_origscale,
                                         sd = 1)
              }


              if(is.na(zdraw_temp)){
                print(" line 2883")

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                print("zdraw_temp = ")
                print(zdraw_temp)


                stop("NA zdraw_temp")
              }


              # if( (zdraw_temp - temp_region_probs[region_ind, 2] < 0.00001 ) | (temp_region_probs[region_ind, 3] - zdraw_temp  < 0.00001 ) ){
              #
              #   print("iter = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #   print("zdraw_temp = ")
              #   print(zdraw_temp)
              #
              #   stop("line 2470 draw very close to limit")
              # }



              # print("Line 1914 after sample")

              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=temp_region_probs[region_ind, 2],
              #                          b=temp_region_probs[region_ind, 3],
              #                          mean = temp_mean2,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs= ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                stop("NA zdraw_temp")
              }

              Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



            } # end loop over time periods

            # check for special cases for n.time - 1, n.time - 2, n.time - 3

            # special case for t = n.time


            temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # for first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat[, 3])[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat[ktemp_tmin1,1]

            # now find interval


            # tildeC_ktminl corresponds to
            # period t+1 k_ind region intereval



            rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

            # inds for j ranked below i in T

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in T
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- max(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind])
            }

            # inds for j ranked above i in T

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period T

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- min(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind])
            }


            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
            #
            # print("line 2202 temp_mean2_debug from predict = ")
            # print(temp_mean2_debug)
            #
            # print("line 2205 temp_mean2_origscale = ")
            # print(temp_mean2_origscale)
            #
            # print("line 2208 temp_mean2 = ")
            # print(temp_mean2)

            # if(temp_upper3 -temp_lower3 < 0.000001 ){
            #
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   stop("very small difference in limits")
            # }


            # if(temp_upper3 - temp_lower3 < 0.001 ){
            #   stop("line 2613.  Very small range")
            #
            # }

            # if(temp_lower3 + 0.00005  >  temp_upper3 - 0.00005 ){
            #   print("line 2623 Very small range")
            #
            # }

            tempbuffer <- (temp_upper3 - temp_lower3)/100

            if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
              upper_buffered <- temp_upper3 - tempbuffer
              lower_buffered <- temp_lower3 + tempbuffer

            }else{
              upper_buffered <- temp_upper3
              lower_buffered <- temp_lower3

              if(temp_upper3 != Inf){
                upper_buffered <- temp_upper3 - 0.00001
              }

              if(temp_upper3 != -Inf){
                lower_buffered <- temp_lower3 + 0.00001
              }
            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean2, #temp_mean2_origscale,
                                     sd = 1)

            # if( (zdraw_temp - temp_lower3 < 0.00001 ) | (temp_upper3 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("temp_lower3 = ")
            #   print(temp_lower3)
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   stop("line 2612 draw very close to limit")
            # }

            # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a = temp_lower3,
            #                          b = temp_upper3,
            #                          mean = temp_mean2,
            #                          sd = 1)

            if(is.na(zdraw_temp)){
              print(" line 2367")
              print("temp_lower3] = ")
              print(temp_lower3)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_mean2 = ")
              print(temp_mean2)

              stop("NA zdraw_temp")
            }

            Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





          } # end loop over items



        } # end loop over individuals indiv in 1:n.ranker

      }
    }else{ # loop over items and rankers within each time period
      for(z_iter_ind in 1:num_z_iters){


        for(indiv in 1:n.ranker){

          # print("indiv = ")
          # print(indiv)
          ########### calculate qkt  ########################################

          ########### calculate qkt   for t = 1 ########################################


          ### calculate qkt integrals for time period t = 1  ################

          # These integrals are already calculated and saved as intersectmat[ktemp,4]

          for(item_ind in 1:n.item){


            #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

            # loop over items

            # Now loop over time periods

            # special case for t=1

            # probability matrix for sampling elements

            # let rows be period zero, and columns be period 1 (2?)

            # probmattemp <- matrix(0,
            #                       nrow = num_regions,
            #                       ncol = num_regions)

            logprobmattemp <- matrix(0,
                                     nrow = num_regions,
                                     ncol = num_regions)

            # loop over period 2 regions into which z_1 can fall


            tempbounds <- matrix(NA,
                                 nrow = num_regions,
                                 ncol = 2)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

            # inds for j ranked below i in t+1



            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]



            rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]

            # if(any(order(rankvec_t) !=
            #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                           n.item*(indiv-1) +
            #                           1:n.item])) ){
            #
            #   # print("order(rankvec_t) = ")
            #   # print(order(rankvec_t))
            #   #
            #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                         n.item*(indiv - 1) +
            #   #                         1:n.item])  = ")
            #
            #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                  n.item*(indiv - 1) +
            #                                  1:n.item]) )
            #
            #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                                n.item*(indiv - 1) +
            #   #                                1:n.item] = ")
            #
            #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item])
            #
            # }

            # inds for j ranked below i in t

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in t
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- max(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind])
            }

            # inds for j ranked above i in t

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period t

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- min(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind])
            }

            # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
            tempmeanfordens <- intersectmat[1:num_regions, 1]

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                    mean = tempmeanfordens,
            #                                    sd = 1)

            # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
            #                                          mean = tempmeanfordens,
            #                                          sd = 1)

            if(temp_lower3 >= temp_upper3){
              print(" temp_lower3 = ")
              print(temp_lower3)

              print(" temp_upper3 = ")
              print(temp_upper3)

              stop("Line 3328. temp_lower3 >= temp_upper3")
            }

            bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

            logprobmattemp[, bad_regions] <- -Inf #rep(-Inf,num_regions)
            tempbounds[bad_regions, 1] <- NA
            tempbounds[bad_regions, 2] <- NA

            good_regions <- setdiff(1:num_regions, bad_regions)


            temp_tnorm_logprobvec <- rep(NA, num_regions)
            temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                   mean = tempmeanfordens[good_regions],
                                                                   sd = 1)


            # logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprobvec[k_ind] +
            #   log(intersectmat[1:num_regions,4])

            logprobmattemp[1:num_regions, good_regions] <- outer(log(intersectmat[1:num_regions,4]),
                                                                 temp_tnorm_logprobvec[good_regions],
                                                                 FUN = "+")


            tempbounds[good_regions,1] <- pmax(intersectmat[good_regions, 2], temp_lower3)
            tempbounds[good_regions,2] <- pmin(intersectmat[good_regions, 3], temp_upper3)

            if(any(tempbounds[good_regions,1] >= tempbounds[good_regions,2])){
              print("intersectmat = ")
              print(intersectmat)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_lower3 = ")
              print(temp_lower3)

              print("good_regions = ")
              print(good_regions)

              print("tempbounds = ")
              print(tempbounds)
              stop(" line 3305 bounds badly defined")
            }

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                 mean = intersectmat[1:num_regions, 1],
            #                                 sd = 1)

            # for(k_ind in 1:num_regions){
            #   # obtain mean for truncated normal distribution
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # want trunc norm probability of latent variable value for item_ind
            #   # in period t+1
            #
            #
            #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #   #                               a=temp_lower,
            #   #                               b=Inf,
            #   #                               mean = temp_mean,
            #   #                               sd = 1)
            #
            #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #   #                          mean = temp_mean,
            #   #                          sd = 1)
            #
            #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
            #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
            #
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #
            #
            #   # now second term
            #
            #
            #   temp_lower2 <- intersectmat[k_ind, 2]
            #   temp_upper2 <- intersectmat[k_ind, 3]
            #
            #
            #   # print(" line 1697 ")
            #   #
            #   # print("temp_lower2 = ")
            #   # print(temp_lower2)
            #   #
            #   # print("temp_lower3 = ")
            #   # print(temp_lower3)
            #   #
            #   # print("temp_upper2 = ")
            #   # print(temp_upper2)
            #   #
            #   # print("temp_upper3 = ")
            #   # print(temp_upper3)
            #
            #
            #   if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
            #     # if((temp_lower2 - temp_upper3) > -0.001 | (temp_lower3 - temp_upper2 > -0.001)){
            #     # intervals do not overlap, therefore assign probability zero
            #     # and skip to next iteration
            #
            #
            #     # print("k_ind = ")
            #     # print(k_ind)
            #
            #     # print("ncol(temp_region_probs) = ")
            #     # print(ncol(temp_region_probs))
            #
            #     # print("nrow(temp_region_probs) = ")
            #     # print(nrow(temp_region_probs))
            #
            #
            #     # these three lines are technically unnecessary
            #     # probmattemp[, k_ind] <- rep(0,num_regions)
            #     logprobmattemp[, k_ind] <- rep(-Inf,num_regions)
            #     tempbounds[k_ind, 1] <- NA
            #     tempbounds[k_ind, 2] <- NA
            #
            #     next
            #
            #   }
            #
            #
            #   temp_lower2 <- max(temp_lower2, temp_lower3)
            #   temp_upper2 <- min(temp_upper2, temp_upper3)
            #
            #   if(temp_lower2 >= temp_upper2){
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                   n.item*(indiv - 1) +
            #                                   1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("Line 1763 temp_lower2 >= temp_upper2")
            #   }
            #
            #   if(all( intersectmat[,4] == 0 ) |all( is.na(intersectmat[,4])  ) ){
            #
            #     print("(1-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item] = ")
            #
            #     print((1-1)*n.item*n.ranker +
            #             n.item*(indiv - 1) +
            #             1:n.item)
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                   n.item*(indiv - 1) +
            #                                   1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("all( intersectmat[,4] == 0 )")
            #
            #   }
            #
            #
            #   for(k0_ind in 1:num_regions){
            #
            #     #loop over all possible means
            #     temp_mean2 <- intersectmat[k0_ind,1]
            #
            #     # probability of being in intersection region
            #
            #     # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
            #
            #
            #     # probmattemp[k0_ind, k_ind] <- prob_t_region*
            #     #   temp_tnorm_prob *
            #     #   intersectmat[k0_ind,4]
            #
            #     # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob * intersectmat[k0_ind,4]
            #     logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob + log(intersectmat[k0_ind,4])
            #
            #     # if(probmattemp[k0_ind, k_ind] < 0){
            #     #   print("probmattemp[k0_ind, k_ind] = ")
            #     #   print(probmattemp[k0_ind, k_ind])
            #     #
            #     #   # print("prob_t_region = ")
            #     #   # print(prob_t_region)
            #     #
            #     #   print("temp_tnorm_prob = ")
            #     #   print(temp_tnorm_prob)
            #     #
            #     #   print("intersectmat[k0_ind,4] = ")
            #     #   print(intersectmat[k0_ind,4])
            #     #
            #     #   print("temp_upper2 = ")
            #     #   print(temp_upper2)
            #     #
            #     #   print("temp_lower2 = ")
            #     #   print(temp_lower2)
            #     #
            #     #   print("temp_mean2 = ")
            #     #   print(temp_mean2)
            #     #
            #     #
            #     # }
            #
            #
            #   } # end loop over k0
            #
            #   # save upper and lower bounds (mean saved in intersectmat)
            #   # or just obtain again later
            #
            #   tempbounds[k_ind,1] <- temp_lower2
            #   tempbounds[k_ind,2] <- temp_upper2
            #
            #
            # } # end loop over k1


            #sample a combination of k0 and k1
            # if necessary can use column sums to sample k1, then k0
            # however, this is probably unnecessary


            # print("Line 1621 before sample")

            # if(all(probmattemp ==0)){
            if(all(logprobmattemp == -Inf)){

              print("iter = ")
              print(iter)

              print("tempbounds = ")
              print(tempbounds)

              print("intersectmat = ")
              print(intersectmat)



              stop("line 1880 all(probmattemp ==0)")
            }




            # region_ind <- sample.int((num_regions^2),
            #                          size = 1,
            #                          replace = TRUE,
            #                          prob = as.vector(probmattemp))


            logprobstemp <- as.vector(logprobmattemp)
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int((num_regions^2),
                                     size = 1,
                                     replace = TRUE,
                                     prob = probstemp)



            # logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
            # max_ll <- max(logprobstemp)
            # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            # probstemp <- exp(logprobstemp - logsumexps)
            # region_ind <- sample((1:num_regions)[good_regions], 1, replace = TRUE, prob = probstemp)


            # print("Line 1629 after sample")

            # k0 region is sampled number modulo number of regions
            k0_region_ind <- (region_ind - 1) %% num_regions + 1
            # if(k0_region_ind ==0){
            #   k0_region_ind <- num_regions
            # }

            # k1 region is the ceiling of sampled number divided by number of regions
            # k1_region_ind <- ceiling(region_ind/num_regions)
            k1_region_ind <- (region_ind - 1) %/% num_regions + 1


            # print("k1_region_ind = ")
            # print(k1_region_ind)

            temp_lower2 <- tempbounds[k1_region_ind,1]
            temp_upper2 <- tempbounds[k1_region_ind,2]

            # print("num_regions = ")
            # print(num_regions)
            #
            # print("region_ind = ")
            # print(region_ind)
            #
            # print("k0_region_ind = ")
            # print(k0_region_ind)

            temp_mean0 <- intersectmat[k0_region_ind, 1]
            # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

            # print("temp_mean0 = ")
            # print(temp_mean0)
            #
            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)

            # if(temp_upper2 - temp_lower2 < 0.000001 ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("very small difference in limits")
            # }


            # if(temp_upper2 - temp_lower2 < 0.001 ){
            #   stop("line 1980.  Very small range")
            #
            # }

            # if(temp_lower2 + 0.00005  >  temp_upper2 - 0.00005 ){
            #   print("line 1985 Very small range")
            #
            # }

            tempbuffer <- (temp_upper2 - temp_lower2)/100

            if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
              upper_buffered <- temp_upper2 - tempbuffer
              lower_buffered <- temp_lower2 + tempbuffer

            }else{
              upper_buffered <- temp_upper2
              lower_buffered <- temp_lower2

              if(temp_upper2 != Inf){
                upper_buffered <- temp_upper2 - 0.00001
              }

              if(temp_lower2 != -Inf){
                lower_buffered <- temp_lower2 + 0.00001
              }

            }


            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean0,
                                     sd = 1)



            # if( (zdraw_temp - temp_lower2 < 0.00001 ) | (temp_upper2 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_mean0 = ")
            #   print(temp_mean0)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   print("line 1988. draw very close to limit")
            # }

            if(is.na(zdraw_temp)){
              print("line 1881")

              print("temp_lower2 = ")
              print(temp_lower2)

              print("temp_upper2 = ")
              print(temp_upper2)

              print("temp_mean0 = ")
              print(temp_mean0)


              stop("NA zdraw_temp")

            }


            Z.mat[item_ind,  indiv ] <- zdraw_temp

          } # end loop over items

        } # end loop over individuals indiv in 1:n.ranker



        # loop over time periods for general case 1 < t < T

        for(t in 2:(n.time - 1)){

          # print("z time t = ")
          # print(t)

          for(indiv in 1:n.ranker){
            # print("z indiv = ")
            # print(indiv)

            for(item_ind in 1:n.item){

              # print("item_ind = ")
              # print(item_ind)

              temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker +
                                                 n.item*(indiv - 1) +
                                                 item_ind]

              if(is.na(temp_ztpmin1)){

                print("line 1895")

                print("Z.mat = ")
                print(Z.mat)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("item_ind = ")
                print(item_ind)

                stop("NA temp_ztpmin1")
              }

              # must find mean corresponding to z in period t-1
              # This will be used in and after the loop over regions.
              # can directly obtain from dbarts
              # or find region
              # and use already saved region mean values


              # must find last lower bound that temp_ztpmin1 is greater than
              # or first upper bound that temp_ztpmin1 is below
              ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat[, 3]) )[1]
              # Then obtain the corresponding region mean value
              temp_mean2 <- intersectmat[ktemp_tmin1,1]


              if(is.na(temp_mean2)){
                print("line 1908")

                print("ktemp_tmin1 = ")
                print(ktemp_tmin1)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_ztpmin1 = ")
                print(temp_ztpmin1)

                stop("temp_mean2 NA")
              }

              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              # print("ktemp_tmin1 = ")
              # print(ktemp_tmin1)

              # Calculate the probabilities for each region in this time period
              # the regions being looped over are actually period t+1 regions

              # Same regions for all time periods if there are no time varying covariates

              # However, the weights are individual and time period specific

              # loop through regions


              # first column is the probabilities
              # second column is the lower bounds
              # third column is the upper bounds
              # temp_region_probs <- matrix(0,
              #                             nrow = nrow(intersectmat),
              #                             ncol = 3)


              temp_region_logprobs <- matrix(-Inf,
                                             nrow = nrow(intersectmat),
                                             ncol = 3)

              # Trunc norm prob of next periods latent value conditional on region

              # Create intervals from interval t+1 latent values

              # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

              # inds for j ranked below i in t+1

              # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
              #
              # #max of latent variables for j ranked below i in t+1
              # # Z.mat
              #
              # if(length(belowrank_ind) ==0){
              #   temp_lower <- -Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    belowrank_ind]
              # }
              #
              # # inds for j ranked above i in t+1
              #
              # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
              #
              # #min of latent variables for j ranked below i in period t+1
              #
              # if(length(aboverank_ind) ==0){
              #   temp_upper <- Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #
              #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    aboverank_ind]
              # }


              # want trunc norm probability of latent variable value for item_ind
              # in period t+1

              temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                              n.item*(indiv - 1) +
                                              item_ind]

              rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]


              # if(any(order(rankvec_t) !=
              #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                           n.item*(indiv - 1) +
              #                           1:n.item]) )){
              #
              #   print("order(rankvec_t) = ")
              #   print(order(rankvec_t))
              #
              #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
              #                         n.item*(indiv - 1) +
              #                         1:n.item])  = ")
              #
              #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                  n.item*(indiv - 1) +
              #                                  1:n.item]) )
              #
              #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                n.item*(indiv - 1) +
              #                                1:n.item] = ")
              #
              #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                            n.item*(indiv - 1) +
              #                            1:n.item])
              #
              #
              # }


              # inds for j ranked below i in t

              belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

              #max of latent variables for j ranked below i in t
              # Z.mat

              if(length(belowrank_ind) ==0){
                temp_lower3 <- -Inf
              }else{
                temp_lower3 <- max(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  belowrank_ind])
              }

              if(is.na(temp_lower3)){
                print("NA temp_lower3")

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                    n.item*(indiv - 1) +
                                                    belowrank_ind] = ")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         belowrank_ind])

                print(" t = ")
                print(t)

                print(" n.item = ")
                print(n.item)

                print(" n.ranker = ")
                print(n.ranker)

                print(" indiv = ")
                print(indiv)

                print(" belowrank_ind = ")
                print(belowrank_ind)

                print(" Z.mat = ")
                print(Z.mat)

                stop("NA temp_lower3")

              }

              # inds for j ranked above i in t

              aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

              #min of latent variables for j ranked below i in period t

              if(length(aboverank_ind) ==0){
                temp_upper3 <- Inf
              }else{
                temp_upper3 <- min(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  aboverank_ind])
              }

              # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
              tempmeanfordens <- intersectmat[1:num_regions, 1]

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                    mean = tempmeanfordens,
              #                                    sd = 1)

              # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
              #                                          mean = tempmeanfordens,
              #                                          sd = 1)

              if(temp_lower3 >= temp_upper3){
                print(" temp_lower3 = ")
                print(temp_lower3)

                print(" temp_upper3 = ")
                print(temp_upper3)

                stop("Line 4016 temp_lower3 >= temp_upper3")
              }

              bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))


              # print("length(bad_regions) = ")
              # print(length(bad_regions))

              temp_region_logprobs[bad_regions, 1] <- -Inf
              temp_region_logprobs[bad_regions, 2] <- NA
              temp_region_logprobs[bad_regions, 3] <- NA

              good_regions <- setdiff(1:num_regions, bad_regions)

              if(length(good_regions) == 0){
                stop("Line 3969. No good regions.")
              }

              if(length(good_regions) > num_regions){
                stop("Line 3973 length(good_regions) > num_regionss.")
              }
              if(length(temp_tnorm_logprobvec) > num_regions){
                stop("Line 3973 length(temp_tnorm_logprobvec) > num_regionss.")
              }
              if(length(tempmeanfordens) > num_regions){
                stop("Line 3979 length(tempmeanfordens) > num_regionss.")
              }
              if(length(temp_ztp1) > 1){
                stop("Line 3979 length(temp_ztp1) > 1")
              }


              temp_tnorm_logprobvec <- rep(NA, num_regions)
              temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                     mean = tempmeanfordens[good_regions],
                                                                     sd = 1)


              temp_region_logprobs[good_regions, 1] <- temp_tnorm_logprobvec[good_regions]
              temp_region_logprobs[good_regions, 2] <- pmax(intersectmat[good_regions, 2], temp_lower3)
              temp_region_logprobs[good_regions, 3] <- pmin(intersectmat[good_regions, 3], temp_upper3)

              if(any(temp_region_logprobs[good_regions, 2] >= temp_region_logprobs[good_regions, 3])){
                stop(" line 3954 bounds badly defined")
              }

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                 mean = intersectmat[1:num_regions, 1],
              #                                 sd = 1)

              # for(k_ind in 1:num_regions){
              #   # obtain mean for truncated normal distribution
              #   # temp_mean <- intersectmat[k_ind, 1]
              #
              #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #   #                               a=temp_lower,
              #   #                               b=Inf,
              #   #                               mean = temp_mean,
              #   #                               sd = 1)
              #
              #
              #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #   #                          mean = temp_mean,
              #   #                          sd = 1)
              #
              #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
              #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
              #
              #   # Probability of z_t in intersection of
              #   # region k_ind (for period t+1)
              #   # and region defined by period t latent variables for other individuals
              #   # and rank for period t
              #
              #
              #   # tildeC_ktminl corresponds to
              #   # period t+1 k_ind region intereval
              #
              #   temp_lower2 <- intersectmat[k_ind, 2]
              #   temp_upper2 <- intersectmat[k_ind, 3]
              #
              #
              #
              #   # print(" line 2075 ")
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   #
              #   # print("temp_lower3 = ")
              #   # print(temp_lower3)
              #   #
              #   # print("temp_upper3 = ")
              #   # print(temp_upper3)
              #
              #
              #   if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
              #     # if((temp_lower2 - temp_upper3 > -0.0001) | (temp_lower3 - temp_upper2 > -0.0001)){
              #     # intervals do not overlap, therefore assign probability zero
              #     # and skip to next iteration
              #
              #     # print("k_ind = ")
              #     # print(k_ind)
              #
              #     # print("ncol(temp_region_probs) = ")
              #     # print(ncol(temp_region_probs))
              #
              #     # print("nrow(temp_region_probs) = ")
              #     # print(nrow(temp_region_probs))
              #
              #     # temp_region_probs[k_ind, 1] <- 0
              #     # temp_region_probs[k_ind, 2] <- NA
              #     # temp_region_probs[k_ind, 3] <- NA
              #
              #     temp_region_logprobs[k_ind, 1] <- -Inf
              #     temp_region_logprobs[k_ind, 2] <- NA
              #     temp_region_logprobs[k_ind, 3] <- NA
              #
              #
              #     next
              #   }
              #
              #
              #
              #   temp_lower2 <- max(temp_lower2, temp_lower3)
              #   temp_upper2 <- min(temp_upper2, temp_upper3)
              #
              #
              #   if(temp_lower2 >= temp_upper2){
              #
              #     print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                 n.item*(indiv - 1) +
              #                                 1:n.item]")
              #     print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                              n.item*(indiv - 1) +
              #                              1:n.item])
              #     print("item_ind = ")
              #     print(item_ind)
              #
              #     print("t = ")
              #     print(t)
              #
              #     print("indiv = ")
              #     print(indiv)
              #
              #
              #     print("rankvec_t = ")
              #     print(rankvec_t)
              #
              #
              #     print("temp_lower2 = ")
              #     print(temp_lower2)
              #
              #     print("temp_upper2 = ")
              #     print(temp_upper2)
              #
              #     print("temp_lower3 = ")
              #     print(temp_lower3)
              #
              #     print("temp_upper3 = ")
              #     print(temp_upper3)
              #
              #
              #
              #     print("intersectmat[k_ind, 2] = ")
              #     print(intersectmat[k_ind, 2])
              #
              #     print("intersectmat[k_ind, 3] = ")
              #     print(intersectmat[k_ind, 3])
              #
              #     print("k_ind = ")
              #     print(k_ind)
              #
              #
              #
              #     stop("Line 1917. temp_lower2 >= temp_upper2")
              #   }
              #
              #
              #
              #   # probability of being in intersection region
              #
              #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
              #
              #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_mean2 = ")
              #   # print(temp_mean2)
              #   #
              #   #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #   #
              #   # print("temp_tnorm_prob = ")
              #   # print(temp_tnorm_prob)
              #
              #   # prob_t_region <- prob_t_region*temp_tnorm_prob
              #   # prob_t_region <- temp_tnorm_prob
              #   logprob_t_region <- temp_tnorm_logprob
              #
              #   # if(temp_tnorm_prob ==0){
              #   if(temp_tnorm_logprob == -Inf){
              #     print("temp_tnorm_prob = ")
              #     print(temp_tnorm_prob)
              #
              #     print("temp_tnorm_probvec =")
              #     print(temp_tnorm_probvec)
              #
              #     print("tempmeanfordens =")
              #     print(tempmeanfordens)
              #
              #     print("temp_ztp1 =")
              #     print(temp_ztp1)
              #
              #   }
              #
              #   # save region probability
              #
              #   # and save region bounds (or maybe more memory efficient to obtain the region again)
              #
              #   # must multiply by other previously obtained probabilities
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   # temp_region_probs[k_ind, 1] <- prob_t_region
              #   # temp_region_probs[k_ind, 2] <- temp_lower2
              #   # temp_region_probs[k_ind, 3] <- temp_upper2
              #
              #   temp_region_logprobs[k_ind, 1] <- logprob_t_region
              #   temp_region_logprobs[k_ind, 2] <- temp_lower2
              #   temp_region_logprobs[k_ind, 3] <- temp_upper2
              #
              # }


              # sample a region using probabilities obtained above

              # print("Line 1903 before sample")


              # if(sum(temp_region_probs[,1] > 0) ==0){
              if(sum(temp_region_logprobs[,1] > -Inf) ==0){

                print("temp_tnorm_probvec =")
                print(temp_tnorm_probvec)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_region_probs = ")
                print(temp_region_probs)

                print("item_ind = ")
                print(item_ind)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("rankvec_t = ")
                print(rankvec_t)

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  1:n.item]")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])

                stop(" Line 2590 sum(temp_region_probs[,1] >0) == 0")
              }



              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])
              # print("line 4219")
              # print("length(temp_region_logprobs) = ")
              # print(length(temp_region_logprobs))
              # logprobstemp <- as.vector(temp_region_logprobs[,1])
              # max_ll <- max(logprobstemp)
              # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
              # probstemp <- exp(logprobstemp - logsumexps)
              #
              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = probstemp)
              if(length(good_regions)==1){
                region_ind <- good_regions[1]
              }else{
                logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
                max_ll <- max(logprobstemp)
                logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
                probstemp <- exp(logprobstemp - logsumexps)

                region_ind <- sample(x = (1:num_regions)[good_regions], size = 1, replace = TRUE, prob = probstemp)
              }

              # print("line 4229")

              # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

              # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
              #
              # print("line 2102 temp_mean2_debug from predict = ")
              # print(temp_mean2_debug)
              #
              # print("line 2105 temp_mean2_origscale = ")
              # print(temp_mean2_origscale)
              #
              # print("line 2108 temp_mean2 = ")
              # print(temp_mean2)


              # if(temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2] < 0.000001 ){
              #
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #
              #
              #   stop("very small difference in limits")
              # }

              # if(temp_region_probs[region_ind, 3] -temp_region_probs[region_ind, 2] < 0.001 ){
              #   stop("line 2456. Very small range")
              #
              # }

              # if(temp_region_probs[region_ind, 2] + 0.00005  >  temp_region_probs[region_ind, 3] - 0.00005 ){
              #
              #   print("iter  = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   stop("line 2467 Very small range")
              #
              # }


              # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
              #
              # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
              #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
              #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
              #
              # }else{
              #   upper_buffered <- temp_region_probs[region_ind, 3]
              #   lower_buffered <- temp_region_probs[region_ind, 2]
              #
              # }

              tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/100

              if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
                upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
                lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer
              }else{
                upper_buffered <- temp_region_logprobs[region_ind, 3]
                lower_buffered <- temp_region_logprobs[region_ind, 2]

                if(temp_region_logprobs[region_ind, 3] != Inf){
                  upper_buffered <- temp_region_logprobs[region_ind, 3] - 0.00001
                }

                if(temp_region_logprobs[region_ind, 2] != -Inf){
                  lower_buffered <- temp_region_logprobs[region_ind, 2] + 0.00001
                }


              }

              if(abs( temp_mean2/ (upper_buffered - lower_buffered ) ) > 10^15){
                # this is a quick fix for when the bounds are close or very far from the mean
                # this does not really address any potential underlying issue
                zdraw_temp <- (lower_buffered + upper_buffered)/2
              }else{
                zdraw_temp <- rtruncnorm(n = 1,
                                         a=lower_buffered,
                                         b=upper_buffered,
                                         mean = temp_mean2, #temp_mean2_origscale,
                                         sd = 1)
              }


              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=lower_buffered,
              #                          b=upper_buffered,
              #                          mean = temp_mean2, #temp_mean2_origscale,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                print("zdraw_temp = ")
                print(zdraw_temp)

                stop("NA zdraw_temp")
              }


              # if( (zdraw_temp - temp_region_probs[region_ind, 2] < 0.00001 ) | (temp_region_probs[region_ind, 3] - zdraw_temp  < 0.00001 ) ){
              #
              #   print("iter = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #   print("zdraw_temp = ")
              #   print(zdraw_temp)
              #
              #   stop("line 2470 draw very close to limit")
              # }



              # print("Line 1914 after sample")

              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=temp_region_probs[region_ind, 2],
              #                          b=temp_region_probs[region_ind, 3],
              #                          mean = temp_mean2,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs= ")
                print(temp_region_logprobs)

                # print("temp_region_logprobs = ")
                # print(temp_region_logprobs)

                print("temp_mean2 = ")
                print(temp_mean2)

                stop("NA zdraw_temp")
              }

              Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp

            } # end loop over items
          } # end loop over rankers


        } # end loop over time periods

        # check for special cases for n.time - 1, n.time - 2, n.time - 3

        # special case for t = n.time

        for(indiv in 1:n.ranker){
          for(item_ind in 1:n.item){
            temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # for first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat[, 3])[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat[ktemp_tmin1,1]

            # now find interval


            # tildeC_ktminl corresponds to
            # period t+1 k_ind region intereval



            rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

            # inds for j ranked below i in T

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in T
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- max(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind])
            }

            # inds for j ranked above i in T

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period T

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- min(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind])
            }


            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
            #
            # print("line 2202 temp_mean2_debug from predict = ")
            # print(temp_mean2_debug)
            #
            # print("line 2205 temp_mean2_origscale = ")
            # print(temp_mean2_origscale)
            #
            # print("line 2208 temp_mean2 = ")
            # print(temp_mean2)

            # if(temp_upper3 -temp_lower3 < 0.000001 ){
            #
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   stop("very small difference in limits")
            # }


            # if(temp_upper3 - temp_lower3 < 0.001 ){
            #   stop("line 2613.  Very small range")
            #
            # }

            # if(temp_lower3 + 0.00005  >  temp_upper3 - 0.00005 ){
            #   print("line 2623 Very small range")
            #
            # }

            tempbuffer <- (temp_upper3 - temp_lower3)/100

            if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
              upper_buffered <- temp_upper3 - tempbuffer
              lower_buffered <- temp_lower3 + tempbuffer

            }else{
              upper_buffered <- temp_upper3
              lower_buffered <- temp_lower3

              if(temp_upper3 != Inf){
                upper_buffered <- temp_upper3 - 0.00001
              }

              if(temp_lower3 != -Inf){
                lower_buffered <- temp_lower3 + 0.00001
              }


            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean2, #temp_mean2_origscale,
                                     sd = 1)

            # if( (zdraw_temp - temp_lower3 < 0.00001 ) | (temp_upper3 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("temp_lower3 = ")
            #   print(temp_lower3)
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   stop("line 2612 draw very close to limit")
            # }

            # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a = temp_lower3,
            #                          b = temp_upper3,
            #                          mean = temp_mean2,
            #                          sd = 1)

            if(is.na(zdraw_temp)){
              print(" line 2367")
              print("temp_lower3] = ")
              print(temp_lower3)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_mean2 = ")
              print(temp_mean2)

              stop("NA zdraw_temp")
            }

            Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp

          } # end loop over items
        } # end loop over rankers

        #   } # end loop over items
        #
        # } # end loop over individuals indiv in 1:n.ranker

      } # end loop over z iters
    } # end else statement

    # print("end z draws ")



    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{

    # temp_break <- 0
    # for(j in 1:num_lags){
    #   # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #
    #   while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {
    #
    #     if(seq_z_draws==1){
    #       stop("updates still not consistent with tree structure")
    #     }
    #     print("new z values not consistent with tree structure, must draw again")
    #
    #     # If this error message occurs
    #     # Check the conditions in the dbart package for setPredictor == FALSE
    #     # And if this is hypothetically possible, even with draws from the smoothing distribution,
    #     # and if it is not a bug
    #     # then need to go back to beginning of this iteration of the Gibbs sampler
    #     # and sample Zmat again
    #
    #
    #     temp_break <- 1
    #     break
    #     # stop("new z values not consistent with tree structure, must draw again")
    #
    #
    #     # #perhaps this can be rewritten to just re-draw the relevant column?
    #     # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #     #                                           Z.mat = Z.mat,
    #     #                                           mu = mu,
    #     #                                           weight.vec = rep(1, n.ranker*n.time),
    #     #                                           n.ranker = n.ranker*n.time,
    #     #                                           n.item = n.item )
    #     #
    #     # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #     #
    #     # for(t in 1:num_lags){
    #     #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #     #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #     #
    #     #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #     #
    #     # }
    #     #
    #     # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j
    #
    #   }
    #
    #   if(temp_break==1){
    #     break
    #   }
    # }
    #
    # # if need to draw z values again, go back to start of loop
    # if(temp_break==1){
    #   if(breakcount == 10){
    #     Z.mat <- Z.matold
    #     Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #     for(t in 1:num_lags){
    #       init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #       # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #       Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #
    #     }
    #
    #   }else{
    #     breakcount <- breakcount +1
    #     next
    #   }
    #
    # }
    #
    # breakcount <- 0


    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }




    ##################### Sample sum-of-trees ##################################################


    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    # #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # mutemp <- sampler$predict(df_for_dbart)
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # mu = mutemp


    # print("line 2768")



    # Must update node sizes for original tree
    # update all node sizes before new proposal

    # Must update node sizes for original tree
    # update all node sizes before new proposal

    for (j in 1:n.trees) {
      # print("curr_trees[[j]] = ")
      # print(curr_trees[[j]] )

      curr_trees[[j]] <- fill_tree_details(curr_trees[[j]],
                                           Zlag.mat)

      # print("line 2785, curr_trees[[j]] = ")
      # print(curr_trees[[j]] )
      # must also update individual tree predictions for calcualtion of partial residuals
      tree_fits_store[,j]  = get_predictions(curr_trees[[j]], Zlag.mat, single_tree = TRUE)

    }

    # option: prune all empty nodes from current trees before proposal?
    # must create new function for this
    # perhaps an issue is that there would not be a (umique) mu value
    # associated with a parent of an empty node
    # print("line 2791")

    # must update mu before and after trees updated because covariates have been updated

    mutemp = get_predictions(curr_trees, Zlag.mat, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))

    # print("line 2801")

    # Start looping through trees
    for (j in 1:n.trees) {

      current_partial_residuals = as.vector(Z.mat) - mu + tree_fits_store[,j]

      # Propose a new tree via grow/change/prune/swap
      type = sample_move(curr_trees[[j]], iter, 0, # nburn # no burnin number, so setting to 100, maybe this is not optimal
                         trans_prob)



      # option: edit the proposal step so that any proposed tree does not contain empty nodes?
      # must create new function for this

      # Generate a new tree based on the current
      if(no_empty_proposals == TRUE){

        new_trees[[j]] = noempty_update_tree(y = as.vector(Z.mat),
                                             X = Zlag.mat,
                                             type = type,
                                             curr_tree = curr_trees[[j]],
                                             node_min_size = node_min_size,
                                             s = s,
                                             splitting_rules = splitting_rules,
                                             max_bad_trees = max_bad_trees)

      }else{
        new_trees[[j]] = update_tree(y = as.vector(Z.mat),
                                     X = Zlag.mat,
                                     type = type,
                                     curr_tree = curr_trees[[j]],
                                     node_min_size = node_min_size,
                                     s = s,
                                     splitting_rules = splitting_rules,
                                     max_bad_trees = max_bad_trees)

      }




      # print("line 2825")


      # CURRENT TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_old = tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(curr_trees[[j]], alpha, beta)

      # print("line 2825")
      #
      # print("new_trees[[j]]")
      # print(new_trees[[j]])

      # NEW TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_new = tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(new_trees[[j]], alpha, beta)

      # Exponentiate and multiply by the transition probabilities

      if(type == 'grow'){
        a = exp(l_new - l_old)*ratio_grow(new_trees[[j]], curr_trees[[j]])
      } else if(type == 'prune'){
        a = exp(l_new - l_old)*ratio_prune(new_trees[[j]], curr_trees[[j]])
      } else{
        a = exp(l_new - l_old)
      }

      vars_empty_pruned <- c()

      if(is.na(a)){
        print("current_partial_residuals = ")
        print(current_partial_residuals)

        print("get_tree_prior(new_trees[[j]], alpha, beta) = ")
        print(get_tree_prior(new_trees[[j]], alpha, beta))

        print("get_tree_prior(curr_trees[[j]], alpha, beta) = ")
        print(get_tree_prior(curr_trees[[j]], alpha, beta))

        print("tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) = ")
        print(tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu))

        print("tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)  = ")
        print(tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) )

        print("new_trees[[j]] = ")
        print(new_trees[[j]])
        print("curr_trees[[j]] = ")
        print(curr_trees[[j]])

        print("l_new = ")
        print(l_new)

        print("l_old = ")
        print(l_old)

        print("ratio_prune(new_trees[[j]], curr_trees[[j]]) = ")
        print(ratio_prune(new_trees[[j]], curr_trees[[j]]))

        print("ratio_grow(new_trees[[j]], curr_trees[[j]]) = ")
        print(ratio_grow(new_trees[[j]], curr_trees[[j]]))

        print("exp(l_new - l_old) = ")
        print(exp(l_new - l_old))

        print("type = ")
        print(type)

        print("is.na(a)")
      }


      if(a > runif(1)) {
        curr_trees[[j]] = new_trees[[j]]
        # only account for pruning if  accept
        vars_empty_pruned <- new_trees[[j]]$vars_empty_pruned

        for(var_ind in vars_empty_pruned){
          var_count[var_ind ] = var_count[var_ind ] - 1
        }


        if (type =='change'){
          var_count[curr_trees[[j]]$var[1] ] = var_count[curr_trees[[j]]$var[1] ] - 1
          var_count[curr_trees[[j]]$var[2] ] = var_count[curr_trees[[j]]$var[2] ] + 1
        }

        if (type=='grow'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] + 1
        } # -1 because of the intercept in X

        if (type=='prune'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] - 1
        } # -1 because of the intercept in X

      }


      ### might need to edit simulate_mu to find right terminal nodes #########

      # Update mu whether tree accepted or not
      curr_trees[[j]] = simulate_mu(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)
      # Updating BART predictions
      current_fit = get_predictions(curr_trees[[j]], Zlag.mat, single_tree = TRUE)
      mu = mu - tree_fits_store[,j] # subtract the old fit
      mu = mu + current_fit # add the new fit
      tree_fits_store[,j] = current_fit # update the new fit

    } # End loop through trees



    # sum_of_squares = sum((y_scale - y_hat)^2)

    # Update sigma2 (variance of the residuals)
    # sigma2 = update_sigma2(sum_of_squares, n = length(y_scale), nu, lambda)
    # variance kept equal to 1, do not update

    # # Update s = (s_1, ..., s_p), where s_p is the probability that predictor p is used to create new terminal nodes
    # if (sparse == 'TRUE' & i > floor(iter.max*0.1)){
    #   s = update_s(var_count, ncol(Zlag.mat), 1)
    # }

    # Update s = (s_1, ..., s_p), where s_p is the probability that predictor q in 1:p is used to create new terminal nodes
    if (sparse & i > floor(iter.max * 0.25)) {
      s <- update_s(var_count, p, alpha_s)
      if(alpha_prior){
        alpha_s <- update_alpha_par(s, alpha_scale, alpha_a, alpha_b)
      }
    }

    if(sigma_mu_prior){
      sigma2_mu <-  update_sigma_mu_par(curr_trees, sigma2_mu)
    }


    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta




    # if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(df_for_dbart)

    # Xmat.test[,1:num_lags] <-  Zlag.mat.test


    temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))

    for(t  in 1:num_lags){
      if(noise_in_pred ==1){
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
      }else{
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]

      }

    }

    # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #                                                                      (num_lags+1):ncol(Xmat.test)])

    temp_test_mat <- data.frame(x = temp_test_mat)
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # print("Line 5488")


    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )


    # if(iter < 5){
    #   print("temp_test_mat = " )
    #   print(temp_test_mat)
    # }

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # must use original column names to prevent an error in the predict function
      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      # testpredvec <- sampler$predict(temp_test_mat)
      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

      #fill in temp_test_preds with noise
      if(noise_in_pred ==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
      }


      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

      if(t1 != num_test_periods){


        if(num_lags ==1){
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }else{
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                    temp_test_mat[,1:(num_lags-1)] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }
      }

      # colnames(temp_test_mat) <- colnames(Xmat.test)


      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?

    # print("Line 5545")


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }


    draw$mu_test[,iter] <- temp_mu_test
    # draw$mu_test[,iter] <- samplestemp$test[,1]

    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

    # draw$mu_test[,1] <- samplestemp$test[,1]

    # }else{
    #   draw$mu_test[,1] <- initial.list$mu_test
    # }




    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

    iter <- iter+1
  } # end loop over MCMC iterations


  return(draw)
}




##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////





#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with partial ranks and with Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and with covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.train An \eqn{N} by \eqn{L} training covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param X.test An \eqn{N} by \eqn{L} test covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param n.item Number of entities/items being ranked.
#' @param n.rankerbytime Number of rankers multiplied by number of time periods
#' @param n.ranker Number of rankers
#' @param n.time Number of time periods
#' @param p.cov Number of covariates.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @param itemcovars Set equal to TRUE if covariates vary across items, and FALSE otherwise.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @useDynLib ROBART2, .registration = TRUE
#' @export
ARRObartWithCovars_fullcond_EmpN_topk <- function(ranks_mat, #pair.comp.ten,
                                                   X.train = matrix(NA, nrow = n.item, ncol = 0),
                                                   X.test = matrix(NA, nrow =0, ncol = 0),
                                                   # tau2.alpha = 5^2,
                                                   # nu.alpha = 3,
                                                   # tau2.beta = 5^2,
                                                   # nu.beta = 3,
                                                   n.item = dim(ranks_mat)[1], # = dim(pair.comp.ten)[1],
                                                   n.rankerbytime  = dim(ranks_mat)[2], # = dim(pair.comp.ten)[3],
                                                   n.ranker,
                                                   n.time,
                                                   p.cov = ncol(X.train),
                                                   iter.max = 5000,
                                                   para.expan = TRUE,
                                                   print.opt = 100,
                                                   initial.list = NULL,
                                                   n.trees = 50L,
                                                   n.burn = 0L,
                                                   n.samples = 1L,
                                                   n.thin = 1L,
                                                   trans_prob = c(2.5, 2.5, 4) / 9, # Probabilities to grow, prune or change, respectively
                                                   n.chains = 1,
                                                   n.threads = 1L,#guessNumCores(),
                                                   printEvery = 100L,
                                                   printCutoffs = 0L,
                                                   rngKind = "default",
                                                   rngNormalKind = "default",
                                                   rngSeed = NA_integer_,
                                                   updateState = FALSE,
                                                   num_lags = 1,
                                                   diff_num_test_rankers = 0,
                                                   keep_zmat = FALSE,
                                                   noise_in_pred = 0,
                                                   seq_z_draws = 1,
                                                   N_hdr = 100,
                                                   rho_hdr = 0.5,
                                                   smoothing_method = "AR",
                                                   num_horizon = 1,
                                                   num_z_iters = 10,
                                                   itemcovars = FALSE,
                                                   node_min_size = 5,
                                                   k = 2,
                                                   sigquant = .90,
                                                   alpha = 0.95,
                                                   beta = 2,
                                                   nu = 3,
                                                   lambda = 0.1,
                                                   no_empty_proposals = FALSE,
                                                   alpha_prior = TRUE,
                                                   sigma_mu_prior = FALSE,
                                                   splitting_rules = "discrete",
                                                   max_bad_trees = 10,
                                                  sparse = FALSE,
                                                  alpha_a_y = 0.5,
                                                  alpha_b_y = 1,
                                                  alpha_split_prior = TRUE){


  if(!(splitting_rules %in% c("discrete", "continuous"))){
    stop("splitting_rules must be 'discrete' or 'continuous'.")
  }

  X.train <- as.matrix(X.train)
  X.test <- as.matrix(X.test)

  ######### set up things for myBART implementation ####################

  # Extract control parameters
  # we only have to allow for empty nodes when updating Z (and therefore Zlag is updated and splits on Zlag are affected)
  # Therefore there is still a minimum node size criterion for the purpose of proposing new splits
  # node_min_size = node_min_size

  # Storage containers
  store_size = iter.max # npost # code currently written to save all output, so no nburnin or npost
  tree_store = vector('list', store_size)
  sigma2_store = rep(NA, store_size)
  # y_hat_store = matrix(NA, ncol = length(y), nrow = store_size)
  # var_count = rep(0, ncol(x))
  # var_count_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # s_prob_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # tree_fits_store = matrix(0, ncol = n.trees, nrow = length(y))

  sigma2 <- 1 # keep sigma2 set to 1


  ########## beginning of original code ############################


  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)

      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  # ranks_mat <- matrix(NA,
  #                     ncol = n.ranker*n.time,
  #                     nrow = n.item )
  #
  #
  # #n.item by n.item
  #
  # for(t in 1:n.time){
  #
  #   for(indiv in 1:n.ranker){
  #     pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]
  #
  #     # 1 corresponding to "highest rank" . i.e. highest utility ite,
  #     # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1
  #
  #     # 1 corresponding to "lowest rank". i.e. lowest utility item
  #
  #     up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
  #
  #
  #     ranks_mat[, (t-1)*n.ranker + indiv] <- up.order
  #
  #   }
  # }


  # it might be more efficient to create and save all rank constraint matrices at this stage


  # rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))
  #
  # for(indiv in 1:n.ranker){
  #
  #   for(t in 1:n.time){
  #
  #     rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]
  #
  #
  #     rankconstraint_t <- matrix(0,
  #                                nrow = n.item - 1,
  #                                ncol = n.item)
  #
  #     # note: ordering of rows is unimportant
  #     # as long as ordering agrees with the ordering of the mean vector
  #
  #     # so can begin by filling in first row
  #
  #     #MUST BE EDITED IF ALLOW FOR TIES
  #     for(rankind in 1:(length(rankvec_t)-1)){
  #
  #       rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
  #       rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1
  #
  #       # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
  #       # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1
  #
  #     }
  #
  #     rank_cons_arr[, , indiv, t] <- rankconstraint_t
  #
  #   }
  # }
  # # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  # boundconstraints <- matrix(NA,
  #                            nrow = 2*n.item,
  #                            ncol = n.item)
  #
  # # use kroenecker product
  # # there is probably a more efficient way of doing this
  #
  # boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      # pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))


      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))

      tempsort <- sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE )

      Z.mat[ tempsort$ix , j] <-
        qnorm(  tempsort$x   /(n.item+1)) +
        rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   qnorm(c(n.item : 1)/(n.item+1)) +
      #   rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }



    print("Line 799.")

    # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )

      Xmat.train.no.y <- cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                  ncol =  ncol(X.train) + num_lags ,
                                                  byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")

        Xmat.test.no.y <- cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                       ncol =  ncol(X.test) , byrow = TRUE ) )




        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        Xmat.train.no.y <- cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          Xmat.test.no.y <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }



    # ##### old dbarts initialization ###############
    #
    # control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
    #                          keepTrees = TRUE,
    #                          n.trees = n.trees,
    #                          n.burn = n.burn,
    #                          n.samples = n.samples,
    #                          n.thin = n.thin,
    #                          n.chains = n.chains,
    #                          n.threads = n.threads,
    #                          printEvery = printEvery,
    #                          printCutoffs = printCutoffs,
    #                          rngKind = rngKind,
    #                          rngNormalKind = rngNormalKind,
    #                          rngSeed = rngSeed)
    #
    #
    # # print(colnames(Xmat.train))
    # # print(colnames(Xmat.test))
    #
    # # print("begin dbarts")
    #
    #
    # if(nrow(X.test )==0){
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     #test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1),
    #                     sigma=1 #check if this is the correct approach for setting the variance to 1
    #   )
    #
    # }else{
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    #                     sigma=1 #
    #   )
    #
    # }
    #
    #
    # # print("error after dbarts")
    #
    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    # #sampler$setPredictor(x= Xmat.train$x, column = 1, forceUpdate = TRUE)
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # sampler$sampleTreesFromPrior()
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mupreds <- sampler$predict(Xmat.train)
    #
    # # mu <- mutemp





    y_hat_store = matrix(NA, ncol = length(as.vector(Z.mat)), nrow = store_size)
    var_count = rep(0, ncol(Xmat.train.no.y))
    var_count_store = matrix(0, ncol = ncol(Xmat.train.no.y), nrow = store_size)
    s_prob_store = matrix(0, ncol = ncol(Xmat.train.no.y), nrow = store_size)
    tree_fits_store = matrix(0, ncol = n.trees, nrow = length(as.vector(Z.mat)))
    s = rep(1/ncol(Xmat.train.no.y), ncol(Xmat.train.no.y))


    p <- ncol(Xmat.train.no.y)
    rho <- p # For DART

    if(alpha_prior){
      alpha_s <- p
    }else{
      alpha_s <- 1
    }
    alpha_scale <- p
    # s <- rep(1 / p, p) # probability vector to be used during the growing process for DART feature weighting


    if(sparse){
      draw$alpha_s_store <- rep(NA, iter.max)
      draw$var_count_store <- matrix(0, ncol = p, nrow = iter.max)
      draw$s_prob_store <- matrix(0, ncol = p, nrow = iter.max)
    }



    ###### new myBART initialization ######################

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }
    }

    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }

    # maybe (max(as.vector(Z.mat))-min(as.vector(Z.mat)))
    # can be replaced by something else
    # sigma2_mu <- (max(as.vector(Z.mat))-min(as.vector(Z.mat)))/((2 * k * sqrt(n.trees))^2)
    sigma2_mu <- ((max(as.vector(Z.mat))-min(as.vector(Z.mat)))/(2 * k * sqrt(n.trees)))^2


    # Create a list of trees for the initial stump
    curr_trees = create_stump(num_trees = n.trees,
                              y = as.vector(Z.mat),
                              X = Xmat.train.no.y)
    # Initialise the new trees as current one
    new_trees = curr_trees

    # Initialise the predicted values to zero
    mutemp = get_predictions(curr_trees, Xmat.train.no.y, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))












    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train.no.y = ")
        print(Xmat.train.no.y)
        print("Z.mat = ")
        print(Z.mat)

        # print("samplestemp$sigma = ")
        # print(samplestemp$sigma)
        # print("samplestemp$varcount = ")
        # print(samplestemp$varcount)
        #
        # print("samplestemp$train[,1] = ")
        # print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  print("Line 954")


  # df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    # temp_test_mat <- as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_mat <- data.frame( x = as.matrix(Xmat.test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(Xmat.test)



    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    temp_mu_test <- rep(NA,  nrow(Xmat.test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      # testpredvec <- sampler$predict(temp_test_mat)
      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }

      colnames(temp_test_mat) <- colnames(Xmat.test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  iter <- 2
  breakcount <- 0

  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    # Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }

      # tempsort <- sort(tempcol)
      #
      # tempdiffs <- tempsort[-1] - tempsort[-(length(tempsort))]

      # if( any( abs(tempdiffs) < 0.001 )   ){
      #
      #   print("tempsort =")
      #   print(tempsort)
      #   print("tempdiffs =")
      #   print(tempdiffs)
      #   print("j = ")
      #   print(j)
      #   print("tempcol =")
      #   print(tempcol)
      #   print("Z.mat =")
      #   print(Z.mat)
      #   print(" some differences in Z vector very small")
      # }

    }

    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA



    # num_regions <- nrow(intersectmat)

    # print("Line 1169")


    for(z_iter_ind in 1:num_z_iters){

      # print("z_iter_ind = ")
      # print(z_iter_ind)

      for(indiv in 1:n.ranker){

        # print("indiv = ")
        # print(indiv)

        ########### calculate qkt   for t = 1 ########################################

        Biglist_list_item_intersectmats <- list()
        Biglist_intersectmats <- list()


        ######## Period 1 Intersection Matrix #########################

        # create vector of indices for ranker indiv in time period 1
        ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        # print("Begin Period 1 intersection matrices = ")
        # print(indiv)

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            # treeexample1 <- sampler$getTrees(treeNums = i,
            #                                  chainNums = 1,
            #                                  sampleNums = 1)
            #
            # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
            #                                   treeNums = i,
            #                                   chainNums = 1,
            #                                   sampleNums = 1)

            temptree <- curr_trees[[i]]$tree_matrix

            treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

            temp_na_inds <- is.na(temptree[,'split_variable'])
            # print("temp_na_inds = ")
            # print(temp_na_inds)
            #
            # print("treeexample1 = ")
            # print(treeexample1)
            #
            # print("temptree[temp_na_inds,'mu'] = ")
            # print(temptree[temp_na_inds,'mu'])

            treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

            # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
            #   1,#rep(sampleNums, nrow(temptree)),
            #   i,#rep(treeNums, nrow(temptree)),
            #   temptree[, 'node_size'],
            #   # mybarttree[,'split_variable'],
            #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
            #          -1,
            #          temptree[,'split_variable']),
            #   fast_ifelse(is.na(temptree[,'split_variable']) ,
            #          temptree[,'mu'],
            #          temptree[,'split_value']))

            # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))


            # print("rebuilt_tree = ")
            # print(rebuilt_tree)

            #must use covariates for individual indiv at time period t

            # print("Xmat.train$x[obs_indices[1],, drop = FALSE] = ")
            # print(Xmat.train$x[obs_indices[1],, drop = FALSE])
            #
            #
            # print("Xmat.train$x[obs_indices[1],] = ")
            # print(Xmat.train$x[obs_indices[1],])
            #
            #
            # print("obs_indices[1] = ")
            # print(obs_indices[1])
            #
            #
            # print("Xmat.train = ")
            # print(Xmat.train)



            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )
            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )


          }

          intersectmat_tmin1 <- interNtreesB(list_inter_mats)


          intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat_tmin1)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat_tmin1[ktemp,1]
            templower <- intersectmat_tmin1[rowind,2]
            tempupper <- intersectmat_tmin1[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[1]] <- intersectmat_tmin1


        }else{ # itemcovars == TRUE


          list_item_intersectmats_tmin1 <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)

              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])

              # print("temp_na_inds = ")
              # print(temp_na_inds)
              #
              # print("treeexample1 = ")
              # print(treeexample1)
              #
              # print("temptree[temp_na_inds,'mu'] = ")
              # print(temptree[temp_na_inds,'mu'])

              treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))
              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )


            } #end loop over trees

            intersectmat_tmin1 <- interNtreesB(list_inter_mats)

            intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat_tmin1)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat_tmin1[ktemp,1]
              templower <- intersectmat_tmin1[rowind,2]
              tempupper <- intersectmat_tmin1[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats_tmin1[[index_item]] <- intersectmat_tmin1


          } #end loop over items

          Biglist_list_item_intersectmats[[1]] <- list_item_intersectmats_tmin1

        } # end else itemcovars == TRUE


        ################ period 2 intersection matrix #################################################

        # create vector of indices for ranker indiv in time period 2
        ind_start <- (2 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (2 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            # treeexample1 <- sampler$getTrees(treeNums = i,
            #                                  chainNums = 1,
            #                                  sampleNums = 1)

            # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
            #                                   treeNums = i,
            #                                   chainNums = 1,
            #                                   sampleNums = 1)

            temptree <- curr_trees[[i]]$tree_matrix

            treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

            temp_na_inds <- is.na(temptree[,'split_variable'])
            treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

            # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
            #   1,#rep(sampleNums, nrow(temptree)),
            #   i,#rep(treeNums, nrow(temptree)),
            #   temptree[, 'node_size'],
            #   # mybarttree[,'split_variable'],
            #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
            #          -1,
            #          temptree[,'split_variable']),
            #   fast_ifelse(is.na(temptree[,'split_variable']) ,
            #          temptree[,'mu'],
            #          temptree[,'split_value']))
            # # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

            #must use covariates for individual indiv at time period t

            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )

          }

          intersectmat <- interNtreesB(list_inter_mats)


          intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat[ktemp,1]
            templower <- intersectmat[rowind,2]
            tempupper <- intersectmat[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[2]] <- intersectmat


        }else{ # itemcovars == TRUE


          list_item_intersectmats <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)


              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])
              treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))
              # # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )

            } #end loop over trees

            intersectmat <- interNtreesB(list_inter_mats)

            intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat[ktemp,1]
              templower <- intersectmat[rowind,2]
              tempupper <- intersectmat[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats[[index_item]] <- intersectmat


          } #end loop over items

          Biglist_list_item_intersectmats[[2]] <- list_item_intersectmats

        } # end else itemcovars == TRUE


        # print("End Period 1 intersection matrices = ")


        ##### t = 3 to T intersect matrices ######################

        # print("Begin loop for intersection matrices = ")

        for(t in 3:n.time){

          #### obtain intersection matrices for time period t ###############
          # print("t = ")
          # print(t)

          # create vector of indices for ranker indiv in time period 1
          ind_start <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          ind_end <- (t - 1)*n.ranker*n.item+n.item*indiv
          obs_indices <- ind_start:ind_end

          if(itemcovars == FALSE){


            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)

              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])
              treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )

            }

            intersectmat <- interNtreesB(list_inter_mats)

            Biglist_intersectmats[[t]] <- intersectmat


          }else{ # itemcovars == TRUE


            list_item_intersectmats <- list()

            for(index_item in 1:n.item){

              obs_one_ind <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

              list_inter_mats <- list()

              for(i in 1:n.trees){

                # treeexample1 <- sampler$getTrees(treeNums = i,
                #                                  chainNums = 1,
                #                                  sampleNums = 1)

                # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
                #                                   treeNums = i,
                #                                   chainNums = 1,
                #                                   sampleNums = 1)

                temptree <- curr_trees[[i]]$tree_matrix

                treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

                temp_na_inds <- is.na(temptree[,'split_variable'])
                treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

                # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
                #   1,#rep(sampleNums, nrow(temptree)),
                #   i,#rep(treeNums, nrow(temptree)),
                #   temptree[, 'node_size'],
                #   # mybarttree[,'split_variable'],
                #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
                #          -1,
                #          temptree[,'split_variable']),
                #   fast_ifelse(is.na(temptree[,'split_variable']) ,
                #          temptree[,'mu'],
                #          temptree[,'split_value']))
                # # rebuilt_tree <- rebuildTree2(treeexample1)

                rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

                #must use covariates for individual indiv at time period t

                # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

                list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                         as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )


              } #end loop over trees

              intersectmat <- interNtreesB(list_inter_mats)

              list_item_intersectmats[[index_item]] <- intersectmat


            } #end loop over items


            Biglist_list_item_intersectmats[[t]] <- list_item_intersectmats


          } # end else itemcovars == TRUE

        }


        # print("End loop for intersection matrices = ")


        ######## Begin loop over items ################################

        # print("Begin loop for over items = ")

        for(item_ind in 1:n.item){

          # print("item_ind = ")
          # print(item_ind)

          if(itemcovars == TRUE){
            list_item_intersectmats <- Biglist_list_item_intersectmats[[2]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[1]]


            intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            intersectmat <- Biglist_intersectmats[[2]]
            intersectmat_tmin1 <- Biglist_intersectmats[[1]]
          }

          num_regions <- nrow(intersectmat)
          num_regions_tmin1 <- nrow(intersectmat_tmin1)

          # ########### begin create intersectmat t = 1 ############
          #
          # # define intersections inside item loop
          # # to allow covariates can be item specific
          #
          # # create vector of indices for ranker indiv in time period 1
          #
          # # this part is not really necessary
          # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
          # obs_indices <- ind_start:ind_end
          #
          # # obs_indices[1] could jsut be replaced by [1] below\
          # # because the only variable is zlag, so the other covariates are not used
          #
          #
          # list_inter_mats <- list()
          #
          # for(i in 1:n.trees){
          #
          #   treeexample1 <- sampler$getTrees(treeNums = i,
          #                                    chainNums = 1,
          #                                    sampleNums = 1)
          #
          #   rebuilt_tree <- rebuildTree2(treeexample1, sampler)
          #
          #
          #   #must use covariates for individual indiv at time period t
          #
          #   list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )
          #   # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
          #
          #
          # }
          #
          # intersectmat <- interNtreesB(list_inter_mats)
          #
          # # print("Line 1146")
          #
          # intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))
          #
          # # print("Line 1150")
          #
          #
          # # calculate one dimensional integrals
          # for(rowind in 1:nrow(intersectmat)){
          #   # ktemp <- nkt_mat[rowind,k_index]
          #   # tempmean <- intersectmat[ktemp,1]
          #   templower <- intersectmat[rowind,2]
          #   tempupper <- intersectmat[rowind,3]
          #
          #   # ASSUMING PRIOR MEAN ALL ZEROS
          #
          #   # These are the q0 integrals
          #   intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
          #   # tempintegralval <- tempintegralval*onedim_int
          # }
          #
          # # intersectmat_tmin1 <- intersectmat
          #
          #
          #
          # ########### end create intersectmat t = 1 ############
          #





          #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

          # loop over items

          # Now loop over time periods

          # special case for t=1

          # probability matrix for sampling elements

          # let rows be period zero, and columns be period 1 (2?)

          # probmattemp <- matrix(0,
          #                       nrow = num_regions_tmin1,
          #                       ncol = num_regions)

          logprobmattemp <- matrix(0,
                                   nrow = num_regions_tmin1,
                                   ncol = num_regions)

          # loop over period 2 regions into which z_1 can fall


          tempbounds <- matrix(NA,
                               nrow = num_regions,
                               ncol = 2)

          # Trunc norm prob of next periods latent value conditional on region

          # Create intervals from interval t+1 latent values

          # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

          # inds for j ranked below i in t+1



          # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in t+1
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower <- -Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    belowrank_ind]
          # }
          #
          # # inds for j ranked above i in t+1
          #
          # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period t+1
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper <- Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #
          #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    aboverank_ind]
          # }


          temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                          n.item*(indiv - 1) +
                                          item_ind]



          rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]

          # if(any(order(rankvec_t) !=
          #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                           n.item*(indiv-1) +
          #                           1:n.item])) ){
          #
          #   # print("order(rankvec_t) = ")
          #   # print(order(rankvec_t))
          #   #
          #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #   #                         n.item*(indiv - 1) +
          #   #                         1:n.item])  = ")
          #
          #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                  n.item*(indiv - 1) +
          #                                  1:n.item]) )
          #
          #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #   #                                n.item*(indiv - 1) +
          #   #                                1:n.item] = ")
          #
          #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                            n.item*(indiv - 1) +
          #                            1:n.item])
          #
          # }

          # inds for j ranked below i in t

          belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

          #max of latent variables for j ranked below i in t
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower3 <- -Inf
          }else{
            temp_lower3 <- max(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              belowrank_ind])
          }

          # inds for j ranked above i in t

          aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

          #min of latent variables for j ranked below i in period t

          if(length(aboverank_ind) ==0){
            temp_upper3 <- Inf
          }else{
            temp_upper3 <- min(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              aboverank_ind])
          }


          temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
                                                   mean = intersectmat[1:num_regions, 1],
                                                   sd = 1)

          for(k_ind in 1:num_regions){




            # obtain mean for truncated normal distribution
            # temp_mean <- intersectmat[k_ind, 1]

            # want trunc norm probability of latent variable value for item_ind
            # in period t+1


            # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #                               a=temp_lower,
            #                               b=Inf,
            #                               mean = temp_mean,
            #                               sd = 1)

            # tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp

            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                                 mean = temp_mean,
            #                                 sd = 1)

            # temp_tnorm_logprob <- fastlognormdens(temp_ztp1,
            #                                          mean = tempmeanfordens,
            #                                          sd = 1)

            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                          mean = temp_mean,
            #                          sd = 1)

            # temp_mean <- intersectmat[k_ind, 1]

            temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]


            # now second term


            temp_lower2 <- intersectmat[k_ind, 2]
            temp_upper2 <- intersectmat[k_ind, 3]




            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_lower3 = ")
            # print(temp_lower3)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)
            #
            # print("temp_upper3 = ")
            # print(temp_upper3)


            if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
              # intervals do not overlap, therefore assign probability zero
              # and skip to next iteration


              # print("k_ind = ")
              # print(k_ind)

              # print("ncol(temp_region_probs) = ")
              # print(ncol(temp_region_probs))

              # print("nrow(temp_region_probs) = ")
              # print(nrow(temp_region_probs))


              # these three lines are technically unnecessary
              # probmattemp[, k_ind] <- rep(0,num_regions_tmin1)
              logprobmattemp[, k_ind] <- rep(-Inf,num_regions_tmin1)
              tempbounds[k_ind, 1] <- NA
              tempbounds[k_ind, 2] <- NA

              next

            }


            temp_lower2 <- max(temp_lower2, temp_lower3)
            temp_upper2 <- min(temp_upper2, temp_upper3)

            if(temp_lower2 > temp_upper2){

              print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

              print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                       n.item*(indiv - 1) +
                                       1:n.item])

              print("item_ind = ")
              print(item_ind)

              print("rankvec_t = ")
              print(rankvec_t)

              stop("Line 1581 temp_lower2 > temp_upper2")
            }


            for(k0_ind in 1:num_regions_tmin1){

              #loop over all possible means
              temp_mean2 <- intersectmat_tmin1[k0_ind,1]

              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # probmattemp[k0_ind, k_ind] <- prob_t_region*
              #   temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob +
                log(intersectmat_tmin1[k0_ind,4])

              # if(probmattemp[k0_ind, k_ind] < 0){
              #   print("probmattemp[k0_ind, k_ind] = ")
              #   print(probmattemp[k0_ind, k_ind])
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   print("temp_tnorm_prob = ")
              #   print(temp_tnorm_prob)
              #
              #   print("intersectmat[k0_ind,4] = ")
              #   print(intersectmat[k0_ind,4])
              #
              #   print("temp_upper2 = ")
              #   print(temp_upper2)
              #
              #   print("temp_lower2 = ")
              #   print(temp_lower2)
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #
              # }


            } # end loop over k0

            # save upper and lower bounds (mean saved in intersectmat)
            # or just obtain again later

            tempbounds[k_ind,1] <- temp_lower2
            tempbounds[k_ind,2] <- temp_upper2


          } # end loop over k1


          #sample a combination of k0 and k1
          # if necessary can use column sums to sample k1, then k0
          # however, this is probably unnecessary


          # print("Line 1621 before sample")

          # region_ind <- sample.int(num_regions_tmin1*num_regions,
          #                          size = 1,
          #                          replace = TRUE,
          #                          prob = as.vector(probmattemp))


          logprobstemp <- as.vector(logprobmattemp)
          max_ll <- max(logprobstemp)
          logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
          probstemp <- exp(logprobstemp - logsumexps)

          region_ind <- sample.int(num_regions_tmin1*num_regions,
                                   size = 1,
                                   replace = TRUE,
                                   prob = as.vector(probstemp))


          # print("Line 1629 after sample")

          # k0 region is sampled number modulo number of regions in period 1
          k0_region_ind <- ((region_ind -1) %% num_regions_tmin1 ) + 1
          # if(k0_region_ind ==0){
          #   k0_region_ind <- num_regions
          # }

          # k1 region is the ceiling of sampled number divided by number of regions in period 1
          # k1_region_ind <- ceiling(region_ind/num_regions)
          k1_region_ind <- (region_ind -1) %/% num_regions_tmin1 + 1


          # print("k1_region_ind = ")
          # print(k1_region_ind)

          temp_lower2 <- tempbounds[k1_region_ind,1]
          temp_upper2 <- tempbounds[k1_region_ind,2]

          # print("num_regions = ")
          # print(num_regions)
          #
          # print("region_ind = ")
          # print(region_ind)
          #
          # print("k0_region_ind = ")
          # print(k0_region_ind)

          temp_mean0 <- intersectmat_tmin1[k0_region_ind, 1]
          # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

          # print("temp_mean0 = ")
          # print(temp_mean0)
          #
          # print("temp_lower2 = ")
          # print(temp_lower2)
          #
          # print("temp_upper2 = ")
          # print(temp_upper2)

          tempbuffer <- (temp_upper2 - temp_lower2)/100

          if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
            upper_buffered <- temp_upper2 - tempbuffer
            lower_buffered <- temp_lower2 + tempbuffer

          }else{
            upper_buffered <- temp_upper2
            lower_buffered <- temp_lower2

          }


          zdraw_temp <- rtruncnorm(n = 1,
                                   a = lower_buffered,
                                   b = upper_buffered,
                                   mean = temp_mean0,
                                   sd = 1)


          Z.mat[item_ind,  indiv ] <- zdraw_temp


          #### Begin Loop over time ###################

          # loop over time periods for general case 1 < t < T

          for(t in 2:(n.time - 1)){


            if(itemcovars == TRUE){
              list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
              list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[t]]


              intersectmat <- list_item_intersectmats[[index_item]]
              intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
            }else{
              intersectmat <- Biglist_intersectmats[[t+1]]
              intersectmat_tmin1 <- Biglist_intersectmats[[t]]
            }

            num_regions <- nrow(intersectmat)

            temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # or first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat_tmin1[, 3]) )[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

            # print("temp_mean2 = ")
            # print(temp_mean2)
            #
            # print("ktemp_tmin1 = ")
            # print(ktemp_tmin1)



            # Calculate the probabilities for each region in this time period
            # the regions being looped over are actually period t+1 regions

            # Same regions for all time periods if there are no time varying covariates

            # However, the weights are individual and time period specific

            # loop through regions


            # first column is the probabilities
            # second column is the lower bounds
            # third column is the upper bounds
            # temp_region_probs <- matrix(0,
            #                             nrow = nrow(intersectmat),
            #                             ncol = 3)

            temp_region_logprobs <- matrix(0,
                                           nrow = nrow(intersectmat),
                                           ncol = 3)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

            # inds for j ranked below i in t+1

            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            # want trunc norm probability of latent variable value for item_ind
            # in period t+1

            temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]

            rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]



            # if(any(order(rankvec_t) !=
            #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                           n.item*(indiv - 1) +
            #                           1:n.item]) )){
            #
            #   print("order(rankvec_t) = ")
            #   print(order(rankvec_t))
            #
            #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                         n.item*(indiv - 1) +
            #                         1:n.item])  = ")
            #
            #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                  n.item*(indiv - 1) +
            #                                  1:n.item]) )
            #
            #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                n.item*(indiv - 1) +
            #                                1:n.item] = ")
            #
            #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item])
            #
            #
            # }





            # inds for j ranked below i in t

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in t
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- max(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind])
            }

            # inds for j ranked above i in t

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period t

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- min(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind])
            }



            temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
                                                     mean = intersectmat[1:num_regions, 1],
                                                     sd = 1)


            for(k_ind in 1:num_regions){



              # obtain mean for truncated normal distribution
              # temp_mean <- intersectmat[k_ind, 1]



              # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #                               a=temp_lower,
              #                               b=Inf,
              #                               mean = temp_mean,
              #                               sd = 1)

              # tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp

              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                                 mean = temp_mean,
              #                                 sd = 1)

              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                          mean = temp_mean,
              #                          sd = 1)

              temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]


              # Probability of z_t in intersection of
              # region k_ind (for period t+1)
              # and region defined by period t latent variables for other individuals
              # and rank for period t


              # tildeC_ktminl corresponds to
              # period t+1 k_ind region intereval

              temp_lower2 <- intersectmat[k_ind, 2]
              temp_upper2 <- intersectmat[k_ind, 3]



              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_upper2 = ")
              # print(temp_upper2)
              #
              # print("temp_lower3 = ")
              # print(temp_lower3)
              #
              # print("temp_upper3 = ")
              # print(temp_upper3)


              if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
                # intervals do not overlap, therefore assign probability zero
                # and skip to next iteration

                # print("k_ind = ")
                # print(k_ind)

                # print("ncol(temp_region_probs) = ")
                # print(ncol(temp_region_probs))

                # print("nrow(temp_region_probs) = ")
                # print(nrow(temp_region_probs))

                # temp_region_probs[k_ind, 1] <- 0
                # temp_region_probs[k_ind, 2] <- NA
                # temp_region_probs[k_ind, 3] <- NA

                temp_region_logprobs[k_ind, 1] <- -Inf
                temp_region_logprobs[k_ind, 2] <- NA
                temp_region_logprobs[k_ind, 3] <- NA

                next
              }

              temp_lower2 <- max(temp_lower2, temp_lower3)
              temp_upper2 <- min(temp_upper2, temp_upper3)


              if(temp_lower2 > temp_upper2){

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")
                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])
                print("item_ind = ")
                print(item_ind)

                print("rankvec_t = ")
                print(rankvec_t)


                print("temp_lower2 = ")
                print(temp_lower2)

                print("temp_upper2 = ")
                print(temp_upper2)

                stop("Line 1917. temp_lower2 > temp_upper2")
              }



              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # print("temp_upper2 = ")
              # print(temp_upper2)
              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              #
              # print("prob_t_region = ")
              # print(prob_t_region)
              #
              # print("temp_tnorm_prob = ")
              # print(temp_tnorm_prob)

              # prob_t_region <- prob_t_region*temp_tnorm_prob
              # prob_t_region <- temp_tnorm_prob
              logprob_t_region <- temp_tnorm_logprob

              # save region probability

              # and save region bounds (or maybe more memory efficient to obtain the region again)

              # must multiply by other previously obtained probabilities

              # print("prob_t_region = ")
              # print(prob_t_region)

              # temp_region_probs[k_ind, 1] <- prob_t_region
              # temp_region_probs[k_ind, 2] <- temp_lower2
              # temp_region_probs[k_ind, 3] <- temp_upper2

              temp_region_logprobs[k_ind, 1] <- logprob_t_region
              temp_region_logprobs[k_ind, 2] <- temp_lower2
              temp_region_logprobs[k_ind, 3] <- temp_upper2


            }


            # sample a region using probabilities obtained above

            # print("Line 1903 before sample")

            # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])


            logprobstemp <- as.vector(temp_region_logprobs[,1])
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int(num_regions, 1, replace = TRUE,
                                     prob = probstemp)


            # print("Line 1914 after sample")

            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
            #
            # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
            #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
            #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
            #
            # }else{
            #   upper_buffered <- temp_region_probs[region_ind, 3]
            #   lower_buffered <- temp_region_probs[region_ind, 2]
            #
            # }

            tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/50

            if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
              upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
              lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer

            }else{
              upper_buffered <- temp_region_logprobs[region_ind, 3]
              lower_buffered <- temp_region_logprobs[region_ind, 2]

            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a=lower_buffered,
                                     b=upper_buffered,
                                     mean = temp_mean2,
                                     sd = 1)

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a=temp_region_probs[region_ind, 2],
            #                          b=temp_region_probs[region_ind, 3],
            #                          mean = temp_mean2,
            #                          sd = 1)



            Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



          } # end loop over time periods

          # check for special cases for n.time - 1, n.time - 2, n.time - 3

          # special case for t = n.time


          if(itemcovars == TRUE){
            # list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[n.time]]


            # intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            # intersectmat <- Biglist_intersectmats[[t+1]]
            intersectmat_tmin1 <- Biglist_intersectmats[[n.time]]
          }

          num_regions <- nrow(intersectmat)

          temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             item_ind]


          # must find mean corresponding to z in period t-1
          # This will be used in and after the loop over regions.
          # can directly obtain from dbarts
          # or find region
          # and use already saved region mean values


          # must find last lower bound that temp_ztpmin1 is greater than
          # for first upper bound that temp_ztpmin1 is below
          ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat_tmin1[, 3])[1]
          # Then obtain the corresponding region mean value
          temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

          # now find interval

          # tildeC_ktminl corresponds to
          # period t+1 k_ind region intereval

          rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

          # inds for j ranked below i in T

          belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

          #max of latent variables for j ranked below i in T
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower3 <- -Inf
          }else{
            temp_lower3 <- max(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              belowrank_ind])
          }

          # inds for j ranked above i in T

          aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

          #min of latent variables for j ranked below i in period T

          if(length(aboverank_ind) ==0){
            temp_upper3 <- Inf
          }else{

            temp_upper3 <- min(as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              aboverank_ind])
          }


          # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

          # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED
          tempbuffer <- (temp_upper3 - temp_lower3)/100

          if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
            upper_buffered <- temp_upper3 - tempbuffer
            lower_buffered <- temp_lower3 + tempbuffer

          }else{
            upper_buffered <- temp_upper3
            lower_buffered <- temp_lower3

          }

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = lower_buffered,
                                   b = upper_buffered,
                                   mean = temp_mean2,
                                   sd = 1)

          # zdraw_temp <- rtruncnorm(n = 1,
          #                          a = temp_lower3,
          #                          b = temp_upper3,
          #                          mean = temp_mean2,
          #                          sd = 1)

          if(is.na(zdraw_temp)){
            print(" line 2367")
            print("temp_lower3] = ")
            print(temp_lower3)

            print("temp_upper3 = ")
            print(temp_upper3)

            print("temp_mean2 = ")
            print(temp_mean2)

            stop("NA zdraw_temp")
          }

          Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





        } # end loop over items



      } # end loop over individuals indiv in 1:n.ranker

    }




    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    # #THEN use SetPredictor
    #
    # # if (i <= n_warmup) {
    # #   for(j in 1:num_lags){
    # #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    # #     }
    # # } else{
    # temp_break <- 0
    # for(j in 1:num_lags){
    #   # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #
    #   while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {
    #
    #     if(seq_z_draws==1){
    #       stop("updates still not consistent with tree structure")
    #     }
    #     print("new z values not consistent with tree structure, must draw again")
    #
    #     # If this error message occurs
    #     # Check the conditions in the dbart package for setPredictor == FALSE
    #     # And if this is hypothetically possible, even with draws from the smoothing distribution,
    #     # and if it is not a bug
    #     # then need to go back to beginning of this iteration of the Gibbs sampler
    #     # and sample Zmat again
    #
    #
    #     temp_break <- 1
    #     break
    #     # stop("new z values not consistent with tree structure, must draw again")
    #
    #
    #     # #perhaps this can be rewritten to just re-draw the relevant column?
    #     # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #     #                                           Z.mat = Z.mat,
    #     #                                           mu = mu,
    #     #                                           weight.vec = rep(1, n.ranker*n.time),
    #     #                                           n.ranker = n.ranker*n.time,
    #     #                                           n.item = n.item )
    #     #
    #     # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #     #
    #     # for(t in 1:num_lags){
    #     #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #     #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #     #
    #     #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #     #
    #     # }
    #     #
    #     # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j
    #
    #   }
    #
    #   if(temp_break==1){
    #     break
    #   }
    # }
    #
    # # if need to draw z values again, go back to start of loop
    # if(temp_break==1){
    #   if(breakcount == 10){
    #     Z.mat <- Z.matold
    #     Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #     for(t in 1:num_lags){
    #       init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #       # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #       Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #
    #     }
    #
    #   }else{
    #     breakcount <- breakcount +1
    #     next
    #   }
    #
    # }
    #
    # breakcount <- 0
    # # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    # #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # mutemp <- sampler$predict(df_for_dbart)
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mu = mutemp
    #
    # if(nrow(X.train)==n.item){
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #
    #   #mu = mutemp[(1:n.item)]
    #   mu = mutemp[n.item+(1:n.item)]
    #
    #
    #
    #
    #   # if(mutemp[1]!= mutemp[n.item+1]){
    #   if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
    #     print("iteration number")
    #     print(iter)
    #     print("n.item = ")
    #     print(n.item)
    #     print("mutemp = ")
    #     print(mutemp)
    #     stop("mutemp[1]!= mutemp[n.item+1]")
    #   }
    #
    #
    #   #mu = mutemp[(1:n.item)*n.ranker]
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     mu = mutemp
    #   }else{
    #     stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    #
    # }



    ########

    # update training data matrix #

    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )

      Xmat.train.no.y <- cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                  ncol =  ncol(X.train) + num_lags ,
                                                  byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")

        Xmat.test.no.y <- cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                       ncol =  ncol(X.test) , byrow = TRUE ) )




        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        Xmat.train.no.y <- cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          Xmat.test.no.y <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }




    # Must update node sizes for original tree
    # update all node sizes before new proposal

    # Must update node sizes for original tree
    # update all node sizes before new proposal

    for (j in 1:n.trees) {
      # print("curr_trees[[j]] = ")
      # print(curr_trees[[j]] )

      curr_trees[[j]] <- fill_tree_details(curr_trees[[j]],
                                           Xmat.train.no.y)

      # print("line 2785, curr_trees[[j]] = ")
      # print(curr_trees[[j]] )
      # must also update individual tree predictions for calcualtion of partial residuals
      tree_fits_store[,j]  = get_predictions(curr_trees[[j]], Xmat.train.no.y, single_tree = TRUE)

    }

    # option: prune all empty nodes from current trees before proposal?
    # must create new function for this
    # perhaps an issue is that there would not be a (umique) mu value
    # associated with a parent of an empty node
    # print("line 2791")

    # must update mu before and after trees updated because covariates have been updated

    mutemp = get_predictions(curr_trees, Xmat.train.no.y, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))

    # print("line 2801")

    # Start looping through trees
    for (j in 1:n.trees) {

      current_partial_residuals = as.vector(Z.mat) - mu + tree_fits_store[,j]

      # Propose a new tree via grow/change/prune/swap
      type = sample_move(curr_trees[[j]], iter, 0, # nburn # no burnin number, so setting to 100, maybe this is not optimal
                         trans_prob)


      # option: edit the proposal step so that any proposed tree does not contain empty nodes?
      # must create new function for this

      # Generate a new tree based on the current
      if(no_empty_proposals == TRUE){

        new_trees[[j]] = noempty_update_tree(y = as.vector(Z.mat),
                                             X = Xmat.train.no.y,
                                             type = type,
                                             curr_tree = curr_trees[[j]],
                                             node_min_size = node_min_size,
                                             s = s,
                                             splitting_rules = splitting_rules,
                                             max_bad_trees = max_bad_trees)

      }else{
        new_trees[[j]] = update_tree(y = as.vector(Z.mat),
                                     X = Xmat.train.no.y,
                                     type = type,
                                     curr_tree = curr_trees[[j]],
                                     node_min_size = node_min_size,
                                     s = s,
                                     splitting_rules = splitting_rules,
                                     max_bad_trees = max_bad_trees)

      }




      # print("line 2825")


      # CURRENT TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_old = tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(curr_trees[[j]], alpha, beta)

      # print("line 2825")
      #
      # print("new_trees[[j]]")
      # print(new_trees[[j]])

      # NEW TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_new = tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(new_trees[[j]], alpha, beta)

      # Exponentiate and multiply by the transition probabilities

      if(type == 'grow'){
        a = exp(l_new - l_old)*ratio_grow(new_trees[[j]], curr_trees[[j]])
      } else if(type == 'prune'){
        a = exp(l_new - l_old)*ratio_prune(new_trees[[j]], curr_trees[[j]])
      } else{
        a = exp(l_new - l_old)
      }

      vars_empty_pruned <- c()

      if(a > runif(1)) {
        curr_trees[[j]] = new_trees[[j]]
        # only account for pruning if  accept
        vars_empty_pruned <- new_trees[[j]]$vars_empty_pruned

        for(var_ind in vars_empty_pruned){
          var_count[var_ind ] = var_count[var_ind ] - 1
        }


        if (type =='change'){
          var_count[curr_trees[[j]]$var[1] ] = var_count[curr_trees[[j]]$var[1] ] - 1
          var_count[curr_trees[[j]]$var[2] ] = var_count[curr_trees[[j]]$var[2] ] + 1
        }

        if (type=='grow'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] + 1
        } # -1 because of the intercept in X

        if (type=='prune'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] - 1
        } # -1 because of the intercept in X

      }


      ### might need to edit simulate_mu to find right terminal nodes #########

      # Update mu whether tree accepted or not
      curr_trees[[j]] = simulate_mu(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)
      # Updating BART predictions
      current_fit = get_predictions(curr_trees[[j]], Xmat.train.no.y, single_tree = TRUE)
      mu = mu - tree_fits_store[,j] # subtract the old fit
      mu = mu + current_fit # add the new fit
      tree_fits_store[,j] = current_fit # update the new fit

    } # End loop through trees



    # sum_of_squares = sum((y_scale - y_hat)^2)

    # Update sigma2 (variance of the residuals)
    # sigma2 = update_sigma2(sum_of_squares, n = length(y_scale), nu, lambda)
    # variance kept equal to 1, do not update

    # # Update s = (s_1, ..., s_p), where s_p is the probability that predictor p is used to create new terminal nodes
    # if (sparse == 'TRUE' & i > floor(iter.max*0.1)){
    #   s = update_s(var_count, ncol(Xmat.train.no.y), 1)
    # }


    # Update s = (s_1, ..., s_p), where s_p is the probability that predictor q in 1:p is used to create new terminal nodes
    if (sparse & i > floor(iter.max * 0.25)) {
      s_update <- update_s(var_count, p, alpha_s)
      s <- s_update[[1]]

      if(alpha_prior){
        alpha_s <- update_alpha(s, alpha_scale, alpha_a, alpha_b, p, s_update[[2]])
      }
    }

    if(sigma_mu_prior){
      sigma2_mu <-  update_sigma_mu_par(curr_trees, sigma2_mu)
    }




    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta



    #
    #     # if(is.null(initial.list)){
    #     # print("samplestemp$test[,1] = ")
    #     # print(samplestemp$test[,1])
    #
    #     # mupreds <- sampler$predict(df_for_dbart)
    #
    #     # Xmat.test[,1:num_lags] <-  Zlag.mat.test
    #
    #
    #     temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))
    #
    #     for(t  in 1:num_lags){
    #       if(noise_in_pred ==1){
    #         temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
    #       }else{
    #         temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
    #       }
    #
    #     }
    #
    #     # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #     #                                                                      (num_lags+1):ncol(Xmat.test)])
    #
    #     temp_test_mat <- data.frame(x = temp_test_mat)
    #     colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #     # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    #     temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    #     print("Line 5488")
    #
    #
    #     temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    #
    #
    #     # if(iter < 5){
    #     #   print("temp_test_mat = " )
    #     #   print(temp_test_mat)
    #     # }
    #
    #     for(t1 in 1:num_test_periods){
    #       #produce a prediction
    #
    #       # must use original column names to prevent an error in the predict function
    #       colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #       testpredvec <- sampler$predict(temp_test_mat)
    #
    #       #fill in temp_test_preds with noise
    #       if(noise_in_pred ==1){
    #         temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #       }else{
    #         temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
    #       }
    #
    #
    #       #update temp_test_mat
    #       #shift z columns to the right and fill in leftmost column
    #
    #       #need to rewrite this if want to allow for no observed covariates
    #
    #       # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )
    #
    #       if(t1 != num_test_periods){
    #
    #
    #         if(num_lags ==1){
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }else{
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
    #                                                  temp_test_mat[,1:(num_lags-1)] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }
    #       }
    #
    #       # colnames(temp_test_mat) <- colnames(Xmat.test)
    #
    #
    #       #fill in temp_mu_test without noise
    #       temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    #     }
    #
    #     #also update Zlag.mat.test ?
    #     #perhaps this is unnecessary here?
    #
    #     print("Line 5545")
    #
    #
    #     Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    #     # if(nrow(X.test) >0 ){
    #     for(t in 1:num_lags){
    #       # if(t==1){
    #       #   #repeating the last period values
    #       #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #       #
    #       #   #other option is to set all unobservable values to zero
    #       #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #       #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #       #
    #       #
    #       # }else{
    #
    #       if(num_test_periods > t ){
    #         #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #       }else{
    #         #nothing to fill in if num_test_periods <= t
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #       }
    #
    #
    #       # }
    #     }
    #     # }
    #
    #     # if(nrow(X.test)>0){
    #     #
    #     #
    #     #   for(j in 1:num_lags){
    #     #
    #     #     #perhaps this should be removed for when Z is updated properly below
    #     #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #     #
    #     #   }
    #     #
    #     # }
    #
    #
    #     draw$mu_test[,iter] <- temp_mu_test
    #     # draw$mu_test[,iter] <- samplestemp$test[,1]
    #
    #     if(keep_zmat==TRUE){
    #       draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    #     }
    #
    #     # draw$mu_test[,1] <- samplestemp$test[,1]
    #
    #     # }else{
    #     #   draw$mu_test[,1] <- initial.list$mu_test
    #     # }
    #


    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        if(noise_in_pred ==1){
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }

      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      temp_test_mat <- data.frame(x = temp_test_mat)
      colnames(temp_test_mat) <- colnames(Xmat.test)

      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )


      # if(iter < 5){
      #   print("temp_test_mat = " )
      #   print(temp_test_mat)
      # }

      for(t1 in 1:num_test_periods){
        #produce a prediction
        # testpredvec <- sampler$predict(temp_test_mat)
        testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }


        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){


          if(num_lags ==1){
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }else{
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      temp_test_mat[,1:(num_lags-1)] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }
        }

        colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }

      # if(nrow(X.test)>0){
      #
      #
      #   for(j in 1:num_lags){
      #
      #     #perhaps this should be removed for when Z is updated properly below
      #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
      #
      #   }
      #
      # }


      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }
    if(sparse){
      draw$alpha_s_store[iter] <- alpha_s
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_store[iter,] <- var_count
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_store[iter,] <- s
      # draw$s_prob_z_store[iter,] <- s_z
    }

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }


    iter <- iter+1
  }


  return(draw)
}








##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data without  Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and without covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @import collapse
#' @importFrom MCMCpack 'rdirichlet'
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @export
ARRObartNOCovars_fullcond_emptynodes <- function(pair.comp.ten,
                                                 # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                                 # X.test = matrix(NA, nrow =0, ncol = 0),
                                                 # tau2.alpha = 5^2,
                                                 # nu.alpha = 3,
                                                 # tau2.beta = 5^2,
                                                 # nu.beta = 3,
                                                 n.item = dim(pair.comp.ten)[1],
                                                 n.rankerbytime = dim(pair.comp.ten)[3],
                                                 n.ranker,
                                                 n.time,
                                                 # p.cov = ncol(X.train),
                                                 iter.max = 5000,
                                                 para.expan = TRUE,
                                                 print.opt = 100,
                                                 initial.list = NULL,
                                                 n.trees = 50L,
                                                 n.burn = 0L,
                                                 n.samples = 1L,
                                                 n.thin = 1L,
                                                 trans_prob = c(2.5, 2.5, 4) / 9, # Probabilities to grow, prune or change, respectively
                                                 n.chains = 1,
                                                 n.threads = 1L,#guessNumCores(),
                                                 printEvery = 100L,
                                                 printCutoffs = 0L,
                                                 rngKind = "default",
                                                 rngNormalKind = "default",
                                                 rngSeed = NA_integer_,
                                                 updateState = FALSE,
                                                 num_lags = 1,
                                                 diff_num_test_rankers = 0,
                                                 keep_zmat = FALSE,
                                                 noise_in_pred = 0,
                                                 seq_z_draws = 1,
                                                 N_hdr = 100,
                                                 rho_hdr = 0.5,
                                                 smoothing_method = "AR",
                                                 num_horizon = 1,
                                                 num_z_iters = 10,
                                                 node_min_size = 5,
                                                 k = 2,
                                                 sigquant = .90,
                                                 alpha = 0.95,
                                                 beta = 2,
                                                 nu = 3,
                                                 lambda = 0.1,
                                                 no_empty_proposals = FALSE,
                                                 alpha_prior = FALSE,
                                                 sigma_mu_prior = FALSE,
                                                 splitting_rules = "discrete",
                                                 loop_order = "time_in_item",
                                                 max_bad_trees = 10,
                                                 sparse = TRUE,
                                                 alpha_a_y = 0.5,
                                                 alpha_b_y = 1,
                                                 alpha_split_prior = TRUE){


  if(!(loop_order %in% c("time_in_item", "item_in_time"))){
    stop("loop_order must be 'time_in_item' or 'item_in_time'.")
  }


  if(!(splitting_rules %in% c("discrete", "continuous"))){
    stop("splitting_rules must be 'discrete' or 'continuous'.")
  }

  ######### set up things for myBART implementation ####################

  # Extract control parameters
  # we only have to allow for empty nodes when updating Z (and therefore Zlag is updated and splits on Zlag are affected)
  # Therefore there is still a minimum node size criterion for the purpose of proposing new splits
  node_min_size = node_min_size

  # Storage containers
  store_size = iter.max # npost # code currently written to save all output, so no nburnin or npost
  tree_store = vector('list', store_size)
  sigma2_store = rep(NA, store_size)
  # y_hat_store = matrix(NA, ncol = length(y), nrow = store_size)
  # var_count = rep(0, ncol(x))
  # var_count_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # s_prob_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # tree_fits_store = matrix(0, ncol = n.trees, nrow = length(y))

  sigma2 <- 1 # keep sigma2 set to 1


  ########## beginning of original code ############################

  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  # length_mu_test <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      # up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
      up.order = -rowSums( pair.comp, na.rm = TRUE ) + n.item

      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }


  # it might be more efficient to create and save all rank constraint matrices at this stage


  rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))

  for(indiv in 1:n.ranker){

    for(t in 1:n.time){

      rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]


      rankconstraint_t <- matrix(0,
                                 nrow = n.item - 1,
                                 ncol = n.item)

      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1

      }

      rank_cons_arr[, , indiv, t] <- rankconstraint_t

    }
  }
  # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  boundconstraints <- matrix(NA,
                             nrow = 2*n.item,
                             ncol = n.item)

  # use kroenecker product
  # there is probably a more efficient way of doing this

  boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))
      # ranks_mat[,j] <-
      #   Z.mat[,j]

      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))


      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
        qnorm(c(n.item : 1)/(n.item+1)) +
        rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues
      # if separate noise for each item, then would need to preserve ranks


      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
      #   Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j]/5

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(n =  t*n.item*n.ranker, mean = 0, sd = 0.005) #maybe add some noise to avoid splitting issues?
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }

    ##### old dbarts initialization ###############

    # # print("Line 799.")
    #
    # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )
    #
    #
    # control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
    #                          keepTrees = TRUE,
    #                          n.trees = n.trees,
    #                          n.burn = n.burn,
    #                          n.samples = n.samples,
    #                          n.thin = n.thin,
    #                          n.chains = n.chains,
    #                          n.threads = n.threads,
    #                          printEvery = printEvery,
    #                          printCutoffs = printCutoffs,
    #                          rngKind = rngKind,
    #                          rngNormalKind = rngNormalKind,
    #                          rngSeed = rngSeed)
    #
    #
    # # print(colnames(Xmat.train))
    # # print(colnames(Xmat.test))
    #
    # # print("begin dbarts")
    #
    #
    # # if(nrow(X.test )==0){
    # sampler <- dbarts(y ~ .,
    #                   data = df_for_dbart,
    #                   #test = Xmat.test,
    #                   control = control,
    #                   resid.prior = fixed(1),
    #                   sigma=1 #check if this is the correct approach for setting the variance to 1
    # )
    #
    # # }else{
    # #   sampler <- dbarts(y ~ .,
    # #                     data = Xmat.train,
    # #                     test = Xmat.test,
    # #                     control = control,
    # #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    # #                     sigma=1 #
    # #   )
    # #
    # # }
    #
    # # print("error after dbarts")
    #
    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    #
    # #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # sampler$sampleTreesFromPrior()
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mupreds <- sampler$predict(Xmat.train)
    #
    # mu <- mutemp


    y_hat_store = matrix(NA, ncol = length(as.vector(Z.mat)), nrow = store_size)
    var_count = rep(0, ncol(Zlag.mat))
    var_count_store = matrix(0, ncol = ncol(Zlag.mat), nrow = store_size)
    s_prob_store = matrix(0, ncol = ncol(Zlag.mat), nrow = store_size)
    tree_fits_store = matrix(0, ncol = n.trees, nrow = length(as.vector(Z.mat)))
    s = rep(1/ncol(Zlag.mat), ncol(Zlag.mat))

    p <- ncol(Zlag.mat)
    rho <- p # For DART

    alpha_s <- 1 # p

    alpha_scale <- p

    ###### new myBART initialization ######################

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }
    }

    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }

    # maybe (max(as.vector(Z.mat))-min(as.vector(Z.mat)))
    # can be replaced by something else
    # sigma2_mu <- (max(as.vector(Z.mat))-min(as.vector(Z.mat)))/((2 * k * sqrt(n.trees))^2)
    sigma2_mu <- ((max(as.vector(Z.mat))-min(as.vector(Z.mat)))/(2 * k * sqrt(n.trees)))^2

    # sigma2_mu <- 1/n.trees

    # Create a list of trees for the initial stump
    curr_trees = create_stump(num_trees = n.trees,
                              y = as.vector(Z.mat),
                              X = Zlag.mat)
    # Initialise the new trees as current one
    new_trees = curr_trees

    # Initialise the predicted values to zero
    mutemp = get_predictions(curr_trees, Zlag.mat, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))



  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  # print("Line 954")


  df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    temp_test_mat <- data.frame(x = as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      # testpredvec <- sampler$predict(temp_test_mat)

      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)



      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker), ] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),] )))

      }

      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  if(any(is.na(Z.mat))){
    print("Z.mat = ")
    print(Z.mat)
    stop("NA values in initial Z.mat")

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration

  iter <- 2
  breakcount <- 0
  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    # Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############


    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }


    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }

      # tempsort <- sort(tempcol)
      #
      # tempdiffs <- tempsort[-1] - tempsort[-(length(tempsort))]

      # if( any( abs(tempdiffs) < 0.001 )   ){
      #
      #   print("tempsort =")
      #   print(tempsort)
      #   print("tempdiffs =")
      #   print(tempdiffs)
      #   print("j = ")
      #   print(j)
      #   print("tempcol =")
      #   print(tempcol)
      #   print("Z.mat =")
      #   print(Z.mat)
      #   print(" some differences in Z vector very small")
      # }

    }


    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA

    # create vector of indices for ranker indiv in time period 1

    # # this part is not really necessary
    # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
    # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
    # obs_indices <- ind_start:ind_end

    # obs_indices[1] could jsut be replaced by [1] below\
    # because the only variable is zlag, so the other covariates are not used


    list_inter_mats <- list()

    emptynodecount <- 0

    for(i in 1:n.trees){



      ####### new tree structures, so need new functions to rebuild trees, create intersections etc

      ### dbarts getTrees returns a matrix with columns:
      ### sample, tree, n, var. and value

      ### simplest, but not most efficient, thing to do is to convert the tree structure
      ### from myBart format to dbarts format.




      # treeexample1_db <- sampler$getTrees(treeNums = i,
      #                                     chainNums = 1,
      #                                     sampleNums = 1)


      # print("curr_trees[[i]]$tree_matrix = ")
      # print(curr_trees[[i]]$tree_matrix)

      temptree <- curr_trees[[i]]$tree_matrix

      # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
      #                                   treeNums = i,
      #                                   chainNums = 1,
      #                                   sampleNums = 1)

      emptynodecount <- emptynodecount + sum(temptree[, 'node_size'] == 0)

      treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

      temp_na_inds <- is.na(temptree[,'split_variable'])
      treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

      # temp_nainds <- is.na(temptree[,'split_variable'])
      # treeexample1[temp_nainds, ] <- cbind(1, i, temptree[, 'node_size'], -1, temptree[,'mu'] )
      # treeexample1[!temp_nainds, ] <- cbind(1, i, temptree[, c('node_size','mu', 'split_variable' )])
      #
      # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
      #   1,#rep(sampleNums, nrow(temptree)),
      #   i,#rep(treeNums, nrow(temptree)),
      #   temptree[, 'node_size'],
      #   # mybarttree[,'split_variable'],
      #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
      #          -1,
      #          temptree[,'split_variable']),
      #   fast_ifelse(is.na(temptree[,'split_variable']) ,
      #          temptree[,'mu'],
      #          temptree[,'split_value']))


      # print("treeexample1 = ")
      # print(treeexample1)

      # rebuilt_tree <- rebuildTree2(treeexample1)
      rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

      # print("rebuilt_tree = ")
      # print(rebuilt_tree)

      #must use covariates for individual indiv at time period t

      # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )

      # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
      list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree[,4] == -1 , 5:7, drop = FALSE]


      # print("list_inter_mats[[i]] = ")
      # print(list_inter_mats[[i]])
    }

    # print("line 1468")

    intersectmat <- interNtreesB(list_inter_mats)

    # print("Line 1146")

    intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))


    # print(" emptynodecount = ")
    # print(emptynodecount)

    if(nrow(intersectmat) > 350){

      print("nrow(intersectmat) > 350")
      print("intersectmat = ")
      print(intersectmat)


    }

    # print("Line 1150")

    # print("line 1478")

    # calculate one dimensional integrals
    for(rowind in 1:nrow(intersectmat)){
      # ktemp <- nkt_mat[rowind,k_index]
      # tempmean <- intersectmat[ktemp,1]
      templower <- intersectmat[rowind,2]
      tempupper <- intersectmat[rowind,3]

      # ASSUMING PRIOR MEAN ALL ZEROS

      # These are the q0 integrals
      intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
      # tempintegralval <- tempintegralval*onedim_int
    }

    intersectmat_tmin1 <- intersectmat



    num_regions <- nrow(intersectmat)

    # print("Line 1169")

    # print("nrow(intersectmat) = ")
    # print(nrow(intersectmat))

    if(loop_order == "time_in_item"){
      for(z_iter_ind in 1:num_z_iters){


        for(indiv in 1:n.ranker){

          # print("indiv = ")
          # print(indiv)
          ########### calculate qkt  ########################################

          ########### calculate qkt   for t = 1 ########################################


          ### calculate qkt integrals for time period t = 1  ################

          # These integrals are already calculated and saved as intersectmat[ktemp,4]

          for(item_ind in 1:n.item){


            #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

            # loop over items

            # Now loop over time periods

            # special case for t=1

            # probability matrix for sampling elements

            # let rows be period zero, and columns be period 1 (2?)

            # probmattemp <- matrix(0,
            #                       nrow = num_regions,
            #                       ncol = num_regions)

            logprobmattemp <- matrix(0,
                                     nrow = num_regions,
                                     ncol = num_regions)

            # loop over period 2 regions into which z_1 can fall


            tempbounds <- matrix(NA,
                                 nrow = num_regions,
                                 ncol = 2)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

            # inds for j ranked below i in t+1



            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]



            rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]

            # if(any(order(rankvec_t) !=
            #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                           n.item*(indiv-1) +
            #                           1:n.item])) ){
            #
            #   # print("order(rankvec_t) = ")
            #   # print(order(rankvec_t))
            #   #
            #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                         n.item*(indiv - 1) +
            #   #                         1:n.item])  = ")
            #
            #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                  n.item*(indiv - 1) +
            #                                  1:n.item]) )
            #
            #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                                n.item*(indiv - 1) +
            #   #                                1:n.item] = ")
            #
            #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item])
            #
            # }

            # inds for j ranked below i in t

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in t
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind]
            }

            # inds for j ranked above i in t

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period t

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind]
            }

            # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
            tempmeanfordens <- intersectmat[1:num_regions, 1]

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                    mean = tempmeanfordens,
            #                                    sd = 1)


            if(temp_lower3 >= temp_upper3){
              print(" temp_lower3 = ")
              print(temp_lower3)

              print(" temp_upper3 = ")
              print(temp_upper3)

              stop("Line 1844. temp_lower3 >= temp_upper3")
            }


            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                 mean = intersectmat[1:num_regions, 1],
            #                                 sd = 1)

            # find intervals that do not overlap

            bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

            logprobmattemp[, bad_regions] <- -Inf #rep(-Inf,num_regions)
            tempbounds[bad_regions, 1] <- NA
            tempbounds[bad_regions, 2] <- NA

            good_regions <- setdiff(1:num_regions, bad_regions)


            temp_tnorm_logprobvec <- rep(NA, num_regions)
            temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                   mean = tempmeanfordens[good_regions],
                                                                   sd = 1)


            # logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprobvec[k_ind] +
            #   log(intersectmat[1:num_regions,4])

            logprobmattemp[1:num_regions, good_regions] <- outer(log(intersectmat[1:num_regions,4]),
                                                                 temp_tnorm_logprobvec[good_regions],
                                                                 FUN = "+")


            tempbounds[good_regions,1] <- pmax(intersectmat[good_regions, 2], temp_lower3)
            tempbounds[good_regions,2] <- pmin(intersectmat[good_regions, 3], temp_upper3)

            if(any(tempbounds[good_regions,1] >= tempbounds[good_regions,2])){
              stop(" line 1868 bounds badly defined")
            }

            # CAN VECTORIZE THIS EVEN MORE

            # # for(k_ind in 1:num_regions){
            # for(k_ind in good_regions){
            #     # obtain mean for truncated normal distribution
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # want trunc norm probability of latent variable value for item_ind
            #   # in period t+1
            #
            #
            #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #   #                               a=temp_lower,
            #   #                               b=Inf,
            #   #                               mean = temp_mean,
            #   #                               sd = 1)
            #
            #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #   #                          mean = temp_mean,
            #   #                          sd = 1)
            #
            #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
            #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
            #
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # now second term
            #
            #   temp_lower2 <- intersectmat[k_ind, 2]
            #   temp_upper2 <- intersectmat[k_ind, 3]
            #
            #
            #   # print(" line 1697 ")
            #   #
            #   # print("temp_lower2 = ")
            #   # print(temp_lower2)
            #   #
            #   # print("temp_lower3 = ")
            #   # print(temp_lower3)
            #   #
            #   # print("temp_upper2 = ")
            #   # print(temp_upper2)
            #   #
            #   # print("temp_upper3 = ")
            #   # print(temp_upper3)
            #
            #
            #   # if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
            #   #   # if((temp_lower2 - temp_upper3) > -0.001 | (temp_lower3 - temp_upper2 > -0.001)){
            #   #   # intervals do not overlap, therefore assign probability zero
            #   #   # and skip to next iteration
            #   #
            #   #
            #   #   # print("k_ind = ")
            #   #   # print(k_ind)
            #   #
            #   #   # print("ncol(temp_region_probs) = ")
            #   #   # print(ncol(temp_region_probs))
            #   #
            #   #   # print("nrow(temp_region_probs) = ")
            #   #   # print(nrow(temp_region_probs))
            #   #
            #   #
            #   #   # these three lines are technically unnecessary
            #   #   # probmattemp[, k_ind] <- rep(0,num_regions)
            #   #   logprobmattemp[, k_ind] <- rep(-Inf,num_regions)
            #   #   tempbounds[k_ind, 1] <- NA
            #   #   tempbounds[k_ind, 2] <- NA
            #   #
            #   #   next
            #   #
            #   # }
            #
            #
            #   temp_lower2 <- max(temp_lower2, temp_lower3)
            #   temp_upper2 <- min(temp_upper2, temp_upper3)
            #
            #   if(temp_lower2 >= temp_upper2){
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                     n.item*(indiv - 1) +
            #                                     1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("Line 1763 temp_lower2 >= temp_upper2")
            #   }
            #
            #   # if(all( intersectmat[,4] == 0 ) |all( is.na(intersectmat[,4])  ) ){
            #   #
            #   #   print("(1-1)*n.item*n.ranker +
            #   #                            n.item*(indiv - 1) +
            #   #                            1:n.item] = ")
            #   #
            #   #   print((1-1)*n.item*n.ranker +
            #   #           n.item*(indiv - 1) +
            #   #           1:n.item)
            #   #
            #   #   print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                                   n.item*(indiv - 1) +
            #   #                                   1:n.item]")
            #   #
            #   #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                            n.item*(indiv - 1) +
            #   #                            1:n.item])
            #   #
            #   #   print("item_ind = ")
            #   #   print(item_ind)
            #   #
            #   #   print("rankvec_t = ")
            #   #   print(rankvec_t)
            #   #
            #   #   print("intersectmat = ")
            #   #   print(intersectmat)
            #   #
            #   #   print("k_ind = ")
            #   #   print(k_ind)
            #   #
            #   #   stop("all( intersectmat[,4] == 0 )")
            #   #
            #   # }
            #
            #   logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprob +
            #     log(intersectmat[1:num_regions,4])
            #
            #
            #   # for(k0_ind in 1:num_regions){
            #   #
            #   #   #loop over all possible means
            #   #   # temp_mean2 <- intersectmat[k0_ind,1]
            #   #
            #   #   # probability of being in intersection region
            #   #
            #   #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
            #   #
            #   #
            #   #   # probmattemp[k0_ind, k_ind] <- prob_t_region*
            #   #   #   temp_tnorm_prob *
            #   #   #   intersectmat[k0_ind,4]
            #   #
            #   #   # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob * intersectmat[k0_ind,4]
            #   #   logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob + log(intersectmat[k0_ind,4])
            #   #
            #   #   # if(probmattemp[k0_ind, k_ind] < 0){
            #   #   #   print("probmattemp[k0_ind, k_ind] = ")
            #   #   #   print(probmattemp[k0_ind, k_ind])
            #   #   #
            #   #   #   # print("prob_t_region = ")
            #   #   #   # print(prob_t_region)
            #   #   #
            #   #   #   print("temp_tnorm_prob = ")
            #   #   #   print(temp_tnorm_prob)
            #   #   #
            #   #   #   print("intersectmat[k0_ind,4] = ")
            #   #   #   print(intersectmat[k0_ind,4])
            #   #   #
            #   #   #   print("temp_upper2 = ")
            #   #   #   print(temp_upper2)
            #   #   #
            #   #   #   print("temp_lower2 = ")
            #   #   #   print(temp_lower2)
            #   #   #
            #   #   #   print("temp_mean2 = ")
            #   #   #   print(temp_mean2)
            #   #   #
            #   #   #
            #   #   # }
            #   #
            #   #
            #   # } # end loop over k0
            #
            #   # save upper and lower bounds (mean saved in intersectmat)
            #   # or just obtain again later
            #
            #   tempbounds[k_ind,1] <- temp_lower2
            #   tempbounds[k_ind,2] <- temp_upper2
            #
            #
            # } # end loop over k1


            #sample a combination of k0 and k1
            # if necessary can use column sums to sample k1, then k0
            # however, this is probably unnecessary


            # print("Line 1621 before sample")

            # if(all(probmattemp ==0)){
            if(all(logprobmattemp == -Inf)){

              print("iter = ")
              print(iter)

              print("tempbounds = ")
              print(tempbounds)

              print("intersectmat = ")
              print(intersectmat)



              stop("line 1880 all(probmattemp ==0)")
            }




            # region_ind <- sample.int((num_regions^2),
            #                          size = 1,
            #                          replace = TRUE,
            #                          prob = as.vector(probmattemp))


            logprobstemp <- as.vector(logprobmattemp)
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int((num_regions^2),
                                     size = 1,
                                     replace = TRUE,
                                     prob = probstemp)

            # print("Line 1629 after sample")

            # k0 region is sampled number modulo number of regions
            k0_region_ind <- (region_ind - 1) %% num_regions + 1
            # if(k0_region_ind ==0){
            #   k0_region_ind <- num_regions
            # }

            # k1 region is the ceiling of sampled number divided by number of regions
            # k1_region_ind <- ceiling(region_ind/num_regions)
            k1_region_ind <- (region_ind - 1) %/% num_regions + 1


            # print("k1_region_ind = ")
            # print(k1_region_ind)

            temp_lower2 <- tempbounds[k1_region_ind,1]
            temp_upper2 <- tempbounds[k1_region_ind,2]

            # print("num_regions = ")
            # print(num_regions)
            #
            # print("region_ind = ")
            # print(region_ind)
            #
            # print("k0_region_ind = ")
            # print(k0_region_ind)

            temp_mean0 <- intersectmat[k0_region_ind, 1]
            # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

            # print("temp_mean0 = ")
            # print(temp_mean0)
            #
            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)

            # if(temp_upper2 - temp_lower2 < 0.000001 ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("very small difference in limits")
            # }


            # if(temp_upper2 - temp_lower2 < 0.001 ){
            #   stop("line 1980.  Very small range")
            #
            # }

            # if(temp_lower2 + 0.00005  >  temp_upper2 - 0.00005 ){
            #   print("line 1985 Very small range")
            #
            # }

            tempbuffer <- (temp_upper2 - temp_lower2)/100

            if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
              upper_buffered <- temp_upper2 - tempbuffer
              lower_buffered <- temp_lower2 + tempbuffer

            }else{


              upper_buffered <- temp_upper2
              lower_buffered <- temp_lower2

              if(temp_upper2 != Inf){
                upper_buffered <- temp_upper2 - 0.00001
              }

              if(temp_lower2 != -Inf){
                lower_buffered <- temp_lower2 + 0.00001
              }

            }


            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean0,
                                     sd = 1)



            # if( (zdraw_temp - temp_lower2 < 0.00001 ) | (temp_upper2 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_mean0 = ")
            #   print(temp_mean0)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   print("line 1988. draw very close to limit")
            # }

            if(is.na(zdraw_temp)){
              print("line 1881")

              print("temp_lower2 = ")
              print(temp_lower2)

              print("temp_upper2 = ")
              print(temp_upper2)

              print("temp_mean0 = ")
              print(temp_mean0)


              stop("NA zdraw_temp")

            }


            Z.mat[item_ind,  indiv ] <- zdraw_temp


            # loop over time periods for general case 1 < t < T

            for(t in 2:(n.time - 1)){

              # print("z time t = ")
              # print(t)

              temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker +
                                                 n.item*(indiv - 1) +
                                                 item_ind]

              if(is.na(temp_ztpmin1)){

                print("line 1895")

                print("Z.mat = ")
                print(Z.mat)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("item_ind = ")
                print(item_ind)

                stop("NA temp_ztpmin1")
              }

              # must find mean corresponding to z in period t-1
              # This will be used in and after the loop over regions.
              # can directly obtain from dbarts
              # or find region
              # and use already saved region mean values


              # must find last lower bound that temp_ztpmin1 is greater than
              # or first upper bound that temp_ztpmin1 is below
              ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat[, 3]) )[1]
              # Then obtain the corresponding region mean value
              temp_mean2 <- intersectmat[ktemp_tmin1,1]


              if(is.na(temp_mean2)){
                print("line 1908")

                print("ktemp_tmin1 = ")
                print(ktemp_tmin1)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_ztpmin1 = ")
                print(temp_ztpmin1)

                stop("temp_mean2 NA")


              }



              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              # print("ktemp_tmin1 = ")
              # print(ktemp_tmin1)



              # Calculate the probabilities for each region in this time period
              # the regions being looped over are actually period t+1 regions

              # Same regions for all time periods if there are no time varying covariates

              # However, the weights are individual and time period specific

              # loop through regions


              # first column is the probabilities
              # second column is the lower bounds
              # third column is the upper bounds
              # temp_region_probs <- matrix(0,
              #                             nrow = nrow(intersectmat),
              #                             ncol = 3)


              temp_region_logprobs <- matrix(-Inf,
                                             nrow = nrow(intersectmat),
                                             ncol = 3)

              # Trunc norm prob of next periods latent value conditional on region

              # Create intervals from interval t+1 latent values

              # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

              # inds for j ranked below i in t+1

              # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
              #
              # #max of latent variables for j ranked below i in t+1
              # # Z.mat
              #
              # if(length(belowrank_ind) ==0){
              #   temp_lower <- -Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    belowrank_ind]
              # }
              #
              # # inds for j ranked above i in t+1
              #
              # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
              #
              # #min of latent variables for j ranked below i in period t+1
              #
              # if(length(aboverank_ind) ==0){
              #   temp_upper <- Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #
              #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    aboverank_ind]
              # }


              # want trunc norm probability of latent variable value for item_ind
              # in period t+1

              temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                              n.item*(indiv - 1) +
                                              item_ind]

              rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]



              # if(any(order(rankvec_t) !=
              #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                           n.item*(indiv - 1) +
              #                           1:n.item]) )){
              #
              #   print("order(rankvec_t) = ")
              #   print(order(rankvec_t))
              #
              #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
              #                         n.item*(indiv - 1) +
              #                         1:n.item])  = ")
              #
              #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                  n.item*(indiv - 1) +
              #                                  1:n.item]) )
              #
              #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                n.item*(indiv - 1) +
              #                                1:n.item] = ")
              #
              #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                            n.item*(indiv - 1) +
              #                            1:n.item])
              #
              #
              # }





              # inds for j ranked below i in t

              belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

              #max of latent variables for j ranked below i in t
              # Z.mat

              if(length(belowrank_ind) ==0){
                temp_lower3 <- -Inf
              }else{
                temp_lower3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  belowrank_ind]
              }

              if(is.na(temp_lower3)){
                print("NA temp_lower3")

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind] = ")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         belowrank_ind])

                print(" t = ")
                print(t)

                print(" n.item = ")
                print(n.item)

                print(" n.ranker = ")
                print(n.ranker)

                print(" indiv = ")
                print(indiv)

                print(" belowrank_ind = ")
                print(belowrank_ind)

                print(" Z.mat = ")
                print(Z.mat)

                stop("NA temp_lower3")

              }



              # inds for j ranked above i in t


              aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

              #min of latent variables for j ranked below i in period t

              if(length(aboverank_ind) ==0){
                temp_upper3 <- Inf
              }else{
                temp_upper3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  aboverank_ind]
              }

              if(temp_lower3 >= temp_upper3){
                print(" temp_lower3 = ")
                print(temp_lower3)

                print(" temp_upper3 = ")
                print(temp_upper3)

                stop("Line 2495. temp_lower3 >= temp_upper3")
              }


              # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
              tempmeanfordens <- intersectmat[1:num_regions, 1]

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                    mean = tempmeanfordens,
              #                                    sd = 1)

              # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
              #                                          mean = tempmeanfordens,
              #                                          sd = 1)


              # find intervals that do not overlap

              bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

              temp_region_logprobs[bad_regions, 1] <- -Inf
              temp_region_logprobs[bad_regions, 2] <- NA
              temp_region_logprobs[bad_regions, 3] <- NA

              good_regions <- setdiff(1:num_regions, bad_regions)

              temp_tnorm_logprobvec <- rep(NA, num_regions)
              temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                     mean = tempmeanfordens[good_regions],
                                                                     sd = 1)


              temp_region_logprobs[good_regions, 1] <- temp_tnorm_logprobvec[good_regions]
              temp_region_logprobs[good_regions, 2] <- pmax(intersectmat[good_regions, 2], temp_lower3)
              temp_region_logprobs[good_regions, 3] <- pmin(intersectmat[good_regions, 3], temp_upper3)


              if(any(temp_region_logprobs[good_regions, 2] >= temp_region_logprobs[good_regions, 3])){
                print("good_regions = ")
                print(good_regions)

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                stop(" line 2525 bounds badly defined")
              }
              # CAN VECTORIZE THIS EVEN MORE


              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                 mean = intersectmat[1:num_regions, 1],
              #                                 sd = 1)

              # for(k_ind in 1:num_regions){
              # for(k_ind in good_regions){
              #   # obtain mean for truncated normal distribution
              #   # temp_mean <- intersectmat[k_ind, 1]
              #
              #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #   #                               a=temp_lower,
              #   #                               b=Inf,
              #   #                               mean = temp_mean,
              #   #                               sd = 1)
              #
              #
              #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #   #                          mean = temp_mean,
              #   #                          sd = 1)
              #
              #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
              #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
              #
              #   # Probability of z_t in intersection of
              #   # region k_ind (for period t+1)
              #   # and region defined by period t latent variables for other individuals
              #   # and rank for period t
              #
              #
              #   # tildeC_ktminl corresponds to
              #   # period t+1 k_ind region intereval
              #
              #   temp_lower2 <- intersectmat[k_ind, 2]
              #   temp_upper2 <- intersectmat[k_ind, 3]
              #
              #
              #
              #   # print(" line 2075 ")
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   #
              #   # print("temp_lower3 = ")
              #   # print(temp_lower3)
              #   #
              #   # print("temp_upper3 = ")
              #   # print(temp_upper3)
              #
              #
              #   # if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
              #   #   # if((temp_lower2 - temp_upper3 > -0.0001) | (temp_lower3 - temp_upper2 > -0.0001)){
              #   #   # intervals do not overlap, therefore assign probability zero
              #   #   # and skip to next iteration
              #   #
              #   #   # print("k_ind = ")
              #   #   # print(k_ind)
              #   #
              #   #   # print("ncol(temp_region_probs) = ")
              #   #   # print(ncol(temp_region_probs))
              #   #
              #   #   # print("nrow(temp_region_probs) = ")
              #   #   # print(nrow(temp_region_probs))
              #   #
              #   #   # temp_region_probs[k_ind, 1] <- 0
              #   #   # temp_region_probs[k_ind, 2] <- NA
              #   #   # temp_region_probs[k_ind, 3] <- NA
              #   #
              #   #   temp_region_logprobs[k_ind, 1] <- -Inf
              #   #   temp_region_logprobs[k_ind, 2] <- NA
              #   #   temp_region_logprobs[k_ind, 3] <- NA
              #   #
              #   #
              #   #   next
              #   # }
              #
              #
              #
              #   temp_lower2 <- max(temp_lower2, temp_lower3)
              #   temp_upper2 <- min(temp_upper2, temp_upper3)
              #
              #
              #   if(temp_lower2 >= temp_upper2){
              #
              #     print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                   n.item*(indiv - 1) +
              #                                   1:n.item]")
              #     print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                              n.item*(indiv - 1) +
              #                              1:n.item])
              #     print("item_ind = ")
              #     print(item_ind)
              #
              #     print("t = ")
              #     print(t)
              #
              #     print("indiv = ")
              #     print(indiv)
              #
              #
              #     print("rankvec_t = ")
              #     print(rankvec_t)
              #
              #
              #     print("temp_lower2 = ")
              #     print(temp_lower2)
              #
              #     print("temp_upper2 = ")
              #     print(temp_upper2)
              #
              #     print("temp_lower3 = ")
              #     print(temp_lower3)
              #
              #     print("temp_upper3 = ")
              #     print(temp_upper3)
              #
              #
              #
              #     print("intersectmat[k_ind, 2] = ")
              #     print(intersectmat[k_ind, 2])
              #
              #     print("intersectmat[k_ind, 3] = ")
              #     print(intersectmat[k_ind, 3])
              #
              #     print("k_ind = ")
              #     print(k_ind)
              #
              #
              #
              #     stop("Line 1917. temp_lower2 >= temp_upper2")
              #   }
              #
              #
              #
              #   # probability of being in intersection region
              #
              #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
              #
              #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_mean2 = ")
              #   # print(temp_mean2)
              #   #
              #   #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #   #
              #   # print("temp_tnorm_prob = ")
              #   # print(temp_tnorm_prob)
              #
              #   # prob_t_region <- prob_t_region*temp_tnorm_prob
              #   # prob_t_region <- temp_tnorm_prob
              #   logprob_t_region <- temp_tnorm_logprob
              #
              #   # if(temp_tnorm_prob ==0){
              #   if(temp_tnorm_logprob == -Inf){
              #     print("temp_tnorm_prob = ")
              #     print(temp_tnorm_prob)
              #
              #     print("temp_tnorm_probvec =")
              #     print(temp_tnorm_probvec)
              #
              #     print("tempmeanfordens =")
              #     print(tempmeanfordens)
              #
              #     print("temp_ztp1 =")
              #     print(temp_ztp1)
              #
              #   }
              #
              #   # save region probability
              #
              #   # and save region bounds (or maybe more memory efficient to obtain the region again)
              #
              #   # must multiply by other previously obtained probabilities
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   # temp_region_probs[k_ind, 1] <- prob_t_region
              #   # temp_region_probs[k_ind, 2] <- temp_lower2
              #   # temp_region_probs[k_ind, 3] <- temp_upper2
              #
              #   temp_region_logprobs[k_ind, 1] <- logprob_t_region
              #   temp_region_logprobs[k_ind, 2] <- temp_lower2
              #   temp_region_logprobs[k_ind, 3] <- temp_upper2
              #
              # }


              # sample a region using probabilities obtained above

              # print("Line 1903 before sample")


              # if(sum(temp_region_probs[,1] > 0) ==0){
              if(sum(temp_region_logprobs[,1] > -Inf) ==0){

                print("temp_tnorm_probvec =")
                print(temp_tnorm_probvec)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_region_probs = ")
                print(temp_region_probs)

                print("item_ind = ")
                print(item_ind)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("rankvec_t = ")
                print(rankvec_t)

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])

                stop(" Line 2590 sum(temp_region_probs[,1] >0) == 0")
              }



              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])

              # logprobstemp <- as.vector(temp_region_logprobs[,1])
              # max_ll <- max(logprobstemp)
              # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
              # probstemp <- exp(logprobstemp - logsumexps)
              #
              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = probstemp)

              if(length(good_regions)==1){
                region_ind <- good_regions[1]
              }else{
                logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
                max_ll <- max(logprobstemp)
                logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
                probstemp <- exp(logprobstemp - logsumexps)

                region_ind <- sample(x = (1:num_regions)[good_regions], size = 1, replace = TRUE, prob = probstemp)
              }


              # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

              # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
              #
              # print("line 2102 temp_mean2_debug from predict = ")
              # print(temp_mean2_debug)
              #
              # print("line 2105 temp_mean2_origscale = ")
              # print(temp_mean2_origscale)
              #
              # print("line 2108 temp_mean2 = ")
              # print(temp_mean2)


              # if(temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2] < 0.000001 ){
              #
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #
              #
              #   stop("very small difference in limits")
              # }

              # if(temp_region_probs[region_ind, 3] -temp_region_probs[region_ind, 2] < 0.001 ){
              #   stop("line 2456. Very small range")
              #
              # }

              # if(temp_region_probs[region_ind, 2] + 0.00005  >  temp_region_probs[region_ind, 3] - 0.00005 ){
              #
              #   print("iter  = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   stop("line 2467 Very small range")
              #
              # }


              # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
              #
              # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
              #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
              #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
              #
              # }else{
              #   upper_buffered <- temp_region_probs[region_ind, 3]
              #   lower_buffered <- temp_region_probs[region_ind, 2]
              #
              # }

              tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/100

              if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
                upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
                lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer

              }else{
                upper_buffered <- temp_region_logprobs[region_ind, 3]
                lower_buffered <- temp_region_logprobs[region_ind, 2]


                if(temp_region_logprobs[region_ind, 3] != Inf){
                  upper_buffered <- temp_region_logprobs[region_ind, 3] - 0.00001
                }

                if(temp_region_logprobs[region_ind, 2] != -Inf){
                  lower_buffered <- temp_region_logprobs[region_ind, 2] + 0.00001
                }

              }


              if(abs( temp_mean2/ (upper_buffered - lower_buffered ) ) > 10^15){
                # this is a quick fix for when the bounds are close or very far from the mean
                # this does not really address any potential underlying issue
                zdraw_temp <- (lower_buffered + upper_buffered)/2
              }else{
                zdraw_temp <- rtruncnorm(n = 1,
                                         a=lower_buffered,
                                         b=upper_buffered,
                                         mean = temp_mean2, #temp_mean2_origscale,
                                         sd = 1)
              }


              if(is.na(zdraw_temp)){
                print(" line 2883")

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                print("zdraw_temp = ")
                print(zdraw_temp)


                stop("NA zdraw_temp")
              }


              # if( (zdraw_temp - temp_region_probs[region_ind, 2] < 0.00001 ) | (temp_region_probs[region_ind, 3] - zdraw_temp  < 0.00001 ) ){
              #
              #   print("iter = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #   print("zdraw_temp = ")
              #   print(zdraw_temp)
              #
              #   stop("line 2470 draw very close to limit")
              # }



              # print("Line 1914 after sample")

              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=temp_region_probs[region_ind, 2],
              #                          b=temp_region_probs[region_ind, 3],
              #                          mean = temp_mean2,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs= ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                stop("NA zdraw_temp")
              }

              Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



            } # end loop over time periods

            # check for special cases for n.time - 1, n.time - 2, n.time - 3

            # special case for t = n.time


            temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # for first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat[, 3])[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat[ktemp_tmin1,1]

            # now find interval


            # tildeC_ktminl corresponds to
            # period t+1 k_ind region intereval



            rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

            # inds for j ranked below i in T

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in T
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind]
            }

            # inds for j ranked above i in T

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period T

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind]
            }


            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
            #
            # print("line 2202 temp_mean2_debug from predict = ")
            # print(temp_mean2_debug)
            #
            # print("line 2205 temp_mean2_origscale = ")
            # print(temp_mean2_origscale)
            #
            # print("line 2208 temp_mean2 = ")
            # print(temp_mean2)

            # if(temp_upper3 -temp_lower3 < 0.000001 ){
            #
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   stop("very small difference in limits")
            # }


            # if(temp_upper3 - temp_lower3 < 0.001 ){
            #   stop("line 2613.  Very small range")
            #
            # }

            # if(temp_lower3 + 0.00005  >  temp_upper3 - 0.00005 ){
            #   print("line 2623 Very small range")
            #
            # }

            tempbuffer <- (temp_upper3 - temp_lower3)/100

            if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
              upper_buffered <- temp_upper3 - tempbuffer
              lower_buffered <- temp_lower3 + tempbuffer

            }else{
              upper_buffered <- temp_upper3
              lower_buffered <- temp_lower3

              if(temp_upper3 != Inf){
                upper_buffered <- temp_upper3 - 0.00001
              }

              if(temp_upper3 != -Inf){
                lower_buffered <- temp_lower3 + 0.00001
              }
            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean2, #temp_mean2_origscale,
                                     sd = 1)

            # if( (zdraw_temp - temp_lower3 < 0.00001 ) | (temp_upper3 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("temp_lower3 = ")
            #   print(temp_lower3)
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   stop("line 2612 draw very close to limit")
            # }

            # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a = temp_lower3,
            #                          b = temp_upper3,
            #                          mean = temp_mean2,
            #                          sd = 1)

            if(is.na(zdraw_temp)){
              print(" line 2367")
              print("temp_lower3] = ")
              print(temp_lower3)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_mean2 = ")
              print(temp_mean2)

              stop("NA zdraw_temp")
            }

            Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





          } # end loop over items



        } # end loop over individuals indiv in 1:n.ranker

      }
    }else{ # loop over items and rankers within each time period
      for(z_iter_ind in 1:num_z_iters){


        for(indiv in 1:n.ranker){

          # print("indiv = ")
          # print(indiv)
          ########### calculate qkt  ########################################

          ########### calculate qkt   for t = 1 ########################################


          ### calculate qkt integrals for time period t = 1  ################

          # These integrals are already calculated and saved as intersectmat[ktemp,4]

          for(item_ind in 1:n.item){


            #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

            # loop over items

            # Now loop over time periods

            # special case for t=1

            # probability matrix for sampling elements

            # let rows be period zero, and columns be period 1 (2?)

            # probmattemp <- matrix(0,
            #                       nrow = num_regions,
            #                       ncol = num_regions)

            logprobmattemp <- matrix(0,
                                     nrow = num_regions,
                                     ncol = num_regions)

            # loop over period 2 regions into which z_1 can fall


            tempbounds <- matrix(NA,
                                 nrow = num_regions,
                                 ncol = 2)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            # rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

            # inds for j ranked below i in t+1



            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]



            rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]

            # if(any(order(rankvec_t) !=
            #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                           n.item*(indiv-1) +
            #                           1:n.item])) ){
            #
            #   # print("order(rankvec_t) = ")
            #   # print(order(rankvec_t))
            #   #
            #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                         n.item*(indiv - 1) +
            #   #                         1:n.item])  = ")
            #
            #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                  n.item*(indiv - 1) +
            #                                  1:n.item]) )
            #
            #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #   #                                n.item*(indiv - 1) +
            #   #                                1:n.item] = ")
            #
            #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item])
            #
            # }

            # inds for j ranked below i in t

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in t
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind]
            }

            # inds for j ranked above i in t

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period t

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind]
            }

            # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
            tempmeanfordens <- intersectmat[1:num_regions, 1]

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                    mean = tempmeanfordens,
            #                                    sd = 1)

            # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
            #                                          mean = tempmeanfordens,
            #                                          sd = 1)

            if(temp_lower3 >= temp_upper3){
              print(" temp_lower3 = ")
              print(temp_lower3)

              print(" temp_upper3 = ")
              print(temp_upper3)

              stop("Line 3328. temp_lower3 >= temp_upper3")
            }

            bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))

            logprobmattemp[, bad_regions] <- -Inf #rep(-Inf,num_regions)
            tempbounds[bad_regions, 1] <- NA
            tempbounds[bad_regions, 2] <- NA

            good_regions <- setdiff(1:num_regions, bad_regions)


            temp_tnorm_logprobvec <- rep(NA, num_regions)
            temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                   mean = tempmeanfordens[good_regions],
                                                                   sd = 1)


            # logprobmattemp[1:num_regions, k_ind] <- temp_tnorm_logprobvec[k_ind] +
            #   log(intersectmat[1:num_regions,4])

            logprobmattemp[1:num_regions, good_regions] <- outer(log(intersectmat[1:num_regions,4]),
                                                                 temp_tnorm_logprobvec[good_regions],
                                                                 FUN = "+")


            tempbounds[good_regions,1] <- pmax(intersectmat[good_regions, 2], temp_lower3)
            tempbounds[good_regions,2] <- pmin(intersectmat[good_regions, 3], temp_upper3)

            if(any(tempbounds[good_regions,1] >= tempbounds[good_regions,2])){
              print("intersectmat = ")
              print(intersectmat)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_lower3 = ")
              print(temp_lower3)

              print("good_regions = ")
              print(good_regions)

              print("tempbounds = ")
              print(tempbounds)
              stop(" line 3305 bounds badly defined")
            }

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                 mean = intersectmat[1:num_regions, 1],
            #                                 sd = 1)

            # for(k_ind in 1:num_regions){
            #   # obtain mean for truncated normal distribution
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #   # want trunc norm probability of latent variable value for item_ind
            #   # in period t+1
            #
            #
            #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #   #                               a=temp_lower,
            #   #                               b=Inf,
            #   #                               mean = temp_mean,
            #   #                               sd = 1)
            #
            #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #   #                          mean = temp_mean,
            #   #                          sd = 1)
            #
            #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
            #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
            #
            #   # temp_mean <- intersectmat[k_ind, 1]
            #
            #
            #
            #   # now second term
            #
            #
            #   temp_lower2 <- intersectmat[k_ind, 2]
            #   temp_upper2 <- intersectmat[k_ind, 3]
            #
            #
            #   # print(" line 1697 ")
            #   #
            #   # print("temp_lower2 = ")
            #   # print(temp_lower2)
            #   #
            #   # print("temp_lower3 = ")
            #   # print(temp_lower3)
            #   #
            #   # print("temp_upper2 = ")
            #   # print(temp_upper2)
            #   #
            #   # print("temp_upper3 = ")
            #   # print(temp_upper3)
            #
            #
            #   if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
            #     # if((temp_lower2 - temp_upper3) > -0.001 | (temp_lower3 - temp_upper2 > -0.001)){
            #     # intervals do not overlap, therefore assign probability zero
            #     # and skip to next iteration
            #
            #
            #     # print("k_ind = ")
            #     # print(k_ind)
            #
            #     # print("ncol(temp_region_probs) = ")
            #     # print(ncol(temp_region_probs))
            #
            #     # print("nrow(temp_region_probs) = ")
            #     # print(nrow(temp_region_probs))
            #
            #
            #     # these three lines are technically unnecessary
            #     # probmattemp[, k_ind] <- rep(0,num_regions)
            #     logprobmattemp[, k_ind] <- rep(-Inf,num_regions)
            #     tempbounds[k_ind, 1] <- NA
            #     tempbounds[k_ind, 2] <- NA
            #
            #     next
            #
            #   }
            #
            #
            #   temp_lower2 <- max(temp_lower2, temp_lower3)
            #   temp_upper2 <- min(temp_upper2, temp_upper3)
            #
            #   if(temp_lower2 >= temp_upper2){
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                   n.item*(indiv - 1) +
            #                                   1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("Line 1763 temp_lower2 >= temp_upper2")
            #   }
            #
            #   if(all( intersectmat[,4] == 0 ) |all( is.na(intersectmat[,4])  ) ){
            #
            #     print("(1-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item] = ")
            #
            #     print((1-1)*n.item*n.ranker +
            #             n.item*(indiv - 1) +
            #             1:n.item)
            #
            #     print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                                   n.item*(indiv - 1) +
            #                                   1:n.item]")
            #
            #     print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                              n.item*(indiv - 1) +
            #                              1:n.item])
            #
            #     print("item_ind = ")
            #     print(item_ind)
            #
            #     print("rankvec_t = ")
            #     print(rankvec_t)
            #
            #     print("intersectmat = ")
            #     print(intersectmat)
            #
            #     print("k_ind = ")
            #     print(k_ind)
            #
            #     stop("all( intersectmat[,4] == 0 )")
            #
            #   }
            #
            #
            #   for(k0_ind in 1:num_regions){
            #
            #     #loop over all possible means
            #     temp_mean2 <- intersectmat[k0_ind,1]
            #
            #     # probability of being in intersection region
            #
            #     # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
            #
            #
            #     # probmattemp[k0_ind, k_ind] <- prob_t_region*
            #     #   temp_tnorm_prob *
            #     #   intersectmat[k0_ind,4]
            #
            #     # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob * intersectmat[k0_ind,4]
            #     logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob + log(intersectmat[k0_ind,4])
            #
            #     # if(probmattemp[k0_ind, k_ind] < 0){
            #     #   print("probmattemp[k0_ind, k_ind] = ")
            #     #   print(probmattemp[k0_ind, k_ind])
            #     #
            #     #   # print("prob_t_region = ")
            #     #   # print(prob_t_region)
            #     #
            #     #   print("temp_tnorm_prob = ")
            #     #   print(temp_tnorm_prob)
            #     #
            #     #   print("intersectmat[k0_ind,4] = ")
            #     #   print(intersectmat[k0_ind,4])
            #     #
            #     #   print("temp_upper2 = ")
            #     #   print(temp_upper2)
            #     #
            #     #   print("temp_lower2 = ")
            #     #   print(temp_lower2)
            #     #
            #     #   print("temp_mean2 = ")
            #     #   print(temp_mean2)
            #     #
            #     #
            #     # }
            #
            #
            #   } # end loop over k0
            #
            #   # save upper and lower bounds (mean saved in intersectmat)
            #   # or just obtain again later
            #
            #   tempbounds[k_ind,1] <- temp_lower2
            #   tempbounds[k_ind,2] <- temp_upper2
            #
            #
            # } # end loop over k1


            #sample a combination of k0 and k1
            # if necessary can use column sums to sample k1, then k0
            # however, this is probably unnecessary


            # print("Line 1621 before sample")

            # if(all(probmattemp ==0)){
            if(all(logprobmattemp == -Inf)){

              print("iter = ")
              print(iter)

              print("tempbounds = ")
              print(tempbounds)

              print("intersectmat = ")
              print(intersectmat)



              stop("line 1880 all(probmattemp ==0)")
            }




            # region_ind <- sample.int((num_regions^2),
            #                          size = 1,
            #                          replace = TRUE,
            #                          prob = as.vector(probmattemp))


            logprobstemp <- as.vector(logprobmattemp)
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int((num_regions^2),
                                     size = 1,
                                     replace = TRUE,
                                     prob = probstemp)



            # logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
            # max_ll <- max(logprobstemp)
            # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            # probstemp <- exp(logprobstemp - logsumexps)
            # region_ind <- sample((1:num_regions)[good_regions], 1, replace = TRUE, prob = probstemp)


            # print("Line 1629 after sample")

            # k0 region is sampled number modulo number of regions
            k0_region_ind <- (region_ind - 1) %% num_regions + 1
            # if(k0_region_ind ==0){
            #   k0_region_ind <- num_regions
            # }

            # k1 region is the ceiling of sampled number divided by number of regions
            # k1_region_ind <- ceiling(region_ind/num_regions)
            k1_region_ind <- (region_ind - 1) %/% num_regions + 1


            # print("k1_region_ind = ")
            # print(k1_region_ind)

            temp_lower2 <- tempbounds[k1_region_ind,1]
            temp_upper2 <- tempbounds[k1_region_ind,2]

            # print("num_regions = ")
            # print(num_regions)
            #
            # print("region_ind = ")
            # print(region_ind)
            #
            # print("k0_region_ind = ")
            # print(k0_region_ind)

            temp_mean0 <- intersectmat[k0_region_ind, 1]
            # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

            # print("temp_mean0 = ")
            # print(temp_mean0)
            #
            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)

            # if(temp_upper2 - temp_lower2 < 0.000001 ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("very small difference in limits")
            # }


            # if(temp_upper2 - temp_lower2 < 0.001 ){
            #   stop("line 1980.  Very small range")
            #
            # }

            # if(temp_lower2 + 0.00005  >  temp_upper2 - 0.00005 ){
            #   print("line 1985 Very small range")
            #
            # }

            tempbuffer <- (temp_upper2 - temp_lower2)/100

            if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
              upper_buffered <- temp_upper2 - tempbuffer
              lower_buffered <- temp_lower2 + tempbuffer

            }else{
              upper_buffered <- temp_upper2
              lower_buffered <- temp_lower2

              if(temp_upper2 != Inf){
                upper_buffered <- temp_upper2 - 0.00001
              }

              if(temp_lower2 != -Inf){
                lower_buffered <- temp_lower2 + 0.00001
              }

            }


            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean0,
                                     sd = 1)



            # if( (zdraw_temp - temp_lower2 < 0.00001 ) | (temp_upper2 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #
            #   print("iter = ")
            #   print(iter)
            #
            #   print("temp_lower2 = ")
            #   print(temp_lower2)
            #
            #   print("temp_upper2 = ")
            #   print(temp_upper2)
            #
            #   print("temp_mean0 = ")
            #   print(temp_mean0)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   print("line 1988. draw very close to limit")
            # }

            if(is.na(zdraw_temp)){
              print("line 1881")

              print("temp_lower2 = ")
              print(temp_lower2)

              print("temp_upper2 = ")
              print(temp_upper2)

              print("temp_mean0 = ")
              print(temp_mean0)


              stop("NA zdraw_temp")

            }


            Z.mat[item_ind,  indiv ] <- zdraw_temp

          } # end loop over items

        } # end loop over individuals indiv in 1:n.ranker



        # loop over time periods for general case 1 < t < T

        for(t in 2:(n.time - 1)){

          # print("z time t = ")
          # print(t)

          for(indiv in 1:n.ranker){
            # print("z indiv = ")
            # print(indiv)

            for(item_ind in 1:n.item){

              # print("item_ind = ")
              # print(item_ind)

              temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker +
                                                 n.item*(indiv - 1) +
                                                 item_ind]

              if(is.na(temp_ztpmin1)){

                print("line 1895")

                print("Z.mat = ")
                print(Z.mat)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("item_ind = ")
                print(item_ind)

                stop("NA temp_ztpmin1")
              }

              # must find mean corresponding to z in period t-1
              # This will be used in and after the loop over regions.
              # can directly obtain from dbarts
              # or find region
              # and use already saved region mean values


              # must find last lower bound that temp_ztpmin1 is greater than
              # or first upper bound that temp_ztpmin1 is below
              ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat[, 3]) )[1]
              # Then obtain the corresponding region mean value
              temp_mean2 <- intersectmat[ktemp_tmin1,1]


              if(is.na(temp_mean2)){
                print("line 1908")

                print("ktemp_tmin1 = ")
                print(ktemp_tmin1)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_ztpmin1 = ")
                print(temp_ztpmin1)

                stop("temp_mean2 NA")
              }

              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              # print("ktemp_tmin1 = ")
              # print(ktemp_tmin1)

              # Calculate the probabilities for each region in this time period
              # the regions being looped over are actually period t+1 regions

              # Same regions for all time periods if there are no time varying covariates

              # However, the weights are individual and time period specific

              # loop through regions


              # first column is the probabilities
              # second column is the lower bounds
              # third column is the upper bounds
              # temp_region_probs <- matrix(0,
              #                             nrow = nrow(intersectmat),
              #                             ncol = 3)


              temp_region_logprobs <- matrix(-Inf,
                                             nrow = nrow(intersectmat),
                                             ncol = 3)

              # Trunc norm prob of next periods latent value conditional on region

              # Create intervals from interval t+1 latent values

              # rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

              # inds for j ranked below i in t+1

              # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
              #
              # #max of latent variables for j ranked below i in t+1
              # # Z.mat
              #
              # if(length(belowrank_ind) ==0){
              #   temp_lower <- -Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    belowrank_ind]
              # }
              #
              # # inds for j ranked above i in t+1
              #
              # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
              #
              # #min of latent variables for j ranked below i in period t+1
              #
              # if(length(aboverank_ind) ==0){
              #   temp_upper <- Inf
              # }else{
              #   # Check that this is the period t+1 latent variable value, not period t
              #
              #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
              #                                    n.item*(indiv - 1) +
              #                                    aboverank_ind]
              # }


              # want trunc norm probability of latent variable value for item_ind
              # in period t+1

              temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                              n.item*(indiv - 1) +
                                              item_ind]

              rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]


              # if(any(order(rankvec_t) !=
              #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                           n.item*(indiv - 1) +
              #                           1:n.item]) )){
              #
              #   print("order(rankvec_t) = ")
              #   print(order(rankvec_t))
              #
              #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
              #                         n.item*(indiv - 1) +
              #                         1:n.item])  = ")
              #
              #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                  n.item*(indiv - 1) +
              #                                  1:n.item]) )
              #
              #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                n.item*(indiv - 1) +
              #                                1:n.item] = ")
              #
              #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                            n.item*(indiv - 1) +
              #                            1:n.item])
              #
              #
              # }


              # inds for j ranked below i in t

              belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

              #max of latent variables for j ranked below i in t
              # Z.mat

              if(length(belowrank_ind) ==0){
                temp_lower3 <- -Inf
              }else{
                temp_lower3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  belowrank_ind]
              }

              if(is.na(temp_lower3)){
                print("NA temp_lower3")

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                    n.item*(indiv - 1) +
                                                    belowrank_ind] = ")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         belowrank_ind])

                print(" t = ")
                print(t)

                print(" n.item = ")
                print(n.item)

                print(" n.ranker = ")
                print(n.ranker)

                print(" indiv = ")
                print(indiv)

                print(" belowrank_ind = ")
                print(belowrank_ind)

                print(" Z.mat = ")
                print(Z.mat)

                stop("NA temp_lower3")

              }

              # inds for j ranked above i in t

              aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

              #min of latent variables for j ranked below i in period t

              if(length(aboverank_ind) ==0){
                temp_upper3 <- Inf
              }else{
                temp_upper3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  aboverank_ind]
              }

              # tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp
              tempmeanfordens <- intersectmat[1:num_regions, 1]

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                    mean = tempmeanfordens,
              #                                    sd = 1)

              # temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
              #                                          mean = tempmeanfordens,
              #                                          sd = 1)

              if(temp_lower3 >= temp_upper3){
                print(" temp_lower3 = ")
                print(temp_lower3)

                print(" temp_upper3 = ")
                print(temp_upper3)

                stop("Line 4016 temp_lower3 >= temp_upper3")
              }

              bad_regions <- which((intersectmat[1:num_regions, 2] >= temp_upper3) | (temp_lower3 >= intersectmat[1:num_regions, 3]))


              # print("length(bad_regions) = ")
              # print(length(bad_regions))

              temp_region_logprobs[bad_regions, 1] <- -Inf
              temp_region_logprobs[bad_regions, 2] <- NA
              temp_region_logprobs[bad_regions, 3] <- NA

              good_regions <- setdiff(1:num_regions, bad_regions)

              if(length(good_regions) == 0){
                stop("Line 3969. No good regions.")
              }

              if(length(good_regions) > num_regions){
                stop("Line 3973 length(good_regions) > num_regionss.")
              }
              if(length(temp_tnorm_logprobvec) > num_regions){
                stop("Line 3973 length(temp_tnorm_logprobvec) > num_regionss.")
              }
              if(length(tempmeanfordens) > num_regions){
                stop("Line 3979 length(tempmeanfordens) > num_regionss.")
              }
              if(length(temp_ztp1) > 1){
                stop("Line 3979 length(temp_ztp1) > 1")
              }


              temp_tnorm_logprobvec <- rep(NA, num_regions)
              temp_tnorm_logprobvec[good_regions] <- fastlognormdens(temp_ztp1,
                                                                     mean = tempmeanfordens[good_regions],
                                                                     sd = 1)


              temp_region_logprobs[good_regions, 1] <- temp_tnorm_logprobvec[good_regions]
              temp_region_logprobs[good_regions, 2] <- pmax(intersectmat[good_regions, 2], temp_lower3)
              temp_region_logprobs[good_regions, 3] <- pmin(intersectmat[good_regions, 3], temp_upper3)

              if(any(temp_region_logprobs[good_regions, 2] >= temp_region_logprobs[good_regions, 3])){
                stop(" line 3954 bounds badly defined")
              }

              # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
              #                                 mean = intersectmat[1:num_regions, 1],
              #                                 sd = 1)

              # for(k_ind in 1:num_regions){
              #   # obtain mean for truncated normal distribution
              #   # temp_mean <- intersectmat[k_ind, 1]
              #
              #   # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #   #                               a=temp_lower,
              #   #                               b=Inf,
              #   #                               mean = temp_mean,
              #   #                               sd = 1)
              #
              #
              #   # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #   #                          mean = temp_mean,
              #   #                          sd = 1)
              #
              #   # temp_tnorm_prob <- temp_tnorm_probvec[k_ind]
              #   temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]
              #
              #   # Probability of z_t in intersection of
              #   # region k_ind (for period t+1)
              #   # and region defined by period t latent variables for other individuals
              #   # and rank for period t
              #
              #
              #   # tildeC_ktminl corresponds to
              #   # period t+1 k_ind region intereval
              #
              #   temp_lower2 <- intersectmat[k_ind, 2]
              #   temp_upper2 <- intersectmat[k_ind, 3]
              #
              #
              #
              #   # print(" line 2075 ")
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   #
              #   # print("temp_lower3 = ")
              #   # print(temp_lower3)
              #   #
              #   # print("temp_upper3 = ")
              #   # print(temp_upper3)
              #
              #
              #   if((temp_lower2 >= temp_upper3) | (temp_lower3 >= temp_upper2)){
              #     # if((temp_lower2 - temp_upper3 > -0.0001) | (temp_lower3 - temp_upper2 > -0.0001)){
              #     # intervals do not overlap, therefore assign probability zero
              #     # and skip to next iteration
              #
              #     # print("k_ind = ")
              #     # print(k_ind)
              #
              #     # print("ncol(temp_region_probs) = ")
              #     # print(ncol(temp_region_probs))
              #
              #     # print("nrow(temp_region_probs) = ")
              #     # print(nrow(temp_region_probs))
              #
              #     # temp_region_probs[k_ind, 1] <- 0
              #     # temp_region_probs[k_ind, 2] <- NA
              #     # temp_region_probs[k_ind, 3] <- NA
              #
              #     temp_region_logprobs[k_ind, 1] <- -Inf
              #     temp_region_logprobs[k_ind, 2] <- NA
              #     temp_region_logprobs[k_ind, 3] <- NA
              #
              #
              #     next
              #   }
              #
              #
              #
              #   temp_lower2 <- max(temp_lower2, temp_lower3)
              #   temp_upper2 <- min(temp_upper2, temp_upper3)
              #
              #
              #   if(temp_lower2 >= temp_upper2){
              #
              #     print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                                 n.item*(indiv - 1) +
              #                                 1:n.item]")
              #     print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
              #                              n.item*(indiv - 1) +
              #                              1:n.item])
              #     print("item_ind = ")
              #     print(item_ind)
              #
              #     print("t = ")
              #     print(t)
              #
              #     print("indiv = ")
              #     print(indiv)
              #
              #
              #     print("rankvec_t = ")
              #     print(rankvec_t)
              #
              #
              #     print("temp_lower2 = ")
              #     print(temp_lower2)
              #
              #     print("temp_upper2 = ")
              #     print(temp_upper2)
              #
              #     print("temp_lower3 = ")
              #     print(temp_lower3)
              #
              #     print("temp_upper3 = ")
              #     print(temp_upper3)
              #
              #
              #
              #     print("intersectmat[k_ind, 2] = ")
              #     print(intersectmat[k_ind, 2])
              #
              #     print("intersectmat[k_ind, 3] = ")
              #     print(intersectmat[k_ind, 3])
              #
              #     print("k_ind = ")
              #     print(k_ind)
              #
              #
              #
              #     stop("Line 1917. temp_lower2 >= temp_upper2")
              #   }
              #
              #
              #
              #   # probability of being in intersection region
              #
              #   # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)
              #
              #
              #   # print("temp_upper2 = ")
              #   # print(temp_upper2)
              #   # print("temp_lower2 = ")
              #   # print(temp_lower2)
              #   #
              #   # print("temp_mean2 = ")
              #   # print(temp_mean2)
              #   #
              #   #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #   #
              #   # print("temp_tnorm_prob = ")
              #   # print(temp_tnorm_prob)
              #
              #   # prob_t_region <- prob_t_region*temp_tnorm_prob
              #   # prob_t_region <- temp_tnorm_prob
              #   logprob_t_region <- temp_tnorm_logprob
              #
              #   # if(temp_tnorm_prob ==0){
              #   if(temp_tnorm_logprob == -Inf){
              #     print("temp_tnorm_prob = ")
              #     print(temp_tnorm_prob)
              #
              #     print("temp_tnorm_probvec =")
              #     print(temp_tnorm_probvec)
              #
              #     print("tempmeanfordens =")
              #     print(tempmeanfordens)
              #
              #     print("temp_ztp1 =")
              #     print(temp_ztp1)
              #
              #   }
              #
              #   # save region probability
              #
              #   # and save region bounds (or maybe more memory efficient to obtain the region again)
              #
              #   # must multiply by other previously obtained probabilities
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   # temp_region_probs[k_ind, 1] <- prob_t_region
              #   # temp_region_probs[k_ind, 2] <- temp_lower2
              #   # temp_region_probs[k_ind, 3] <- temp_upper2
              #
              #   temp_region_logprobs[k_ind, 1] <- logprob_t_region
              #   temp_region_logprobs[k_ind, 2] <- temp_lower2
              #   temp_region_logprobs[k_ind, 3] <- temp_upper2
              #
              # }


              # sample a region using probabilities obtained above

              # print("Line 1903 before sample")


              # if(sum(temp_region_probs[,1] > 0) ==0){
              if(sum(temp_region_logprobs[,1] > -Inf) ==0){

                print("temp_tnorm_probvec =")
                print(temp_tnorm_probvec)


                print("intersectmat = ")
                print(intersectmat)

                print("temp_region_probs = ")
                print(temp_region_probs)

                print("item_ind = ")
                print(item_ind)

                print("t = ")
                print(t)

                print("indiv = ")
                print(indiv)

                print("rankvec_t = ")
                print(rankvec_t)

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                  n.item*(indiv - 1) +
                                                  1:n.item]")

                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])

                stop(" Line 2590 sum(temp_region_probs[,1] >0) == 0")
              }



              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])
              # print("line 4219")
              # print("length(temp_region_logprobs) = ")
              # print(length(temp_region_logprobs))
              # logprobstemp <- as.vector(temp_region_logprobs[,1])
              # max_ll <- max(logprobstemp)
              # logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
              # probstemp <- exp(logprobstemp - logsumexps)
              #
              # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = probstemp)
              if(length(good_regions)==1){
                region_ind <- good_regions[1]
              }else{
                logprobstemp <- as.vector(temp_region_logprobs[good_regions,1])
                max_ll <- max(logprobstemp)
                logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
                probstemp <- exp(logprobstemp - logsumexps)

                region_ind <- sample(x = (1:num_regions)[good_regions], size = 1, replace = TRUE, prob = probstemp)
              }

              # print("line 4229")

              # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

              # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
              #
              # print("line 2102 temp_mean2_debug from predict = ")
              # print(temp_mean2_debug)
              #
              # print("line 2105 temp_mean2_origscale = ")
              # print(temp_mean2_origscale)
              #
              # print("line 2108 temp_mean2 = ")
              # print(temp_mean2)


              # if(temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2] < 0.000001 ){
              #
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #
              #
              #   stop("very small difference in limits")
              # }

              # if(temp_region_probs[region_ind, 3] -temp_region_probs[region_ind, 2] < 0.001 ){
              #   stop("line 2456. Very small range")
              #
              # }

              # if(temp_region_probs[region_ind, 2] + 0.00005  >  temp_region_probs[region_ind, 3] - 0.00005 ){
              #
              #   print("iter  = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   stop("line 2467 Very small range")
              #
              # }


              # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
              #
              # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
              #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
              #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
              #
              # }else{
              #   upper_buffered <- temp_region_probs[region_ind, 3]
              #   lower_buffered <- temp_region_probs[region_ind, 2]
              #
              # }

              tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/100

              if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
                upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
                lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer
              }else{
                upper_buffered <- temp_region_logprobs[region_ind, 3]
                lower_buffered <- temp_region_logprobs[region_ind, 2]

                if(temp_region_logprobs[region_ind, 3] != Inf){
                  upper_buffered <- temp_region_logprobs[region_ind, 3] - 0.00001
                }

                if(temp_region_logprobs[region_ind, 2] != -Inf){
                  lower_buffered <- temp_region_logprobs[region_ind, 2] + 0.00001
                }


              }

              if(abs( temp_mean2/ (upper_buffered - lower_buffered ) ) > 10^15){
                # this is a quick fix for when the bounds are close or very far from the mean
                # this does not really address any potential underlying issue
                zdraw_temp <- (lower_buffered + upper_buffered)/2
              }else{
                zdraw_temp <- rtruncnorm(n = 1,
                                         a=lower_buffered,
                                         b=upper_buffered,
                                         mean = temp_mean2, #temp_mean2_origscale,
                                         sd = 1)
              }


              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=lower_buffered,
              #                          b=upper_buffered,
              #                          mean = temp_mean2, #temp_mean2_origscale,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs = ")
                print(temp_region_logprobs)

                # print("temp_region_probs[region_ind, 3] = ")
                # print(temp_region_probs[region_ind, 3])

                print("temp_mean2 = ")
                print(temp_mean2)

                print("zdraw_temp = ")
                print(zdraw_temp)

                stop("NA zdraw_temp")
              }


              # if( (zdraw_temp - temp_region_probs[region_ind, 2] < 0.00001 ) | (temp_region_probs[region_ind, 3] - zdraw_temp  < 0.00001 ) ){
              #
              #   print("iter = ")
              #   print(iter)
              #
              #   print("temp_region_probs =")
              #   print(temp_region_probs)
              #
              #   print("intersectmat = ")
              #   print(intersectmat)
              #
              #   print("region_ind = ")
              #   print(region_ind)
              #
              #   print("temp_region_probs[region_ind, 2] = ")
              #   print(temp_region_probs[region_ind, 2])
              #
              #   print("temp_region_probs[region_ind, 3] = ")
              #   print(temp_region_probs[region_ind, 3])
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #   print("zdraw_temp = ")
              #   print(zdraw_temp)
              #
              #   stop("line 2470 draw very close to limit")
              # }



              # print("Line 1914 after sample")

              # zdraw_temp <- rtruncnorm(n = 1,
              #                          a=temp_region_probs[region_ind, 2],
              #                          b=temp_region_probs[region_ind, 3],
              #                          mean = temp_mean2,
              #                          sd = 1)


              if(is.na(zdraw_temp)){
                print(" line 2256")

                print("temp_region_logprobs= ")
                print(temp_region_logprobs)

                # print("temp_region_logprobs = ")
                # print(temp_region_logprobs)

                print("temp_mean2 = ")
                print(temp_mean2)

                stop("NA zdraw_temp")
              }

              Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp

            } # end loop over items
          } # end loop over rankers


        } # end loop over time periods

        # check for special cases for n.time - 1, n.time - 2, n.time - 3

        # special case for t = n.time

        for(indiv in 1:n.ranker){
          for(item_ind in 1:n.item){
            temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # for first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat[, 3])[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat[ktemp_tmin1,1]

            # now find interval


            # tildeC_ktminl corresponds to
            # period t+1 k_ind region intereval



            rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

            # inds for j ranked below i in T

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in T
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind]
            }

            # inds for j ranked above i in T

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period T

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind]
            }


            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
            #
            # print("line 2202 temp_mean2_debug from predict = ")
            # print(temp_mean2_debug)
            #
            # print("line 2205 temp_mean2_origscale = ")
            # print(temp_mean2_origscale)
            #
            # print("line 2208 temp_mean2 = ")
            # print(temp_mean2)

            # if(temp_upper3 -temp_lower3 < 0.000001 ){
            #
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   stop("very small difference in limits")
            # }


            # if(temp_upper3 - temp_lower3 < 0.001 ){
            #   stop("line 2613.  Very small range")
            #
            # }

            # if(temp_lower3 + 0.00005  >  temp_upper3 - 0.00005 ){
            #   print("line 2623 Very small range")
            #
            # }

            tempbuffer <- (temp_upper3 - temp_lower3)/100

            if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
              upper_buffered <- temp_upper3 - tempbuffer
              lower_buffered <- temp_lower3 + tempbuffer

            }else{
              upper_buffered <- temp_upper3
              lower_buffered <- temp_lower3

              if(temp_upper3 != Inf){
                upper_buffered <- temp_upper3 - 0.00001
              }

              if(temp_lower3 != -Inf){
                lower_buffered <- temp_lower3 + 0.00001
              }


            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a = lower_buffered,
                                     b = upper_buffered,
                                     mean = temp_mean2, #temp_mean2_origscale,
                                     sd = 1)

            # if( (zdraw_temp - temp_lower3 < 0.00001 ) | (temp_upper3 - zdraw_temp  < 0.00001 ) ){
            #
            #   print("iter = ")
            #   print(iter)
            #
            #
            #   print("intersectmat = ")
            #   print(intersectmat)
            #
            #   print("temp_lower3 = ")
            #   print(temp_lower3)
            #
            #   print("temp_upper3 = ")
            #   print(temp_upper3)
            #
            #   print("temp_mean2 = ")
            #   print(temp_mean2)
            #
            #   print("zdraw_temp = ")
            #   print(zdraw_temp)
            #
            #   stop("line 2612 draw very close to limit")
            # }

            # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a = temp_lower3,
            #                          b = temp_upper3,
            #                          mean = temp_mean2,
            #                          sd = 1)

            if(is.na(zdraw_temp)){
              print(" line 2367")
              print("temp_lower3] = ")
              print(temp_lower3)

              print("temp_upper3 = ")
              print(temp_upper3)

              print("temp_mean2 = ")
              print(temp_mean2)

              stop("NA zdraw_temp")
            }

            Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp

          } # end loop over items
        } # end loop over rankers

        #   } # end loop over items
        #
        # } # end loop over individuals indiv in 1:n.ranker

      } # end loop over z iters
    } # end else statement

    # print("end z draws ")



    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{

    # temp_break <- 0
    # for(j in 1:num_lags){
    #   # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #
    #   while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {
    #
    #     if(seq_z_draws==1){
    #       stop("updates still not consistent with tree structure")
    #     }
    #     print("new z values not consistent with tree structure, must draw again")
    #
    #     # If this error message occurs
    #     # Check the conditions in the dbart package for setPredictor == FALSE
    #     # And if this is hypothetically possible, even with draws from the smoothing distribution,
    #     # and if it is not a bug
    #     # then need to go back to beginning of this iteration of the Gibbs sampler
    #     # and sample Zmat again
    #
    #
    #     temp_break <- 1
    #     break
    #     # stop("new z values not consistent with tree structure, must draw again")
    #
    #
    #     # #perhaps this can be rewritten to just re-draw the relevant column?
    #     # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #     #                                           Z.mat = Z.mat,
    #     #                                           mu = mu,
    #     #                                           weight.vec = rep(1, n.ranker*n.time),
    #     #                                           n.ranker = n.ranker*n.time,
    #     #                                           n.item = n.item )
    #     #
    #     # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #     #
    #     # for(t in 1:num_lags){
    #     #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #     #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #     #
    #     #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #     #
    #     # }
    #     #
    #     # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j
    #
    #   }
    #
    #   if(temp_break==1){
    #     break
    #   }
    # }
    #
    # # if need to draw z values again, go back to start of loop
    # if(temp_break==1){
    #   if(breakcount == 10){
    #     Z.mat <- Z.matold
    #     Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #     for(t in 1:num_lags){
    #       init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #       # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #       Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #
    #     }
    #
    #   }else{
    #     breakcount <- breakcount +1
    #     next
    #   }
    #
    # }
    #
    # breakcount <- 0


    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }




    ##################### Sample sum-of-trees ##################################################


    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    # #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # mutemp <- sampler$predict(df_for_dbart)
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # mu = mutemp


    # print("line 2768")



    # Must update node sizes for original tree
    # update all node sizes before new proposal

    # Must update node sizes for original tree
    # update all node sizes before new proposal

    for (j in 1:n.trees) {
      # print("curr_trees[[j]] = ")
      # print(curr_trees[[j]] )

      curr_trees[[j]] <- fill_tree_details(curr_trees[[j]],
                                           Zlag.mat)

      # print("line 2785, curr_trees[[j]] = ")
      # print(curr_trees[[j]] )
      # must also update individual tree predictions for calcualtion of partial residuals
      tree_fits_store[,j]  = get_predictions(curr_trees[[j]], Zlag.mat, single_tree = TRUE)

    }

    # option: prune all empty nodes from current trees before proposal?
    # must create new function for this
    # perhaps an issue is that there would not be a (umique) mu value
    # associated with a parent of an empty node
    # print("line 2791")

    # must update mu before and after trees updated because covariates have been updated

    mutemp = get_predictions(curr_trees, Zlag.mat, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))

    # print("line 2801")

    # Start looping through trees
    for (j in 1:n.trees) {

      current_partial_residuals = as.vector(Z.mat) - mu + tree_fits_store[,j]

      # Propose a new tree via grow/change/prune/swap
      type = sample_move(curr_trees[[j]], iter, 0, # nburn # no burnin number, so setting to 100, maybe this is not optimal
                         trans_prob)



      # option: edit the proposal step so that any proposed tree does not contain empty nodes?
      # must create new function for this

      # Generate a new tree based on the current
      if(no_empty_proposals == TRUE){

        new_trees[[j]] = noempty_update_tree(y = as.vector(Z.mat),
                                             X = Zlag.mat,
                                             type = type,
                                             curr_tree = curr_trees[[j]],
                                             node_min_size = node_min_size,
                                             s = s,
                                             splitting_rules = splitting_rules,
                                             max_bad_trees = max_bad_trees)

      }else{
        new_trees[[j]] = update_tree(y = as.vector(Z.mat),
                                     X = Zlag.mat,
                                     type = type,
                                     curr_tree = curr_trees[[j]],
                                     node_min_size = node_min_size,
                                     s = s,
                                     splitting_rules = splitting_rules,
                                     max_bad_trees = max_bad_trees)

      }




      # print("line 2825")


      # CURRENT TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_old = tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(curr_trees[[j]], alpha, beta)

      # print("line 2825")
      #
      # print("new_trees[[j]]")
      # print(new_trees[[j]])

      # NEW TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_new = tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(new_trees[[j]], alpha, beta)

      # Exponentiate and multiply by the transition probabilities

      if(type == 'grow'){
        a = exp(l_new - l_old)*ratio_grow(new_trees[[j]], curr_trees[[j]])
      } else if(type == 'prune'){
        a = exp(l_new - l_old)*ratio_prune(new_trees[[j]], curr_trees[[j]])
      } else{
        a = exp(l_new - l_old)
      }

      vars_empty_pruned <- c()

      if(is.na(a)){
        print("current_partial_residuals = ")
        print(current_partial_residuals)

        print("get_tree_prior(new_trees[[j]], alpha, beta) = ")
        print(get_tree_prior(new_trees[[j]], alpha, beta))

        print("get_tree_prior(curr_trees[[j]], alpha, beta) = ")
        print(get_tree_prior(curr_trees[[j]], alpha, beta))

        print("tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) = ")
        print(tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu))

        print("tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)  = ")
        print(tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) )

        print("new_trees[[j]] = ")
        print(new_trees[[j]])
        print("curr_trees[[j]] = ")
        print(curr_trees[[j]])

        print("l_new = ")
        print(l_new)

        print("l_old = ")
        print(l_old)

        print("ratio_prune(new_trees[[j]], curr_trees[[j]]) = ")
        print(ratio_prune(new_trees[[j]], curr_trees[[j]]))

        print("ratio_grow(new_trees[[j]], curr_trees[[j]]) = ")
        print(ratio_grow(new_trees[[j]], curr_trees[[j]]))

        print("exp(l_new - l_old) = ")
        print(exp(l_new - l_old))

        print("type = ")
        print(type)

        print("is.na(a)")
      }


      if(a > runif(1)) {
        curr_trees[[j]] = new_trees[[j]]
        # only account for pruning if  accept
        vars_empty_pruned <- new_trees[[j]]$vars_empty_pruned

        for(var_ind in vars_empty_pruned){
          var_count[var_ind ] = var_count[var_ind ] - 1
        }


        if (type =='change'){
          var_count[curr_trees[[j]]$var[1] ] = var_count[curr_trees[[j]]$var[1] ] - 1
          var_count[curr_trees[[j]]$var[2] ] = var_count[curr_trees[[j]]$var[2] ] + 1
        }

        if (type=='grow'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] + 1
        } # -1 because of the intercept in X

        if (type=='prune'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] - 1
        } # -1 because of the intercept in X

      }


      ### might need to edit simulate_mu to find right terminal nodes #########

      # Update mu whether tree accepted or not
      curr_trees[[j]] = simulate_mu(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)
      # Updating BART predictions
      current_fit = get_predictions(curr_trees[[j]], Zlag.mat, single_tree = TRUE)
      mu = mu - tree_fits_store[,j] # subtract the old fit
      mu = mu + current_fit # add the new fit
      tree_fits_store[,j] = current_fit # update the new fit

    } # End loop through trees



    # sum_of_squares = sum((y_scale - y_hat)^2)

    # Update sigma2 (variance of the residuals)
    # sigma2 = update_sigma2(sum_of_squares, n = length(y_scale), nu, lambda)
    # variance kept equal to 1, do not update

    # # Update s = (s_1, ..., s_p), where s_p is the probability that predictor p is used to create new terminal nodes
    # if (sparse == 'TRUE' & i > floor(iter.max*0.1)){
    #   s = update_s(var_count, ncol(Zlag.mat), 1)
    # }

    # Update s = (s_1, ..., s_p), where s_p is the probability that predictor q in 1:p is used to create new terminal nodes
    if (sparse & i > floor(iter.max * 0.25)) {
      s <- update_s(var_count, p, alpha_s)
      if(alpha_prior){
        alpha_s <- update_alpha_par(s, alpha_scale, alpha_a, alpha_b)
      }
    }

    if(sigma_mu_prior){
      sigma2_mu <-  update_sigma_mu_par(curr_trees, sigma2_mu)
    }


    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta




    # if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(df_for_dbart)

    # Xmat.test[,1:num_lags] <-  Zlag.mat.test


    temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))

    for(t  in 1:num_lags){
      if(noise_in_pred ==1){
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
      }else{
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]

      }

    }

    # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #                                                                      (num_lags+1):ncol(Xmat.test)])

    temp_test_mat <- data.frame(x = temp_test_mat)
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # print("Line 5488")


    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )


    # if(iter < 5){
    #   print("temp_test_mat = " )
    #   print(temp_test_mat)
    # }

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # must use original column names to prevent an error in the predict function
      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      # testpredvec <- sampler$predict(temp_test_mat)
      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

      #fill in temp_test_preds with noise
      if(noise_in_pred ==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
      }


      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

      if(t1 != num_test_periods){


        if(num_lags ==1){
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }else{
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                    temp_test_mat[,1:(num_lags-1)] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }
      }

      # colnames(temp_test_mat) <- colnames(Xmat.test)


      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?

    # print("Line 5545")


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }


    draw$mu_test[,iter] <- temp_mu_test
    # draw$mu_test[,iter] <- samplestemp$test[,1]

    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

    # draw$mu_test[,1] <- samplestemp$test[,1]

    # }else{
    #   draw$mu_test[,1] <- initial.list$mu_test
    # }




    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

    iter <- iter+1
  } # end loop over MCMC iterations


  return(draw)
}






##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data without  Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and without covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @export
ARRObartNOCovars_fullcond <- function(pair.comp.ten,
                                      # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                      # X.test = matrix(NA, nrow =0, ncol = 0),
                                      # tau2.alpha = 5^2,
                                      # nu.alpha = 3,
                                      # tau2.beta = 5^2,
                                      # nu.beta = 3,
                                      n.item = dim(pair.comp.ten)[1],
                                      n.rankerbytime = dim(pair.comp.ten)[3],
                                      n.ranker,
                                      n.time,
                                      # p.cov = ncol(X.train),
                                      iter.max = 5000,
                                      para.expan = TRUE,
                                      print.opt = 100,
                                      initial.list = NULL,
                                      n.trees = 50L,
                                      n.burn = 0L,
                                      n.samples = 1L,
                                      n.thin = 1L,
                                      n.chains = 1,
                                      n.threads = 1L,#guessNumCores(),
                                      printEvery = 100L,
                                      printCutoffs = 0L,
                                      rngKind = "default",
                                      rngNormalKind = "default",
                                      rngSeed = NA_integer_,
                                      updateState = TRUE,
                                      num_lags = 1,
                                      diff_num_test_rankers = 0,
                                      keep_zmat = FALSE,
                                      noise_in_pred = 0,
                                      seq_z_draws = 1,
                                      N_hdr = 100,
                                      rho_hdr = 0.5,
                                      smoothing_method = "AR",
                                      num_horizon = 1,
                                      num_z_iters = 10,
                                      tree_power = 2,
                                      tree_base = 0.95,
                                      n.burnin = floor(dim(pair.comp.ten)[1]/2),
                                      sparse = TRUE,
                                      alpha_a_y = 0.5,
                                      alpha_b_y = 1,
                                      alpha_split_prior = TRUE){


  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  # length_mu_test <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }


  # it might be more efficient to create and save all rank constraint matrices at this stage


  rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))

  for(indiv in 1:n.ranker){

    for(t in 1:n.time){

      rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]


      rankconstraint_t <- matrix(0,
                                 nrow = n.item - 1,
                                 ncol = n.item)

      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1

      }

      rank_cons_arr[, , indiv, t] <- rankconstraint_t

    }
  }
  # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  boundconstraints <- matrix(NA,
                             nrow = 2*n.item,
                             ncol = n.item)

  # use kroenecker product
  # there is probably a more efficient way of doing this

  boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))


      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }



    # print("Line 799.")

    df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )

    p_y <- ncol(df_for_dbart) - 1 # subtracting 1. outcome is a column of df_for_dbart

    if(sparse){
      s_y <- rep(1 / p_y, p_y) # probability vector to be used during the growing process for DART feature weighting
      rho_y <- p_y # For DART

      if(alpha_split_prior){
        alpha_s_y <- p_y
      }else{
        alpha_s_y <- 1
      }
      alpha_scale_y <- p_y


      var_count_y <- rep(0, p_y)

      draw$alpha_s_y_store <- rep(NA, iter.max)
      draw$var_count_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
      draw$s_prob_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
    }

    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")


    # if(nrow(X.test )==0){
    sampler <- dbarts(y ~ .,
                      data = df_for_dbart,
                      #test = Xmat.test,
                      control = control,
                      resid.prior = fixed(1),
                      tree.prior = dbarts:::cgm(power = tree_power, base =  tree_base,  split.probs = rep(1 / p_y, p_y)),
                      sigma=1 #check if this is the correct approach for setting the variance to 1
    )

    # }else{
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    #                     sigma=1 #
    #   )
    #
    # }

    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    min_resp <- min(as.vector(Z.mat))
    max_resp <- max(as.vector(Z.mat))

    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }
    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)

    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()


    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y <- rep(0, p_y)
      var_count_y[tempcounts$x] <- tempcounts$N
    }

    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    mu <- mutemp

    #
    # if(nrow(X.train)==n.item){
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #   stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #   # if(mutemp[1]!= mutemp[n.item+1]){
    #   if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
    #     print("initiating mu")
    #     print("Xmat.train = ")
    #     print(Xmat.train)
    #     print("Z.mat = ")
    #     print(Z.mat)
    #
    #     print("samplestemp$sigma = ")
    #     print(samplestemp$sigma)
    #     print("samplestemp$varcount = ")
    #     print(samplestemp$varcount)
    #
    #     print("samplestemp$train[,1] = ")
    #     print(samplestemp$train[,1])
    #
    #     print("n.item = ")
    #     print(n.item)
    #     print("mutemp = ")
    #     print(mutemp)
    #
    #     # print("mupreds= ")
    #     # print(mupreds)
    #
    #     stop("mutemp[1]!= mutemp[n.item+1]")
    #   }
    #
    #   #mu = mutemp[(1:n.item)]
    #   mu = mutemp[n.item+(1:n.item)]
    #
    #   #mu = mutemp[(1:n.item)*n.ranker]
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     mu <- mutemp
    #   }else{
    #     stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    #
    # }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  # print("Line 954")


  df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    temp_test_mat <- data.frame(x = as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      testpredvec <- sampler$predict(temp_test_mat)

      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker), ] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),] )))

      }

      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration

  iter <- 2
  breakcount <- 0
  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############



    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA

    # create vector of indices for ranker indiv in time period 1

    # # this part is not really necessary
    # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
    # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
    # obs_indices <- ind_start:ind_end

    # obs_indices[1] could jsut be replaced by [1] below\
    # because the only variable is zlag, so the other covariates are not used


    list_inter_mats <- list()

    for(i in 1:n.trees){

      treeexample1 <- sampler$getTrees(treeNums = i,
                                       chainNums = 1,
                                       sampleNums = 1)

      # rebuilt_tree <- rebuildTree2(treeexample1)
      rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))


      #must use covariates for individual indiv at time period t

      # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )

      # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
      list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree[,4] == -1 , 5:7, drop = FALSE]


    }

    intersectmat <- interNtreesB(list_inter_mats)

    # print("Line 1146")

    intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

    # print("Line 1150")


    # calculate one dimensional integrals
    for(rowind in 1:nrow(intersectmat)){
      # ktemp <- nkt_mat[rowind,k_index]
      # tempmean <- intersectmat[ktemp,1]
      templower <- intersectmat[rowind,2]
      tempupper <- intersectmat[rowind,3]

      # ASSUMING PRIOR MEAN ALL ZEROS

      # These are the q0 integrals
      intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
      # tempintegralval <- tempintegralval*onedim_int
    }

    intersectmat_tmin1 <- intersectmat



    num_regions <- nrow(intersectmat)

    # print("Line 1169")


    for(z_iter_ind in 1:num_z_iters){


      for(indiv in 1:n.ranker){

        # print("indiv = ")
        # print(indiv)
        ########### calculate qkt  ########################################

        ########### calculate qkt   for t = 1 ########################################


        ### calculate qkt integrals for time period t = 1  ################

        # These integrals are already calculated and saved as intersectmat[ktemp,4]

        for(item_ind in 1:n.item){


          #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

          # loop over items

          # Now loop over time periods

          # special case for t=1

          # probability matrix for sampling elements

          # let rows be period zero, and columns be period 1 (2?)

          probmattemp <- matrix(0,
                                nrow = num_regions,
                                ncol = num_regions)

          # loop over period 2 regions into which z_1 can fall


          tempbounds <- matrix(NA,
                               nrow = num_regions,
                               ncol = 2)

          # Trunc norm prob of next periods latent value conditional on region

          # Create intervals from interval t+1 latent values

          rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

          # inds for j ranked below i in t+1



          belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )

          #max of latent variables for j ranked below i in t+1
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower <- -Inf
          }else{
            # Check that this is the period t+1 latent variable value, not period t
            temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             belowrank_ind]
          }

          # inds for j ranked above i in t+1

          aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)

          #min of latent variables for j ranked below i in period t+1

          if(length(aboverank_ind) ==0){
            temp_upper <- Inf
          }else{
            # Check that this is the period t+1 latent variable value, not period t

            temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             aboverank_ind]
          }


          temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                          n.item*(indiv - 1) +
                                          item_ind]



          rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]

          # if(any(order(rankvec_t) !=
          #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                           n.item*(indiv-1) +
          #                           1:n.item])) ){
          #
          #   # print("order(rankvec_t) = ")
          #   # print(order(rankvec_t))
          #   #
          #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #   #                         n.item*(indiv - 1) +
          #   #                         1:n.item])  = ")
          #
          #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                  n.item*(indiv - 1) +
          #                                  1:n.item]) )
          #
          #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #   #                                n.item*(indiv - 1) +
          #   #                                1:n.item] = ")
          #
          #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                            n.item*(indiv - 1) +
          #                            1:n.item])
          #
          # }

          # inds for j ranked below i in t

          belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

          #max of latent variables for j ranked below i in t
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower3 <- -Inf
          }else{
            temp_lower3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              belowrank_ind]
          }

          # inds for j ranked above i in t

          aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

          #min of latent variables for j ranked below i in period t

          if(length(aboverank_ind) ==0){
            temp_upper3 <- Inf
          }else{
            temp_upper3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              aboverank_ind]
          }



          tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp

          temp_tnorm_probvec <- fastnormdens(temp_ztp1,
                                             mean = tempmeanfordens,
                                             sd = 1)



          # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
          #                                 mean = intersectmat[1:num_regions, 1],
          #                                 sd = 1)

          for(k_ind in 1:num_regions){
            # obtain mean for truncated normal distribution
            # temp_mean <- intersectmat[k_ind, 1]

            # want trunc norm probability of latent variable value for item_ind
            # in period t+1


            # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #                               a=temp_lower,
            #                               b=Inf,
            #                               mean = temp_mean,
            #                               sd = 1)

            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                          mean = temp_mean,
            #                          sd = 1)

            temp_tnorm_prob <- temp_tnorm_probvec[k_ind]

            # temp_mean <- intersectmat[k_ind, 1]



            # now second term


            temp_lower2 <- intersectmat[k_ind, 2]
            temp_upper2 <- intersectmat[k_ind, 3]




            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_lower3 = ")
            # print(temp_lower3)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)
            #
            # print("temp_upper3 = ")
            # print(temp_upper3)


            if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
              # intervals do not overlap, therefore assign probability zero
              # and skip to next iteration


              # print("k_ind = ")
              # print(k_ind)

              # print("ncol(temp_region_probs) = ")
              # print(ncol(temp_region_probs))

              # print("nrow(temp_region_probs) = ")
              # print(nrow(temp_region_probs))


              # these three lines are technically unnecessary
              probmattemp[, k_ind] <- rep(0,num_regions)
              tempbounds[k_ind, 1] <- NA
              tempbounds[k_ind, 2] <- NA

              next

            }


            temp_lower2 <- max(temp_lower2, temp_lower3)
            temp_upper2 <- min(temp_upper2, temp_upper3)

            if(temp_lower2 > temp_upper2){

              print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

              print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                       n.item*(indiv - 1) +
                                       1:n.item])

              print("item_ind = ")
              print(item_ind)

              print("rankvec_t = ")
              print(rankvec_t)

              stop("Line 1581 temp_lower2 > temp_upper2")
            }


            for(k0_ind in 1:num_regions){

              #loop over all possible means
              temp_mean2 <- intersectmat[k0_ind,1]

              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # probmattemp[k0_ind, k_ind] <- prob_t_region*
              #   temp_tnorm_prob *
              #   intersectmat[k0_ind,4]

              probmattemp[k0_ind, k_ind] <- temp_tnorm_prob * intersectmat[k0_ind,4]

              if(probmattemp[k0_ind, k_ind] <0){
                print("probmattemp[k0_ind, k_ind] = ")
                print(probmattemp[k0_ind, k_ind])

                # print("prob_t_region = ")
                # print(prob_t_region)

                print("temp_tnorm_prob = ")
                print(temp_tnorm_prob)

                print("intersectmat[k0_ind,4] = ")
                print(intersectmat[k0_ind,4])

                print("temp_upper2 = ")
                print(temp_upper2)

                print("temp_lower2 = ")
                print(temp_lower2)

                print("temp_mean2 = ")
                print(temp_mean2)


              }


            } # end loop over k0

            # save upper and lower bounds (mean saved in intersectmat)
            # or just obtain again later

            tempbounds[k_ind,1] <- temp_lower2
            tempbounds[k_ind,2] <- temp_upper2


          } # end loop over k1


          #sample a combination of k0 and k1
          # if necessary can use column sums to sample k1, then k0
          # however, this is probably unnecessary


          # print("Line 1621 before sample")

          region_ind <- sample.int((num_regions^2),
                                   size = 1,
                                   replace = TRUE,
                                   prob = as.vector(probmattemp))


          # print("Line 1629 after sample")

          # k0 region is sampled number modulo number of regions
          k0_region_ind <- (region_ind - 1) %% num_regions + 1
          # if(k0_region_ind ==0){
          #   k0_region_ind <- num_regions
          # }

          # k1 region is the ceiling of sampled number divided by number of regions
          # k1_region_ind <- ceiling(region_ind/num_regions)
          k1_region_ind <- (region_ind - 1) %/% num_regions + 1


          # print("k1_region_ind = ")
          # print(k1_region_ind)

          temp_lower2 <- tempbounds[k1_region_ind,1]
          temp_upper2 <- tempbounds[k1_region_ind,2]

          # print("num_regions = ")
          # print(num_regions)
          #
          # print("region_ind = ")
          # print(region_ind)
          #
          # print("k0_region_ind = ")
          # print(k0_region_ind)

          temp_mean0 <- intersectmat[k0_region_ind, 1]
          temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

          # print("temp_mean0 = ")
          # print(temp_mean0)
          #
          # print("temp_lower2 = ")
          # print(temp_lower2)
          #
          # print("temp_upper2 = ")
          # print(temp_upper2)

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = temp_lower2,
                                   b = temp_upper2,
                                   mean = temp_mean0,
                                   sd = 1)


          Z.mat[item_ind,  indiv ] <- zdraw_temp


          # loop over time periods for general case 1 < t < T

          for(t in 2:(n.time - 1)){

            temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # or first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat[, 3]) )[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat[ktemp_tmin1,1]

            # print("temp_mean2 = ")
            # print(temp_mean2)
            #
            # print("ktemp_tmin1 = ")
            # print(ktemp_tmin1)



            # Calculate the probabilities for each region in this time period
            # the regions being looped over are actually period t+1 regions

            # Same regions for all time periods if there are no time varying covariates

            # However, the weights are individual and time period specific

            # loop through regions


            # first column is the probabilities
            # second column is the lower bounds
            # third column is the upper bounds
            temp_region_probs <- matrix(0,
                                        nrow = nrow(intersectmat),
                                        ncol = 3)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

            # inds for j ranked below i in t+1

            belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )

            #max of latent variables for j ranked below i in t+1
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower <- -Inf
            }else{
              # Check that this is the period t+1 latent variable value, not period t
              temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               belowrank_ind]
            }

            # inds for j ranked above i in t+1

            aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)

            #min of latent variables for j ranked below i in period t+1

            if(length(aboverank_ind) ==0){
              temp_upper <- Inf
            }else{
              # Check that this is the period t+1 latent variable value, not period t

              temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               aboverank_ind]
            }


            # want trunc norm probability of latent variable value for item_ind
            # in period t+1

            temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]

            rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]



            # if(any(order(rankvec_t) !=
            #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                           n.item*(indiv - 1) +
            #                           1:n.item]) )){
            #
            #   print("order(rankvec_t) = ")
            #   print(order(rankvec_t))
            #
            #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                         n.item*(indiv - 1) +
            #                         1:n.item])  = ")
            #
            #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                  n.item*(indiv - 1) +
            #                                  1:n.item]) )
            #
            #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                n.item*(indiv - 1) +
            #                                1:n.item] = ")
            #
            #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item])
            #
            #
            # }





            # inds for j ranked below i in t

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in t
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind]
            }

            # inds for j ranked above i in t

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period t

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind]
            }

            tempmeanfordens <- (intersectmat[1:num_regions, 1] + 0.5)*(max_resp - min_resp) + min_resp

            temp_tnorm_probvec <- fastnormdens(temp_ztp1,
                                               mean = tempmeanfordens,
                                               sd = 1)

            # temp_tnorm_probvec <- fastnormdens(temp_ztp1,
            #                                 mean = intersectmat[1:num_regions, 1],
            #                                 sd = 1)

            for(k_ind in 1:num_regions){
              # obtain mean for truncated normal distribution
              # temp_mean <- intersectmat[k_ind, 1]

              # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #                               a=temp_lower,
              #                               b=Inf,
              #                               mean = temp_mean,
              #                               sd = 1)


              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                          mean = temp_mean,
              #                          sd = 1)

              temp_tnorm_prob <- temp_tnorm_probvec[k_ind]

              # Probability of z_t in intersection of
              # region k_ind (for period t+1)
              # and region defined by period t latent variables for other individuals
              # and rank for period t


              # tildeC_ktminl corresponds to
              # period t+1 k_ind region intereval

              temp_lower2 <- intersectmat[k_ind, 2]
              temp_upper2 <- intersectmat[k_ind, 3]



              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_upper2 = ")
              # print(temp_upper2)
              #
              # print("temp_lower3 = ")
              # print(temp_lower3)
              #
              # print("temp_upper3 = ")
              # print(temp_upper3)


              if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
                # intervals do not overlap, therefore assign probability zero
                # and skip to next iteration

                # print("k_ind = ")
                # print(k_ind)

                # print("ncol(temp_region_probs) = ")
                # print(ncol(temp_region_probs))

                # print("nrow(temp_region_probs) = ")
                # print(nrow(temp_region_probs))

                temp_region_probs[k_ind, 1] <- 0
                temp_region_probs[k_ind, 2] <- NA
                temp_region_probs[k_ind, 3] <- NA


                next
              }



              temp_lower2 <- max(temp_lower2, temp_lower3)
              temp_upper2 <- min(temp_upper2, temp_upper3)


              if(temp_lower2 > temp_upper2){

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")
                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])
                print("item_ind = ")
                print(item_ind)

                print("rankvec_t = ")
                print(rankvec_t)


                print("temp_lower2 = ")
                print(temp_lower2)

                print("temp_upper2 = ")
                print(temp_upper2)

                stop("Line 1917. temp_lower2 > temp_upper2")
              }



              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # print("temp_upper2 = ")
              # print(temp_upper2)
              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              #
              # print("prob_t_region = ")
              # print(prob_t_region)
              #
              # print("temp_tnorm_prob = ")
              # print(temp_tnorm_prob)

              # prob_t_region <- prob_t_region*temp_tnorm_prob
              prob_t_region <- temp_tnorm_prob

              # save region probability

              # and save region bounds (or maybe more memory efficient to obtain the region again)

              # must multiply by other previously obtained probabilities

              # print("prob_t_region = ")
              # print(prob_t_region)

              temp_region_probs[k_ind, 1] <- prob_t_region
              temp_region_probs[k_ind, 2] <- temp_lower2
              temp_region_probs[k_ind, 3] <- temp_upper2


            }


            # sample a region using probabilities obtained above

            # print("Line 1903 before sample")

            region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])

            temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
            #
            # print("line 2102 temp_mean2_debug from predict = ")
            # print(temp_mean2_debug)
            #
            # print("line 2105 temp_mean2_origscale = ")
            # print(temp_mean2_origscale)
            #
            # print("line 2108 temp_mean2 = ")
            # print(temp_mean2)

            zdraw_temp <- rtruncnorm(n = 1,
                                     a=temp_region_probs[region_ind, 2],
                                     b=temp_region_probs[region_ind, 3],
                                     mean = temp_mean2_origscale,
                                     sd = 1)


            # print("Line 1914 after sample")

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a=temp_region_probs[region_ind, 2],
            #                          b=temp_region_probs[region_ind, 3],
            #                          mean = temp_mean2,
            #                          sd = 1)



            Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



          } # end loop over time periods

          # check for special cases for n.time - 1, n.time - 2, n.time - 3

          # special case for t = n.time


          temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             item_ind]


          # must find mean corresponding to z in period t-1
          # This will be used in and after the loop over regions.
          # can directly obtain from dbarts
          # or find region
          # and use already saved region mean values


          # must find last lower bound that temp_ztpmin1 is greater than
          # for first upper bound that temp_ztpmin1 is below
          ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat[, 3])[1]
          # Then obtain the corresponding region mean value
          temp_mean2 <- intersectmat[ktemp_tmin1,1]

          # now find interval


          # tildeC_ktminl corresponds to
          # period t+1 k_ind region intereval



          rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

          # inds for j ranked below i in T

          belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

          #max of latent variables for j ranked below i in T
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower3 <- -Inf
          }else{
            temp_lower3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              belowrank_ind]
          }

          # inds for j ranked above i in T

          aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

          #min of latent variables for j ranked below i in period T

          if(length(aboverank_ind) ==0){
            temp_upper3 <- Inf
          }else{

            temp_upper3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              aboverank_ind]
          }


          temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

          # temp_mean2_debug <- sampler$predict(x.test = as.matrix(rep(temp_ztpmin1,100)), offset.test = NULL)[1]
          #
          # print("line 2202 temp_mean2_debug from predict = ")
          # print(temp_mean2_debug)
          #
          # print("line 2205 temp_mean2_origscale = ")
          # print(temp_mean2_origscale)
          #
          # print("line 2208 temp_mean2 = ")
          # print(temp_mean2)

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = temp_lower3,
                                   b = temp_upper3,
                                   mean = temp_mean2_origscale,
                                   sd = 1)


          # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

          # zdraw_temp <- rtruncnorm(n = 1,
          #                          a = temp_lower3,
          #                          b = temp_upper3,
          #                          mean = temp_mean2,
          #                          sd = 1)


          Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





        } # end loop over items



      } # end loop over individuals indiv in 1:n.ranker

    }




    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{

    temp_break <- 0
    for(j in 1:num_lags){
      # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)

      while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {

        if(seq_z_draws==1){
          stop("updates still not consistent with tree structure")
        }
        print("new z values not consistent with tree structure, must draw again")

        # If this error message occurs
        # Check the conditions in the dbart package for setPredictor == FALSE
        # And if this is hypothetically possible, even with draws from the smoothing distribution,
        # and if it is not a bug
        # then need to go back to beginning of this iteration of the Gibbs sampler
        # and sample Zmat again


        temp_break <- 1
        break
        # stop("new z values not consistent with tree structure, must draw again")


        # #perhaps this can be rewritten to just re-draw the relevant column?
        # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                           Z.mat = Z.mat,
        #                                           mu = mu,
        #                                           weight.vec = rep(1, n.ranker*n.time),
        #                                           n.ranker = n.ranker*n.time,
        #                                           n.item = n.item )
        #
        # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
        #
        # for(t in 1:num_lags){
        #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
        #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
        #
        #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
        #
        # }
        #
        # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j

      }

      if(temp_break==1){
        break
      }
    }

    # if need to draw z values again, go back to start of loop
    if(temp_break==1){
      if(breakcount == 10){
        Z.mat <- Z.matold
        Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

        for(t in 1:num_lags){
          init_Z_t0 <- rep(0, t*n.item*n.ranker)
          # init_Z_t0 <- rnorm(t*n.item*n.ranker)

          Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

        }

      }else{
        breakcount <- breakcount +1
        next
      }

    }

    breakcount <- 0


    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)

    min_resp <- min(as.vector(Z.mat))
    max_resp <- max(as.vector(Z.mat))

    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }
    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples
    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y[tempcounts$x] <- tempcounts$N
    }
    # mutemp <- sampler$predict(df_for_dbart)
    # print("sigma = ")
    # print(samplestemp$sigma)

    mu = mutemp


    if (sparse & (iter > floor(n.burnin * 0.5))) {
      # s_update_z <- update_s(var_count_z, p_z, alpha_s_z)
      # s_z <- s_update_z[[1]]

      s_update_y <- update_s(var_count_y, p_y, alpha_s_y)
      s_y <- s_update_y[[1]]

      if(alpha_split_prior){
        # alpha_s_z <- update_alpha(s_z, alpha_scale_z, alpha_a_z, alpha_b_z, p_z, s_update_z[[2]])
        alpha_s_y <- update_alpha(s_y, alpha_scale_y, alpha_a_y, alpha_b_y, p_y, s_update_y[[2]])
      }
    }
    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta




    # if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(df_for_dbart)

    # Xmat.test[,1:num_lags] <-  Zlag.mat.test


    temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))

    for(t  in 1:num_lags){
      if(noise_in_pred ==1){
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
      }else{
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]

      }

    }

    # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #                                                                      (num_lags+1):ncol(Xmat.test)])

    temp_test_mat <- data.frame(x = temp_test_mat)
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # print("Line 5488")


    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )


    # if(iter < 5){
    #   print("temp_test_mat = " )
    #   print(temp_test_mat)
    # }

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # must use original column names to prevent an error in the predict function
      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      testpredvec <- sampler$predict(temp_test_mat)

      #fill in temp_test_preds with noise
      if(noise_in_pred ==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
      }


      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

      if(t1 != num_test_periods){


        if(num_lags ==1){
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }else{
          temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                    temp_test_mat[,1:(num_lags-1)] #,
                                                    # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }
      }

      # colnames(temp_test_mat) <- colnames(Xmat.test)


      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?

    # print("Line 5545")


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }


    draw$mu_test[,iter] <- temp_mu_test
    # draw$mu_test[,iter] <- samplestemp$test[,1]

    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }


    if(sparse){
      draw$alpha_s_y_store[iter] <- alpha_s_y
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_y_store[iter,] <- var_count_y
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_y_store[iter,] <- s_y
      # draw$s_prob_z_store[iter,] <- s_z
    }

    # draw$mu_test[,1] <- samplestemp$test[,1]

    # }else{
    #   draw$mu_test[,1] <- initial.list$mu_test
    # }




    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

    iter <- iter+1
  } # end loop over MCMC iterations


  return(draw)
}




##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and with covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.train An \eqn{N} by \eqn{L} training covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param X.test An \eqn{N} by \eqn{L} test covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param n.item Number of entities/items being ranked.
#' @param n.rankerbytime Number of rankers multiplied by number of time periods
#' @param n.ranker Number of rankers
#' @param n.time Number of time periods
#' @param p.cov Number of covariates.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @param itemcovars Set equal to TRUE if covariates vary across items, and FALSE otherwise.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @useDynLib ROBART2, .registration = TRUE
#' @export
ARRObartWithCovars_fullcond_emptynodes <- function(pair.comp.ten,
                                                   X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                                   X.test = matrix(NA, nrow =0, ncol = 0),
                                                   # tau2.alpha = 5^2,
                                                   # nu.alpha = 3,
                                                   # tau2.beta = 5^2,
                                                   # nu.beta = 3,
                                                   n.item = dim(pair.comp.ten)[1],
                                                   n.rankerbytime = dim(pair.comp.ten)[3],
                                                   n.ranker,
                                                   n.time,
                                                   p.cov = ncol(X.train),
                                                   iter.max = 5000,
                                                   para.expan = TRUE,
                                                   print.opt = 100,
                                                   initial.list = NULL,
                                                   n.trees = 50L,
                                                   n.burn = 0L,
                                                   n.samples = 1L,
                                                   n.thin = 1L,
                                                   trans_prob = c(2.5, 2.5, 4) / 9, # Probabilities to grow, prune or change, respectively
                                                   n.chains = 1,
                                                   n.threads = 1L,#guessNumCores(),
                                                   printEvery = 100L,
                                                   printCutoffs = 0L,
                                                   rngKind = "default",
                                                   rngNormalKind = "default",
                                                   rngSeed = NA_integer_,
                                                   updateState = FALSE,
                                                   num_lags = 1,
                                                   diff_num_test_rankers = 0,
                                                   keep_zmat = FALSE,
                                                   noise_in_pred = 0,
                                                   seq_z_draws = 1,
                                                   N_hdr = 100,
                                                   rho_hdr = 0.5,
                                                   smoothing_method = "AR",
                                                   num_horizon = 1,
                                                   num_z_iters = 10,
                                                   itemcovars = FALSE,
                                                   node_min_size = 5,
                                                   k = 2,
                                                   sigquant = .90,
                                                   alpha = 0.95,
                                                   beta = 2,
                                                   nu = 3,
                                                   lambda = 0.1,
                                                   no_empty_proposals = FALSE,
                                                   alpha_prior = TRUE,
                                                   sigma_mu_prior = FALSE,
                                                   splitting_rules = "discrete",
                                                   max_bad_trees = 10,
                                                   sparse = TRUE,
                                                   alpha_a_y = 0.5,
                                                   alpha_b_y = 1,
                                                   alpha_split_prior = TRUE){


  if(!(splitting_rules %in% c("discrete", "continuous"))){
    stop("splitting_rules must be 'discrete' or 'continuous'.")
  }

  X.train <- as.matrix(X.train)
  X.test <- as.matrix(X.test)

  ######### set up things for myBART implementation ####################

  # Extract control parameters
  # we only have to allow for empty nodes when updating Z (and therefore Zlag is updated and splits on Zlag are affected)
  # Therefore there is still a minimum node size criterion for the purpose of proposing new splits
  # node_min_size = node_min_size

  # Storage containers
  store_size = iter.max # npost # code currently written to save all output, so no nburnin or npost
  tree_store = vector('list', store_size)
  sigma2_store = rep(NA, store_size)
  # y_hat_store = matrix(NA, ncol = length(y), nrow = store_size)
  # var_count = rep(0, ncol(x))
  # var_count_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # s_prob_store = matrix(0, ncol = ncol(x), nrow = store_size)
  # tree_fits_store = matrix(0, ncol = n.trees, nrow = length(y))

  sigma2 <- 1 # keep sigma2 set to 1


  ########## beginning of original code ############################


  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)

      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }


  # it might be more efficient to create and save all rank constraint matrices at this stage


  rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))

  for(indiv in 1:n.ranker){

    for(t in 1:n.time){

      rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]


      rankconstraint_t <- matrix(0,
                                 nrow = n.item - 1,
                                 ncol = n.item)

      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1

      }

      rank_cons_arr[, , indiv, t] <- rankconstraint_t

    }
  }
  # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  boundconstraints <- matrix(NA,
                             nrow = 2*n.item,
                             ncol = n.item)

  # use kroenecker product
  # there is probably a more efficient way of doing this

  boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))


      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))

      # print("sort(rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix )
      #
      # print("sort(rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE ) = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE ) )
      #
      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE  = ")
      # print( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )
      #
      #
      #
      #
      # print("ranks_mat[,j] = ")
      # print(ranks_mat[,j])
      #
      #
      # print("sort(ranks_mat[,j], decreasing = FALSE, index.return = TRUE ) = ")
      # print(sort(ranks_mat[,j], decreasing = FALSE, index.return = TRUE ))
      #
      # print("sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE ) = ")
      # print(sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE ))


      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <-
        qnorm(c(n.item : 1)/(n.item+1)) +
        rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }

# stop("end test code")

    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }



    print("Line 799.")

    # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )

      Xmat.train.no.y <- cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                  ncol =  ncol(X.train) + num_lags ,
                                                  byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")

        Xmat.test.no.y <- cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                       ncol =  ncol(X.test) , byrow = TRUE ) )




        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        Xmat.train.no.y <- cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          Xmat.test.no.y <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }



    # ##### old dbarts initialization ###############
    #
    # control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
    #                          keepTrees = TRUE,
    #                          n.trees = n.trees,
    #                          n.burn = n.burn,
    #                          n.samples = n.samples,
    #                          n.thin = n.thin,
    #                          n.chains = n.chains,
    #                          n.threads = n.threads,
    #                          printEvery = printEvery,
    #                          printCutoffs = printCutoffs,
    #                          rngKind = rngKind,
    #                          rngNormalKind = rngNormalKind,
    #                          rngSeed = rngSeed)
    #
    #
    # # print(colnames(Xmat.train))
    # # print(colnames(Xmat.test))
    #
    # # print("begin dbarts")
    #
    #
    # if(nrow(X.test )==0){
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     #test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1),
    #                     sigma=1 #check if this is the correct approach for setting the variance to 1
    #   )
    #
    # }else{
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    #                     sigma=1 #
    #   )
    #
    # }
    #
    #
    # # print("error after dbarts")
    #
    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    # #sampler$setPredictor(x= Xmat.train$x, column = 1, forceUpdate = TRUE)
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # sampler$sampleTreesFromPrior()
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mupreds <- sampler$predict(Xmat.train)
    #
    # # mu <- mutemp





    y_hat_store = matrix(NA, ncol = length(as.vector(Z.mat)), nrow = store_size)
    var_count = rep(0, ncol(Xmat.train.no.y))
    var_count_store = matrix(0, ncol = ncol(Xmat.train.no.y), nrow = store_size)
    s_prob_store = matrix(0, ncol = ncol(Xmat.train.no.y), nrow = store_size)
    tree_fits_store = matrix(0, ncol = n.trees, nrow = length(as.vector(Z.mat)))
    s = rep(1/ncol(Xmat.train.no.y), ncol(Xmat.train.no.y))


    p <- ncol(Xmat.train.no.y)
    rho <- p # For DART

    if(alpha_prior){
      alpha_s <- p
    }else{
      alpha_s <- 1
    }
    alpha_scale <- p
    # s <- rep(1 / p, p) # probability vector to be used during the growing process for DART feature weighting


    if(sparse){
      draw$alpha_s_store <- rep(NA, iter.max)
      draw$var_count_store <- matrix(0, ncol = p, nrow = iter.max)
      draw$s_prob_store <- matrix(0, ncol = p, nrow = iter.max)
    }



    ###### new myBART initialization ######################

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }
    }

    # if(length(as.vector(Z.mat)) !=  length(unique(as.vector(Z.mat)))){
    #   print("Z.mat =")
    #   print(Z.mat)
    #   stop(" Not all Z values unique")
    # }

    # maybe (max(as.vector(Z.mat))-min(as.vector(Z.mat)))
    # can be replaced by something else
    # sigma2_mu <- (max(as.vector(Z.mat))-min(as.vector(Z.mat)))/((2 * k * sqrt(n.trees))^2)
    sigma2_mu <- ((max(as.vector(Z.mat))-min(as.vector(Z.mat)))/(2 * k * sqrt(n.trees)))^2


    # Create a list of trees for the initial stump
    curr_trees = create_stump(num_trees = n.trees,
                              y = as.vector(Z.mat),
                              X = Xmat.train.no.y)
    # Initialise the new trees as current one
    new_trees = curr_trees

    # Initialise the predicted values to zero
    mutemp = get_predictions(curr_trees, Xmat.train.no.y, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))












    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train.no.y = ")
        print(Xmat.train.no.y)
        print("Z.mat = ")
        print(Z.mat)

        # print("samplestemp$sigma = ")
        # print(samplestemp$sigma)
        # print("samplestemp$varcount = ")
        # print(samplestemp$varcount)
        #
        # print("samplestemp$train[,1] = ")
        # print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  print("Line 954")


  # df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    # temp_test_mat <- as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_mat <- data.frame( x = as.matrix(Xmat.test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(Xmat.test)



    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    temp_mu_test <- rep(NA,  nrow(Xmat.test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      # testpredvec <- sampler$predict(temp_test_mat)
      testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }

      colnames(temp_test_mat) <- colnames(Xmat.test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  iter <- 2
  breakcount <- 0

  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    # Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############

    for(j in 1:ncol(Z.mat)){
      tempcol <- Z.mat[,j]
      if(length(tempcol) !=  length(tempcol)){
        print("j = ")
        print(j)
        print("tempcol =")
        print(tempcol)
        print("Z.mat =")
        print(Z.mat)
        stop(" Not all Z.mat[,j] values unique")
      }

      # tempsort <- sort(tempcol)
      #
      # tempdiffs <- tempsort[-1] - tempsort[-(length(tempsort))]

      # if( any( abs(tempdiffs) < 0.001 )   ){
      #
      #   print("tempsort =")
      #   print(tempsort)
      #   print("tempdiffs =")
      #   print(tempdiffs)
      #   print("j = ")
      #   print(j)
      #   print("tempcol =")
      #   print(tempcol)
      #   print("Z.mat =")
      #   print(Z.mat)
      #   print(" some differences in Z vector very small")
      # }

    }

    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA



    # num_regions <- nrow(intersectmat)

    # print("Line 1169")


    for(z_iter_ind in 1:num_z_iters){

      # print("z_iter_ind = ")
      # print(z_iter_ind)

      for(indiv in 1:n.ranker){

        # print("indiv = ")
        # print(indiv)

        ########### calculate qkt   for t = 1 ########################################

        Biglist_list_item_intersectmats <- list()
        Biglist_intersectmats <- list()


        ######## Period 1 Intersection Matrix #########################

        # create vector of indices for ranker indiv in time period 1
        ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        # print("Begin Period 1 intersection matrices = ")
        # print(indiv)

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            # treeexample1 <- sampler$getTrees(treeNums = i,
            #                                  chainNums = 1,
            #                                  sampleNums = 1)
            #
            # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
            #                                   treeNums = i,
            #                                   chainNums = 1,
            #                                   sampleNums = 1)

            temptree <- curr_trees[[i]]$tree_matrix

            treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

            temp_na_inds <- is.na(temptree[,'split_variable'])
            # print("temp_na_inds = ")
            # print(temp_na_inds)
            #
            # print("treeexample1 = ")
            # print(treeexample1)
            #
            # print("temptree[temp_na_inds,'mu'] = ")
            # print(temptree[temp_na_inds,'mu'])

            treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

            # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
            #   1,#rep(sampleNums, nrow(temptree)),
            #   i,#rep(treeNums, nrow(temptree)),
            #   temptree[, 'node_size'],
            #   # mybarttree[,'split_variable'],
            #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
            #          -1,
            #          temptree[,'split_variable']),
            #   fast_ifelse(is.na(temptree[,'split_variable']) ,
            #          temptree[,'mu'],
            #          temptree[,'split_value']))

            # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))


            # print("rebuilt_tree = ")
            # print(rebuilt_tree)

            #must use covariates for individual indiv at time period t

            # print("Xmat.train$x[obs_indices[1],, drop = FALSE] = ")
            # print(Xmat.train$x[obs_indices[1],, drop = FALSE])
            #
            #
            # print("Xmat.train$x[obs_indices[1],] = ")
            # print(Xmat.train$x[obs_indices[1],])
            #
            #
            # print("obs_indices[1] = ")
            # print(obs_indices[1])
            #
            #
            # print("Xmat.train = ")
            # print(Xmat.train)



            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )
            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )


          }

          intersectmat_tmin1 <- interNtreesB(list_inter_mats)


          intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat_tmin1)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat_tmin1[ktemp,1]
            templower <- intersectmat_tmin1[rowind,2]
            tempupper <- intersectmat_tmin1[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[1]] <- intersectmat_tmin1


        }else{ # itemcovars == TRUE


          list_item_intersectmats_tmin1 <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)

              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])

              # print("temp_na_inds = ")
              # print(temp_na_inds)
              #
              # print("treeexample1 = ")
              # print(treeexample1)
              #
              # print("temptree[temp_na_inds,'mu'] = ")
              # print(temptree[temp_na_inds,'mu'])

              treeexample1[temp_na_inds , 4:5 ] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))
              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )


            } #end loop over trees

            intersectmat_tmin1 <- interNtreesB(list_inter_mats)

            intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat_tmin1)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat_tmin1[ktemp,1]
              templower <- intersectmat_tmin1[rowind,2]
              tempupper <- intersectmat_tmin1[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats_tmin1[[index_item]] <- intersectmat_tmin1


          } #end loop over items

          Biglist_list_item_intersectmats[[1]] <- list_item_intersectmats_tmin1

        } # end else itemcovars == TRUE


        ################ period 2 intersection matrix #################################################

        # create vector of indices for ranker indiv in time period 2
        ind_start <- (2 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (2 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            # treeexample1 <- sampler$getTrees(treeNums = i,
            #                                  chainNums = 1,
            #                                  sampleNums = 1)

            # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
            #                                   treeNums = i,
            #                                   chainNums = 1,
            #                                   sampleNums = 1)

            temptree <- curr_trees[[i]]$tree_matrix

            treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

            temp_na_inds <- is.na(temptree[,'split_variable'])
            treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

            # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
            #   1,#rep(sampleNums, nrow(temptree)),
            #   i,#rep(treeNums, nrow(temptree)),
            #   temptree[, 'node_size'],
            #   # mybarttree[,'split_variable'],
            #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
            #          -1,
            #          temptree[,'split_variable']),
            #   fast_ifelse(is.na(temptree[,'split_variable']) ,
            #          temptree[,'mu'],
            #          temptree[,'split_value']))
            # # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

            #must use covariates for individual indiv at time period t

            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )

          }

          intersectmat <- interNtreesB(list_inter_mats)


          intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat[ktemp,1]
            templower <- intersectmat[rowind,2]
            tempupper <- intersectmat[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[2]] <- intersectmat


        }else{ # itemcovars == TRUE


          list_item_intersectmats <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)


              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])
              treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))
              # # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )

            } #end loop over trees

            intersectmat <- interNtreesB(list_inter_mats)

            intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat[ktemp,1]
              templower <- intersectmat[rowind,2]
              tempupper <- intersectmat[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats[[index_item]] <- intersectmat


          } #end loop over items

          Biglist_list_item_intersectmats[[2]] <- list_item_intersectmats

        } # end else itemcovars == TRUE


        # print("End Period 1 intersection matrices = ")


        ##### t = 3 to T intersect matrices ######################

        # print("Begin loop for intersection matrices = ")

        for(t in 3:n.time){

          #### obtain intersection matrices for time period t ###############
          # print("t = ")
          # print(t)

          # create vector of indices for ranker indiv in time period 1
          ind_start <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          ind_end <- (t - 1)*n.ranker*n.item+n.item*indiv
          obs_indices <- ind_start:ind_end

          if(itemcovars == FALSE){


            list_inter_mats <- list()

            for(i in 1:n.trees){

              # treeexample1 <- sampler$getTrees(treeNums = i,
              #                                  chainNums = 1,
              #                                  sampleNums = 1)

              # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
              #                                   treeNums = i,
              #                                   chainNums = 1,
              #                                   sampleNums = 1)

              temptree <- curr_trees[[i]]$tree_matrix

              treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

              temp_na_inds <- is.na(temptree[,'split_variable'])
              treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

              # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
              #   1,#rep(sampleNums, nrow(temptree)),
              #   i,#rep(treeNums, nrow(temptree)),
              #   temptree[, 'node_size'],
              #   # mybarttree[,'split_variable'],
              #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
              #          -1,
              #          temptree[,'split_variable']),
              #   fast_ifelse(is.na(temptree[,'split_variable']) ,
              #          temptree[,'mu'],
              #          temptree[,'split_value']))

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train.no.y[obs_indices[1],, drop = FALSE]) )

            }

            intersectmat <- interNtreesB(list_inter_mats)

            Biglist_intersectmats[[t]] <- intersectmat


          }else{ # itemcovars == TRUE


            list_item_intersectmats <- list()

            for(index_item in 1:n.item){

              obs_one_ind <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

              list_inter_mats <- list()

              for(i in 1:n.trees){

                # treeexample1 <- sampler$getTrees(treeNums = i,
                #                                  chainNums = 1,
                #                                  sampleNums = 1)

                # treeexample1 <- mybart2dbart_tree(curr_trees[[i]]$tree_matrix,
                #                                   treeNums = i,
                #                                   chainNums = 1,
                #                                   sampleNums = 1)

                temptree <- curr_trees[[i]]$tree_matrix

                treeexample1 <- cbind(1, i, temptree[, c('node_size','split_variable', 'split_value' ), drop = FALSE])

                temp_na_inds <- is.na(temptree[,'split_variable'])
                treeexample1[temp_na_inds , 4:5] <- cbind(-1, temptree[temp_na_inds,'mu'])

                # treeexample1 <- cbind(#rep(chainNums, nrow(mybarttree)),
                #   1,#rep(sampleNums, nrow(temptree)),
                #   i,#rep(treeNums, nrow(temptree)),
                #   temptree[, 'node_size'],
                #   # mybarttree[,'split_variable'],
                #   fast_ifint_elsevec(is.na(temptree[,'split_variable']) ,
                #          -1,
                #          temptree[,'split_variable']),
                #   fast_ifelse(is.na(temptree[,'split_variable']) ,
                #          temptree[,'mu'],
                #          temptree[,'split_value']))
                # # rebuilt_tree <- rebuildTree2(treeexample1)

                rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

                #must use covariates for individual indiv at time period t

                # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

                list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                         as.matrix(Xmat.train.no.y[obs_one_ind,, drop = FALSE]) )


              } #end loop over trees

              intersectmat <- interNtreesB(list_inter_mats)

              list_item_intersectmats[[index_item]] <- intersectmat


            } #end loop over items


            Biglist_list_item_intersectmats[[t]] <- list_item_intersectmats


          } # end else itemcovars == TRUE

        }


        # print("End loop for intersection matrices = ")


        ######## Begin loop over items ################################

        # print("Begin loop for over items = ")

        for(item_ind in 1:n.item){

          # print("item_ind = ")
          # print(item_ind)

          if(itemcovars == TRUE){
            list_item_intersectmats <- Biglist_list_item_intersectmats[[2]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[1]]


            intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            intersectmat <- Biglist_intersectmats[[2]]
            intersectmat_tmin1 <- Biglist_intersectmats[[1]]
          }

          num_regions <- nrow(intersectmat)
          num_regions_tmin1 <- nrow(intersectmat_tmin1)

          # ########### begin create intersectmat t = 1 ############
          #
          # # define intersections inside item loop
          # # to allow covariates can be item specific
          #
          # # create vector of indices for ranker indiv in time period 1
          #
          # # this part is not really necessary
          # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
          # obs_indices <- ind_start:ind_end
          #
          # # obs_indices[1] could jsut be replaced by [1] below\
          # # because the only variable is zlag, so the other covariates are not used
          #
          #
          # list_inter_mats <- list()
          #
          # for(i in 1:n.trees){
          #
          #   treeexample1 <- sampler$getTrees(treeNums = i,
          #                                    chainNums = 1,
          #                                    sampleNums = 1)
          #
          #   rebuilt_tree <- rebuildTree2(treeexample1, sampler)
          #
          #
          #   #must use covariates for individual indiv at time period t
          #
          #   list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )
          #   # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
          #
          #
          # }
          #
          # intersectmat <- interNtreesB(list_inter_mats)
          #
          # # print("Line 1146")
          #
          # intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))
          #
          # # print("Line 1150")
          #
          #
          # # calculate one dimensional integrals
          # for(rowind in 1:nrow(intersectmat)){
          #   # ktemp <- nkt_mat[rowind,k_index]
          #   # tempmean <- intersectmat[ktemp,1]
          #   templower <- intersectmat[rowind,2]
          #   tempupper <- intersectmat[rowind,3]
          #
          #   # ASSUMING PRIOR MEAN ALL ZEROS
          #
          #   # These are the q0 integrals
          #   intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
          #   # tempintegralval <- tempintegralval*onedim_int
          # }
          #
          # # intersectmat_tmin1 <- intersectmat
          #
          #
          #
          # ########### end create intersectmat t = 1 ############
          #





          #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

          # loop over items

          # Now loop over time periods

          # special case for t=1

          # probability matrix for sampling elements

          # let rows be period zero, and columns be period 1 (2?)

          # probmattemp <- matrix(0,
          #                       nrow = num_regions_tmin1,
          #                       ncol = num_regions)

          logprobmattemp <- matrix(0,
                                   nrow = num_regions_tmin1,
                                   ncol = num_regions)

          # loop over period 2 regions into which z_1 can fall


          tempbounds <- matrix(NA,
                               nrow = num_regions,
                               ncol = 2)

          # Trunc norm prob of next periods latent value conditional on region

          # Create intervals from interval t+1 latent values

          rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

          # inds for j ranked below i in t+1



          # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
          #
          # #max of latent variables for j ranked below i in t+1
          # # Z.mat
          #
          # if(length(belowrank_ind) ==0){
          #   temp_lower <- -Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #   temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    belowrank_ind]
          # }
          #
          # # inds for j ranked above i in t+1
          #
          # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
          #
          # #min of latent variables for j ranked below i in period t+1
          #
          # if(length(aboverank_ind) ==0){
          #   temp_upper <- Inf
          # }else{
          #   # Check that this is the period t+1 latent variable value, not period t
          #
          #   temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
          #                                    n.item*(indiv - 1) +
          #                                    aboverank_ind]
          # }


          temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                          n.item*(indiv - 1) +
                                          item_ind]



          rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]

          # if(any(order(rankvec_t) !=
          #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                           n.item*(indiv-1) +
          #                           1:n.item])) ){
          #
          #   # print("order(rankvec_t) = ")
          #   # print(order(rankvec_t))
          #   #
          #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #   #                         n.item*(indiv - 1) +
          #   #                         1:n.item])  = ")
          #
          #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                  n.item*(indiv - 1) +
          #                                  1:n.item]) )
          #
          #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #   #                                n.item*(indiv - 1) +
          #   #                                1:n.item] = ")
          #
          #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                            n.item*(indiv - 1) +
          #                            1:n.item])
          #
          # }

          # inds for j ranked below i in t

          belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

          #max of latent variables for j ranked below i in t
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower3 <- -Inf
          }else{
            temp_lower3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              belowrank_ind]
          }

          # inds for j ranked above i in t

          aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

          #min of latent variables for j ranked below i in period t

          if(length(aboverank_ind) ==0){
            temp_upper3 <- Inf
          }else{
            temp_upper3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              aboverank_ind]
          }


          temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
                                                   mean = intersectmat[1:num_regions, 1],
                                                   sd = 1)

          for(k_ind in 1:num_regions){




            # obtain mean for truncated normal distribution
            # temp_mean <- intersectmat[k_ind, 1]

            # want trunc norm probability of latent variable value for item_ind
            # in period t+1


            # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #                               a=temp_lower,
            #                               b=Inf,
            #                               mean = temp_mean,
            #                               sd = 1)

            # tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp

            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                                 mean = temp_mean,
            #                                 sd = 1)

            # temp_tnorm_logprob <- fastlognormdens(temp_ztp1,
            #                                          mean = tempmeanfordens,
            #                                          sd = 1)

            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                          mean = temp_mean,
            #                          sd = 1)

            # temp_mean <- intersectmat[k_ind, 1]

            temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]


            # now second term


            temp_lower2 <- intersectmat[k_ind, 2]
            temp_upper2 <- intersectmat[k_ind, 3]




            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_lower3 = ")
            # print(temp_lower3)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)
            #
            # print("temp_upper3 = ")
            # print(temp_upper3)


            if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
              # intervals do not overlap, therefore assign probability zero
              # and skip to next iteration


              # print("k_ind = ")
              # print(k_ind)

              # print("ncol(temp_region_probs) = ")
              # print(ncol(temp_region_probs))

              # print("nrow(temp_region_probs) = ")
              # print(nrow(temp_region_probs))


              # these three lines are technically unnecessary
              # probmattemp[, k_ind] <- rep(0,num_regions_tmin1)
              logprobmattemp[, k_ind] <- rep(-Inf,num_regions_tmin1)
              tempbounds[k_ind, 1] <- NA
              tempbounds[k_ind, 2] <- NA

              next

            }


            temp_lower2 <- max(temp_lower2, temp_lower3)
            temp_upper2 <- min(temp_upper2, temp_upper3)

            if(temp_lower2 > temp_upper2){

              print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

              print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                       n.item*(indiv - 1) +
                                       1:n.item])

              print("item_ind = ")
              print(item_ind)

              print("rankvec_t = ")
              print(rankvec_t)

              stop("Line 1581 temp_lower2 > temp_upper2")
            }


            for(k0_ind in 1:num_regions_tmin1){

              #loop over all possible means
              temp_mean2 <- intersectmat_tmin1[k0_ind,1]

              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # probmattemp[k0_ind, k_ind] <- prob_t_region*
              #   temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              # probmattemp[k0_ind, k_ind] <- temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              logprobmattemp[k0_ind, k_ind] <- temp_tnorm_logprob +
                log(intersectmat_tmin1[k0_ind,4])

              # if(probmattemp[k0_ind, k_ind] < 0){
              #   print("probmattemp[k0_ind, k_ind] = ")
              #   print(probmattemp[k0_ind, k_ind])
              #
              #   # print("prob_t_region = ")
              #   # print(prob_t_region)
              #
              #   print("temp_tnorm_prob = ")
              #   print(temp_tnorm_prob)
              #
              #   print("intersectmat[k0_ind,4] = ")
              #   print(intersectmat[k0_ind,4])
              #
              #   print("temp_upper2 = ")
              #   print(temp_upper2)
              #
              #   print("temp_lower2 = ")
              #   print(temp_lower2)
              #
              #   print("temp_mean2 = ")
              #   print(temp_mean2)
              #
              #
              # }


            } # end loop over k0

            # save upper and lower bounds (mean saved in intersectmat)
            # or just obtain again later

            tempbounds[k_ind,1] <- temp_lower2
            tempbounds[k_ind,2] <- temp_upper2


          } # end loop over k1


          #sample a combination of k0 and k1
          # if necessary can use column sums to sample k1, then k0
          # however, this is probably unnecessary


          # print("Line 1621 before sample")

          # region_ind <- sample.int(num_regions_tmin1*num_regions,
          #                          size = 1,
          #                          replace = TRUE,
          #                          prob = as.vector(probmattemp))


          logprobstemp <- as.vector(logprobmattemp)
          max_ll <- max(logprobstemp)
          logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
          probstemp <- exp(logprobstemp - logsumexps)

          region_ind <- sample.int(num_regions_tmin1*num_regions,
                                   size = 1,
                                   replace = TRUE,
                                   prob = as.vector(probstemp))


          # print("Line 1629 after sample")

          # k0 region is sampled number modulo number of regions in period 1
          k0_region_ind <- ((region_ind -1) %% num_regions_tmin1 ) + 1
          # if(k0_region_ind ==0){
          #   k0_region_ind <- num_regions
          # }

          # k1 region is the ceiling of sampled number divided by number of regions in period 1
          # k1_region_ind <- ceiling(region_ind/num_regions)
          k1_region_ind <- (region_ind -1) %/% num_regions_tmin1 + 1


          # print("k1_region_ind = ")
          # print(k1_region_ind)

          temp_lower2 <- tempbounds[k1_region_ind,1]
          temp_upper2 <- tempbounds[k1_region_ind,2]

          # print("num_regions = ")
          # print(num_regions)
          #
          # print("region_ind = ")
          # print(region_ind)
          #
          # print("k0_region_ind = ")
          # print(k0_region_ind)

          temp_mean0 <- intersectmat_tmin1[k0_region_ind, 1]
          # temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

          # print("temp_mean0 = ")
          # print(temp_mean0)
          #
          # print("temp_lower2 = ")
          # print(temp_lower2)
          #
          # print("temp_upper2 = ")
          # print(temp_upper2)

          tempbuffer <- (temp_upper2 - temp_lower2)/100

          if( (temp_upper2 != Inf) & (temp_lower2 != -Inf)){
            upper_buffered <- temp_upper2 - tempbuffer
            lower_buffered <- temp_lower2 + tempbuffer

          }else{
            upper_buffered <- temp_upper2
            lower_buffered <- temp_lower2

          }


          zdraw_temp <- rtruncnorm(n = 1,
                                   a = lower_buffered,
                                   b = upper_buffered,
                                   mean = temp_mean0,
                                   sd = 1)


          Z.mat[item_ind,  indiv ] <- zdraw_temp


          #### Begin Loop over time ###################

          # loop over time periods for general case 1 < t < T

          for(t in 2:(n.time - 1)){


            if(itemcovars == TRUE){
              list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
              list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[t]]


              intersectmat <- list_item_intersectmats[[index_item]]
              intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
            }else{
              intersectmat <- Biglist_intersectmats[[t+1]]
              intersectmat_tmin1 <- Biglist_intersectmats[[t]]
            }

            num_regions <- nrow(intersectmat)

            temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # or first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat_tmin1[, 3]) )[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

            # print("temp_mean2 = ")
            # print(temp_mean2)
            #
            # print("ktemp_tmin1 = ")
            # print(ktemp_tmin1)



            # Calculate the probabilities for each region in this time period
            # the regions being looped over are actually period t+1 regions

            # Same regions for all time periods if there are no time varying covariates

            # However, the weights are individual and time period specific

            # loop through regions


            # first column is the probabilities
            # second column is the lower bounds
            # third column is the upper bounds
            # temp_region_probs <- matrix(0,
            #                             nrow = nrow(intersectmat),
            #                             ncol = 3)

            temp_region_logprobs <- matrix(0,
                                           nrow = nrow(intersectmat),
                                           ncol = 3)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

            # inds for j ranked below i in t+1

            # belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )
            #
            # #max of latent variables for j ranked below i in t+1
            # # Z.mat
            #
            # if(length(belowrank_ind) ==0){
            #   temp_lower <- -Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #   temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    belowrank_ind]
            # }
            #
            # # inds for j ranked above i in t+1
            #
            # aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)
            #
            # #min of latent variables for j ranked below i in period t+1
            #
            # if(length(aboverank_ind) ==0){
            #   temp_upper <- Inf
            # }else{
            #   # Check that this is the period t+1 latent variable value, not period t
            #
            #   temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
            #                                    n.item*(indiv - 1) +
            #                                    aboverank_ind]
            # }


            # want trunc norm probability of latent variable value for item_ind
            # in period t+1

            temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]

            rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]



            # if(any(order(rankvec_t) !=
            #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                           n.item*(indiv - 1) +
            #                           1:n.item]) )){
            #
            #   print("order(rankvec_t) = ")
            #   print(order(rankvec_t))
            #
            #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                         n.item*(indiv - 1) +
            #                         1:n.item])  = ")
            #
            #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                  n.item*(indiv - 1) +
            #                                  1:n.item]) )
            #
            #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                n.item*(indiv - 1) +
            #                                1:n.item] = ")
            #
            #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item])
            #
            #
            # }





            # inds for j ranked below i in t

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in t
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind]
            }

            # inds for j ranked above i in t

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period t

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind]
            }



            temp_tnorm_logprobvec <- fastlognormdens(temp_ztp1,
                                                     mean = intersectmat[1:num_regions, 1],
                                                     sd = 1)


            for(k_ind in 1:num_regions){



              # obtain mean for truncated normal distribution
              # temp_mean <- intersectmat[k_ind, 1]



              # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #                               a=temp_lower,
              #                               b=Inf,
              #                               mean = temp_mean,
              #                               sd = 1)

              # tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp

              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                                 mean = temp_mean,
              #                                 sd = 1)

              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                          mean = temp_mean,
              #                          sd = 1)

              temp_tnorm_logprob <- temp_tnorm_logprobvec[k_ind]


              # Probability of z_t in intersection of
              # region k_ind (for period t+1)
              # and region defined by period t latent variables for other individuals
              # and rank for period t


              # tildeC_ktminl corresponds to
              # period t+1 k_ind region intereval

              temp_lower2 <- intersectmat[k_ind, 2]
              temp_upper2 <- intersectmat[k_ind, 3]



              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_upper2 = ")
              # print(temp_upper2)
              #
              # print("temp_lower3 = ")
              # print(temp_lower3)
              #
              # print("temp_upper3 = ")
              # print(temp_upper3)


              if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
                # intervals do not overlap, therefore assign probability zero
                # and skip to next iteration

                # print("k_ind = ")
                # print(k_ind)

                # print("ncol(temp_region_probs) = ")
                # print(ncol(temp_region_probs))

                # print("nrow(temp_region_probs) = ")
                # print(nrow(temp_region_probs))

                # temp_region_probs[k_ind, 1] <- 0
                # temp_region_probs[k_ind, 2] <- NA
                # temp_region_probs[k_ind, 3] <- NA

                temp_region_logprobs[k_ind, 1] <- -Inf
                temp_region_logprobs[k_ind, 2] <- NA
                temp_region_logprobs[k_ind, 3] <- NA

                next
              }

              temp_lower2 <- max(temp_lower2, temp_lower3)
              temp_upper2 <- min(temp_upper2, temp_upper3)


              if(temp_lower2 > temp_upper2){

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")
                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])
                print("item_ind = ")
                print(item_ind)

                print("rankvec_t = ")
                print(rankvec_t)


                print("temp_lower2 = ")
                print(temp_lower2)

                print("temp_upper2 = ")
                print(temp_upper2)

                stop("Line 1917. temp_lower2 > temp_upper2")
              }



              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # print("temp_upper2 = ")
              # print(temp_upper2)
              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              #
              # print("prob_t_region = ")
              # print(prob_t_region)
              #
              # print("temp_tnorm_prob = ")
              # print(temp_tnorm_prob)

              # prob_t_region <- prob_t_region*temp_tnorm_prob
              # prob_t_region <- temp_tnorm_prob
              logprob_t_region <- temp_tnorm_logprob

              # save region probability

              # and save region bounds (or maybe more memory efficient to obtain the region again)

              # must multiply by other previously obtained probabilities

              # print("prob_t_region = ")
              # print(prob_t_region)

              # temp_region_probs[k_ind, 1] <- prob_t_region
              # temp_region_probs[k_ind, 2] <- temp_lower2
              # temp_region_probs[k_ind, 3] <- temp_upper2

              temp_region_logprobs[k_ind, 1] <- logprob_t_region
              temp_region_logprobs[k_ind, 2] <- temp_lower2
              temp_region_logprobs[k_ind, 3] <- temp_upper2


            }


            # sample a region using probabilities obtained above

            # print("Line 1903 before sample")

            # region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])


            logprobstemp <- as.vector(temp_region_logprobs[,1])
            max_ll <- max(logprobstemp)
            logsumexps <- max_ll + log(sum(exp( logprobstemp  -  max_ll )))
            probstemp <- exp(logprobstemp - logsumexps)

            region_ind <- sample.int(num_regions, 1, replace = TRUE,
                                     prob = probstemp)


            # print("Line 1914 after sample")

            # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            # tempbuffer <- (temp_region_probs[region_ind, 3] - temp_region_probs[region_ind, 2])/50
            #
            # if( (temp_region_probs[region_ind, 3] != Inf) & (temp_region_probs[region_ind, 2] != -Inf)){
            #   upper_buffered <- temp_region_probs[region_ind, 3] - tempbuffer
            #   lower_buffered <- temp_region_probs[region_ind, 2] + tempbuffer
            #
            # }else{
            #   upper_buffered <- temp_region_probs[region_ind, 3]
            #   lower_buffered <- temp_region_probs[region_ind, 2]
            #
            # }

            tempbuffer <- (temp_region_logprobs[region_ind, 3] - temp_region_logprobs[region_ind, 2])/50

            if( (temp_region_logprobs[region_ind, 3] != Inf) & (temp_region_logprobs[region_ind, 2] != -Inf)){
              upper_buffered <- temp_region_logprobs[region_ind, 3] - tempbuffer
              lower_buffered <- temp_region_logprobs[region_ind, 2] + tempbuffer

            }else{
              upper_buffered <- temp_region_logprobs[region_ind, 3]
              lower_buffered <- temp_region_logprobs[region_ind, 2]

            }

            zdraw_temp <- rtruncnorm(n = 1,
                                     a=lower_buffered,
                                     b=upper_buffered,
                                     mean = temp_mean2,
                                     sd = 1)

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a=temp_region_probs[region_ind, 2],
            #                          b=temp_region_probs[region_ind, 3],
            #                          mean = temp_mean2,
            #                          sd = 1)



            Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



          } # end loop over time periods

          # check for special cases for n.time - 1, n.time - 2, n.time - 3

          # special case for t = n.time


          if(itemcovars == TRUE){
            # list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[n.time]]


            # intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            # intersectmat <- Biglist_intersectmats[[t+1]]
            intersectmat_tmin1 <- Biglist_intersectmats[[n.time]]
          }

          num_regions <- nrow(intersectmat)

          temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             item_ind]


          # must find mean corresponding to z in period t-1
          # This will be used in and after the loop over regions.
          # can directly obtain from dbarts
          # or find region
          # and use already saved region mean values


          # must find last lower bound that temp_ztpmin1 is greater than
          # for first upper bound that temp_ztpmin1 is below
          ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat_tmin1[, 3])[1]
          # Then obtain the corresponding region mean value
          temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

          # now find interval

          # tildeC_ktminl corresponds to
          # period t+1 k_ind region intereval

          rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

          # inds for j ranked below i in T

          belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

          #max of latent variables for j ranked below i in T
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower3 <- -Inf
          }else{
            temp_lower3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              belowrank_ind]
          }

          # inds for j ranked above i in T

          aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

          #min of latent variables for j ranked below i in period T

          if(length(aboverank_ind) ==0){
            temp_upper3 <- Inf
          }else{

            temp_upper3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              aboverank_ind]
          }


          # temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

          # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED
          tempbuffer <- (temp_upper3 - temp_lower3)/100

          if( (temp_upper3 != Inf) & (temp_lower3 != -Inf)){
            upper_buffered <- temp_upper3 - tempbuffer
            lower_buffered <- temp_lower3 + tempbuffer

          }else{
            upper_buffered <- temp_upper3
            lower_buffered <- temp_lower3

          }

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = lower_buffered,
                                   b = upper_buffered,
                                   mean = temp_mean2,
                                   sd = 1)

          # zdraw_temp <- rtruncnorm(n = 1,
          #                          a = temp_lower3,
          #                          b = temp_upper3,
          #                          mean = temp_mean2,
          #                          sd = 1)

          if(is.na(zdraw_temp)){
            print(" line 2367")
            print("temp_lower3] = ")
            print(temp_lower3)

            print("temp_upper3 = ")
            print(temp_upper3)

            print("temp_mean2 = ")
            print(temp_mean2)

            stop("NA zdraw_temp")
          }

          Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





        } # end loop over items



      } # end loop over individuals indiv in 1:n.ranker

    }




    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    # #THEN use SetPredictor
    #
    # # if (i <= n_warmup) {
    # #   for(j in 1:num_lags){
    # #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    # #     }
    # # } else{
    # temp_break <- 0
    # for(j in 1:num_lags){
    #   # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #
    #   while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {
    #
    #     if(seq_z_draws==1){
    #       stop("updates still not consistent with tree structure")
    #     }
    #     print("new z values not consistent with tree structure, must draw again")
    #
    #     # If this error message occurs
    #     # Check the conditions in the dbart package for setPredictor == FALSE
    #     # And if this is hypothetically possible, even with draws from the smoothing distribution,
    #     # and if it is not a bug
    #     # then need to go back to beginning of this iteration of the Gibbs sampler
    #     # and sample Zmat again
    #
    #
    #     temp_break <- 1
    #     break
    #     # stop("new z values not consistent with tree structure, must draw again")
    #
    #
    #     # #perhaps this can be rewritten to just re-draw the relevant column?
    #     # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #     #                                           Z.mat = Z.mat,
    #     #                                           mu = mu,
    #     #                                           weight.vec = rep(1, n.ranker*n.time),
    #     #                                           n.ranker = n.ranker*n.time,
    #     #                                           n.item = n.item )
    #     #
    #     # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #     #
    #     # for(t in 1:num_lags){
    #     #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #     #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #     #
    #     #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #     #
    #     # }
    #     #
    #     # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j
    #
    #   }
    #
    #   if(temp_break==1){
    #     break
    #   }
    # }
    #
    # # if need to draw z values again, go back to start of loop
    # if(temp_break==1){
    #   if(breakcount == 10){
    #     Z.mat <- Z.matold
    #     Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #     for(t in 1:num_lags){
    #       init_Z_t0 <- rep(0, t*n.item*n.ranker)
    #       # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #       Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
    #
    #     }
    #
    #   }else{
    #     breakcount <- breakcount +1
    #     next
    #   }
    #
    # }
    #
    # breakcount <- 0
    # # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    # #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)
    #
    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # mutemp <- sampler$predict(df_for_dbart)
    # # print("sigma = ")
    # # print(samplestemp$sigma)
    #
    # # mu = mutemp
    #
    # if(nrow(X.train)==n.item){
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #
    #   #mu = mutemp[(1:n.item)]
    #   mu = mutemp[n.item+(1:n.item)]
    #
    #
    #
    #
    #   # if(mutemp[1]!= mutemp[n.item+1]){
    #   if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
    #     print("iteration number")
    #     print(iter)
    #     print("n.item = ")
    #     print(n.item)
    #     print("mutemp = ")
    #     print(mutemp)
    #     stop("mutemp[1]!= mutemp[n.item+1]")
    #   }
    #
    #
    #   #mu = mutemp[(1:n.item)*n.ranker]
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     mu = mutemp
    #   }else{
    #     stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    #
    # }



    ########

    # update training data matrix #

    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )

      Xmat.train.no.y <- cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                  ncol =  ncol(X.train) + num_lags ,
                                                  byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")

        Xmat.test.no.y <- cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                       ncol =  ncol(X.test) , byrow = TRUE ) )




        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        Xmat.train.no.y <- cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          Xmat.test.no.y <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }




    # Must update node sizes for original tree
    # update all node sizes before new proposal

    # Must update node sizes for original tree
    # update all node sizes before new proposal

    for (j in 1:n.trees) {
      # print("curr_trees[[j]] = ")
      # print(curr_trees[[j]] )

      curr_trees[[j]] <- fill_tree_details(curr_trees[[j]],
                                           Xmat.train.no.y)

      # print("line 2785, curr_trees[[j]] = ")
      # print(curr_trees[[j]] )
      # must also update individual tree predictions for calcualtion of partial residuals
      tree_fits_store[,j]  = get_predictions(curr_trees[[j]], Xmat.train.no.y, single_tree = TRUE)

    }

    # option: prune all empty nodes from current trees before proposal?
    # must create new function for this
    # perhaps an issue is that there would not be a (umique) mu value
    # associated with a parent of an empty node
    # print("line 2791")

    # must update mu before and after trees updated because covariates have been updated

    mutemp = get_predictions(curr_trees, Xmat.train.no.y, single_tree = n.trees == 1)

    mu <- mutemp

    # min_resp <- min(as.vector(Z.mat))
    # max_resp <- max(as.vector(Z.mat))

    # print("line 2801")

    # Start looping through trees
    for (j in 1:n.trees) {

      current_partial_residuals = as.vector(Z.mat) - mu + tree_fits_store[,j]

      # Propose a new tree via grow/change/prune/swap
      type = sample_move(curr_trees[[j]], iter, 0, # nburn # no burnin number, so setting to 100, maybe this is not optimal
                         trans_prob)


      # option: edit the proposal step so that any proposed tree does not contain empty nodes?
      # must create new function for this

      # Generate a new tree based on the current
      if(no_empty_proposals == TRUE){

        new_trees[[j]] = noempty_update_tree(y = as.vector(Z.mat),
                                             X = Xmat.train.no.y,
                                             type = type,
                                             curr_tree = curr_trees[[j]],
                                             node_min_size = node_min_size,
                                             s = s,
                                             splitting_rules = splitting_rules,
                                             max_bad_trees = max_bad_trees)

      }else{
        new_trees[[j]] = update_tree(y = as.vector(Z.mat),
                                     X = Xmat.train.no.y,
                                     type = type,
                                     curr_tree = curr_trees[[j]],
                                     node_min_size = node_min_size,
                                     s = s,
                                     splitting_rules = splitting_rules,
                                     max_bad_trees = max_bad_trees)

      }




      # print("line 2825")


      # CURRENT TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_old = tree_full_conditional(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(curr_trees[[j]], alpha, beta)

      # print("line 2825")
      #
      # print("new_trees[[j]]")
      # print(new_trees[[j]])

      # NEW TREE: compute the log of the marginalised likelihood + log of the tree prior
      l_new = tree_full_conditional(new_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu) +
        get_tree_prior(new_trees[[j]], alpha, beta)

      # Exponentiate and multiply by the transition probabilities

      if(type == 'grow'){
        a = exp(l_new - l_old)*ratio_grow(new_trees[[j]], curr_trees[[j]])
      } else if(type == 'prune'){
        a = exp(l_new - l_old)*ratio_prune(new_trees[[j]], curr_trees[[j]])
      } else{
        a = exp(l_new - l_old)
      }

      vars_empty_pruned <- c()

      if(a > runif(1)) {
        curr_trees[[j]] = new_trees[[j]]
        # only account for pruning if  accept
        vars_empty_pruned <- new_trees[[j]]$vars_empty_pruned

        for(var_ind in vars_empty_pruned){
          var_count[var_ind ] = var_count[var_ind ] - 1
        }


        if (type =='change'){
          var_count[curr_trees[[j]]$var[1] ] = var_count[curr_trees[[j]]$var[1] ] - 1
          var_count[curr_trees[[j]]$var[2] ] = var_count[curr_trees[[j]]$var[2] ] + 1
        }

        if (type=='grow'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] + 1
        } # -1 because of the intercept in X

        if (type=='prune'){
          var_count[curr_trees[[j]]$var ] = var_count[curr_trees[[j]]$var ] - 1
        } # -1 because of the intercept in X

      }


      ### might need to edit simulate_mu to find right terminal nodes #########

      # Update mu whether tree accepted or not
      curr_trees[[j]] = simulate_mu(curr_trees[[j]],
                                    current_partial_residuals,
                                    sigma2,
                                    sigma2_mu)
      # Updating BART predictions
      current_fit = get_predictions(curr_trees[[j]], Xmat.train.no.y, single_tree = TRUE)
      mu = mu - tree_fits_store[,j] # subtract the old fit
      mu = mu + current_fit # add the new fit
      tree_fits_store[,j] = current_fit # update the new fit

    } # End loop through trees



    # sum_of_squares = sum((y_scale - y_hat)^2)

    # Update sigma2 (variance of the residuals)
    # sigma2 = update_sigma2(sum_of_squares, n = length(y_scale), nu, lambda)
    # variance kept equal to 1, do not update

    # # Update s = (s_1, ..., s_p), where s_p is the probability that predictor p is used to create new terminal nodes
    # if (sparse == 'TRUE' & i > floor(iter.max*0.1)){
    #   s = update_s(var_count, ncol(Xmat.train.no.y), 1)
    # }


    # Update s = (s_1, ..., s_p), where s_p is the probability that predictor q in 1:p is used to create new terminal nodes
    if (sparse & i > floor(iter.max * 0.25)) {
      s_update <- update_s(var_count, p, alpha_s)
      s <- s_update[[1]]

      if(alpha_prior){
        alpha_s <- update_alpha(s, alpha_scale, alpha_a, alpha_b, p, s_update[[2]])
      }
    }

    if(sigma_mu_prior){
      sigma2_mu <-  update_sigma_mu_par(curr_trees, sigma2_mu)
    }




    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta



    #
    #     # if(is.null(initial.list)){
    #     # print("samplestemp$test[,1] = ")
    #     # print(samplestemp$test[,1])
    #
    #     # mupreds <- sampler$predict(df_for_dbart)
    #
    #     # Xmat.test[,1:num_lags] <-  Zlag.mat.test
    #
    #
    #     temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))
    #
    #     for(t  in 1:num_lags){
    #       if(noise_in_pred ==1){
    #         temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
    #       }else{
    #         temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
    #       }
    #
    #     }
    #
    #     # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #     #                                                                      (num_lags+1):ncol(Xmat.test)])
    #
    #     temp_test_mat <- data.frame(x = temp_test_mat)
    #     colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #     # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    #     temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    #     print("Line 5488")
    #
    #
    #     temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    #
    #
    #     # if(iter < 5){
    #     #   print("temp_test_mat = " )
    #     #   print(temp_test_mat)
    #     # }
    #
    #     for(t1 in 1:num_test_periods){
    #       #produce a prediction
    #
    #       # must use original column names to prevent an error in the predict function
    #       colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #       testpredvec <- sampler$predict(temp_test_mat)
    #
    #       #fill in temp_test_preds with noise
    #       if(noise_in_pred ==1){
    #         temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #       }else{
    #         temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
    #       }
    #
    #
    #       #update temp_test_mat
    #       #shift z columns to the right and fill in leftmost column
    #
    #       #need to rewrite this if want to allow for no observed covariates
    #
    #       # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )
    #
    #       if(t1 != num_test_periods){
    #
    #
    #         if(num_lags ==1){
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }else{
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
    #                                                  temp_test_mat[,1:(num_lags-1)] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }
    #       }
    #
    #       # colnames(temp_test_mat) <- colnames(Xmat.test)
    #
    #
    #       #fill in temp_mu_test without noise
    #       temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    #     }
    #
    #     #also update Zlag.mat.test ?
    #     #perhaps this is unnecessary here?
    #
    #     print("Line 5545")
    #
    #
    #     Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    #     # if(nrow(X.test) >0 ){
    #     for(t in 1:num_lags){
    #       # if(t==1){
    #       #   #repeating the last period values
    #       #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #       #
    #       #   #other option is to set all unobservable values to zero
    #       #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #       #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #       #
    #       #
    #       # }else{
    #
    #       if(num_test_periods > t ){
    #         #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #       }else{
    #         #nothing to fill in if num_test_periods <= t
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #       }
    #
    #
    #       # }
    #     }
    #     # }
    #
    #     # if(nrow(X.test)>0){
    #     #
    #     #
    #     #   for(j in 1:num_lags){
    #     #
    #     #     #perhaps this should be removed for when Z is updated properly below
    #     #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #     #
    #     #   }
    #     #
    #     # }
    #
    #
    #     draw$mu_test[,iter] <- temp_mu_test
    #     # draw$mu_test[,iter] <- samplestemp$test[,1]
    #
    #     if(keep_zmat==TRUE){
    #       draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    #     }
    #
    #     # draw$mu_test[,1] <- samplestemp$test[,1]
    #
    #     # }else{
    #     #   draw$mu_test[,1] <- initial.list$mu_test
    #     # }
    #


    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        if(noise_in_pred ==1){
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }

      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      temp_test_mat <- data.frame(x = temp_test_mat)
      colnames(temp_test_mat) <- colnames(Xmat.test)

      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )


      # if(iter < 5){
      #   print("temp_test_mat = " )
      #   print(temp_test_mat)
      # }

      for(t1 in 1:num_test_periods){
        #produce a prediction
        # testpredvec <- sampler$predict(temp_test_mat)
        testpredvec = get_predictions(curr_trees, temp_test_mat, single_tree = n.trees == 1)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }


        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){


          if(num_lags ==1){
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }else{
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      temp_test_mat[,1:(num_lags-1)] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }
        }

        colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }

      # if(nrow(X.test)>0){
      #
      #
      #   for(j in 1:num_lags){
      #
      #     #perhaps this should be removed for when Z is updated properly below
      #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
      #
      #   }
      #
      # }


      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }
    if(sparse){
      draw$alpha_s_store[iter] <- alpha_s
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_store[iter,] <- var_count
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_store[iter,] <- s
      # draw$s_prob_z_store[iter,] <- s_z
    }

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }


    iter <- iter+1
  }


  return(draw)
}







##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and with covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.train An \eqn{N} by \eqn{L} training covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param X.test An \eqn{N} by \eqn{L} test covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param n.item Number of entities/items being ranked.
#' @param n.rankerbytime Number of rankers multiplied by number of time periods
#' @param n.ranker Number of rankers
#' @param n.time Number of time periods
#' @param p.cov Number of covariates.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @param num_z_iters Number of Gibbs iterations for latent outcome z samples per overall MCMC iteration.
#' @param itemcovars Set equal to TRUE if covariates vary across items, and FALSE otherwise.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @useDynLib ROBART2, .registration = TRUE
#' @export
ARRObartWithCovars_fullcond <- function(pair.comp.ten,
                                        X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                        X.test = matrix(NA, nrow =0, ncol = 0),
                                        # tau2.alpha = 5^2,
                                        # nu.alpha = 3,
                                        # tau2.beta = 5^2,
                                        # nu.beta = 3,
                                        n.item = dim(pair.comp.ten)[1],
                                        n.rankerbytime = dim(pair.comp.ten)[3],
                                        n.ranker,
                                        n.time,
                                        p.cov = ncol(X.train),
                                        iter.max = 5000,
                                        para.expan = TRUE,
                                        print.opt = 100,
                                        initial.list = NULL,
                                        n.trees = 50L,
                                        n.burn = 0L,
                                        n.samples = 1L,
                                        n.thin = 1L,
                                        n.chains = 1,
                                        n.threads = 1L,#guessNumCores(),
                                        printEvery = 100L,
                                        printCutoffs = 0L,
                                        rngKind = "default",
                                        rngNormalKind = "default",
                                        rngSeed = NA_integer_,
                                        updateState = FALSE,
                                        num_lags = 1,
                                        diff_num_test_rankers = 0,
                                        keep_zmat = FALSE,
                                        noise_in_pred = 0,
                                        seq_z_draws = 1,
                                        N_hdr = 100,
                                        rho_hdr = 0.5,
                                        smoothing_method = "AR",
                                        num_horizon = 1,
                                        num_z_iters = 10,
                                        itemcovars = FALSE,
                                        tree_power = 2,
                                        tree_base = 0.95,
                                        n.burnin = floor(dim(pair.comp.ten)[1]/2),
                                        sparse = TRUE,
                                        alpha_a_y = 0.5,
                                        alpha_b_y = 1,
                                        alpha_split_prior = TRUE){


  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)

      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }


  # it might be more efficient to create and save all rank constraint matrices at this stage


  rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))

  for(indiv in 1:n.ranker){

    for(t in 1:n.time){

      rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]


      rankconstraint_t <- matrix(0,
                                 nrow = n.item - 1,
                                 ncol = n.item)

      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1

      }

      rank_cons_arr[, , indiv, t] <- rankconstraint_t

    }
  }
  # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  boundconstraints <- matrix(NA,
                             nrow = 2*n.item,
                             ncol = n.item)

  # use kroenecker product
  # there is probably a more efficient way of doing this

  boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  # print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      pair.comp <- pair.comp.ten[,,j]

      # print("rowSums( pair.comp.ten[,,j], na.rm = TRUE ) = ")
      # print(rowSums( pair.comp.ten[,,j], na.rm = TRUE ))

      # print("sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix = ")
      # print(sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix)

      # print("rank(-rowSums( pair.comp, na.rm = TRUE ) + 1) = ")
      # print(rank(-rowSums( pair.comp, na.rm = TRUE ) + 1))


      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))

      # print("(c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)) = ")
      # print((c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1)))

    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }



    print("Line 799.")

    # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )


      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")





        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }


    p_y <- ncol(Xmat.train) - 1 # subtracting 1. Outcome is a column of Xmat.train

    if(sparse){
      s_y <- rep(1 / p_y, p_y) # probability vector to be used during the growing process for DART feature weighting
      rho_y <- p_y # For DART

      if(alpha_split_prior){
        alpha_s_y <- p_y
      }else{
        alpha_s_y <- 1
      }
      alpha_scale_y <- p_y


      var_count_y <- rep(0, p_y)

      draw$alpha_s_y_store <- rep(NA, iter.max)
      draw$var_count_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
      draw$s_prob_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
    }

    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")


    if(nrow(X.test )==0){
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        #test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1),
                        tree.prior = dbarts:::cgm(power = tree_power, base =  tree_base,  split.probs = rep(1 / p_y, p_y)),
                        sigma=1 #check if this is the correct approach for setting the variance to 1
      )

    }else{
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
                        tree.prior = dbarts:::cgm(power = tree_power, base =  tree_base,  split.probs = rep(1 / p_y, p_y)),
                        sigma=1 #
      )

    }


    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    min_resp <- min(as.vector(Z.mat))
    max_resp <- max(as.vector(Z.mat))

    #sampler$setPredictor(x= Xmat.train$x, column = 1, forceUpdate = TRUE)
    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }
    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples
    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y <- rep(0, p_y)
      var_count_y[tempcounts$x] <- tempcounts$N
    }
    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    # mu <- mutemp

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train = ")
        print(Xmat.train)
        print("Z.mat = ")
        print(Z.mat)

        print("samplestemp$sigma = ")
        print(samplestemp$sigma)
        print("samplestemp$varcount = ")
        print(samplestemp$varcount)

        print("samplestemp$train[,1] = ")
        print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  print("Line 954")


  # df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    # temp_test_mat <- as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_mat <- data.frame( x = as.matrix(Xmat.test[1:(n.item*n.ranker) ,]) ) #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    colnames(temp_test_mat) <- colnames(Xmat.test)



    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    # temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    temp_mu_test <- rep(NA,  nrow(Xmat.test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      testpredvec <- sampler$predict(temp_test_mat)

      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }else{
        temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                  as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

      }

      colnames(temp_test_mat) <- colnames(Xmat.test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  iter <- 2
  breakcount <- 0

  while(iter <= iter.max){
    # for(iter in 2:iter.max){

    Z.matold <- Z.mat

    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############



    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA



    # num_regions <- nrow(intersectmat)

    # print("Line 1169")


    for(z_iter_ind in 1:num_z_iters){

      # print("z_iter_ind = ")
      # print(z_iter_ind)

      for(indiv in 1:n.ranker){

        # print("indiv = ")
        # print(indiv)

        ########### calculate qkt   for t = 1 ########################################

        Biglist_list_item_intersectmats <- list()
        Biglist_intersectmats <- list()


        ######## Period 1 Intersection Matrix #########################

        # create vector of indices for ranker indiv in time period 1
        ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        # print("Begin Period 1 intersection matrices = ")
        # print(indiv)

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            treeexample1 <- sampler$getTrees(treeNums = i,
                                             chainNums = 1,
                                             sampleNums = 1)

            # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))


            # print("rebuilt_tree = ")
            # print(rebuilt_tree)

            #must use covariates for individual indiv at time period t

            # print("Xmat.train$x[obs_indices[1],, drop = FALSE] = ")
            # print(Xmat.train$x[obs_indices[1],, drop = FALSE])
            #
            #
            # print("Xmat.train$x[obs_indices[1],] = ")
            # print(Xmat.train$x[obs_indices[1],])
            #
            #
            # print("obs_indices[1] = ")
            # print(obs_indices[1])
            #
            #
            # print("Xmat.train = ")
            # print(Xmat.train)



            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )
            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train[obs_indices[1],-1, drop = FALSE]) )


          }

          intersectmat_tmin1 <- interNtreesB(list_inter_mats)


          intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat_tmin1)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat_tmin1[ktemp,1]
            templower <- intersectmat_tmin1[rowind,2]
            tempupper <- intersectmat_tmin1[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[1]] <- intersectmat_tmin1


        }else{ # itemcovars == TRUE


          list_item_intersectmats_tmin1 <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              treeexample1 <- sampler$getTrees(treeNums = i,
                                               chainNums = 1,
                                               sampleNums = 1)

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train[obs_one_ind,-1, drop = FALSE]) )


            } #end loop over trees

            intersectmat_tmin1 <- interNtreesB(list_inter_mats)

            intersectmat_tmin1 <- cbind(intersectmat_tmin1, rep(NA, nrow(intersectmat_tmin1)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat_tmin1)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat_tmin1[ktemp,1]
              templower <- intersectmat_tmin1[rowind,2]
              tempupper <- intersectmat_tmin1[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat_tmin1[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats_tmin1[[index_item]] <- intersectmat_tmin1


          } #end loop over items

          Biglist_list_item_intersectmats[[1]] <- list_item_intersectmats_tmin1

        } # end else itemcovars == TRUE


        ################ period 2 intersection matrix #################################################

        # create vector of indices for ranker indiv in time period 2
        ind_start <- (2 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (2 - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            treeexample1 <- sampler$getTrees(treeNums = i,
                                             chainNums = 1,
                                             sampleNums = 1)

            # rebuilt_tree <- rebuildTree2(treeexample1)

            rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

            #must use covariates for individual indiv at time period t

            # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

            list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                     as.matrix(Xmat.train[obs_indices[1],-1, drop = FALSE]) )

          }

          intersectmat <- interNtreesB(list_inter_mats)


          intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat[ktemp,1]
            templower <- intersectmat[rowind,2]
            tempupper <- intersectmat[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          Biglist_intersectmats[[2]] <- intersectmat


        }else{ # itemcovars == TRUE


          list_item_intersectmats <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              treeexample1 <- sampler$getTrees(treeNums = i,
                                               chainNums = 1,
                                               sampleNums = 1)

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train[obs_one_ind,-1, drop = FALSE]) )

            } #end loop over trees

            intersectmat <- interNtreesB(list_inter_mats)

            intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

            # calculate one dimensional integrals
            for(rowind in 1:nrow(intersectmat)){
              # ktemp <- nkt_mat[rowind,k_index]
              # tempmean <- intersectmat[ktemp,1]
              templower <- intersectmat[rowind,2]
              tempupper <- intersectmat[rowind,3]

              # ASSUMING PRIOR MEAN ALL ZEROS
              intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
              # tempintegralval <- tempintegralval*onedim_int
            }


            list_item_intersectmats[[index_item]] <- intersectmat


          } #end loop over items

          Biglist_list_item_intersectmats[[2]] <- list_item_intersectmats

        } # end else itemcovars == TRUE


        # print("End Period 1 intersection matrices = ")


        ##### t = 3 to T intersect matrices ######################

        # print("Begin loop for intersection matrices = ")

        for(t in 3:n.time){

          #### obtain intersection matrices for time period t ###############
          # print("t = ")
          # print(t)

          # create vector of indices for ranker indiv in time period 1
          ind_start <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          ind_end <- (t - 1)*n.ranker*n.item+n.item*indiv
          obs_indices <- ind_start:ind_end

          if(itemcovars == FALSE){


            list_inter_mats <- list()

            for(i in 1:n.trees){

              treeexample1 <- sampler$getTrees(treeNums = i,
                                               chainNums = 1,
                                               sampleNums = 1)

              # rebuilt_tree <- rebuildTree2(treeexample1)

              rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

              #must use covariates for individual indiv at time period t

              # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],-1, drop = FALSE] )

              list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                       as.matrix(Xmat.train[obs_indices[1],-1, drop = FALSE]) )

            }

            intersectmat <- interNtreesB(list_inter_mats)

            Biglist_intersectmats[[t]] <- intersectmat


          }else{ # itemcovars == TRUE


            list_item_intersectmats <- list()

            for(index_item in 1:n.item){

              obs_one_ind <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

              list_inter_mats <- list()

              for(i in 1:n.trees){

                treeexample1 <- sampler$getTrees(treeNums = i,
                                                 chainNums = 1,
                                                 sampleNums = 1)

                # rebuilt_tree <- rebuildTree2(treeexample1)

                rebuilt_tree <- rebuildTree2_cpp(as.matrix(treeexample1))

                #must use covariates for individual indiv at time period t

                # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,-1, drop = FALSE] )

                list_inter_mats[[i]] <- getPredictionsRangesForTree3_cpp(as.matrix(rebuilt_tree),
                                                                         as.matrix(Xmat.train[obs_one_ind,-1, drop = FALSE]) )


              } #end loop over trees

              intersectmat <- interNtreesB(list_inter_mats)

              list_item_intersectmats[[index_item]] <- intersectmat


            } #end loop over items


            Biglist_list_item_intersectmats[[t]] <- list_item_intersectmats


          } # end else itemcovars == TRUE

        }


        # print("End loop for intersection matrices = ")


        ######## Begin loop over items ################################

        # print("Begin loop for over items = ")

        for(item_ind in 1:n.item){

          # print("item_ind = ")
          # print(item_ind)

          if(itemcovars == TRUE){
            list_item_intersectmats <- Biglist_list_item_intersectmats[[2]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[1]]


            intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            intersectmat <- Biglist_intersectmats[[2]]
            intersectmat_tmin1 <- Biglist_intersectmats[[1]]
          }

          num_regions <- nrow(intersectmat)
          num_regions_tmin1 <- nrow(intersectmat_tmin1)

          # ########### begin create intersectmat t = 1 ############
          #
          # # define intersections inside item loop
          # # to allow covariates can be item specific
          #
          # # create vector of indices for ranker indiv in time period 1
          #
          # # this part is not really necessary
          # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
          # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
          # obs_indices <- ind_start:ind_end
          #
          # # obs_indices[1] could jsut be replaced by [1] below\
          # # because the only variable is zlag, so the other covariates are not used
          #
          #
          # list_inter_mats <- list()
          #
          # for(i in 1:n.trees){
          #
          #   treeexample1 <- sampler$getTrees(treeNums = i,
          #                                    chainNums = 1,
          #                                    sampleNums = 1)
          #
          #   rebuilt_tree <- rebuildTree2(treeexample1, sampler)
          #
          #
          #   #must use covariates for individual indiv at time period t
          #
          #   list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )
          #   # list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]
          #
          #
          # }
          #
          # intersectmat <- interNtreesB(list_inter_mats)
          #
          # # print("Line 1146")
          #
          # intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))
          #
          # # print("Line 1150")
          #
          #
          # # calculate one dimensional integrals
          # for(rowind in 1:nrow(intersectmat)){
          #   # ktemp <- nkt_mat[rowind,k_index]
          #   # tempmean <- intersectmat[ktemp,1]
          #   templower <- intersectmat[rowind,2]
          #   tempupper <- intersectmat[rowind,3]
          #
          #   # ASSUMING PRIOR MEAN ALL ZEROS
          #
          #   # These are the q0 integrals
          #   intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
          #   # tempintegralval <- tempintegralval*onedim_int
          # }
          #
          # # intersectmat_tmin1 <- intersectmat
          #
          #
          #
          # ########### end create intersectmat t = 1 ############
          #





          #QUESTION: LOOP OVER ITEMS THEN TIME OT TIME THEN ITEMS?

          # loop over items

          # Now loop over time periods

          # special case for t=1

          # probability matrix for sampling elements

          # let rows be period zero, and columns be period 1 (2?)

          probmattemp <- matrix(0,
                                nrow = num_regions_tmin1,
                                ncol = num_regions)

          # loop over period 2 regions into which z_1 can fall


          tempbounds <- matrix(NA,
                               nrow = num_regions,
                               ncol = 2)

          # Trunc norm prob of next periods latent value conditional on region

          # Create intervals from interval t+1 latent values

          rankvec_tp1 <- ranks_mat[,  1*n.ranker + indiv]

          # inds for j ranked below i in t+1



          belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )

          #max of latent variables for j ranked below i in t+1
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower <- -Inf
          }else{
            # Check that this is the period t+1 latent variable value, not period t
            temp_lower <- as.vector(Z.mat)[1*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             belowrank_ind]
          }

          # inds for j ranked above i in t+1

          aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)

          #min of latent variables for j ranked below i in period t+1

          if(length(aboverank_ind) ==0){
            temp_upper <- Inf
          }else{
            # Check that this is the period t+1 latent variable value, not period t

            temp_upper <- as.vector(Z.mat)[1*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             aboverank_ind]
          }


          temp_ztp1 <- as.vector(Z.mat)[1*n.item*n.ranker+
                                          n.item*(indiv - 1) +
                                          item_ind]



          rankvec_t <- ranks_mat[,  (1-1)*n.ranker + indiv]

          # if(any(order(rankvec_t) !=
          #    order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                           n.item*(indiv-1) +
          #                           1:n.item])) ){
          #
          #   # print("order(rankvec_t) = ")
          #   # print(order(rankvec_t))
          #   #
          #   # print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #   #                         n.item*(indiv - 1) +
          #   #                         1:n.item])  = ")
          #
          #   print(order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                                  n.item*(indiv - 1) +
          #                                  1:n.item]) )
          #
          #   # print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #   #                                n.item*(indiv - 1) +
          #   #                                1:n.item] = ")
          #
          #   print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
          #                            n.item*(indiv - 1) +
          #                            1:n.item])
          #
          # }

          # inds for j ranked below i in t

          belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

          #max of latent variables for j ranked below i in t
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower3 <- -Inf
          }else{
            temp_lower3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              belowrank_ind]
          }

          # inds for j ranked above i in t

          aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

          #min of latent variables for j ranked below i in period t

          if(length(aboverank_ind) ==0){
            temp_upper3 <- Inf
          }else{
            temp_upper3 <- as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              aboverank_ind]
          }


          for(k_ind in 1:num_regions){




            # obtain mean for truncated normal distribution
            temp_mean <- intersectmat[k_ind, 1]

            # want trunc norm probability of latent variable value for item_ind
            # in period t+1


            # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
            #                               a=temp_lower,
            #                               b=Inf,
            #                               mean = temp_mean,
            #                               sd = 1)

            tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp

            temp_tnorm_prob <- fastnormdens(temp_ztp1,
                                            mean = tempmeanfordens,
                                            sd = 1)

            # temp_tnorm_prob <- fastnormdens(temp_ztp1,
            #                          mean = temp_mean,
            #                          sd = 1)

            temp_mean <- intersectmat[k_ind, 1]



            # now second term


            temp_lower2 <- intersectmat[k_ind, 2]
            temp_upper2 <- intersectmat[k_ind, 3]




            # print("temp_lower2 = ")
            # print(temp_lower2)
            #
            # print("temp_lower3 = ")
            # print(temp_lower3)
            #
            # print("temp_upper2 = ")
            # print(temp_upper2)
            #
            # print("temp_upper3 = ")
            # print(temp_upper3)


            if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
              # intervals do not overlap, therefore assign probability zero
              # and skip to next iteration


              # print("k_ind = ")
              # print(k_ind)

              # print("ncol(temp_region_probs) = ")
              # print(ncol(temp_region_probs))

              # print("nrow(temp_region_probs) = ")
              # print(nrow(temp_region_probs))


              # these three lines are technically unnecessary
              probmattemp[, k_ind] <- rep(0,num_regions_tmin1)
              tempbounds[k_ind, 1] <- NA
              tempbounds[k_ind, 2] <- NA

              next

            }


            temp_lower2 <- max(temp_lower2, temp_lower3)
            temp_upper2 <- min(temp_upper2, temp_upper3)

            if(temp_lower2 > temp_upper2){

              print("as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")

              print(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
                                       n.item*(indiv - 1) +
                                       1:n.item])

              print("item_ind = ")
              print(item_ind)

              print("rankvec_t = ")
              print(rankvec_t)

              stop("Line 1581 temp_lower2 > temp_upper2")
            }


            for(k0_ind in 1:num_regions_tmin1){

              #loop over all possible means
              temp_mean2 <- intersectmat_tmin1[k0_ind,1]

              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # probmattemp[k0_ind, k_ind] <- prob_t_region*
              #   temp_tnorm_prob *
              #   intersectmat_tmin1[k0_ind,4]

              probmattemp[k0_ind, k_ind] <- temp_tnorm_prob *
                intersectmat_tmin1[k0_ind,4]

              if(probmattemp[k0_ind, k_ind] <0){
                print("probmattemp[k0_ind, k_ind] = ")
                print(probmattemp[k0_ind, k_ind])

                # print("prob_t_region = ")
                # print(prob_t_region)

                print("temp_tnorm_prob = ")
                print(temp_tnorm_prob)

                print("intersectmat[k0_ind,4] = ")
                print(intersectmat[k0_ind,4])

                print("temp_upper2 = ")
                print(temp_upper2)

                print("temp_lower2 = ")
                print(temp_lower2)

                print("temp_mean2 = ")
                print(temp_mean2)


              }


            } # end loop over k0

            # save upper and lower bounds (mean saved in intersectmat)
            # or just obtain again later

            tempbounds[k_ind,1] <- temp_lower2
            tempbounds[k_ind,2] <- temp_upper2


          } # end loop over k1


          #sample a combination of k0 and k1
          # if necessary can use column sums to sample k1, then k0
          # however, this is probably unnecessary


          # print("Line 1621 before sample")

          region_ind <- sample.int(num_regions_tmin1*num_regions,
                                   size = 1,
                                   replace = TRUE,
                                   prob = as.vector(probmattemp))


          # print("Line 1629 after sample")

          # k0 region is sampled number modulo number of regions in period 1
          k0_region_ind <- ((region_ind -1) %% num_regions_tmin1 ) + 1
          # if(k0_region_ind ==0){
          #   k0_region_ind <- num_regions
          # }

          # k1 region is the ceiling of sampled number divided by number of regions in period 1
          # k1_region_ind <- ceiling(region_ind/num_regions)
          k1_region_ind <- (region_ind -1) %/% num_regions_tmin1 + 1


          # print("k1_region_ind = ")
          # print(k1_region_ind)

          temp_lower2 <- tempbounds[k1_region_ind,1]
          temp_upper2 <- tempbounds[k1_region_ind,2]

          # print("num_regions = ")
          # print(num_regions)
          #
          # print("region_ind = ")
          # print(region_ind)
          #
          # print("k0_region_ind = ")
          # print(k0_region_ind)

          temp_mean0 <- intersectmat_tmin1[k0_region_ind, 1]
          temp_mean0 <- (temp_mean0 + 0.5)*(max_resp - min_resp) + min_resp

          # print("temp_mean0 = ")
          # print(temp_mean0)
          #
          # print("temp_lower2 = ")
          # print(temp_lower2)
          #
          # print("temp_upper2 = ")
          # print(temp_upper2)

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = temp_lower2,
                                   b = temp_upper2,
                                   mean = temp_mean0,
                                   sd = 1)


          Z.mat[item_ind,  indiv ] <- zdraw_temp


          #### Begin Loop over time ###################

          # loop over time periods for general case 1 < t < T

          for(t in 2:(n.time - 1)){


            if(itemcovars == TRUE){
              list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
              list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[t]]


              intersectmat <- list_item_intersectmats[[index_item]]
              intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
            }else{
              intersectmat <- Biglist_intersectmats[[t+1]]
              intersectmat_tmin1 <- Biglist_intersectmats[[t]]
            }

            num_regions <- nrow(intersectmat)

            temp_ztpmin1 <- as.vector(Z.mat)[(t-2)*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               item_ind]


            # must find mean corresponding to z in period t-1
            # This will be used in and after the loop over regions.
            # can directly obtain from dbarts
            # or find region
            # and use already saved region mean values


            # must find last lower bound that temp_ztpmin1 is greater than
            # or first upper bound that temp_ztpmin1 is below
            ktemp_tmin1 <- which((temp_ztpmin1 < intersectmat_tmin1[, 3]) )[1]
            # Then obtain the corresponding region mean value
            temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

            # print("temp_mean2 = ")
            # print(temp_mean2)
            #
            # print("ktemp_tmin1 = ")
            # print(ktemp_tmin1)



            # Calculate the probabilities for each region in this time period
            # the regions being looped over are actually period t+1 regions

            # Same regions for all time periods if there are no time varying covariates

            # However, the weights are individual and time period specific

            # loop through regions


            # first column is the probabilities
            # second column is the lower bounds
            # third column is the upper bounds
            temp_region_probs <- matrix(0,
                                        nrow = nrow(intersectmat),
                                        ncol = 3)

            # Trunc norm prob of next periods latent value conditional on region

            # Create intervals from interval t+1 latent values

            rankvec_tp1 <- ranks_mat[,  (t)*n.ranker + indiv]

            # inds for j ranked below i in t+1

            belowrank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] - 1 )

            #max of latent variables for j ranked below i in t+1
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower <- -Inf
            }else{
              # Check that this is the period t+1 latent variable value, not period t
              temp_lower <- as.vector(Z.mat)[t*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               belowrank_ind]
            }

            # inds for j ranked above i in t+1

            aboverank_ind <- which(rankvec_tp1 == rankvec_tp1[item_ind] + 1)

            #min of latent variables for j ranked below i in period t+1

            if(length(aboverank_ind) ==0){
              temp_upper <- Inf
            }else{
              # Check that this is the period t+1 latent variable value, not period t

              temp_upper <- as.vector(Z.mat)[t*n.item*n.ranker+
                                               n.item*(indiv - 1) +
                                               aboverank_ind]
            }


            # want trunc norm probability of latent variable value for item_ind
            # in period t+1

            temp_ztp1 <- as.vector(Z.mat)[t*n.item*n.ranker+
                                            n.item*(indiv - 1) +
                                            item_ind]

            rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]



            # if(any(order(rankvec_t) !=
            #    order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                           n.item*(indiv - 1) +
            #                           1:n.item]) )){
            #
            #   print("order(rankvec_t) = ")
            #   print(order(rankvec_t))
            #
            #   print("order(as.vector(Z.mat)[(1-1)*n.item*n.ranker +
            #                         n.item*(indiv - 1) +
            #                         1:n.item])  = ")
            #
            #   print(order(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                  n.item*(indiv - 1) +
            #                                  1:n.item]) )
            #
            #   print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                                n.item*(indiv - 1) +
            #                                1:n.item] = ")
            #
            #   print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
            #                            n.item*(indiv - 1) +
            #                            1:n.item])
            #
            #
            # }





            # inds for j ranked below i in t

            belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

            #max of latent variables for j ranked below i in t
            # Z.mat

            if(length(belowrank_ind) ==0){
              temp_lower3 <- -Inf
            }else{
              temp_lower3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                belowrank_ind]
            }

            # inds for j ranked above i in t

            aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

            #min of latent variables for j ranked below i in period t

            if(length(aboverank_ind) ==0){
              temp_upper3 <- Inf
            }else{
              temp_upper3 <- as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                                n.item*(indiv - 1) +
                                                aboverank_ind]
            }



            for(k_ind in 1:num_regions){



              # obtain mean for truncated normal distribution
              temp_mean <- intersectmat[k_ind, 1]



              # temp_tnorm_prob <- dtruncnorm(temp_ztp1,
              #                               a=temp_lower,
              #                               b=Inf,
              #                               mean = temp_mean,
              #                               sd = 1)

              tempmeanfordens <- (temp_mean + 0.5)*(max_resp - min_resp) + min_resp

              temp_tnorm_prob <- fastnormdens(temp_ztp1,
                                              mean = tempmeanfordens,
                                              sd = 1)

              # temp_tnorm_prob <- fastnormdens(temp_ztp1,
              #                          mean = temp_mean,
              #                          sd = 1)


              # Probability of z_t in intersection of
              # region k_ind (for period t+1)
              # and region defined by period t latent variables for other individuals
              # and rank for period t


              # tildeC_ktminl corresponds to
              # period t+1 k_ind region intereval

              temp_lower2 <- intersectmat[k_ind, 2]
              temp_upper2 <- intersectmat[k_ind, 3]



              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_upper2 = ")
              # print(temp_upper2)
              #
              # print("temp_lower3 = ")
              # print(temp_lower3)
              #
              # print("temp_upper3 = ")
              # print(temp_upper3)


              if((temp_lower2 > temp_upper3) | (temp_lower3 > temp_upper2)){
                # intervals do not overlap, therefore assign probability zero
                # and skip to next iteration

                # print("k_ind = ")
                # print(k_ind)

                # print("ncol(temp_region_probs) = ")
                # print(ncol(temp_region_probs))

                # print("nrow(temp_region_probs) = ")
                # print(nrow(temp_region_probs))

                temp_region_probs[k_ind, 1] <- 0
                temp_region_probs[k_ind, 2] <- NA
                temp_region_probs[k_ind, 3] <- NA


                next
              }



              temp_lower2 <- max(temp_lower2, temp_lower3)
              temp_upper2 <- min(temp_upper2, temp_upper3)


              if(temp_lower2 > temp_upper2){

                print("as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              1:n.item]")
                print(as.vector(Z.mat)[(t-1)*n.item*n.ranker +
                                         n.item*(indiv - 1) +
                                         1:n.item])
                print("item_ind = ")
                print(item_ind)

                print("rankvec_t = ")
                print(rankvec_t)


                print("temp_lower2 = ")
                print(temp_lower2)

                print("temp_upper2 = ")
                print(temp_upper2)

                stop("Line 1917. temp_lower2 > temp_upper2")
              }



              # probability of being in intersection region

              # prob_t_region <- pnorm(temp_upper2 - temp_mean2) - pnorm(temp_lower2 - temp_mean2)


              # print("temp_upper2 = ")
              # print(temp_upper2)
              # print("temp_lower2 = ")
              # print(temp_lower2)
              #
              # print("temp_mean2 = ")
              # print(temp_mean2)
              #
              #
              # print("prob_t_region = ")
              # print(prob_t_region)
              #
              # print("temp_tnorm_prob = ")
              # print(temp_tnorm_prob)

              # prob_t_region <- prob_t_region*temp_tnorm_prob
              prob_t_region <- temp_tnorm_prob

              # save region probability

              # and save region bounds (or maybe more memory efficient to obtain the region again)

              # must multiply by other previously obtained probabilities

              # print("prob_t_region = ")
              # print(prob_t_region)

              temp_region_probs[k_ind, 1] <- prob_t_region
              temp_region_probs[k_ind, 2] <- temp_lower2
              temp_region_probs[k_ind, 3] <- temp_upper2


            }


            # sample a region using probabilities obtained above

            # print("Line 1903 before sample")

            region_ind <- sample.int(num_regions, 1, replace = TRUE, prob = temp_region_probs[,1])

            # print("Line 1914 after sample")

            temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

            zdraw_temp <- rtruncnorm(n = 1,
                                     a=temp_region_probs[region_ind, 2],
                                     b=temp_region_probs[region_ind, 3],
                                     mean = temp_mean2_origscale,
                                     sd = 1)

            # zdraw_temp <- rtruncnorm(n = 1,
            #                          a=temp_region_probs[region_ind, 2],
            #                          b=temp_region_probs[region_ind, 3],
            #                          mean = temp_mean2,
            #                          sd = 1)



            Z.mat[item_ind, (t - 1)*n.ranker + indiv ] <- zdraw_temp



          } # end loop over time periods

          # check for special cases for n.time - 1, n.time - 2, n.time - 3

          # special case for t = n.time


          if(itemcovars == TRUE){
            # list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]
            list_item_intersectmats_tmin1 <- Biglist_list_item_intersectmats[[n.time]]


            # intersectmat <- list_item_intersectmats[[index_item]]
            intersectmat_tmin1 <- list_item_intersectmats_tmin1[[index_item]]
          }else{
            # intersectmat <- Biglist_intersectmats[[t+1]]
            intersectmat_tmin1 <- Biglist_intersectmats[[n.time]]
          }

          num_regions <- nrow(intersectmat)

          temp_ztpmin1 <- as.vector(Z.mat)[(n.time-2)*n.item*n.ranker+
                                             n.item*(indiv - 1) +
                                             item_ind]


          # must find mean corresponding to z in period t-1
          # This will be used in and after the loop over regions.
          # can directly obtain from dbarts
          # or find region
          # and use already saved region mean values


          # must find last lower bound that temp_ztpmin1 is greater than
          # for first upper bound that temp_ztpmin1 is below
          ktemp_tmin1 <- which(temp_ztpmin1 < intersectmat_tmin1[, 3])[1]
          # Then obtain the corresponding region mean value
          temp_mean2 <- intersectmat_tmin1[ktemp_tmin1,1]

          # now find interval


          # tildeC_ktminl corresponds to
          # period t+1 k_ind region intereval



          rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

          # inds for j ranked below i in T

          belowrank_ind <- which(rankvec_t == rankvec_t[item_ind] - 1 )

          #max of latent variables for j ranked below i in T
          # Z.mat

          if(length(belowrank_ind) ==0){
            temp_lower3 <- -Inf
          }else{
            temp_lower3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              belowrank_ind]
          }

          # inds for j ranked above i in T

          aboverank_ind <- which(rankvec_t == rankvec_t[item_ind] + 1)

          #min of latent variables for j ranked below i in period T

          if(length(aboverank_ind) ==0){
            temp_upper3 <- Inf
          }else{

            temp_upper3 <- as.vector(Z.mat)[(n.time-1)*n.item*n.ranker +
                                              n.item*(indiv - 1) +
                                              aboverank_ind]
          }


          temp_mean2_origscale <- (temp_mean2 + 0.5)*(max_resp - min_resp) + min_resp

          # CHECK IF THESE BOUNDS ARE CORRECTLY DEFINED

          zdraw_temp <- rtruncnorm(n = 1,
                                   a = temp_lower3,
                                   b = temp_upper3,
                                   mean = temp_mean2_origscale,
                                   sd = 1)

          # zdraw_temp <- rtruncnorm(n = 1,
          #                          a = temp_lower3,
          #                          b = temp_upper3,
          #                          mean = temp_mean2,
          #                          sd = 1)


          Z.mat[item_ind, (n.time -1)*n.ranker + indiv ] <- zdraw_temp





        } # end loop over items



      } # end loop over individuals indiv in 1:n.ranker

    }




    # print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{
    temp_break <- 0
    for(j in 1:num_lags){
      # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)

      while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {

        if(seq_z_draws==1){
          stop("updates still not consistent with tree structure")
        }
        print("new z values not consistent with tree structure, must draw again")

        # If this error message occurs
        # Check the conditions in the dbart package for setPredictor == FALSE
        # And if this is hypothetically possible, even with draws from the smoothing distribution,
        # and if it is not a bug
        # then need to go back to beginning of this iteration of the Gibbs sampler
        # and sample Zmat again


        temp_break <- 1
        break
        # stop("new z values not consistent with tree structure, must draw again")


        # #perhaps this can be rewritten to just re-draw the relevant column?
        # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                           Z.mat = Z.mat,
        #                                           mu = mu,
        #                                           weight.vec = rep(1, n.ranker*n.time),
        #                                           n.ranker = n.ranker*n.time,
        #                                           n.item = n.item )
        #
        # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
        #
        # for(t in 1:num_lags){
        #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
        #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
        #
        #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
        #
        # }
        #
        # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j

      }

      if(temp_break==1){
        break
      }
    }

    # if need to draw z values again, go back to start of loop
    if(temp_break==1){
      if(breakcount == 10){
        Z.mat <- Z.matold
        Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

        for(t in 1:num_lags){
          init_Z_t0 <- rep(0, t*n.item*n.ranker)
          # init_Z_t0 <- rnorm(t*n.item*n.ranker)

          Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

        }

      }else{
        breakcount <- breakcount +1
        next
      }

    }

    breakcount <- 0
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)

    min_resp <- min(as.vector(Z.mat))
    max_resp <- max(as.vector(Z.mat))
    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }
    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples
    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y[tempcounts$x] <- tempcounts$N
    }
    # mutemp <- sampler$predict(df_for_dbart)
    # print("sigma = ")
    # print(samplestemp$sigma)

    # mu = mutemp

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]




      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("iteration number")
        print(iter)
        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)
        stop("mutemp[1]!= mutemp[n.item+1]")
      }


      #mu = mutemp[(1:n.item)*n.ranker]
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu = mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    if (sparse & (iter > floor(n.burnin * 0.5))) {
      # s_update_z <- update_s(var_count_z, p_z, alpha_s_z)
      # s_z <- s_update_z[[1]]

      s_update_y <- update_s(var_count_y, p_y, alpha_s_y)
      s_y <- s_update_y[[1]]

      if(alpha_split_prior){
        # alpha_s_z <- update_alpha(s_z, alpha_scale_z, alpha_a_z, alpha_b_z, p_z, s_update_z[[2]])
        alpha_s_y <- update_alpha(s_y, alpha_scale_y, alpha_a_y, alpha_b_y, p_y, s_update_y[[2]])
      }
    }


    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta



    #
    #     # if(is.null(initial.list)){
    #     # print("samplestemp$test[,1] = ")
    #     # print(samplestemp$test[,1])
    #
    #     # mupreds <- sampler$predict(df_for_dbart)
    #
    #     # Xmat.test[,1:num_lags] <-  Zlag.mat.test
    #
    #
    #     temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))
    #
    #     for(t  in 1:num_lags){
    #       if(noise_in_pred ==1){
    #         temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
    #       }else{
    #         temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
    #       }
    #
    #     }
    #
    #     # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #     #                                                                      (num_lags+1):ncol(Xmat.test)])
    #
    #     temp_test_mat <- data.frame(x = temp_test_mat)
    #     colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #     # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    #     temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    #     print("Line 5488")
    #
    #
    #     temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )
    #
    #
    #     # if(iter < 5){
    #     #   print("temp_test_mat = " )
    #     #   print(temp_test_mat)
    #     # }
    #
    #     for(t1 in 1:num_test_periods){
    #       #produce a prediction
    #
    #       # must use original column names to prevent an error in the predict function
    #       colnames(temp_test_mat) <- colnames(df_for_dbart_test)
    #
    #       testpredvec <- sampler$predict(temp_test_mat)
    #
    #       #fill in temp_test_preds with noise
    #       if(noise_in_pred ==1){
    #         temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #       }else{
    #         temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
    #       }
    #
    #
    #       #update temp_test_mat
    #       #shift z columns to the right and fill in leftmost column
    #
    #       #need to rewrite this if want to allow for no observed covariates
    #
    #       # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )
    #
    #       if(t1 != num_test_periods){
    #
    #
    #         if(num_lags ==1){
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }else{
    #           temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
    #                                                  temp_test_mat[,1:(num_lags-1)] #,
    #                                                  # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
    #           ))
    #
    #         }
    #       }
    #
    #       # colnames(temp_test_mat) <- colnames(Xmat.test)
    #
    #
    #       #fill in temp_mu_test without noise
    #       temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    #     }
    #
    #     #also update Zlag.mat.test ?
    #     #perhaps this is unnecessary here?
    #
    #     print("Line 5545")
    #
    #
    #     Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    #     # if(nrow(X.test) >0 ){
    #     for(t in 1:num_lags){
    #       # if(t==1){
    #       #   #repeating the last period values
    #       #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #       #
    #       #   #other option is to set all unobservable values to zero
    #       #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #       #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #       #
    #       #
    #       # }else{
    #
    #       if(num_test_periods > t ){
    #         #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #       }else{
    #         #nothing to fill in if num_test_periods <= t
    #         Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #       }
    #
    #
    #       # }
    #     }
    #     # }
    #
    #     # if(nrow(X.test)>0){
    #     #
    #     #
    #     #   for(j in 1:num_lags){
    #     #
    #     #     #perhaps this should be removed for when Z is updated properly below
    #     #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #     #
    #     #   }
    #     #
    #     # }
    #
    #
    #     draw$mu_test[,iter] <- temp_mu_test
    #     # draw$mu_test[,iter] <- samplestemp$test[,1]
    #
    #     if(keep_zmat==TRUE){
    #       draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    #     }
    #
    #     # draw$mu_test[,1] <- samplestemp$test[,1]
    #
    #     # }else{
    #     #   draw$mu_test[,1] <- initial.list$mu_test
    #     # }
    #


    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        if(noise_in_pred ==1){
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }

      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      temp_test_mat <- data.frame(x = temp_test_mat)
      colnames(temp_test_mat) <- colnames(Xmat.test)

      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )


      # if(iter < 5){
      #   print("temp_test_mat = " )
      #   print(temp_test_mat)
      # }

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }


        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){


          if(num_lags ==1){
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }else{
            temp_test_mat <-  data.frame(x =  cbind(  temp_test_preds[ , t1] ,
                                                      temp_test_mat[,1:(num_lags-1)] ,
                                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                          (num_lags+1):(ncol(Xmat.test))]) ))

          }
        }

        colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }

      # if(nrow(X.test)>0){
      #
      #
      #   for(j in 1:num_lags){
      #
      #     #perhaps this should be removed for when Z is updated properly below
      #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
      #
      #   }
      #
      # }


      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    if(sparse){
      draw$alpha_s_y_store[iter] <- alpha_s_y
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_y_store[iter,] <- var_count_y
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_y_store[iter,] <- s_y
      # draw$s_prob_z_store[iter,] <- s_z
    }


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }


    iter <- iter+1
  }


  return(draw)
}





##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////



#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data without  Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and without covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @param num_horizon Number of time periods into the furture to predict ranks.
#' @return A list is returned containing the following elements:
#' \item{mu}{A matrix of dimension n.item.n.ranker.n.time by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in time period 1, then all items for ranker 2 in time period 1, and so on. }
#' \item{mu_test}{A matrix of dimension n.item.n.ranker.num_horizon by iter.max. Columns correspond to MCMC iterations. Each column gives direct predictions given the previous lagged draws of Z (no filtering or smoothing, not in agreement with observed ranks). The rows are ordered with all items for ranker 1 in the first horizon, then all items for ranker 2 in the first horizon, and so on. }
#' \item{Z.mat}{A 3d array of dimenions c(n.item, n.ranker*n.time, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time period. The second n.ranker columns are for the second time period, and so on.}
#' \item{Z.mat.test}{A 3d array of dimenions c(n.item, n.ranker*num_horizon, iter.max). Each slice corresponds to an MCMC iteration. The first n.ranker columns are for all rankers in the first time horizon. The second n.ranker columns are for the second time horizon, and so on.}
#' @export
ARRObartNOCovars <- function(pair.comp.ten,
                             # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                             # X.test = matrix(NA, nrow =0, ncol = 0),
                             # tau2.alpha = 5^2,
                             # nu.alpha = 3,
                             # tau2.beta = 5^2,
                             # nu.beta = 3,
                             n.item = dim(pair.comp.ten)[1],
                             n.rankerbytime = dim(pair.comp.ten)[3],
                             n.ranker,
                             n.time,
                             # p.cov = ncol(X.train),
                             iter.max = 5000,
                             para.expan = TRUE,
                             print.opt = 100,
                             initial.list = NULL,
                             n.trees = 50L,
                             n.burn = 0L,
                             n.samples = 1L,
                             n.thin = 1L,
                             n.chains = 1,
                             n.threads = 1L,
                             printEvery = 100L,
                             printCutoffs = 0L,
                             rngKind = "default",
                             rngNormalKind = "default",
                             rngSeed = NA_integer_,
                             updateState = FALSE,
                             num_lags = 1,
                             diff_num_test_rankers = 0,
                             keep_zmat = FALSE,
                             noise_in_pred = 0,
                             seq_z_draws = 1,
                             N_hdr = 100,
                             rho_hdr = 0.5,
                             smoothing_method = "AR",
                             num_horizon = 1){


  Num_lin_ess_samples <- 100
  num_test_periods <- num_horizon

  if(num_horizon < 1){
    stop("num_horizon must be >=1")
  }

  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime


  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  # length_mu_test <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),#,
    mu_test = array(NA, dim = c(n.item*n.ranker*num_horizon, iter.max))
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
    draw$Z.mat.test = array(NA, dim = c(n.item, n.ranker*num_horizon, iter.max))
  }

  # if(nrow(X.test) >0 ){
  #   draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  #
  #   if(keep_zmat==TRUE){
  #     draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
  #   }
  # }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on


  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }


  # it might be more efficient to create and save all rank constraint matrices at this stage


  rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))

  for(indiv in 1:n.ranker){

    for(t in 1:n.time){

      rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]


      rankconstraint_t <- matrix(0,
                                 nrow = n.item - 1,
                                 ncol = n.item)

      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1

      }

      rank_cons_arr[, , indiv, t] <- rankconstraint_t

    }
  }
  # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  boundconstraints <- matrix(NA,
                             nrow = 2*n.item,
                             ncol = n.item)

  # use kroenecker product
  # there is probably a more efficient way of doing this

  boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


  print("Line 670.")

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }


    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   (num_test_periods-t) )  )

        # #other option is to set all unobservable values to zero
        # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }


    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #   }
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }



    print("Line 799.")

    df_for_dbart <- data.frame(y = as.vector(Z.mat), x = Zlag.mat )


    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")


    # if(nrow(X.test )==0){
    sampler <- dbarts(y ~ .,
                      data = df_for_dbart,
                      #test = Xmat.test,
                      control = control,
                      resid.prior = fixed(1),
                      sigma=1 #check if this is the correct approach for setting the variance to 1
    )

    # }else{
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    #                     sigma=1 #
    #   )
    #
    # }

    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    #sampler$setPredictor(x= Xmat.train$x, column = 1, forceUpdate = TRUE)

    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    mu <- mutemp

    #
    # if(nrow(X.train)==n.item){
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #   stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #   # if(mutemp[1]!= mutemp[n.item+1]){
    #   if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
    #     print("initiating mu")
    #     print("Xmat.train = ")
    #     print(Xmat.train)
    #     print("Z.mat = ")
    #     print(Z.mat)
    #
    #     print("samplestemp$sigma = ")
    #     print(samplestemp$sigma)
    #     print("samplestemp$varcount = ")
    #     print(samplestemp$varcount)
    #
    #     print("samplestemp$train[,1] = ")
    #     print(samplestemp$train[,1])
    #
    #     print("n.item = ")
    #     print(n.item)
    #     print("mutemp = ")
    #     print(mutemp)
    #
    #     # print("mupreds= ")
    #     # print(mupreds)
    #
    #     stop("mutemp[1]!= mutemp[n.item+1]")
    #   }
    #
    #   #mu = mutemp[(1:n.item)]
    #   mu = mutemp[n.item+(1:n.item)]
    #
    #   #mu = mutemp[(1:n.item)*n.ranker]
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     mu <- mutemp
    #   }else{
    #     stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    #
    # }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
    draw$Z.mat.test[,,1] <- Z.mat.test
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  print("Line 954")


  df_for_dbart_test <- data.frame( x = Zlag.mat.test )


  if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(Xmat.train)

    temp_test_mat <- as.matrix(df_for_dbart_test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )

    # print("colnames(temp_test_mat) = ")

    # print(colnames(temp_test_mat))

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # print("t1 = ")
      # print(t1)
      #
      #
      # print("colnames(temp_test_mat) = ")
      # print(colnames(temp_test_mat))

      testpredvec <- sampler$predict(temp_test_mat)

      #fill in temp_test_preds with noise

      if(noise_in_pred==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec
      }



      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      if(num_lags ==1){
        temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
                                               as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker), ] )))

      }else{
        temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                               as.matrix(df_for_dbart_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),] )))

      }

      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
        # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
        #
        # print("as.vector(temp_test_mat)")
        # print(as.vector(as.matrix(temp_test_mat)))
        #
        # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
        # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }




    draw$mu_test[,1] <- temp_mu_test

    # draw$mu_test[,1] <- samplestemp$test[,1]
    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

  }else{
    draw$mu_test[,1] <- initial.list$mu_test
  }



  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    print("iter = ")
    print(iter)

    ##################### Sample from the Smoothing Distribution #################################################################

    # Sample from the smoothing distribution at each time period beginning at T

    # loop over individuals/rankers (if there is more than one individual/ranker)


    #################### calculate intersection matrices ########################################

    # since there are no covariates, the intersection matrices do not vary across time or individuals

    #### obtain intersection matrices for time period t = 1 ###############



    # create intersection matrices


    intersectmat_tmin1 <- NA
    list_item_intersectmats_tmin1 <- NA

    # create vector of indices for ranker indiv in time period 1

    # # this part is not really necessary
    # ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
    # ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
    # obs_indices <- ind_start:ind_end

    # obs_indices[1] could jsut be replaced by [1] below\
    # because the only variable is zlag, so the other covariates are not used


    list_inter_mats <- list()

    for(i in 1:n.trees){

      treeexample1 <- sampler$getTrees(treeNums = i,
                                       chainNums = 1,
                                       sampleNums = 1)

      rebuilt_tree <- rebuildTree2(treeexample1)


      #must use covariates for individual indiv at time period t

      # list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )
      list_inter_mats[[i]] <- rebuilt_tree[rebuilt_tree$var == -1 , 5:7]


    }

    intersectmat <- interNtreesB(list_inter_mats)

    print("Line 1146")

    intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

    print("Line 1150")


    # calculate one dimensional integrals
    for(rowind in 1:nrow(intersectmat)){
      # ktemp <- nkt_mat[rowind,k_index]
      # tempmean <- intersectmat[ktemp,1]
      templower <- intersectmat[rowind,2]
      tempupper <- intersectmat[rowind,3]

      # ASSUMING PRIOR MEAN ALL ZEROS
      intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
      # tempintegralval <- tempintegralval*onedim_int
    }

    intersectmat_tmin1 <- intersectmat



    print("Line 1169")


    for(indiv in 1:n.ranker){

      print("indiv = ")
      print(indiv)
      ########### calculate qkt  ########################################

      # each element of list corresponds to a time period

      qkt_list <- list()


      # list of intersectmats across time periods
      # Biglist_intersectmats <- list()

      # If allow for intersect matrices
      # then save list of lists of matrices
      # Biglist_list_item_intersectmats <- list()

      # list_item_intersectmats

      # in each time period, there are item and time specific ranges of k
      # (also ranker specific, although the whole outer loop is over rankers, so this is less important)

      #begin with the special case of t = 1

      # requires z_prior
      # zprior_vec arbitraily set to all zeros


      # obtain regions for time period t = 1
      # time period 1 is unlike other time periods for qkt integral calculations
      # in that the integrals are not constrained by observed ranks

      # for t = 1 C_k has k corresponding to t = 1

      # obtain period 1 lower and upper bounds for constrained regions
      # then evaluate products of univariate normal integrals



      ########### calculate qkt   for t = 1 ########################################






      ### calculate qkt integrals for time period t = 1  ################

      #there are n.item*nrow(intersectmat) possible regions

      # create list of vectors of indices for k1, k2, ..., k_{n.item}
      # to be used as input to expand.grid

      #straightforward for itemcovars == FALSE

      K_ind_list <-list()
      print("Line 1228")

      for(index_item in 1:n.item){
        K_ind_list[[index_item]] <- 1:nrow(intersectmat)
      }

      print("Line 1233")
      print("K_ind_list = ")
      print(K_ind_list)
      # there are many possible combinations
      # this might produce a huge matrix
      # not the most efficeient way of coding this
      kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

      # this line is included to avoid an error later using all.equal
      colnames(kcomb_vec_mat) <- NULL


      # qkt_mat <- cbind(kcomb_vec_mat, rep(NA, nrow(kcomb_vec_mat)))
      print("Line 1236")

      qkt_vec <-rep(0, nrow(kcomb_vec_mat))

      # rm(kcomb_vec_mat)

      # lastcol_ind <- ncol(qkt_mat)

      for(rowind in 1:length(qkt_vec) ){

        #obtain means
        #vector k1, k2, k3, etc
        k_indvec <- kcomb_vec_mat[rowind,]

        #note: k_indvec can include repeated values
        # tempmeans <- intersectmat[k_indvec,1]

        # print("k_indvec = ")
        # print(k_indvec)
        #
        # print("intersectmat = ")
        # print(intersectmat)

        templowers <- intersectmat[k_indvec,2]
        tempuppers <- intersectmat[k_indvec,3]


        # Apply methods of Gessner et al

        # create matrix A, vector b

        # for qkt_mat calcultions, the only constraint is the rank order A_t
        # so

        # A matrix is rankconstraint_t
        # original b vector is vector of zeros
        # However must shist the constraints as outlined in the paper
        # the mu vector is tempmeans
        # Therefore the shifted b vector is
        # (rankconstraint_t)%*%tempmeans
        #
        # bvec_temp <- (rankconstraint_t)%*%tempmeans
        #
        #
        #
        #
        # sub_retFast <- LinConGauss::SubsetSimFast(rankconstraint_t,
        #                                           bvec_temp,
        #                                           N_hdr,
        #                                           rho_hdr )
        #
        # hdr_retFast <- LinConGauss::HDR_algoFast(rankconstraint_t,
        #                                          bvec_temp,
        #                                          c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
        #                                          N_hdr )
        #
        # #Probability Estimate from subset simulation
        # # exp(sub_retFast$logZ)
        #
        # #Probability Estimate from HDR
        # tempintegralval <- exp(hdr_retFast)


        tempintegralval <- 1

        for(k_index in 1:n.item){
          ktemp <- k_indvec[k_index]

          # tempmean <- intersectmat[ktemp,1]

          # tempmean <- zprior_vec[k_index]
          # templower <- intersectmat[ktemp,2]
          # tempupper <- intersectmat[ktemp,3]

          # onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
          tempintegralval <- tempintegralval*intersectmat[ktemp,4]

        }

        #Save integral result
        qkt_vec[ rowind] <- tempintegralval#include product here

      }


      # If ordering does not obey constraint
      #check if ordering obeys rankvec_t

      #n columns of kcomb_vec_mat

      # for a given row,
      # the ordering must agree with rankvec_t (with strict or weak inequality)


      # remove rows that do not obey constraint
      # or set corresponding nkt value to 0

      # possibly uses a lot of memory to create another matrix of ranks

      # how to deal with ties?
      # kcomb_rank_mat <- apply(kcomb_vec_mat, 1, rank)

      # or just loop through all rows

      # ASSUMING NO TIES IN OBSERVED RANKS rankvec_t


      # ACTUALLY, nkt does not involve restricted ranks. Can apply to ALL k

      # keepbools <- rep(NA, nrow(kcomb_vec_mat))
      # strictbools <- rep(NA, nrow(kcomb_vec_mat))
      #
      #
      # for(rowind in 1:nrow(kcomb_vec_mat)){
      #
      #   krow <- kcomb_vec_mat[rowind,]
      #
      #   # TRUE if obeys with weak or strict equality
      #   keepbools[rowind] <- all(rank( krow , ties.method = "min") <= rankvec_t)
      #   strictbools[rowind] <- all(rank( krow , ties.method = "min") == rankvec_t)
      #
      # }
      #
      # #this might not be optimal if want to preserve ordering of combinations
      # kcomb_strict_mat <- kcomb_vec_mat[strictbools, ]
      # kcomb_weak_mat <- kcomb_vec_mat[keepbools & (!strictbools), ]
      #
      #
      #
      # # free up some memory ?
      # rm(kcomb_vec_mat)
      #
      # # perhaps need to keep track of k1, k2, k3, etc
      #
      # n_strict <- nrow(kcomb_strict_mat)
      # n_weak <- nrow(kcomb_weak_mat)
      #
      # #
      # qkt_mat <- rbind(kcomb_strict_mat, kcomb_weak_mat)
      #
      #
      # # free up some memory ?
      # rm(kcomb_strict_mat, kcomb_weak_mat)
      #
      # #last column be integral values
      # qkt_mat <- cbind(qkt_mat, rep(NA, nrow(qkt_mat)))
      #
      # lastcol_ind <- ncol(qkt_mat)
      # # now fill in values of qkt_mat
      #
      # for(rowind in 1:n_strict ){
      #
      #   #obeys constraint exactly, so just take product of univariate normal integrals
      #
      #   tempintegralval <- 1
      #   # Product of pnorm() interval values with
      #   for(k_index in 1:(lastcol_ind-1)){
      #     ktemp <- qkt_mat[rowind,k_index]
      #     tempmean <- intersectmat[ktemp,1]
      #     templower <- intersectmat[ktemp,2]
      #     tempupper <- intersectmat[ktemp,3]
      #
      #     onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
      #     tempintegralval <- tempintegralval*onedim_int
      #
      #   }
      #
      #   qkt_mat[rowind,lastcol_ind] <- tempintegralval#include product here
      #
      # }
      # for(rowind in 1:n_weak ){
      #
      #   #apply method of Gessner et al
      #   qkt_mat[n_strict+ rowind,lastcol_ind] <- notcalculatedyet#include product here
      #
      # }

      qkt_list[[1]] <- qkt_vec

      intersectmat_tmin1 <- intersectmat


      rankvec_tmin1 <- ranks_mat[,  (1-1)*n.ranker + indiv]

      rankconstraint_tmin1 <- matrix(0,
                                     nrow = length(rankvec_tmin1)-1,
                                     ncol = length(rankvec_tmin1))


      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_tmin1)-1)){

        rankconstraint_tmin1[rankind, which(rankvec_tmin1 == rankind)] <- -1
        rankconstraint_tmin1[rankind, which(rankvec_tmin1 == rankind+1)] <- 1

        # rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        # rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_tmin1[rankind, rankvec_tmin1[rankind]] <- -1
        # rankconstraint_tmin1[rankind, rankvec_tmin1[rankind+1]] <- 1


      }

      A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)

      tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)


      print("rankconstraint_tmin1 = ")
      print(rankconstraint_tmin1)

      print("rank_cons_arr[, , indiv, 1] = ")
      print(rank_cons_arr[, , indiv, 1])


      # K_ind_list <-list()
      #
      # for(index_item in 1:n.item){
      #   K_ind_list[[index_item]] <- 1:nrow(intersectmat)
      # }
      #
      # # there are many possible combinations
      # # this might produce a huge matrix
      # # not the most efficeient way of coding this
      # kcomb_vec_mat <- expand.grid(K_ind_list)


      ########### calculate qkt   for t = 2 to T ########################################

      for(t in 2:(n.time+1)){
        rankvec_tmin1 <- ranks_mat[,  (t-2)*n.ranker + indiv]



        # rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]

        # rankconstraint_t <- matrix(0,
        #                            nrow = length(rankvec_t)-1,
        #                            ncol = length(rankvec_t))
        #
        #
        # # note: ordering of rows is unimportant
        # # as long as ordering agrees with the ordering of the mean vector
        #
        # # so can begin by filling in first row
        #
        # #MUST BE EDITED IF ALLOW FOR TIES
        # for(rankind in 1:(length(rankvec_t)-1)){
        #
        #   rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        #   rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1
        #
        # }


        rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t- 1]

        ### calculate qkt integrals for time period t = 2 to T  ######


        #there are n.item*nrow(intersectmat) possible regions

        # create list of vectors of indices for k1, k2, ..., k_{n.item}
        # to be used as input to expand.grid

        #straightforward for itemcovars == FALSE


        # qkt_mat <- cbind(kcomb_vec_mat, rep(NA, nrow(kcomb_vec_mat)))

        qkt_vec <-rep(0, nrow(kcomb_vec_mat))


        print("Line 1494")


        # lastcol_ind <- ncol(qkt_mat)

        for(rowind in 1:length(qkt_vec) ){


          # if ordering does not agree, all integrals will evaluate to zero and can then skip to next
          # NOTE THAT THIS REQUIRES NO ITEM-SPECIFIC COVARIATES
          # OTHERWISE MUST CHECK BOUNDS

          # can probably vectorize this
          # vectorize later if need to increase speed

          krow <- kcomb_vec_mat[rowind,]

          keepbool <- all(rank( krow , ties.method = "min") <= rankvec_tmin1)

          if(keepbool == FALSE){
            qkt_vec[rowind] <- 0
            next
          }

          strictbool <- all(rank( krow , ties.method = "min") == rankvec_tmin1)

          k_indvec <- krow #qkt_mat[rowind,1:(lastcol_ind-1)]

          templowers <- intersectmat[k_indvec,2]
          tempuppers <- intersectmat[k_indvec,3]

          # loop over previous time period

          num_m_vecs <- length(qkt_list[[t-1]])

          # print("qkt_list[[t-1]] = ")
          # print(qkt_list[[t-1]])
          #
          # print("num_m_vecs = ")
          # print(num_m_vecs)

          # number of indices/regions
          # should be n.item ?
          num_m_inds <- n.item #ncol(qkt_list[[t-1]])

          qm_1min1_vec <- qkt_list[[t-1]] #(qkt_list[[t-1]])[,ncol(qkt_list[[t-1]])]

          if(strictbool == TRUE){
            # can calculate relatively straightforward integrals

            for(m_ind in 1:num_m_vecs){

              # obtain mean vector from t-1 corresponding to m_ind

              m_inds <-  kcomb_vec_mat[m_ind,] #(qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
              tempmeans <- intersectmat_tmin1[m_inds,1]

              # tempintegralval <- 1
              #
              # # can probably vectorize this?
              # for(k_index in 1:(lastcol_ind-1)){
              #   ktemp <- k_indvec[k_index]
              #
              #   # tempmean <- intersectmat[ktemp,1]
              #
              #   tempmean <- tempmeans[k_index]
              #   templower <- templowers[k_index]
              #   tempupper <- tempuppers[k_index]
              #
              #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
              #   tempintegralval <- tempintegralval*onedim_int
              #
              # }

              # TEST
              tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

              # if(tempintegralval == tempintegralval2){
              #   print("Vectorization of qkt integral calculation seems to work.")
              # }else{
              #   print("Line 1677. error in vectorization of qkt integral.")
              # }

              #Save integral result
              # qkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

              # keep adding as loop over m_ind
              qkt_vec[rowind] <- qkt_vec[rowind] +
                qm_1min1_vec[m_ind]*tempintegralval


            } # end of loop over m_ind

            # rest of code is for integrals bounded by the rank constraint

            # so can skip

            next
          }




          # will use constraint implied by ranks in previous time period
          # rankconstraint_tmin1

          # rankconstraint_t

          # obtain constraint implied by templowers and tempuppers


          # corresponds to A_C in the paper
          # number of rows is 2*n.item
          # number of columns is n.item

          # boundconstraints <- matrix(NA,
          #                            nrow = 2*n.item,
          #                            ncol = n.item)
          #
          # # use kroenecker product
          # # there is probably a more efficient way of doing this
          #
          # boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


          # t(diag(1,3, 3) %x% c(1,-1))

          # A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)
          #
          # tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)


          #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT




          # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
          # and for each pair of bounds, the first is the negative of the upper bound
          # and the second is the upper bound

          # jumps of 2 from n.item to 3*n.item - 2
          lb_inds <- n.item - 2 + 2*(1:n.item)
          # jumps of 2 from n.item + 1 to 3*n.item - 1
          ub_inds <- n.item - 1+ 2*(1:n.item)



          # print("Line 1635")

          bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
          bvec[lb_inds] <- -1*templowers
          bvec[ub_inds] <- tempuppers

          # print("lb_inds = ")
          # print(lb_inds)
          #
          # print("ub_inds = ")
          # print(ub_inds)


          # must shift the constraint




          # print("num_m_vecs = ")
          # print(num_m_vecs)

          for(m_ind in 1:num_m_vecs){

            # obtain mean vector from t-1 corresponding to m_ind
            m_inds <-  kcomb_vec_mat[m_ind,] #(qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]

            # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
            tempmeans <- intersectmat_tmin1[m_inds,1]



            # print("tA_Cktmin1_constraint = ")
            # print(tA_Cktmin1_constraint)

            # print("tempmeans = ")
            # print(tempmeans)

            bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans

            # print("ncol(tA_Cktmin1_constraint) = ")
            # print(ncol(tA_Cktmin1_constraint))
            #
            # print("length(bvec_temp) = ")
            # print(length(bvec_temp) )

            # NOTE: The SubsetSimFast and HDR_algoFast functions
            # use the transpose of the constraint matrix as an input

            # print("line 1879")

            # sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
            #                                           bvec_temp,
            #                                           N_hdr,
            #                                           rho_hdr )


            sub_retFast <- tryCatch(LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                               bvec_temp,
                                                               N_hdr,
                                                               rho_hdr ),
                                    error = function(e){

                                      print("rbind(rankconstraint_tmin1, boundconstraints) = ")
                                      print(rbind(rankconstraint_tmin1, boundconstraints))

                                      print("A_Cktmin1_constraint = ")
                                      print(A_Cktmin1_constraint)


                                      print("tA_Cktmin1_constraint = ")
                                      print(tA_Cktmin1_constraint)

                                      print("bvec_temp = ")
                                      print(bvec_temp)

                                      print("N_hdr = ")
                                      print(N_hdr)

                                      print("rho_hdr = ")
                                      print(rho_hdr)

                                      print("tempmeans= ")
                                      print(tempmeans)

                                      print("bvec = ")
                                      print(bvec)


                                      krow <- kcomb_vec_mat[rowind,]

                                      keepbool <- all(rank( krow , ties.method = "min") <= rankvec_tmin1)


                                      print("krow = ")
                                      print(krow)

                                      print("t = ")
                                      print(t)

                                      print("rankvec_tmin1 = ")
                                      print(rankvec_tmin1)


                                      print("rankconstraint_tmin1 = ")
                                      print(rankconstraint_tmin1)

                                      print("rank( krow , ties.method = min) = ")
                                      print(rank( krow , ties.method = "min"))

                                      print("keepbool = ")
                                      print(keepbool)


                                      print("Error message = ")
                                      print(e)
                                      stop("error in SubsetSimFast")


                                    }
            )

            # print("line 1887")

            hdr_retFast <- tryCatch(LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                              bvec_temp,
                                                              c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                              N_hdr ),
                                    error = function(e){
                                      print("tA_Cktmin1_constraint = ")
                                      print(tA_Cktmin1_constraint)

                                      print("bvec_temp = ")
                                      print(bvec_temp)

                                      print("sub_retFast = ")
                                      print(sub_retFast)

                                      print("c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0) = ")
                                      print(c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0))

                                      print("N_hdr = ")
                                      print(N_hdr)

                                      print("tempmeans= ")
                                      print(tempmeans)

                                      print("bvec = ")
                                      print(bvec)


                                      print("Error message = ")
                                      print(e)
                                      stop("error in hdr_retFast")

                                    }
            )





            # hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
            #                                          bvec_temp,
            #                                          c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
            #                                          N_hdr )

            #Probability Estimate from subset simulation
            # exp(sub_retFast$logZ)

            #Probability Estimate from HDR
            tempintegralval <- exp(hdr_retFast)




            # tempintegralval <- 1
            #
            # # can probably vectorize this?
            # for(k_index in 1:(lastcol_ind-1)){
            #   ktemp <- k_indvec[k_index]
            #
            #   # tempmean <- intersectmat[ktemp,1]
            #
            #   tempmean <- tempmeans[k_index]
            #   templower <- templowers[k_index]
            #   tempupper <- tempuppers[k_index]
            #
            #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
            #   tempintegralval <- tempintegralval*onedim_int
            #
            # }

            # TEST
            # tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

            # if(tempintegralval == tempintegralval2){
            #   print("Vectorization of qkt integral calculation seems to work.")
            # }else{
            #   print("Line 1677. error in vectorization of qkt integral.")
            # }

            #Save integral result
            # qkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

            # keep adding as loop over m_ind
            qkt_vec[rowind] <- qkt_vec[rowind] +
              qm_1min1_vec[m_ind]*tempintegralval


          } # end of loop over m_ind



        } # end of loop over rowind (rows of qkt_mat)


        # If ordering does not obey constraint
        #check if ordering obeys rankvec_t

        #n columns of kcomb_vec_mat

        # for a given row,
        # the ordering must agree with rankvec_t (with strict or weak inequality)


        # remove rows that do not obey constraint
        # or set corresponding nkt value to 0

        # possibly uses a lot of memory to create another matrix of ranks

        # how to deal with ties?
        # kcomb_rank_mat <- apply(kcomb_vec_mat, 1, rank)

        # or just loop through all rows

        # ASSUMING NO TIES IN OBSERVED RANKS rankvec_t


        # ACTUALLY, nkt does not involve restricted ranks. Can apply to ALL k

        # keepbools <- rep(NA, nrow(kcomb_vec_mat))
        # strictbools <- rep(NA, nrow(kcomb_vec_mat))
        #
        #
        # for(rowind in 1:nrow(kcomb_vec_mat)){
        #
        #   krow <- kcomb_vec_mat[rowind,]
        #
        #   # TRUE if obeys with weak or strict equality
        #   keepbools[rowind] <- all(rank( krow , ties.method = "min") <= rankvec_t)
        #   strictbools[rowind] <- all(rank( krow , ties.method = "min") == rankvec_t)
        #
        # }
        #
        # #this might not be optimal if want to preserve ordering of combinations
        # kcomb_strict_mat <- kcomb_vec_mat[strictbools, ]
        # kcomb_weak_mat <- kcomb_vec_mat[keepbools & (!strictbools), ]
        #
        #
        #
        # # free up some memory ?
        # rm(kcomb_vec_mat)
        #
        # # perhaps need to keep track of k1, k2, k3, etc
        #
        # n_strict <- nrow(kcomb_strict_mat)
        # n_weak <- nrow(kcomb_weak_mat)
        #
        # #
        # qkt_mat <- rbind(kcomb_strict_mat, kcomb_weak_mat)
        #
        #
        # # free up some memory ?
        # rm(kcomb_strict_mat, kcomb_weak_mat)
        #
        # #last column be integral values
        # qkt_mat <- cbind(qkt_mat, rep(NA, nrow(qkt_mat)))
        #
        # lastcol_ind <- ncol(qkt_mat)
        # # now fill in values of qkt_mat
        #
        # for(rowind in 1:n_strict ){
        #
        #   #obeys constraint exactly, so just take product of univariate normal integrals
        #
        #   tempintegralval <- 1
        #   # Product of pnorm() interval values with
        #   for(k_index in 1:(lastcol_ind-1)){
        #     ktemp <- qkt_mat[rowind,k_index]
        #     tempmean <- intersectmat[ktemp,1]
        #     templower <- intersectmat[ktemp,2]
        #     tempupper <- intersectmat[ktemp,3]
        #
        #     onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
        #     tempintegralval <- tempintegralval*onedim_int
        #
        #   }
        #
        #   qkt_mat[rowind,lastcol_ind] <- tempintegralval#include product here
        #
        # }
        # for(rowind in 1:n_weak ){
        #
        #   #apply method of Gessner et al
        #   qkt_mat[n_strict+ rowind,lastcol_ind] <- notcalculatedyet#include product here
        #
        # }


        print("qkt loop, t = ")
        print(t)

        qkt_list[[t]] <- qkt_vec




        # update tmin1 intersection matrices
        # for next round
        # if(itemcovars == FALSE){
        intersectmat_tmin1 <- intersectmat

        # }else{
        #   list_item_intersectmats_tmin1 <- list_item_intersectmats
        #
        # }


        # rankconstraint_tmin1 <- rank_cons_arr[,,t]

        if(t < n.time+1){
          rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t]


          A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)

          tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)

        }



      } # END LOOP OVER t, finished creating qkt_list

      ###### beginning nkt calculations ####################################################

      # loop backwards over time periods

      # begin with special cases t=T and t = T-1

      # t = T

      # obtain ordering for time T
      rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]

      ##### Consider creating and storing all rank constraints outside of Gibbs sampler################
      # this will save computational time
      # and possibly require a lot of memory?

      rankconstraint_t <- matrix(0,
                                 nrow = length(rankvec_t)-1,
                                 ncol = length(rankvec_t))


      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        # rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1
      }


      rankconstraint_T <- rankconstraint_t

      # The smoothing distribution coincides with the filtering distribution

      # Calculate the necessary values to compute the weights of the mixture distribution


      # nkt_vec is a vector of integrals for regions-specific parameters k
      # the integrals are constrained by the ranker and time specific sets A_{i,t}
      # where A_{i,t} is defined by the ordering of the ranks given by ranker i at time t

      # requires:
      # 1. ranker and time specific rankings
      # 2. vector of mean parameters for all possible regions defined by the sum-of-tree structure


      # create intersection matrices


      # # create vector of indices for ranker indiv in time period T
      # ind_start <- (n.time - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
      # ind_end <- (n.time - 1)*n.ranker*n.item+n.item*indiv
      # obs_indices <- ind_start:ind_end

      # if(itemcovars == FALSE){
      #
      #
      #   list_inter_mats <- list()
      #
      #   for(i in 1:n.trees){
      #
      #     treeexample1 <- sampler$getTrees(treeNums = i,
      #                                       chainNums = 1,
      #                                       sampleNums = 1)
      #
      #     rebuilt_tree <- rebuildTree2(treeexample1, sampler)
      #
      #
      #     #must use covariates for individual indiv at time period t
      #
      #     list_inter_mats[[i]] <- getPredictionsRangesForTree2(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )
      #
      #
      #   }
      #
      #   intersectmat <- interNtreesB(list_inter_mats)
      #
      #
      # }else{ # itemcovars == TRUE
      #
      #
      #   list_item_intersectmats <- list()
      #
      #   for(index_item in 1:n.item){
      #
      #     obs_one_ind <- (n.time - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item
      #
      #     list_inter_mats <- list()
      #
      #     for(i in 1:n.trees){
      #
      #       treeexample1 <- sampler$getTrees(treeNums = i,
      #                                         chainNums = 1,
      #                                         sampleNums = 1)
      #
      #       rebuilt_tree <- rebuildTree2(treeexample1, sampler)
      #
      #
      #       #must use covariates for individual indiv at time period t
      #
      #       list_inter_mats[[i]] <- getPredictionsRangesForTree2(rebuilt_tree, as.matrix(df_for_dbart$x[obs_indices[1]]) )
      #
      #
      #     } #end loop over trees
      #
      #     intersectmat <- interNtreesB(list_inter_mats)
      #
      #     list_item_intersectmats[[index_item]] <- intersectmat
      #
      #
      #   } #end loop over items
      #
      # } # end else itemcovars == TRUE


      # obtain intersections



      ########### calculate nkt for t = T ########################################


      # If regions vary across time
      # Then nktvec and qkt vec are time-specific
      # NOT JUST THROUGH dependence on observed ranks at time t
      # also through time-specific k

      # if covariates are item-specific, then the
      # combinations of regions, k involve
      # item-specific ranges of regions

      # in either case, must loop through combinations of regions
      # there are some possible symmetries
      # IGNORE SYMMETRIES



      #there are n.item*nrow(intersectmat) possible regions

      # create list of vectors of indices for k1, k2, ..., k_{n.item}
      # to be used as input to expand.grid

      #straightforward for itemcovars == FALSE

      # K_ind_list <-list()
      #
      # for(index_item in 1:n.item){
      #   K_ind_list[[index_item]] <- 1:nrow(intersectmat)
      # }
      #
      # # there are many possible combinations
      # # this might produce a huge matrix
      # # not the most efficeient way of coding this
      # kcomb_vec_mat <- expand.grid(K_ind_list)


      print("Line 2006")

      nkt_vec <- rep(NA, nrow(kcomb_vec_mat))
      # rm(kcomb_vec_mat)


      for(rowind in 1:length(nkt_vec) ){

        #obtain means
        #vector k1, k2, k3, etc
        k_indvec <- kcomb_vec_mat[rowind,]

        #note: k_indvec can include repeated values
        tempmeans <- intersectmat[k_indvec,1]

        # templowers <- intersectmat[k_indvec,2]
        # tempuppers <- intersectmat[k_indvec,3]


        # Apply methods of Gessner et al

        # create matrix A, vector b

        # for nkt_mat calcultions, the only constraint is the rank order A_t
        # so

        # A matrix is rankconstraint_t
        # original b vector is vector of zeros
        # However must shift the constraints as outlined in the paper
        # the mu vector is tempmeans
        # Therefore the shifted b vector is
        # t(rankconstraint_t)%*%tempmeans

        bvec_temp <- (rankconstraint_t)%*%tempmeans



        # NOTE: The SubsetSimFast and HDR_algoFast functions
        # use the transpose of the constraint matrix as an input

        # sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
        #                                           bvec_temp,
        #                                           N_hdr,
        #                                           rho_hdr )


        sub_retFast <- tryCatch(LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                           bvec_temp,
                                                           N_hdr,
                                                           rho_hdr ),
                                error = function(e){

                                  print("tempmeans = ")
                                  print(tempmeans)

                                  print("rankconstraint_t = ")
                                  print(rankconstraint_t)


                                  print("bvec_temp = ")
                                  print(bvec_temp)

                                  print("k_indvec = ")
                                  print(k_indvec)

                                  print("N_hdr = ")
                                  print(N_hdr)

                                  # print("rho_hdr = ")
                                  # print(rho_hdr)
                                  #
                                  # print("tempmeans= ")
                                  # print(tempmeans)
                                  #
                                  # print("bvec = ")
                                  # print(bvec)
                                  #
                                  #
                                  # krow <- kcomb_vec_mat[rowind,]
                                  #
                                  # keepbool <- all(rank( krow , ties.method = "min") <= rankvec_tmin1)
                                  #
                                  #
                                  # print("krow = ")
                                  # print(krow)
                                  #
                                  # print("t = ")
                                  # print(t)
                                  #
                                  # print("rankvec_tmin1 = ")
                                  # print(rankvec_tmin1)
                                  #
                                  #
                                  # print("rankconstraint_tmin1 = ")
                                  # print(rankconstraint_tmin1)
                                  #
                                  # print("rank( krow , ties.method = min) = ")
                                  # print(rank( krow , ties.method = "min"))
                                  #
                                  # print("keepbool = ")
                                  # print(keepbool)
                                  #
                                  #
                                  # print("Error message = ")
                                  # print(e)
                                  stop("error in SubsetSimFast")


                                }
        )

        hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                 bvec_temp,
                                                 c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                 N_hdr )

        #Probability Estimate from subset simulation
        # exp(sub_retFast$logZ)

        #Probability Estimate from HDR
        tempintegralval <- exp(hdr_retFast)




        # for(k_index in 1:(lastcol_ind-1)){
        #       ktemp <- nkt_mat[rowind,k_index]
        #       tempmean <- intersectmat[ktemp,1]
        #       templower <- intersectmat[ktemp,2]
        #       tempupper <- intersectmat[ktemp,3]
        #
        #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
        #       tempintegralval <- tempintegralval*onedim_int
        # }

        #Save integral result
        nkt_vec[ rowind] <- tempintegralval#include product here

      }



      # intersectmat_T <- NA
      # list_item_intersectmats_T <- NA

      # if(itemcovars == TRUE){
      intersectmat_T <- intersectmat

      # }else{
      #   list_item_intersectmats_T <- list_item_intersectmats
      # }


      nkt_vec_T <- nkt_vec

      print("Line 2519")


      ######### calculate wkt for T ###########################################

      # Then calculate weights

      temp_qkt_vec <- qkt_list[[n.time]]

      wkt_vec <- temp_qkt_vec*nkt_vec
      # normalize
      wkt_vec <- wkt_vec/sum(wkt_vec)

      if(any(is.na((wkt_vec)))){
        print("temp_qkt_vec*nkt_vec = ")
        print(temp_qkt_vec*nkt_vec)

        print("temp_qkt_vec = ")
        print(temp_qkt_vec)

        print("nkt_vec = ")
        print(nkt_vec)

        print("sum(temp_qkt_vec*nkt_vec) = ")
        print(sum(temp_qkt_vec*nkt_vec))

        print("wkt_vec = ")
        print(wkt_vec)


      }


      # sample an index vector k
      component_ind <- sample.int(length(wkt_vec),
                                  size = 1,
                                  replace = FALSE,
                                  prob = wkt_vec)

      ####### Sample for T given component ###########################

      # Now draw from corresponding truncated normal distribution
      # with means mu_k
      # and constraint matrix rankconstraint_t

      # lastcol_ind <- ncol(nkt_mat)
      k_indvec <- kcomb_vec_mat[component_ind,]

      #note: k_indvec can include repeated values
      tempmeans <- intersectmat[k_indvec,1]

      bvec_temp <- (rankconstraint_t)%*%tempmeans

      # require an initial value in the domain
      # arbitrarily set lowest to 10/n.item
      # then add 10/n.item for each

      # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

      # z_init <- rep(NA, n.item)
      #
      # # This can probably be vectorized
      # for(z_ind in 1:n.item){
      #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
      # }

      # or is a random sample required?
      # z_init <- rep(0, n.item)

      # z_init<- rnorm(n.item)
      z_init<- rnorm(n = n.item, mean = -1* tempmeans)

      if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
        # in domain
        # print("in domain")
      }else{
        # stop("Error. Initial vector not in domain")

        # perhaps take random samples until a point is found in the doain
        # ElilipticalSliceSampler python function might do something like this
        # at least if there is not any initial value

        while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
          print("not in domain. Sample x0 again")

          # x0 <- rnorm(length(z_init))
          z_init<- rnorm(n.item)

          # x0 <- xnew
        }
      }


      # Take 100 samples, then just use last column
      # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
      z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                  bvec_temp,
                                  Num_lin_ess_samples,
                                  z_init,
                                  nskip = 0)

      #save sample

      #note: must add mean
      Z.mat[,(n.time-1)*n.ranker + indiv] <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans



      ######## Sample Z for T-1 ######################################################

      ######## ranks, intersections for T-1 ######################################################

      # t = T-1

      # obtain ordering for time T-1
      rankvec_t <- ranks_mat[,  (n.time-1-1)*n.ranker + indiv]


      ##### Consider creating and storing all rank constraints outside of Gibbs sampler################
      # this will save computational time
      # and possibly require a lot of memory?

      rankconstraint_t <- matrix(0,
                                 nrow = length(rankvec_t)-1,
                                 ncol = length(rankvec_t))


      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        # rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1

      }


      # The smoothing distribution coincides with the filtering distribution

      # Calculate the necessary values to compute the weights of the mixture distribution


      # nkt_vec is a vector of integrals for regions-specific parameters k
      # the integrals are constrained by the ranker and time specific sets A_{i,t}
      # where A_{i,t} is defined by the ordering of the ranks given by ranker i at time t

      # requires:
      # 1. ranker and time specific rankings
      # 2. vector of mean parameters for all possible regions defined by the sum-of-tree structure


      # create intersection matrices
      # note that intersection matrices can be time period specific if allow for time period specific covariates

      # # create vector of indices for ranker indiv in time period T
      # ind_start <- (n.time -1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
      # ind_end <- (n.time -1 - 1)*n.ranker*n.item+n.item*indiv
      # obs_indices <- ind_start:ind_end


      intersectmat_Tmin1 <- intersectmat


      #will use this for r_{\K^T}^{(T)}


      nkt_vec_T <- nkt_vec




      ###########  calculate nkt for t = T - 1 ########################################


      # If regions vary across time
      # Then nktvec and qkt vec are time-specific
      # NOT JUST THROUGH dependence on observed ranks at time t
      # also through time-specific k

      # if covariates are item-specific, then the
      # combinations of regions, k involve
      # item-specific ranges of regions

      # in either case, must loop through combinations of regions
      # there are some possible symmetries
      # IGNORE SYMMETRIES


      print("Line 2695")

      #there are n.item*nrow(intersectmat) possible regions

      # create list of vectors of indices for k1, k2, ..., k_{n.item}
      # to be used as input to expand.grid

      #straightforward for itemcovars == FALSE

      nkt_vec <- rep(NA, nrow(kcomb_vec_mat))

      for(rowind in 1:length(nkt_vec) ){

        #obtain means
        #vector k1, k2, k3, etc
        k_indvec <- kcomb_vec_mat[rowind,]

        #note: k_indvec can include repeated values
        tempmeans <- intersectmat[k_indvec,1]

        # templowers <- intersectmat[k_indvec,2]
        # tempuppers <- intersectmat[k_indvec,3]


        # Apply methods of Gessner et al

        # create matrix A, vector b

        # for nkt_mat calcultions, the only constraint is the rank order A_t
        # so

        # A matrix is rankconstraint_t
        # original b vector is vector of zeros
        # However must shift the constraints as outlined in the paper
        # the mu vector is tempmeans
        # Therefore the shifted b vector is
        # (rankconstraint_t)%*%tempmeans

        bvec_temp <- (rankconstraint_t)%*%tempmeans



        # NOTE: The SubsetSimFast and HDR_algoFast functions
        # use the transpose of the constraint matrix as an input
        #
        #         sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
        #                                                   bvec_temp,
        #                                                   N_hdr,
        #                                                   rho_hdr )

        sub_retFast <- tryCatch(LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                           bvec_temp,
                                                           N_hdr,
                                                           rho_hdr ),
                                error = function(e){

                                  print("tempmeans = ")
                                  print(tempmeans)

                                  print("rankconstraint_t = ")
                                  print(rankconstraint_t)


                                  print("bvec_temp = ")
                                  print(bvec_temp)

                                  print("k_indvec = ")
                                  print(k_indvec)

                                  print("N_hdr = ")
                                  print(N_hdr)

                                  # print("rho_hdr = ")
                                  # print(rho_hdr)
                                  #
                                  # print("tempmeans= ")
                                  # print(tempmeans)
                                  #
                                  # print("bvec = ")
                                  # print(bvec)
                                  #
                                  #
                                  # krow <- kcomb_vec_mat[rowind,]
                                  #
                                  # keepbool <- all(rank( krow , ties.method = "min") <= rankvec_tmin1)
                                  #
                                  #
                                  # print("krow = ")
                                  # print(krow)
                                  #
                                  # print("t = ")
                                  # print(t)
                                  #
                                  # print("rankvec_tmin1 = ")
                                  # print(rankvec_tmin1)
                                  #
                                  #
                                  # print("rankconstraint_tmin1 = ")
                                  # print(rankconstraint_tmin1)
                                  #
                                  # print("rank( krow , ties.method = min) = ")
                                  # print(rank( krow , ties.method = "min"))
                                  #
                                  # print("keepbool = ")
                                  # print(keepbool)
                                  #
                                  #
                                  # print("Error message = ")
                                  # print(e)
                                  stop("error in SubsetSimFast")


                                }
        )


        hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                 bvec_temp,
                                                 c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                 N_hdr )

        #Probability Estimate from subset simulation
        # exp(sub_retFast$logZ)

        #Probability Estimate from HDR
        tempintegralval <- exp(hdr_retFast)




        # for(k_index in 1:(lastcol_ind-1)){
        #       ktemp <- nkt_mat[rowind,k_index]
        #       tempmean <- intersectmat[ktemp,1]
        #       templower <- intersectmat[ktemp,2]
        #       tempupper <- intersectmat[ktemp,3]
        #
        #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
        #       tempintegralval <- tempintegralval*onedim_int
        # }

        #Save integral result
        nkt_vec[ rowind ] <- tempintegralval#include product here

      }


      nkt_vec_Tmin1 <- nkt_vec


      ######## Calculate mkt_mat for T-1 ######################################################

      # For all indices K^T correpsponding to possible sets in time period T
      # calculate r_{\K^T}^{(T)}
      # and r_{\K^T, \K^{(T-1)}}^{(T-1)}

      # First note that r_{\K^T}^{(T)} is nkt_mat for period T row \K, last column


      # For r_{\K^T, \K^{(T-1)}}^{(T-1)}
      # Could probably save values from qkt calculations

      # For now, will just try to save all


      rankvec_tmin1 <- ranks_mat[,  (n.time-1-1)*n.ranker + indiv]

      rankconstraint_tmin1 <- rank_cons_arr[, , indiv, n.time-1]


      A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)

      tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)

      #create mkt mat for time period T-1
      # mkt_mat <- nkt_mat
      #last column contains values
      # mkt_mat[,ncol(mkt_mat)] <- rep(NA, nrow(mkt_mat))


      #actually just need a vector, do not need a new matrix
      mkt_vec <- rep(0, length(nkt_vec))

      # now loop over elements, corresponding to time T-1 and fill in values
      print("Line 2874")

      for(k_t_min1 in 1:length(nkt_vec_Tmin1)){

        #now will calculate a sum over k^T of products
        # r_{\K^T, \K^{(T-1)}}^{(T-1)} * r_{\K^T}^{(T)}

        # obtain means corresponding to k_t_min1

        # obtain indices
        k_tmin1_indvec <- kcomb_vec_mat[k_t_min1,]

        # obtain means

        tempmeans <- intersectmat_Tmin1[k_tmin1_indvec,1]



        # assuming intersection matrix is still defined for period T-1?
        temp_sum <- 0

        for(k_t_ind in 1:length(nkt_vec_T)){
          # calculate  r_{\K^T, \K^{(T-1)}}^{(T-1)}

          # similar to corresponding integral for qkt

          # obtain lower and upper bounds corresponding to k_t_ind

          # obtain indices
          k_t_indvec <- kcomb_vec_mat[k_t_ind,]


          #obtain lower and upper bound vectors
          templowers <- intersectmat_T[k_t_indvec,2]
          tempuppers <- intersectmat_T[k_t_indvec,3]


          krow <- k_t_indvec #kcomb_vec_mat[rowind,]

          # check if time period T regions, indexed by k_t_indvec
          # are guaranteed to satisfy or not satisfy the constraint implied
          # by period T-1 observed ranks

          # current rankvec_t correponds to T-1


          keepbool <- all(rank( krow , ties.method = "min") <= rankvec_tmin1)

          temp_integral <- NA

          if(keepbool == FALSE){
            temp_integral <- 0
            # add nothing to the sum
            next
          }


          strictbool <- all(rank( krow , ties.method = "min") == rankvec_tmin1)

          if(strictbool == TRUE){
            temp_integral <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

            temp_sum <- temp_sum + nkt_vec_T[k_t_ind]*temp_integral
            next

          }

          # t(diag(1,3, 3) %x% c(1,-1))

          # A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)
          #
          # tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)


          #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT

          # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
          # and for each pair of bounds, the first is the negative of the uper bound
          # and the second is the upper bound

          # jumps of 2 from n.item to 3*n.item - 2
          lb_inds <- n.item - 2 + 2*(1:n.item)
          # jumps of 2 from n.item + 1 to 3*n.item - 1
          ub_inds <- n.item - 1+ 2*(1:n.item)


          bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
          bvec[lb_inds] <- -1*templowers
          bvec[ub_inds] <- tempuppers

          # must shift the constraint

          # obtain mean vector from t-1 corresponding to m_ind

          # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
          # tempmeans <- intersectmat_tmin1[m_inds,1]

          bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans

          # NOTE: The SubsetSimFast and HDR_algoFast functions
          # use the transpose of the constraint matrix as an input

          # sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
          #                                           bvec_temp,
          #                                           N_hdr,
          #                                           rho_hdr )

          sub_retFast <- tryCatch(LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                             bvec_temp,
                                                             N_hdr,
                                                             rho_hdr ),
                                  error = function(e){

                                    print("tempmeans = ")
                                    print(tempmeans)

                                    print("tA_Cktmin1_constraint = ")
                                    print(tA_Cktmin1_constraint)


                                    print("bvec_temp = ")
                                    print(bvec_temp)

                                    print("k_t_indvec = ")
                                    print(k_t_indvec)

                                    print("N_hdr = ")
                                    print(N_hdr)

                                    # print("rho_hdr = ")
                                    # print(rho_hdr)
                                    #
                                    # print("tempmeans= ")
                                    # print(tempmeans)
                                    #
                                    # print("bvec = ")
                                    # print(bvec)
                                    #
                                    #
                                    # krow <- kcomb_vec_mat[rowind,]
                                    #
                                    # keepbool <- all(rank( krow , ties.method = "min") <= rankvec_tmin1)
                                    #
                                    #
                                    # print("krow = ")
                                    # print(krow)
                                    #
                                    # print("t = ")
                                    # print(t)
                                    #
                                    # print("rankvec_tmin1 = ")
                                    # print(rankvec_tmin1)
                                    #
                                    #
                                    # print("rankconstraint_tmin1 = ")
                                    # print(rankconstraint_tmin1)
                                    #
                                    # print("rank( krow , ties.method = min) = ")
                                    # print(rank( krow , ties.method = "min"))
                                    #
                                    # print("keepbool = ")
                                    # print(keepbool)
                                    #
                                    #
                                    # print("Error message = ")
                                    # print(e)
                                    stop("error in SubsetSimFast")


                                  }
          )


          hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                   bvec_temp,
                                                   c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                   N_hdr )

          #Probability Estimate from subset simulation
          # exp(sub_retFast$logZ)

          #Probability Estimate from HDR
          temp_integral <- exp(hdr_retFast)


          temp_sum <- temp_sum + nkt_vec_T[k_t_ind]*temp_integral

          if(is.na(temp_sum)){
            print("temp_integral = ")
            print(temp_integral)

            print("nkt_vec_T[k_t_ind] = ")
            print(nkt_vec_T[k_t_ind])

            print("k_t_ind = ")
            print(k_t_ind)

            print("k_t_min1 = ")
            print(k_t_min1)



            print("hdr_retFast = ")
            print(hdr_retFast)


            print("tA_Cktmin1_constraint = ")
            print(tA_Cktmin1_constraint)


            print("bvec_temp = ")
            print(bvec_temp)


            print("c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0) = ")
            print(c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0))

            print("sub_retFast$shift_seq = ")
            print(sub_retFast$shift_seq)


            print("tempmeans = ")
            print(tempmeans)


            stop("is.na(temp_sum)")


          }


        }


        if(is.na(temp_sum)){
          print("temp_integral = ")
          print(temp_integral)

          print("nkt_vec_T[k_t_ind] = ")
          print(nkt_vec_T[k_t_ind])

          print("k_t_min1 = ")
          print(k_t_min1)


        }


        mkt_vec[k_t_min1] <- temp_sum

      }




      print("Line 3096")

      ####### Calculate wkt for T-1 smoothing distribution ##################


      ######### calculate wktS for T-1 ###########################################

      # Then calculate weights

      temp_qkt_vec <- qkt_list[[n.time-1]]

      wktS_vec <- temp_qkt_vec*mkt_vec
      # normalize
      wktS_vec <- wktS_vec/sum(wktS_vec)

      if(any(is.na(wktS_vec))){

        print("wktS_vec = ")
        print(wktS_vec)

        print("temp_qkt_vec = ")
        print(temp_qkt_vec)

        print("mkt_vec = ")
        print(mkt_vec)

        print("nkt_vec_T = ")
        print(nkt_vec_T)

        print("temp_qkt_vec*mkt_vec = ")
        print(temp_qkt_vec*mkt_vec)

      }

      # sample an index vector k
      component_ind <- sample.int(length(wktS_vec),
                                  size = 1,
                                  replace = FALSE,
                                  prob = wktS_vec)

      #
      # ######### calculate wktF for T-1 ###########################################
      #
      # # Then calculate weights
      #
      # # temp_qkt_mat <- qkt_list[[n.time-1]]
      #
      # wktF_vec <- temp_qkt_mat[, ncol(temp_qkt_mat)]*nkt_mat_Tmin1[ ,ncol(nkt_mat_Tmin1)]
      # # normalize
      # wktF_vec <- sum(wktF_vec)
      #
      # # sample an index vector k
      # component_ind <- sample.int(length(wktF_vec),
      #                         size = 1,
      #                         replace = FALSE,
      #                         prob = wktF_vec)
      #
      # lastcol_ind <- ncol(nkt_mat_Tmin1)
      #
      #
      #

      # The component sample is fixed. Just the distribution conditional on the component is sampled by AR or MH

      ####### Sample for T - 1 given component ###########################


      # Sampling from the filtering distribution as proposal distribution for
      # both AR and MH methods
      # There is probably a more efficient way of writing this

      if(smoothing_method == "AR"){

        # Accept-Reject sampling

        #Aside: perhaps useful to know M= nkt/mkt

        print("Perhaps useful to know M = nkt/mkt = ")
        print(nkt_vec_Tmin1[ component_ind] / mkt_vec[component_ind])


        accepted <- FALSE

        while(accepted == FALSE){

          # Sample from the filtering distribution



          ####### Filtering Proposal Sample for T-1 given component ###########################

          # Now draw from corresponding truncated normal distribution
          # with means mu_k
          # and constraint matrix rankconstraint_t

          k_indvec <- kcomb_vec_mat[component_ind,]


          #note: k_indvec can include repeated values
          tempmeans <- intersectmat_Tmin1[k_indvec,1]


          # current rankconstraint_t corresponds to T-1

          bvec_temp <- (rankconstraint_t)%*%tempmeans

          # require an initial value in the domain
          # arbitrarily set lowest to 10/n.item
          # then add 10/n.item for each

          # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

          # z_init <- rep(NA, n.item)
          #
          # # This can probably be vectorized
          # for(z_ind in 1:n.item){
          #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
          # }

          # or is a random sample required?
          # z_init <- rep(0, n.item)
          # z_init<- rnorm(n.item)
          z_init<- rnorm(n = n.item, mean = -1* tempmeans)

          if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
            # in domain
            # print("in domain")
          }else{
            # stop("Error. Initial vector not in domain")

            # perhaps take random samples until a point is found in the doain
            # ElilipticalSliceSampler python function might do something like this
            # at least if there is not any initial value

            while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
              print("not in domain. Sample x0 again")

              # x0 <- rnorm(length(z_init))
              z_init<- rnorm(n.item)

              # x0 <- xnew
            }
          }


          # Take 100 samples, then just use last column
          # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
          z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                      bvec_temp,
                                      Num_lin_ess_samples,
                                      z_init,
                                      nskip = 0)

          #save Z values sampled from proposal


          z_prop_vec <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans


          ####### Uniform sample ###########################

          # sample from the uniform distribution

          u_temp <- runif(n = 1)


          ####### Calculate Acceptance Prob T-1 ###########################


          #calculate acceptance probability given choice of M = nkt/mkt

          # acceptance probability equals r_t(z_t)
          # here t = T-1

          # first, must obtain means corresponding to predictions given covariates and z_prop_vec
          # and covariate observations in time period T


          # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

          # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

          obs_inds <- (n.time - 1 )*n.ranker*n.item+n.item*(indiv-1) + 1:n.item

          # # df_for_dbart$x
          #
          # # temp_df <- data.frame(x = cbind( z_prop_vec, df_for_dbart$x[obs_inds, 2:ncol(df_for_dbart$x), drop = FALSE] ) )
          # temp_df <- data.frame(x = z_prop_vec  )
          #
          # tempmeans <- sampler$predict(temp_df)
          #
          # # use period T rank constraint rankconstraint_T
          # # for t < T-1 might have to save rankconstraint_t, rankconstraint_tplus1, and maybe rankconstraint_tmin1
          # # or even all rank constraints in one big array
          #
          # # integral calculation is essentially the same as nkT with different means
          #
          #
          #
          # ##### INCLUDING BOTH CALCULATIONS FOR TEST
          #
          #
          # bvec_temp <- (rankconstraint_T)%*%tempmeans
          #
          #
          # # NOTE: The SubsetSimFast and HDR_algoFast functions
          # # use the transpose of the constraint matrix as an input
          #
          # sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_T),
          #                                           bvec_temp,
          #                                           N_hdr,
          #                                           rho_hdr )
          #
          # hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_T),
          #                                          bvec_temp,
          #                                          c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
          #                                          N_hdr )
          #
          # #Probability Estimate from subset simulation
          # # exp(sub_retFast$logZ)
          #
          # #Probability Estimate from HDR
          # tempintegralval <- exp(hdr_retFast)
          #


          # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
          # a second time


          #attempt at alternative to integration


          r_Tmin1_zTmin1 <- NA


          kvectemp <- rep(NA, n.item)

          for(index_item in 1:n.item){

            # find row of intersectmat_T corresponding to
            # z_prop_vec[index_item]

            #ranges for zlag
            zranges <- c(-Inf, (intersectmat_T)[,3])

            tempinds <- which((zranges <z_prop_vec[index_item] ))

            #which is the last one below (count includes -inf, so gives row of correct interval)
            temp_ind <- tempinds[length(tempinds)]

            # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

            kvectemp[index_item] <- temp_ind # intersectmat_T[temp_ind,1]

          }

          # now find corresponding element of # nkt_vec_T

          rowind_temp <- which(apply(kcomb_vec_mat,
                                     1,
                                     function(x) all.equal(x, kvectemp)) == "TRUE")



          # print("kcomb_vec_mat = ")
          # print(kcomb_vec_mat)
          #
          #
          # print("kvectemp = ")
          # print(kvectemp)
          #
          # print("nkt_vec_T = ")
          # print(nkt_vec_T)
          #
          # print("nkt_vec_T[rowind_temp] = ")
          # print(nkt_vec_T[rowind_temp])
          #
          #
          # print("rowind_temp = ")
          # print(rowind_temp)

          #

          r_Tmin1_zTmin1 <- nkt_vec_T[rowind_temp]




          # if(r_Tmin1_zTmin1 == tempintegralval){
          #   print(" two methods for r_Tmin1_zTmin1 give the same value")
          #
          # }else{
          #
          #   print("r_Tmin1_zTmin1 = ")
          #   print(r_Tmin1_zTmin1)
          #
          #   print("tempintegralval = ")
          #   print(tempintegralval)
          #
          #   stop(" two methods for r_Tmin1_zTmin1 give diffferent values")
          #
          #
          #
          # }


          # accept or reject

          if(u_temp <= r_Tmin1_zTmin1){

            # accept
            Z.mat[,(n.time-1-1)*n.ranker + indiv] <- z_prop_vec
            accepted <- TRUE

          }else{

            # reject
            accepted <- FALSE

          }




        }# end while loop for Accept-Reject

      }else{ # Metropolis-Hastings sampler

        # Essentially the same as Accept-Reject code, except different acceptance probability
        # and not a while loop




        # Sample from the filtering distribution



        ####### Filtering Proposal Sample for T-1 given component ###########################

        # Now draw from corresponding truncated normal distribution
        # with means mu_k
        # and constraint matrix rankconstraint_t

        k_indvec <- nkt_vec_Tmin1[component_ind]


        #note: k_indvec can include repeated values
        tempmeans <- intersectmat_Tmin1[k_indvec,1]

        # current rankconstraint_t corresponds to T-1

        bvec_temp <- (rankconstraint_t)%*%tempmeans

        # require an initial value in the domain
        # arbitrarily set lowest to 10/n.item
        # then add 10/n.item for each

        # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

        # z_init <- rep(NA, n.item)
        #
        # # This can probably be vectorized
        # for(z_ind in 1:n.item){
        #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
        # }

        # or is a random sample required?
        # z_init <- rep(0, n.item)
        # z_init<- rnorm(n.item)
        z_init<- rnorm(n = n.item, mean = -1* tempmeans)

        if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
          # in domain
          # print("in domain")
        }else{
          # stop("Error. Initial vector not in domain")

          # perhaps take random samples until a point is found in the doain
          # ElilipticalSliceSampler python function might do something like this
          # at least if there is not any initial value

          while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
            print("not in domain. Sample x0 again")

            # x0 <- rnorm(length(z_init))
            z_init<- rnorm(n.item)

            # x0 <- xnew
          }
        }


        # Take 100 samples, then just use last column
        # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
        z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                    bvec_temp,
                                    Num_lin_ess_samples,
                                    z_init,
                                    nskip = 0)

        #save Z values sampled from proposal

        z_prop_vec <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans


        ####### Uniform sample ###########################

        # sample from the uniform distribution

        u_temp <- runif(n = 1)


        ####### Calculate Acceptance Prob T-1 ###########################


        #calculate acceptance probability given choice of M = nkt/mkt

        # acceptance probability equals r_t(z_t)
        # here t = T-1

        # first, must obtain means corresponding to predictions given covariates and z_prop_vec
        # and covaraite observations in time period T


        # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

        # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

        obs_inds <- (n.time - 1 )*n.ranker*n.item+n.item*(indiv-1) + 1:n.item

        # # df_for_dbart$x
        #
        # # temp_df <- data.frame(x = cbind( z_prop_vec, df_for_dbart$x[obs_inds, 2:ncol(df_for_dbart$x), drop = FALSE] ) )
        # temp_df <- data.frame(x =  z_prop_vec )
        #
        # tempmeans <- sampler$predict(temp_df)
        #
        # # use period T rank constraint rankconstraint_T
        # # for t < T-1 might have to save rankconstraint_t, rankconstraint_tplus1, and maybe rankconstraint_tmin1
        # # or even all rank constraints in one big array
        #
        # # integral calculation is essentially the same as nkT with different means
        #
        #
        #
        # ##### INCLUDING BOTH CALCULATIONS FOR TEST
        #
        #
        # bvec_temp <- (rankconstraint_T)%*%tempmeans
        #
        #
        # # NOTE: The SubsetSimFast and HDR_algoFast functions
        # # use the transpose of the constraint matrix as an input
        #
        # sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_T),
        #                                           bvec_temp,
        #                                           N_hdr,
        #                                           rho_hdr )
        #
        # hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_T),
        #                                          bvec_temp,
        #                                          c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
        #                                          N_hdr )
        #
        # #Probability Estimate from subset simulation
        # # exp(sub_retFast$logZ)
        #
        # #Probability Estimate from HDR
        # tempintegralval <- exp(hdr_retFast)


        # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
        # a second time


        #attempt at alternative to integration


        r_Tmin1_zTmin1 <- NA


        kvectemp <- rep(NA, n.item)

        for(index_item in 1:n.item){

          # find row of intersectmat_T corresponding to
          # z_prop_vec[index_item]

          #ranges for zlag
          zranges <- c(-Inf, (intersectmat_T)[,3])

          tempinds <- which((zranges < z_prop_vec[index_item] ))

          #which is the last one below (count includes -inf, so gives row of correct interval)
          temp_ind <- tempinds[length(tempinds)]

          # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

          kvectemp[index_item] <- temp_ind # intersectmat_T[temp_ind,1]

        }

        # now find corresponding row of #   nkt_mat_T

        rowind_temp <- which(apply(kcomb_vec_mat,
                                   1,
                                   function(x) all.equal(x, kvectemp)) == "TRUE")


        #

        r_Tmin1_zTmin1 <- nkt_vec_T[rowind_temp]


        # if(r_Tmin1_zTmin1 == tempintegralval){
        #   print(" two methods for r_Tmin1_zTmin1 give the same value")
        #
        # }else{
        #
        #   print("r_Tmin1_zTmin1 = ")
        #   print(r_Tmin1_zTmin1)
        #
        #   print("tempintegralval = ")
        #   print(tempintegralval)
        #
        #   stop(" two methods for r_Tmin1_zTmin1 give diffferent values")
        #
        #
        #
        # }


        # for denominator of acceptance ratio,
        # can NOT save values in previous iteration of Gibbs sampler becasuet eh tree structures change.
        # Therefore, must recalculate in each iteration

        #

        z_old_vec <- Z.mat[,(n.time-1-1)*n.ranker + indiv]

        # temp_df <- data.frame(x = cbind( z_old_vec, df_for_dbart$x[obs_inds, 2:ncol(df_for_dbart$x), drop = FALSE] ) )

        # temp_df <- data.frame(x = z_old_vec )
        #
        #
        # tempmeans <- sampler$predict(temp_df)
        #
        # # use period T rank constraint rankconstraint_T
        # # for t < T-1 might have to save rankconstraint_t, rankconstraint_tplus1, and maybe rankconstraint_tmin1
        # # or even all rank constraints in one big array
        #
        # # integral calculation is essentially the same as nkT with different means
        #
        #
        #
        # ##### INCLUDING BOTH CALCULATIONS FOR TEST
        #
        #
        # bvec_temp <- (rankconstraint_T)%*%tempmeans
        #
        #
        # # NOTE: The SubsetSimFast and HDR_algoFast functions
        # # use the transpose of the constraint matrix as an input
        #
        # sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_T),
        #                                           bvec_temp,
        #                                           N_hdr,
        #                                           rho_hdr )
        #
        # hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_T),
        #                                          bvec_temp,
        #                                          c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
        #                                          N_hdr )
        #
        # #Probability Estimate from subset simulation
        # # exp(sub_retFast$logZ)
        #
        # #Probability Estimate from HDR
        # tempintegralval <- exp(hdr_retFast)


        # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
        # a second time


        #attempt at alternative to integration


        r_Tmin1_zTmin1_denom <- NA


        kvectemp <- rep(NA, n.item)

        for(index_item in 1:n.item){

          # find row of intersectmat_T corresponding to
          # z_old_vec[index_item]

          #ranges for zlag
          zranges <- c(-Inf, (intersectmat_T)[,3])

          tempinds <- which((zranges <z_old_vec[index_item] ))

          #which is the last one below (count includes -inf, so gives row of correct interval)
          temp_ind <- tempinds[length(tempinds)]

          # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

          kvectemp[index_item] <- temp_ind # intersectmat_T[temp_ind,1]

        }

        # now find corresponding row of # kcomb_vec_mat

        rowind_temp <- which(apply(kcomb_vec_mat,
                                   1,
                                   function(x) all.equal(x, kvectemp)) == "TRUE")


        #

        r_Tmin1_zTmin1_denom <- nkt_vec_T[rowind_temp]


        # if(r_Tmin1_zTmin1_denom == tempintegralval){
        #   print(" two methods for r_Tmin1_zTmin1_denom give the same value")
        #
        # }else{
        #
        #   print("r_Tmin1_zTmin1 = ")
        #   print(r_Tmin1_zTmin1_denom)
        #
        #   print("tempintegralval = ")
        #   print(tempintegralval)
        #
        #   stop(" two methods for r_Tmin1_zTmin1_denom give diffferent values")
        #
        # }


        ratio_temp <- r_Tmin1_zTmin1 / r_Tmin1_zTmin1_denom

        if(u_temp <= ratio_temp){

          # accept
          Z.mat[,(n.time-1-1)*n.ranker + indiv] <- z_prop_vec
          accepted <- TRUE

        }else{

          # reject
          # keep  z value from previous round

          # accepted <- FALSE

        }


        # stop("Metropolis-Hastings code not written yet")

      } # End else statement (corresponding to MH sampler )


      print("Line 3632")

      ##////////////////////////////////////////////////////////////////////////////////////
      ##////////////////////////////////////////////////////////////////////////////////////
      ######## Sample Z for t < T-1 ######################################################

      ##////////////////////////////////////////////////////////////////////////////////////
      ##////////////////////////////////////////////////////////////////////////////////////


      # Now sample for all other time periods


      # for t < T-1
      #makes more sense to calculate mkt values beginning at t=1 and increasing




      ######## Calculate mkt values ######################################################
      # Note: also gives all r_t(z_t) values
      # because r_t(z_t) is one of the m_{k,t+1} values


      # If necessary, can put this within the loop over (n.time-2):1

      # smoothing distribution is filtering distribution at time n.time
      # so do not need to calculate mkt at time T
      # therefore list is of length n.time -1

      # IF NEED TO SAVE MEMORY, JUST ADD A COLUMN TO ELEMENTS OF qkt_list ?
      # Or perhaps this does not save memory if just save mkt vectors

      mkt_list <- vector(mode = "list", length = n.time-1)

      mkt_list[[n.time-1]] <- mkt_vec

      num_k_t <- nrow(kcomb_vec_mat)
      num_ktp1 <- num_k_t #nrow(qkt_list[[t+1]])

      for(t in 1:(n.time -2)){


        rankvec_temp <- ranks_mat[,  (t-1)*n.ranker + indiv]

        #constraint is at time period t, not t minus 1
        rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t]


        A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)

        tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)

        # require all possible regions for each time period.
        # Can use qkt_list for this

        # k_index_matrix_t <- kcomb_vec_mat#qkt_list[[t]][,1:(ncol(qkt_list[[t]])-1)  ]
        #
        # num_k_t <- nrow(k_index_matrix_t)

        # two options:

        # 1. Save all save all r_{\k^{t+1},\k^{t}}^{(t)} for all \k^{t}
        # then iterate forward the summations up to the sum over \k^T
        # 2. Separately iterate over summations for each \k^{t}
        # actually a bit more complicated than this


        # will try first option because this involve less repetition of the same integrals.
        # However, if really wanted to avoid repetition of integrals
        # would save big multidimensional array outside of all loops of all possible values of
        # r_{\k^{t+1},\k^{t}}^{(t)} for all t

        # k_index_matrix_tp1 <- k_index_matrix_t # qkt_list[[t+1]][,1:(ncol(qkt_list[[t+1]])-1)  ]
        #
        # num_ktp1 <- num_k_t #nrow(qkt_list[[t+1]])

        rk_t_tp1_mat <- matrix(NA,
                               nrow = num_k_t,
                               ncol = num_ktp1)


        for(kt_ind in 1:num_k_t){

          krow_t <- kcomb_vec_mat[kt_ind, ]

          tempmeans <- intersectmat[krow_t,1]


          for(ktp1_ind in 1:num_ktp1 ){

            krow_tp1 <- kcomb_vec_mat[ktp1_ind, ]#kcomb_vec_mat[rowind,]


            # must agree with period t ranks

            keepbool <- all(rank( krow_tp1 , ties.method = "min") <= rankvec_temp)

            if(keepbool == FALSE){
              # qkt_mat[rowind,lastcol_ind] <- 0
              # integral is zero
              rk_t_tp1_mat[kt_ind, ktp1_ind] <- 0
              next
            }

            strictbool <- all(rank( krow_tp1 , ties.method = "min") == rankvec_temp)

            # k_indvec <- qkt_mat[rowind,1:(lastcol_ind-1)]


            # MUST OBTAIN INTERSECT MATRIX for t+1 (or append relevant elements to qkt)
            # might as well save within the qkt calcualtions

            templowers <- intersectmat[krow_tp1,2]
            tempuppers <- intersectmat[krow_tp1,3]

            # loop over previous time period

            # num_m_vecs <- nrow(qkt_list[[t-1]])
            # number of indices/regions
            # should be n.item ?
            # num_m_inds <- ncol(qkt_list[[t-1]])

            # qm_1min1_vec <- (qkt_list[[t-1]])[,ncol(qkt_list[[t-1]])]

            if(strictbool == TRUE){

              # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]

              # period t intersect matrix
              # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

              # tempintegralval <- 1
              #
              # # can probably vectorize this?
              # for(k_index in 1:(lastcol_ind-1)){
              #   ktemp <- k_indvec[k_index]
              #
              #   # tempmean <- intersectmat[ktemp,1]
              #
              #   tempmean <- tempmeans[k_index]
              #   templower <- templowers[k_index]
              #   tempupper <- tempuppers[k_index]
              #
              #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
              #   tempintegralval <- tempintegralval*onedim_int
              #
              # }

              # TEST
              tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

              rk_t_tp1_mat[kt_ind, ktp1_ind] <- tempintegralval
              # rest of code is for integrals bounded by the rank constraint

              # so can skip

              next
            }


            #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT


            # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
            # and for each pair of bounds, the first is the negative of the uper bound
            # and the second is the upper bound

            # jumps of 2 from n.item to 3*n.item - 2
            lb_inds <- n.item - 2 + 2*(1:n.item)
            # jumps of 2 from n.item + 1 to 3*n.item - 1
            ub_inds <- n.item - 1+ 2*(1:n.item)

            # print("Line 3282")

            bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
            bvec[lb_inds] <- -1*templowers
            bvec[ub_inds] <- tempuppers


            # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
            # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

            bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans

            # NOTE: The SubsetSimFast and HDR_algoFast functions
            # use the transpose of the constraint matrix as an input

            sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                      bvec_temp,
                                                      N_hdr,
                                                      rho_hdr )

            hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                     bvec_temp,
                                                     c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                     N_hdr )

            #Probability Estimate from subset simulation
            # exp(sub_retFast$logZ)

            #Probability Estimate from HDR
            tempintegralval <- exp(hdr_retFast)

            rk_t_tp1_mat[kt_ind, ktp1_ind] <- tempintegralval


            # rk_t_tp1_mat[kt_ind, ktp1_ind] <- TO BE CALCULATED

          } # end loop over ktp1_ind in 1:num_ktp1

          # rk_t_tp1_vec[kt_ind] <- TO BE CALCULATED

          # mkt_vec <- rep(NA, num_k_t)
          #
          # mkt_vec <- TO BE CALCULATED
          #
          # mkt_list[[t]] <- mkt_vec


        } # end loop over kt_ind in 1:num_kt



        # now must iterate forwards in time to create  mkt_vec

        # from t+2 up to T

        rankvec_temp <- ranks_mat[,  (t-1)*n.ranker + indiv]

        # require all possible regions for each time period.
        # Can use qkt_list for this

        # k_index_matrix_t <- kcomb_vec_mat#qkt_list[[t]][,1:(ncol(qkt_list[[t]])-1)  ]

        # num_k_t <- nrow(k_index_matrix_t)


        prev_mat <- rk_t_tp1_mat

        new_rk_t_pp1_mat <- NA

        num_k_p <- nrow(kcomb_vec_mat)
        num_kpp1 <- nrow(kcomb_vec_mat)

        for(p_ind in (t+1):(n.time-1)){

          #loop over k_pplus1
          rankvec_temp <- ranks_mat[,  (p_ind-1)*n.ranker + indiv]


          # # constraint is actually at time period p_ind
          # rankconstraint_tmin1 <- rank_cons_arr[, , indiv, p_ind]
          #
          # A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)
          #
          # tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)

          rankconstraint_p <- rank_cons_arr[, , indiv, p_ind]

          A_Ckp_constraint <- rbind(rankconstraint_p, boundconstraints)

          tA_Ckp_constraint <- t(A_Ckp_constraint)

          # require all possible regions for each time period.
          # Can use qkt_list for this

          # k_index_matrix_p <- kcomb_vec_mat#qkt_list[[p_ind]][,1:(ncol(qkt_list[[p_ind]])-1)  ]

          # num_k_p <- nrow(k_index_matrix_p)

          # two options:

          # 1. Save all save all r_{\k^{t+1},\k^{t}}^{(t)} for all \k^{t}
          # then iterate forward the summations to sum over \k^T
          # 2. Separately iterate over summations for each \k^{t}
          # actually a bit more complicated than this


          # will try first option because this involve less repetition of the same integrals.
          # However, if really wanted to avoid repetition of integrals
          # would save big multidimensional array outside of all loops of all possible values of
          # r_{\k^{t+1},\k^{t}}^{(t)} for all t

          # k_index_matrix_pp1 <- qkt_list[[p_ind+1]][,1:(ncol(qkt_list[[p_ind+1]])-1)  ]

          # num_kpp1 <- nrow(qkt_list[[p_ind+1]])




          for(kpp1_ind in 1:num_kpp1){

            # num_k_t rows is correct
            new_rk_t_pp1_mat <- matrix(0,
                                       nrow = num_k_t,
                                       ncol = num_kpp1)


            krow_pp1 <- kcomb_vec_mat[kpp1_ind, ]#kcomb_vec_mat[rowind,]

            # must agree with period t ranks

            keepbool <- all(rank( krow_pp1 , ties.method = "min") <= rankvec_temp)
            strictbool <- all(rank( krow_pp1 , ties.method = "min") == rankvec_temp)


            templowers <- intersectmat[krow_pp1,2]
            tempuppers <- intersectmat[krow_pp1,3]




            for(kp_ind in 1: num_k_p){


              krow_p <- kcomb_vec_mat[kp_ind, ]

              tempmeans <- intersectmat[krow_p,1]


              # calculate the scalar_{\K^{p+1}, \K^p }^{(p)}




              # must agree with period t ranks

              # keepbool <- all(rank( krow_pp1 , ties.method = "min") <= rankvec_temp)

              if(keepbool == FALSE){
                # qkt_mat[rowind,lastcol_ind] <- 0
                # integral is zero

                #add zero
                # r_kpp1_kp_p <- 0
                # new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]

                next
              }

              # strictbool <- all(rank( krow_pp1 , ties.method = "min") == rankvec_temp)
              #
              #
              # templowers <- Biglist_intersectmats[[p+1]][krow_pp1,2]
              # tempuppers <- Biglist_intersectmats[[p+1]][krow_pp1,3]

              if(strictbool == TRUE){

                # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]

                # period t intersect matrix
                # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

                # tempintegralval <- 1
                #
                # # can probably vectorize this?
                # for(k_index in 1:(lastcol_ind-1)){
                #   ktemp <- k_indvec[k_index]
                #
                #   # tempmean <- intersectmat[ktemp,1]
                #
                #   tempmean <- tempmeans[k_index]
                #   templower <- templowers[k_index]
                #   tempupper <- tempuppers[k_index]
                #
                #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
                #   tempintegralval <- tempintegralval*onedim_int
                #
                # }

                # TEST
                tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

                r_kpp1_kp_p <- tempintegralval

                new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]


                # rest of code is for integrals bounded by the rank constraint

                # so can skip

                next
              }


              #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT


              # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
              # and for each pair of bounds, the first is the negative of the uper bound
              # and the second is the upper bound

              # jumps of 2 from n.item to 3*n.item - 2
              lb_inds <- n.item - 2 + 2*(1:n.item)
              # jumps of 2 from n.item + 1 to 3*n.item - 1
              ub_inds <- n.item - 1+ 2*(1:n.item)


              bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
              bvec[lb_inds] <- -1*templowers
              bvec[ub_inds] <- tempuppers


              # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
              # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

              # rankconstraint_p <- rank_cons_arr[, , indiv, p]
              #
              # A_Ckp_constraint <- rbind(rankconstraint_p, boundconstraints)
              #
              # tA_Ckp_constraint <- t(A_Ckp_constraint)


              bvec_temp <- bvec + A_Ckp_constraint%*%tempmeans


              # NOTE: The SubsetSimFast and HDR_algoFast functions
              # use the transpose of the constraint matrix as an input

              sub_retFast <- LinConGauss::SubsetSimFast(tA_Ckp_constraint,
                                                        bvec_temp,
                                                        N_hdr,
                                                        rho_hdr )

              hdr_retFast <- LinConGauss::HDR_algoFast(tA_Ckp_constraint,
                                                       bvec_temp,
                                                       c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                       N_hdr )

              #Probability Estimate from subset simulation
              # exp(sub_retFast$logZ)

              #Probability Estimate from HDR
              tempintegralval <- exp(hdr_retFast)

              r_kpp1_kp_p <- tempintegralval

              new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]






              # r_kpp1_kp_p <- TO BE CALCULATED

              # multiply by prev_mat column for kp_ind and add to the
              # kpp1_ind column of new mat


              # new_rk_t_pp1_mat[ ,kpp1_ind ] <- r_kpp1_kp_p*prev_mat[,kp_ind]

            } # end loop over kp_ind in 1: num_k_p

          } # end loop over kpp1_ind in 1:num_kpp1

          prev_mat <- new_rk_t_pp1_mat


        } # end loop over p_ind

        # now for time period T

        rankvec_temp <- ranks_mat[,  (n.time-1)*n.ranker + indiv]



        # require all possible regions for each time period.
        # Can use qkt_list for this

        # k_index_matrix_T <- kcomb_vec_mat #qkt_list[[n.time]][,1:(ncol(qkt_list[[n.time]])-1)  ]

        num_k_T <- nrow(kcomb_vec_mat)

        for(kT_ind in 1:num_k_T){

          # calculate r_{\K^T}^{(T)} = nkT  =mkT
          # equal to nkT, so does not need to be calculated again
          rkT <- nkt_vec_T[kT_ind]

          new_rk_t_pp1_mat[, kT_ind] <- rkT*new_rk_t_pp1_mat[, kT_ind]

        }


        # mkt_vec <- rowSums(new_rk_t_pp1_mat)
        mkt_vec <- apply(new_rk_t_pp1_mat,1,sum)

        mkt_list[[t]] <- mkt_vec


      } # end loop over time periods t


      print("Line 4127")


      ###### Begin main Z loop ###############


      # rkt_tmin1_list <- list()


      # Loop for
      # t < T-1

      # save intersection matrices from previous time period

      intersectmat_tplus1 <- intersectmat_Tmin1

      nkt_tplus1 <-  nkt_vec_Tmin1


      for(t in (n.time-2):1){

        print("iter = ")
        print(iter)

        print("indiv = ")
        print(indiv)

        print("t = ")
        print(t)



        # obtain ordering for time t
        rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]

        if(t >1){
          rankvec_tmin1 <- ranks_mat[,  (t-1-1)*n.ranker + indiv]
        }


        rankvec_tplus1 <- ranks_mat[,  (t)*n.ranker + indiv]


        #EDIT THIS IF rank_cons_arr uses up too much memory

        rankconstraint_t <- rank_cons_arr[, , indiv, t]
        if(t>1){
          rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t-1] #  rank_cons_arr[[t-1]]
        }

        # perhaps unnecessary
        rankconstraint_tplus1 <- rank_cons_arr[, , indiv, t+1] #rank_cons_arr[[t+1]]


        ######## obtain intersection matrices ########



        # The smoothing distribution coincides with the filtering distribution

        # Calculate the necessary values to compute the weights of the mixture distribution


        # nkt_vec is a vector of integrals for regions-specific parameters k
        # the integrals are constrained by the ranker and time specific sets A_{i,t}
        # where A_{i,t} is defined by the ordering of the ranks given by ranker i at time t

        # requires:
        # 1. ranker and time specific rankings
        # 2. vector of mean parameters for all possible regions defined by the sum-of-tree structure


        # create intersection matrices
        # note that intersection matrices can be time period specific if allow for time period specific covariates

        # # create vector of indices for ranker indiv in time period T
        # ind_start <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        # ind_end <- (t - 1)*n.ranker*n.item+n.item*indiv
        # obs_indices <- ind_start:ind_end

        # intersectmat <- Biglist_intersectmats[[t]]


        ###########  calculate nkt for t < T - 1 ########################################

        # If regions vary across time
        # Then nktvec and qkt vec are time-specific
        # NOT JUST THROUGH dependence on observed ranks at time t
        # also through time-specific k

        # if covariates are item-specific, then the
        # combinations of regions, k involve
        # item-specific ranges of regions

        # in either case, must loop through combinations of regions
        # there are some possible symmetries
        # IGNORE SYMMETRIES


        #there are n.item*nrow(intersectmat) possible regions

        # create list of vectors of indices for k1, k2, ..., k_{n.item}
        # to be used as input to expand.grid

        #straightforward for itemcovars == FALSE



        nkt_vec <- rep(NA, nrow(kcomb_vec_mat))


        for(rowind in 1:length(nkt_vec) ){

          #obtain means
          #vector k1, k2, k3, etc
          k_indvec <- kcomb_vec_mat[rowind,]

          #note: k_indvec can include repeated values
          tempmeans <- intersectmat[k_indvec,1]

          # templowers <- intersectmat[k_indvec,2]
          # tempuppers <- intersectmat[k_indvec,3]


          # Apply methods of Gessner et al

          # create matrix A, vector b

          # for nkt_mat calcultions, the only constraint is the rank order A_t
          # so

          # A matrix is rankconstraint_t
          # original b vector is vector of zeros
          # However must shift the constraints as outlined in the paper
          # the mu vector is tempmeans
          # Therefore the shifted b vector is
          # (rankconstraint_t)%*%tempmeans

          bvec_temp <- (rankconstraint_t)%*%tempmeans



          # NOTE: The SubsetSimFast and HDR_algoFast functions
          # use the transpose of the constraint matrix as an input

          sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                    bvec_temp,
                                                    N_hdr,
                                                    rho_hdr )

          hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                   bvec_temp,
                                                   c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                   N_hdr )

          #Probability Estimate from subset simulation
          # exp(sub_retFast$logZ)

          #Probability Estimate from HDR
          tempintegralval <- exp(hdr_retFast)




          # for(k_index in 1:(lastcol_ind-1)){
          #       ktemp <- nkt_mat[rowind,k_index]
          #       tempmean <- intersectmat[ktemp,1]
          #       templower <- intersectmat[ktemp,2]
          #       tempupper <- intersectmat[ktemp,3]
          #
          #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
          #       tempintegralval <- tempintegralval*onedim_int
          # }

          #Save integral result
          nkt_vec[ rowind ] <- tempintegralval#include product here

        }



        ######### calculate wktS for t < T-1 ###########################################

        # Then calculate weights

        temp_qkt_vec <- qkt_list[[t]]

        mkt_vec <- mkt_list[[t]]
        wktS_vec <- temp_qkt_vec*mkt_vec
        # normalize
        wktS_vec <- wktS_vec/sum(wktS_vec)

        # sample an index vector k
        component_ind <- sample.int(length(wktS_vec),
                                    size = 1,
                                    replace = FALSE,
                                    prob = wktS_vec)


        ####### Sample for t < T - 1 given component ###########################


        # Sampling from the filtering distribution as proposal distribution for
        # both AR and MH methods
        # There is probably a more efficient way of writing this

        # if(itemcovars == FALSE){
        #   intersectmat <- Biglist_intersectmats[[t]]
        # }else{
        #   list_item_intersectmats <- Biglist_list_item_intersectmats[[t]]
        # }

        if(smoothing_method == "AR"){

          # Accept-Reject sampling

          #Aside: perhaps useful to know M= nkt/mkt

          print("Perhaps useful to know M = nkt/mkt = ")
          print(nkt_vec[ component_ind] / mkt_vec[ component_ind])


          accepted <- FALSE

          while(accepted == FALSE){

            # Sample from the filtering distribution



            ####### AR Filtering Proposal Sample for t < T-1 given component ###########################

            # Now draw from corresponding truncated normal distribution
            # with means mu_k
            # and constraint matrix rankconstraint_t

            # k_indvec <- nkt_mat[component_ind,1:(lastcol_ind-1)]

            # or
            k_indvec <- kcomb_vec_mat[component_ind,]

            #note: k_indvec can include repeated values
            tempmeans <- intersectmat[k_indvec,1]

            # current rankconstraint_t corresponds to T-1

            bvec_temp <- (rankconstraint_t)%*%tempmeans

            # require an initial value in the domain
            # arbitrarily set lowest to 10/n.item
            # then add 10/n.item for each

            # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

            # z_init <- rep(NA, n.item)
            #
            # # This can probably be vectorized
            # for(z_ind in 1:n.item){
            #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
            # }

            # or is a random sample required?
            # z_init <- rep(0, n.item)
            # z_init<- rnorm(n.item)
            z_init<- rnorm(n = n.item, mean = -1* tempmeans)

            if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
              # in domain
              # print("in domain")
            }else{
              # stop("Error. Initial vector not in domain")

              # perhaps take random samples until a point is found in the doain
              # ElilipticalSliceSampler python function might do something like this
              # at least if there is not any initial value

              while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
                print("not in domain. Sample x0 again")

                # x0 <- rnorm(length(z_init))
                z_init<- rnorm(n.item)

                # x0 <- xnew
              }
            }


            # Take 100 samples, then just use last column
            # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
            z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                        bvec_temp,
                                        Num_lin_ess_samples,
                                        z_init,
                                        nskip = 0)

            #save Z values sampled from proposal

            z_prop_vec <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans


            ####### AR Uniform sample ###########################

            # sample from the uniform distribution

            u_temp <- runif(n = 1)


            ####### AR Calculate Acceptance Prob t < T-1 ###########################


            #calculate acceptance probability given choice of M = nkt/mkt

            # acceptance probability equals r_t(z_t)
            # here t = T-1

            # first, must obtain means corresponding to predictions given covariates and z_prop_vec
            # and covaraite observations in time period T


            # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            obs_inds <- (t - 1 )*n.ranker*n.item+n.item*(indiv-1) + 1:n.item

            # df_for_dbart$x


            # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
            # a second time


            #attempt at alternative to integration


            r_t_zt <- NA


            kvectemp <- rep(NA, n.item)

            intersectmat_tplus1 <- intersectmat #Biglist_intersectmats[[t+1]]

            for(index_item in 1:n.item){

              # find row of intersectmat_T corresponding to
              # z_prop_vec[index_item]

              #ranges for zlag
              zranges <- c(-Inf, (intersectmat_tplus1)[,3])

              tempinds <- which((zranges < z_prop_vec[index_item] ))

              #which is the last one below (count includes -inf, so gives row of correct interval)
              temp_ind <- tempinds[length(tempinds)]

              # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

              kvectemp[index_item] <- temp_ind # intersectmat_tplus1[temp_ind,1]

            }

            # now find corresponding element of # mvec

            qkt_tp1_temp <- qkt_list[[t+1]]



            rowind_temp <- which(apply(kcomb_vec_mat,
                                       1,
                                       function(x) all.equal(x, kvectemp)) == "TRUE")

            mvec_tp1 <- mkt_list[[t+1]]

            r_t_zt <- mvec_tp1[rowind_temp]


            # accept or reject

            if(u_temp <= r_t_zt){

              # accept
              Z.mat[,(t-1)*n.ranker + indiv] <- z_prop_vec
              accepted <- TRUE

            }else{

              # reject
              accepted <- FALSE

            }



          }# end while loop for Accept-Reject

        }else{ # Metropolis-Hastings sampler

          # Essentially the same as Accept-Reject code, except different acceptance probability
          # and not a while loop


          # Sample from the filtering distribution

          ####### MH Filtering Proposal Sample for t<- T-1 given component ###########################

          # Now draw from corresponding truncated normal distribution
          # with means mu_k
          # and constraint matrix rankconstraint_t



          # k_indvec <- nkt_mat_Tmin1[component_ind,1:(lastcol_ind-1)]


          k_indvec <- kcomb_vec_mat[component_ind,]

          #note: k_indvec can include repeated values
          tempmeans <- intersectmat[k_indvec,1]

          # current rankconstraint_t corresponds to T-1

          bvec_temp <- (rankconstraint_t)%*%tempmeans

          # require an initial value in the domain
          # arbitrarily set lowest to 10/n.item
          # then add 10/n.item for each

          # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

          # z_init <- rep(NA, n.item)
          #
          # # This can probably be vectorized
          # for(z_ind in 1:n.item){
          #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
          # }

          # or is a random sample required?
          # z_init<- rnorm(n.item)
          z_init<- rnorm(n = n.item, mean = -1* tempmeans)

          if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
            # in domain
            # print("in domain")
          }else{
            # stop("Error. Initial vector not in domain")

            # perhaps take random samples until a point is found in the doain
            # ElilipticalSliceSampler python function might do something like this
            # at least if there is not any initial value

            while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
              print("not in domain. Sample x0 again")

              # x0 <- rnorm(length(z_init))
              z_init<- rnorm(n.item)

              # x0 <- xnew
            }
          }


          # Take 100 samples, then just use last column
          # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
          z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                      bvec_temp,
                                      Num_lin_ess_samples,
                                      z_init,
                                      nskip = 0)

          #save Z values sampled from proposal

          z_prop_vec <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans


          ####### MH Uniform sample ###########################

          # sample from the uniform distribution

          u_temp <- runif(n = 1)

          ####### MH Calculate Acceptance Prob t < T-1 ###########################


          #calculate acceptance probability given choice of M = nkt/mkt

          # acceptance probability equals r_t(z_t)
          # here t = T-1

          # first, must obtain means corresponding to predictions given covariates and z_prop_vec
          # and covaraite observations in time period T


          # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
          # a second time


          #attempt at alternative to integration


          r_t_zt <- NA


          kvectemp <- rep(NA, n.item)

          intersectmat_tplus1 <- intersectmat#Biglist_intersectmats[[t+1]]

          for(index_item in 1:n.item){

            # find row of intersectmat_T corresponding to
            # z_prop_vec[index_item]



            #ranges for zlag
            zranges <- c(-Inf, (intersectmat_tplus1)[,3])

            tempinds <- which((zranges < z_prop_vec[index_item] ))

            #which is the last one below (count includes -inf, so gives row of correct interval)
            temp_ind <- tempinds[length(tempinds)]

            # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

            kvectemp[index_item] <- temp_ind #intersectmat_tplus1[temp_ind,1]

          }

          # now find corresponding element of # mvec

          qkt_tp1_temp <- qkt_list[[t+1]]



          rowind_temp <- which(apply(kcomb_vec_mat,
                                     1,
                                     function(x) all.equal(x, kvectemp)) == "TRUE")

          mvec_tp1 <- mkt_list[[t+1]]

          r_t_zt <- mvec_tp1[rowind_temp]





          # for denominator of acceptance ratio,
          # can NOT save values in previous iteration of Gibbs sampler because the tree structures change.
          # Therefore, must recalculate in each iteration

          #

          z_old_vec <- Z.mat[,(t-1)*n.ranker + indiv]




          # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
          # a second time


          #attempt at alternative to integration


          r_t_zt_denom <- NA


          kvectemp <- rep(NA, n.item)

          intersectmat_tplus1 <- intersectmat #Biglist_intersectmats[[t+1]]

          for(index_item in 1:n.item){

            # find row of intersectmat_T corresponding to
            # z_old_vec[index_item]

            #ranges for zlag
            zranges <- c(-Inf, (intersectmat_tplus1)[,3])

            tempinds <- which((zranges < z_old_vec[index_item] ))

            #which is the last one below (count includes -inf, so gives row of correct interval)
            temp_ind <- tempinds[length(tempinds)]

            # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

            kvectemp[index_item] <- temp_ind#intersectmat_tplus1[temp_ind,1]

          }

          # now find corresponding element of # mvec

          qkt_tp1_temp <- qkt_list[[t+1]]



          rowind_temp <- which(apply(kcomb_vec_mat,
                                     1,
                                     function(x) all.equal(x, kvectemp)) == "TRUE")

          mvec_tp1 <- mkt_list[[t+1]]

          r_t_zt_denom <- mvec_tp1[rowind_temp]

          ratio_temp <- r_Tmin1_zTmin1 / r_Tmin1_zTmin1_denom

          if(u_temp <= ratio_temp){

            # accept
            Z.mat[,(t-1)*n.ranker + indiv] <- z_prop_vec
            accepted <- TRUE

          }else{

            # reject
            # keep  z value from previous round

            # accepted <- FALSE

          }


          # stop("Metropolis-Hastings code not written yet")

        } # End else statement (corresponding to MH sampler )



        # End of loop over t
        # update intersection matrices

        intersectmat_tplus1 <- intersectmat


        nkt_tplus1 <-  nkt_vec





      } # end loop over t in (n.time-2):1


      ########### sample from the predictive distribution #####################

      ####### First calculate all q_k_tp1 ##########################

      qktp1_vec <- qkt_list[[n.time+1]]

      predmix_weights <- qktp1_vec/sum(qktp1_vec)


      # sample an index vector k
      component_ind <- sample.int(length(predmix_weights),
                                  size = 1,
                                  replace = FALSE,
                                  prob = predmix_weights)


      # obtain means for relevant component
      # or
      k_indvec <- kcomb_vec_mat[component_ind,]

      #note: k_indvec can include repeated values
      tempmeans <- intersectmat[k_indvec,1]

      # now sample Z vector for T + 1

      # Multivariate normal with means tempmeans

      # can use rnorm because independent
      Z.mat.test[,(1-1)*n.ranker + indiv] <- rnorm(n = n.item, mean = tempmeans)



      print("Line 4240")


      for(h in 2:num_horizon){

        # obtain means for time periodt + h

        z_temp_hmin1 <- Z.mat.test[,(h-2)*n.ranker + indiv]


        tempmeans <- rep(NA, n.item)

        intersectmat_h <- intersectmat #Biglist_intersectmats[[t+1]]

        for(index_item in 1:n.item){

          # find row of intersectmat_T corresponding to
          # z_old_vec[index_item]
          # ranges for zlag
          zranges <- c(-Inf, (intersectmat_h)[,3])
          tempinds <- which((zranges < z_temp_hmin1[index_item] ))

          #which is the last one below (count includes -inf, so gives row of correct interval)
          temp_ind <- tempinds[length(tempinds)]

          # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

          tempmeans[index_item] <- intersectmat_h[temp_ind,1]

        }

        Z.mat.test[,(h-1)*n.ranker + indiv] <- rnorm(n = n.item, mean = tempmeans)


      }



      print("Line 4837")


    } # end loop over individuals indiv in 1:n.ranker


    print("Line 4843")


    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #
    #               # df_for_dbart <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(df_for_dbart[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    print("Line 4424")

    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{
    for(j in 1:num_lags){
      # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)

      while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {

        if(seq_z_draws==1){
          stop("updates still not consistent with tree structure")
        }
        print("new z values not consistent with tree structure, must draw again")

        # If this error message occurs
        # Check the conditions in the dbart package for setPredictor == FALSE
        # And if this is hypothetically possible, even with draws formt he smoothing distribution,
        # and if it is not a bug
        # then need to go back to beginning of this iteration of the Gibbs sampler
        # and sample Zmat again
        stop("new z values not consistent with tree structure, must draw again")


        # #perhaps this can be rewritten to just re-draw the relevant column?
        # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                           Z.mat = Z.mat,
        #                                           mu = mu,
        #                                           weight.vec = rep(1, n.ranker*n.time),
        #                                           n.ranker = n.ranker*n.time,
        #                                           n.item = n.item )
        #
        # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
        #
        # for(t in 1:num_lags){
        #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
        #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
        #
        #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
        #
        # }
        #
        # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j

      }
    }
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= df_for_dbart$x, column = 1, forceUpdate = TRUE)

    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # mutemp <- sampler$predict(df_for_dbart)
    # print("sigma = ")
    # print(samplestemp$sigma)

    mu = mutemp



    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
      draw$Z.mat.test[,,iter] = Z.mat.test

    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta




    # if(is.null(initial.list)){
    # print("samplestemp$test[,1] = ")
    # print(samplestemp$test[,1])

    # mupreds <- sampler$predict(df_for_dbart)

    # Xmat.test[,1:num_lags] <-  Zlag.mat.test


    temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(df_for_dbart_test))

    for(t  in 1:num_lags){
      if(noise_in_pred ==1){
        temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
      }else{
        temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
      }

    }

    # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
    #                                                                      (num_lags+1):ncol(Xmat.test)])

    temp_test_mat <- data.frame(x = temp_test_mat)
    colnames(temp_test_mat) <- colnames(df_for_dbart_test)

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

    temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

    print("Line 5488")


    temp_mu_test <- rep(NA,  nrow(df_for_dbart_test) )


    if(iter < 5){
      print("temp_test_mat = " )
      print(temp_test_mat)
    }

    for(t1 in 1:num_test_periods){
      #produce a prediction

      # must use original column names to prevent an error in the predict function
      colnames(temp_test_mat) <- colnames(df_for_dbart_test)

      testpredvec <- sampler$predict(temp_test_mat)

      #fill in temp_test_preds with noise
      if(noise_in_pred ==1){
        temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
      }else{
        temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
      }


      #update temp_test_mat
      #shift z columns to the right and fill in leftmost column

      #need to rewrite this if want to allow for no observed covariates

      # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

      if(t1 != num_test_periods){


        if(num_lags ==1){
          temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] #,
                                                 # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }else{
          temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
                                                 temp_test_mat[,1:(num_lags-1)] #,
                                                 # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker),])
          ))

        }
      }

      # colnames(temp_test_mat) <- colnames(Xmat.test)


      #fill in temp_mu_test without noise
      temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


    }

    #also update Zlag.mat.test ?
    #perhaps this is unnecessary here?

    print("Line 5545")


    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    # if(nrow(X.test) >0 ){
    for(t in 1:num_lags){
      # if(t==1){
      #   #repeating the last period values
      #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
      #
      #   #other option is to set all unobservable values to zero
      #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
      #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
      #
      #
      # }else{

      if(num_test_periods > t ){
        #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                               as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



      }else{
        #nothing to fill in if num_test_periods <= t
        Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

      }


      # }
    }
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }


    draw$mu_test[,iter] <- temp_mu_test
    # draw$mu_test[,iter] <- samplestemp$test[,1]

    if(keep_zmat==TRUE){
      draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
    }

    # draw$mu_test[,1] <- samplestemp$test[,1]

    # }else{
    #   draw$mu_test[,1] <- initial.list$mu_test
    # }




    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }


  return(draw)
}






##///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

##/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with  Covariates
#'
#' Implement the Bayesian model for rank-order data with at most 1 lag of the latent variable (and filtering and smoothing) and with covariate information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import LinConGauss
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @param seq_z_draws deprecated option for drawing latent variable values within MCMC
#' @param itemcovars Set equal to TRUE if covariates vary across items, and FALSE otherwise.
#' @param N_hdr number of draws for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param rho_hdr Rho parameter for Holmes-Diaconis-Ross algorithm applied to linearly constrained Gaussians (Algorithm 1 of Gessner et al.). Used for calculation of integrals within sampling of latent variables in MCMC.
#' @param smoothing_method Method for sampling the latent variable from the smoothing distribution within MCMC. If "AR", then Accept-Reject sampling. If "MH", then Metropolis-Hastings sampling.
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARRObartWithCovars <- function(pair.comp.ten,
                               X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                               X.test = matrix(NA, nrow =0, ncol = 0),
                               # tau2.alpha = 5^2,
                               # nu.alpha = 3,
                               # tau2.beta = 5^2,
                               # nu.beta = 3,
                               n.item = dim(pair.comp.ten)[1],
                               n.rankerbytime = dim(pair.comp.ten)[3],
                               n.ranker,
                               n.time,
                               p.cov = ncol(X.train),
                               iter.max = 5000,
                               para.expan = TRUE,
                               print.opt = 100,
                               initial.list = NULL,
                               n.trees = 50L,
                               n.burn = 0L,
                               n.samples = 1L,
                               n.thin = 1L,
                               n.chains = 1,
                               n.threads = 1L,#guessNumCores(),
                               printEvery = 100L,
                               printCutoffs = 0L,
                               rngKind = "default",
                               rngNormalKind = "default",
                               rngSeed = NA_integer_,
                               updateState = FALSE,
                               num_lags = 1,
                               diff_num_test_rankers = 0,
                               num_test_periods = 0,
                               keep_zmat = FALSE,
                               noise_in_pred = 0,
                               seq_z_draws = 1,
                               itemcovars = FALSE,
                               N_hdr = 10000,
                               rho_hdr = 0.5,
                               smoothing_method = "AR",
                               num_horizon=1){


  Num_lin_ess_samples <- 1000


  if(num_lags>1){
    stop("Code only written for num_lags == 1")
  }


  if(smoothing_method != "AR"){
    if(smoothing_method != "MH"){

      stop("smoothing_method must equal AR (Accept-Reject) or MH (Metropolis-Hastings)")

    }
  }


  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  length_mu <- 1

  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)

      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max))#,
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(nrow(X.test) >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }
  }



  # create observed ranks for constraints
  # OR EDIT CODE SO THAT INPUT IS RANKS?
  # can then apply function FullRankToPairComp to create pair.comp.ten


  # ranks matrix
  # number of columns is n.ranker*n.time
  # number or rows is n.item

  # first M columns are for all rankers in the first time period
  # next M columns are for all rankers in the second time period
  # and so on



  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )





  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }


  # it might be more efficient to create and save all rank constraint matrices at this stage


  rank_cons_arr <- array(data = NA,dim = c(n.item - 1, n.item,n.ranker ,  n.time))

  for(indiv in 1:n.ranker){

    for(t in 1:n.time){

      rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]


      rankconstraint_t <- matrix(0,
                                 nrow = n.item - 1,
                                 ncol = n.item)

      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        # rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1


      }

      rank_cons_arr[, , indiv, t] <- rankconstraint_t

    }
  }
  # create array of rank constraint matrices










  # arbitrarily set zprior_vec
  zprior_vec <- rep(0, n.item)


  boundconstraints <- matrix(NA,
                             nrow = 2*n.item,
                             ncol = n.item)

  # use kroenecker product
  # there is probably a more efficient way of doing this

  boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)



  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    Z.mat.test = matrix(NA, nrow = n.item, ncol = n.ranker*num_horizon)

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(nrow(X.test) >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )


      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")





        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }



    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")


    if(nrow(X.test )==0){
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        #test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1),
                        sigma=1 #check if this is the correct approach for setting the variance to 1
      )

    }else{
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
                        sigma=1 #
      )

    }

    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    #sampler$setPredictor(x= Xmat.train$x, column = 1, forceUpdate = TRUE)

    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train = ")
        print(Xmat.train)
        print("Z.mat = ")
        print(Z.mat)

        print("samplestemp$sigma = ")
        print(samplestemp$sigma)
        print("samplestemp$varcount = ")
        print(samplestemp$varcount)

        print("samplestemp$train[,1] = ")
        print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    Z.mat.test <- initial.list$Z.mat.test

    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  if( nrow(X.test) > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec
        }



        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
                                                 as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

        }else{
          temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                 as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]
      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ##################### Begin Gibbs sampler ##################################################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){



    ##################### Sample from the Smoothing Distribution #################################################################


    # Sample from the smoothing distribution at each time period beginning at T


    # loop over individuals/rankers (if there is more than one individual/ranker)





    for(indiv in 1:n.ranker){






      ########### calculate qkt  ########################################


      # each element of list corresponds to a time period


      qkt_list <- list()


      # list of intersectmats across time periods
      Biglist_intersectmats <- list()

      # If allow for intersect matrices
      # then save list of lists of matrices
      Biglist_list_item_intersectmats <- list()

      # list_item_intersectmats

      # in each time period, there are item and time specific ranges of k
      # (also ranker specific, although the whole outer loop is over rankers, so this is less important)

      #begin with the special case of t = 1

      # requires z_prior
      # zprior_vec arbitraily set to all zeros


      # obtain regions for time period t = 1
      # time period 1 is unlike other time periods for qkt integral calculations
      # in that the integrals are not constrained by observed ranks

      # for t = 1 C_k has k corresponding to t = 1

      # obtain period 1 lower and upper bounds for constrained regions
      # then evaluate products of univariate normal integrals



      ########### calculate qkt   for t = 1 ########################################


      #### obtain intersection matrices for time period t = 1 ###############



      # create intersection matrices


      intersectmat_tmin1 <- NA
      list_item_intersectmats_tmin1 <- NA

      # create vector of indices for ranker indiv in time period 1
      ind_start <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
      ind_end <- (1 - 1)*n.ranker*n.item+n.item*indiv
      obs_indices <- ind_start:ind_end

      if(itemcovars == FALSE){


        list_inter_mats <- list()

        for(i in 1:n.trees){

          treeexample1 <- sampler$getTrees(treeNums = i,
                                           chainNums = 1,
                                           sampleNums = 1)

          rebuilt_tree <- rebuildTree2(treeexample1)


          #must use covariates for individual indiv at time period t

          # print("obs_indices[1] = ")
          #
          # print(obs_indices)
          #
          # print("Xmat.train$x[obs_indices[1] = ")
          #
          # print(Xmat.train$x[obs_indices[1],, drop = FALSE])

          list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],, drop = FALSE] )


        }

        intersectmat <- interNtreesB(list_inter_mats)


        intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

        # calculate one dimensional integrals
        for(rowind in 1:nrow(intersectmat)){
          # ktemp <- nkt_mat[rowind,k_index]
          # tempmean <- intersectmat[ktemp,1]
          templower <- intersectmat[rowind,2]
          tempupper <- intersectmat[rowind,3]

          # ASSUMING PRIOR MEAN ALL ZEROS
          intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
          # tempintegralval <- tempintegralval*onedim_int
        }


        Biglist_intersectmats[[1]] <- intersectmat


      }else{ # itemcovars == TRUE


        list_item_intersectmats <- list()

        for(index_item in 1:n.item){

          obs_one_ind <- (1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

          list_inter_mats <- list()

          for(i in 1:n.trees){

            treeexample1 <- sampler$getTrees(treeNums = i,
                                             chainNums = 1,
                                             sampleNums = 1)

            rebuilt_tree <- rebuildTree2(treeexample1)


            #must use covariates for individual indiv at time period t

            list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,, drop = FALSE] )


          } #end loop over trees

          intersectmat <- interNtreesB(list_inter_mats)

          intersectmat <- cbind(intersectmat, rep(NA, nrow(intersectmat)))

          # calculate one dimensional integrals
          for(rowind in 1:nrow(intersectmat)){
            # ktemp <- nkt_mat[rowind,k_index]
            # tempmean <- intersectmat[ktemp,1]
            templower <- intersectmat[rowind,2]
            tempupper <- intersectmat[rowind,3]

            # ASSUMING PRIOR MEAN ALL ZEROS
            intersectmat[rowind, 4] <- pnorm(tempupper, mean = 0, sd = 1) - pnorm(templower, mean = 0, sd = 1)
            # tempintegralval <- tempintegralval*onedim_int
          }


          list_item_intersectmats[[index_item]] <- intersectmat


        } #end loop over items

        Biglist_list_item_intersectmats[[1]] <- list_item_intersectmats

      } # end else itemcovars == TRUE




      ### calculate qkt integrals for time period t = 1  ################

      if(itemcovars == FALSE){

        #there are n.item*nrow(intersectmat) possible regions

        # create list of vectors of indices for k1, k2, ..., k_{n.item}
        # to be used as input to expand.grid

        #straightforward for itemcovars == FALSE

        K_ind_list <-list()

        for(index_item in 1:n.item){
          K_ind_list[[index_item]] <- 1:nrow(intersectmat)
        }

        # there are many possible combinations
        # this might produce a huge matrix
        # not the most efficeient way of coding this
        # print("K_ind_list = ")
        # print(K_ind_list)
        kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

        # this line is included to avoid an error later using all.equal
        colnames(kcomb_vec_mat) <- NULL

        qkt_mat <- cbind(kcomb_vec_mat, rep(0, nrow(kcomb_vec_mat)))
        rm(kcomb_vec_mat)

        lastcol_ind <- ncol(qkt_mat)

        for(rowind in 1:nrow(qkt_mat) ){

          #obtain means
          #vector k1, k2, k3, etc
          k_indvec <- qkt_mat[rowind,1:(lastcol_ind-1)]

          #note: k_indvec can include repeated values
          # tempmeans <- intersectmat[k_indvec,1]

          templowers <- intersectmat[k_indvec,2]
          tempuppers <- intersectmat[k_indvec,3]


          # Apply methods of Gessner et al

          # create matrix A, vector b

          # for qkt_mat calcultions, the only constraint is the rank order A_t
          # so

          # A matrix is rankconstraint_t
          # original b vector is vector of zeros
          # However must shist the constraints as outlined in the paper
          # the mu vector is tempmeans
          # Therefore the shifted b vector is
          # (rankconstraint_t)%*%tempmeans
          #
          # bvec_temp <- (rankconstraint_t)%*%tempmeans
          #
          #
          #
          #
          # sub_retFast <- LinConGauss::SubsetSimFast(rankconstraint_t,
          #                                           bvec_temp,
          #                                           N_hdr,
          #                                           rho_hdr )
          #
          # hdr_retFast <- LinConGauss::HDR_algoFast(rankconstraint_t,
          #                                          bvec_temp,
          #                                          c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
          #                                          N_hdr )
          #
          # #Probability Estimate from subset simulation
          # # exp(sub_retFast$logZ)
          #
          # #Probability Estimate from HDR
          # tempintegralval <- exp(hdr_retFast)


          tempintegralval <- 1

          for(k_index in 1:(lastcol_ind-1)){
            ktemp <- k_indvec[k_index]

            # tempmean <- intersectmat[ktemp,1]

            # tempmean <- zprior_vec[k_index]
            # templower <- intersectmat[ktemp,2]
            # tempupper <- intersectmat[ktemp,3]

            # onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
            tempintegralval <- tempintegralval*intersectmat[ktemp,4]

          }

          #Save integral result
          qkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

        }


        # If ordering does not obey constraint
        #check if ordering obeys rankvec_t

        #n columns of kcomb_vec_mat

        # for a given row,
        # the ordering must agree with rankvec_t (with strict or weak inequality)


        # remove rows that do not obey constraint
        # or set corresponding nkt value to 0

        # possibly uses a lot of memory to create another matrix of ranks

        # how to deal with ties?
        # kcomb_rank_mat <- apply(kcomb_vec_mat, 1, rank)

        # or just loop through all rows

        # ASSUMING NO TIES IN OBSERVED RANKS rankvec_t


        # ACTUALLY, nkt does not involve restricted ranks. Can apply to ALL k

        # keepbools <- rep(NA, nrow(kcomb_vec_mat))
        # strictbools <- rep(NA, nrow(kcomb_vec_mat))
        #
        #
        # for(rowind in 1:nrow(kcomb_vec_mat)){
        #
        #   krow <- kcomb_vec_mat[rowind,]
        #
        #   # TRUE if obeys with weak or strict equality
        #   keepbools[rowind] <- all(rank( krow , ties.method = "min") <= rankvec_t)
        #   strictbools[rowind] <- all(rank( krow , ties.method = "min") == rankvec_t)
        #
        # }
        #
        # #this might not be optimal if want to preserve ordering of combinations
        # kcomb_strict_mat <- kcomb_vec_mat[strictbools, ]
        # kcomb_weak_mat <- kcomb_vec_mat[keepbools & (!strictbools), ]
        #
        #
        #
        # # free up some memory ?
        # rm(kcomb_vec_mat)
        #
        # # perhaps need to keep track of k1, k2, k3, etc
        #
        # n_strict <- nrow(kcomb_strict_mat)
        # n_weak <- nrow(kcomb_weak_mat)
        #
        # #
        # qkt_mat <- rbind(kcomb_strict_mat, kcomb_weak_mat)
        #
        #
        # # free up some memory ?
        # rm(kcomb_strict_mat, kcomb_weak_mat)
        #
        # #last column be integral values
        # qkt_mat <- cbind(qkt_mat, rep(NA, nrow(qkt_mat)))
        #
        # lastcol_ind <- ncol(qkt_mat)
        # # now fill in values of qkt_mat
        #
        # for(rowind in 1:n_strict ){
        #
        #   #obeys constraint exactly, so just take product of univariate normal integrals
        #
        #   tempintegralval <- 1
        #   # Product of pnorm() interval values with
        #   for(k_index in 1:(lastcol_ind-1)){
        #     ktemp <- qkt_mat[rowind,k_index]
        #     tempmean <- intersectmat[ktemp,1]
        #     templower <- intersectmat[ktemp,2]
        #     tempupper <- intersectmat[ktemp,3]
        #
        #     onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
        #     tempintegralval <- tempintegralval*onedim_int
        #
        #   }
        #
        #   qkt_mat[rowind,lastcol_ind] <- tempintegralval#include product here
        #
        # }
        # for(rowind in 1:n_weak ){
        #
        #   #apply method of Gessner et al
        #   qkt_mat[n_strict+ rowind,lastcol_ind] <- notcalculatedyet#include product here
        #
        # }



        qkt_list[[1]] <- qkt_mat

      }else{ # Allow covariates to vary over items, so sets of possible regions are item specific

        #there are n.item*nrow(intersectmat) possible regions

        # create list of vectors of indices for k1, k2, ..., k_{n.item}
        # to be used as input to expand.grid

        #straightforward for itemcovars == FALSE

        K_ind_list <-list()

        for(index_item in 1:n.item){
          K_ind_list[[index_item]] <- 1:nrow(list_item_intersectmats[[index_item]])
        }

        # there are many possible combinations
        # this might produce a huge matrix
        # not the most efficient way of coding this
        kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

        # this line is included to avoid an error later using all.equal
        colnames(kcomb_vec_mat) <- NULL

        qkt_mat <- cbind(kcomb_vec_mat, rep(0, nrow(kcomb_vec_mat)))
        rm(kcomb_vec_mat)


        for(rowind in 1:nrow(qkt_mat) ){

          #obtain means
          #vector k1, k2, k3, etc

          k_indvec <- qkt_mat[rowind,1:(lastcol_ind-1)]

          #note: k_indvec can include repeated values

          # since covariates can vary over items
          # the means are obtained from item-specific intersectmats


          tempmeans <- zprior_vec

          # tempmeans <- rep(NA, length(k_indvec))
          #
          # for(ktemp in 1:length(k_indvec)){
          #
          #   tempmeans[ktemp] <- (intersectmat[[ktemp]])[k_indvec[ktemp],1]
          # }
          #


          # tempmeans <- intersectmat[k_indvec,1]

          # templowers <- intersectmat[k_indvec,2]
          # tempuppers <- intersectmat[k_indvec,3]


          # Apply methods of Gessner et al

          # create matrix A, vector b

          # for qkt_mat calcultions, the only constraint is the rank order A_t
          # so

          # A matrix is rankconstraint_t
          # original b vector is vector of zeros
          # However must shist the constraints as outlined in the paper
          # the mu vector is tempmeans
          # Therefore the shifted b vector is
          # (rankconstraint_t)%*%tempmeans

          # bvec_temp <- (rankconstraint_t)%*%tempmeans
          #
          #
          #
          #
          # sub_retFast <- LinConGauss::SubsetSimFast(rankconstraint_t,
          #                                           bvec_temp,
          #                                           N_hdr,
          #                                           rho_hdr )
          #
          # hdr_retFast <- LinConGauss::HDR_algoFast(rankconstraint_t,
          #                                          bvec_temp,
          #                                          c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
          #                                          N_hdr )
          #
          #
          # #Probability Estimate from subset simulation
          # # exp(sub_retFast$logZ)
          #
          # #Probability Estimate from HDR
          # tempintegralval <- exp(hdr_retFast)
          #



          for(k_index in 1:(lastcol_ind-1)){
            ktemp <- k_indvec[k_index]
            # tempmean <- intersectmat[ktemp,1]

            tempmean <- tempmeans[k_index]

            # templower <- list_item_intersectmats[[k_index]][ktemp,2]
            # tempupper <- list_item_intersectmats[[k_index]][ktemp,3]
            #
            # onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)

            onedim_int <- (list_item_intersectmats[[k_index]])[ktemp,4]

            tempintegralval <- tempintegralval*onedim_int
          }

          #Save integral result
          qkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

        } # end for loop over row indices of qkt_mat



        qkt_list[[1]] <- qkt_mat

      } # end else statement # Allow covariates to vary over items, so sets of possible regions are item specific



      if(itemcovars == FALSE){
        intersectmat_tmin1 <- intersectmat

      }else{
        list_item_intersectmats_tmin1 <- list_item_intersectmats

      }




      rankvec_tmin1 <- ranks_mat[,  (1-1)*n.ranker + indiv]

      rankconstraint_tmin1 <- matrix(0,
                                     nrow = length(rankvec_tmin1)-1,
                                     ncol = length(rankvec_tmin1))


      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_tmin1)-1)){

        rankconstraint_tmin1[rankind, which(rankvec_tmin1 == rankind)] <- -1
        rankconstraint_tmin1[rankind, which(rankvec_tmin1 == rankind+1)] <- 1

        # rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        # rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_tmin1[rankind, rankvec_tmin1[rankind]] <- -1
        # rankconstraint_tmin1[rankind, rankvec_tmin1[rankind+1]] <- 1

      }

      A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)

      tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)




      ########### calculate qkt   for t = 2 to T ########################################

      for(t in 2:n.time){
        rankvec_tmin1 <- ranks_mat[,  (t-1)*n.ranker + indiv]

        # rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]

        # rankconstraint_t <- matrix(0,
        #                            nrow = length(rankvec_t)-1,
        #                            ncol = length(rankvec_t))
        #
        #
        # # note: ordering of rows is unimportant
        # # as long as ordering agrees with the ordering of the mean vector
        #
        # # so can begin by filling in first row
        #
        # #MUST BE EDITED IF ALLOW FOR TIES
        # for(rankind in 1:(length(rankvec_t)-1)){
        #
        #   rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        #   rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1
        #
        # }

        rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t- 1]

        #### obtain intersection matrices for time period t ###############


        # create vector of indices for ranker indiv in time period 1
        ind_start <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        ind_end <- (t - 1)*n.ranker*n.item+n.item*indiv
        obs_indices <- ind_start:ind_end

        if(itemcovars == FALSE){


          list_inter_mats <- list()

          for(i in 1:n.trees){

            treeexample1 <- sampler$getTrees(treeNums = i,
                                             chainNums = 1,
                                             sampleNums = 1)

            rebuilt_tree <- rebuildTree2(treeexample1)


            #must use covariates for individual indiv at time period t

            list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],, drop = FALSE] )


          }

          intersectmat <- interNtreesB(list_inter_mats)

          Biglist_intersectmats[[t]] <- intersectmat


        }else{ # itemcovars == TRUE


          list_item_intersectmats <- list()

          for(index_item in 1:n.item){

            obs_one_ind <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            list_inter_mats <- list()

            for(i in 1:n.trees){

              treeexample1 <- sampler$getTrees(treeNums = i,
                                               chainNums = 1,
                                               sampleNums = 1)

              rebuilt_tree <- rebuildTree2(treeexample1)


              #must use covariates for individual indiv at time period t

              list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,, drop = FALSE] )


            } #end loop over trees

            intersectmat <- interNtreesB(list_inter_mats)

            list_item_intersectmats[[index_item]] <- intersectmat


          } #end loop over items


          Biglist_list_item_intersectmats[[t]] <- list_item_intersectmats


        } # end else itemcovars == TRUE




        ### calculate qkt integrals for time period t = 2 to T  ######

        if(itemcovars == FALSE){






          #there are n.item*nrow(intersectmat) possible regions

          # create list of vectors of indices for k1, k2, ..., k_{n.item}
          # to be used as input to expand.grid

          #straightforward for itemcovars == FALSE

          K_ind_list <-list()

          for(index_item in 1:n.item){
            K_ind_list[[index_item]] <- 1:nrow(intersectmat)
          }

          # there are many possible combinations
          # this might produce a huge matrix
          # not the most efficient way of coding this
          kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

          # this line is included to avoid an error later using all.equal
          colnames(kcomb_vec_mat) <- NULL

          qkt_mat <- cbind(kcomb_vec_mat, rep(0, nrow(kcomb_vec_mat)))
          # rm(kcomb_vec_mat)

          lastcol_ind <- ncol(qkt_mat)

          for(rowind in 1:nrow(qkt_mat) ){


            # if ordering does not agree, all integrals will evaluate to zero and can then skip to next
            # NOTE THAT THIS REQUIRES NO ITEM-SPECIFIC COVARIATES
            # OTHERWISE MUST CHECK BOUNDS

            # can probably vectorize this
            # vectorize later if need to increase speed

            krow <- kcomb_vec_mat[rowind,]

            keepbool <- all(rank( krow , ties.method = "min") <= rankvec_tmin1)

            if(keepbool == FALSE){
              qkt_mat[rowind,lastcol_ind] <- 0
              next
            }

            strictbool <- all(rank( krow , ties.method = "min") == rankvec_tmin1)

            k_indvec <- qkt_mat[rowind,1:(lastcol_ind-1)]

            templowers <- intersectmat[k_indvec,2]
            tempuppers <- intersectmat[k_indvec,3]

            # loop over previous time period

            num_m_vecs <- nrow(qkt_list[[t-1]])
            # number of indices/regions
            # should be n.item ?
            num_m_inds <- ncol(qkt_list[[t-1]])

            qm_1min1_vec <- (qkt_list[[t-1]])[,ncol(qkt_list[[t-1]])]

            if(strictbool == TRUE){
              # can calculate relatively straightforward integrals

              for(m_ind in 1:num_m_vecs){

                # obtain mean vector from t-1 corresponding to m_ind

                m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
                tempmeans <- intersectmat_tmin1[m_inds,1]

                # tempintegralval <- 1
                #
                # # can probably vectorize this?
                # for(k_index in 1:(lastcol_ind-1)){
                #   ktemp <- k_indvec[k_index]
                #
                #   # tempmean <- intersectmat[ktemp,1]
                #
                #   tempmean <- tempmeans[k_index]
                #   templower <- templowers[k_index]
                #   tempupper <- tempuppers[k_index]
                #
                #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
                #   tempintegralval <- tempintegralval*onedim_int
                #
                # }

                # TEST
                tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

                # if(tempintegralval == tempintegralval2){
                #   print("Vectorization of qkt integral calculation seems to work.")
                # }else{
                #   print("Line 1677. error in vectorization of qkt integral.")
                # }

                #Save integral result
                # qkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

                # keep adding as loop over m_ind
                qkt_mat[rowind,lastcol_ind] <- qkt_mat[rowind,lastcol_ind] +
                  qm_1min1_vec[m_ind]*tempintegralval


              } # end of loop over m_ind

              # rest of code is for integrals bounded by the rank constraint

              # so can skip

              next
            }




            # will use constraint implied by ranks in previous time period
            # rankconstraint_tmin1

            # rankconstraint_t

            # obtain constraint implied by templowers and tempuppers


            # corresponds to A_C in the paper
            # number of rows is 2*n.item
            # number of columns is n.item

            # boundconstraints <- matrix(NA,
            #                            nrow = 2*n.item,
            #                            ncol = n.item)
            #
            # # use kroenecker product
            # # there is probably a more efficient way of doing this
            #
            # boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


            # t(diag(1,3, 3) %x% c(1,-1))

            # A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)
            #
            # tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)


            #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT




            # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
            # and for each pair of bounds, the first is the negative of the uper bound
            # and the second is the upper bound

            # jumps of 2 from n.item to 3*n.item - 2
            lb_inds <- n.item - 2 + 2*(1:n.item)
            # jumps of 2 from n.item + 1 to 3*n.item - 1
            ub_inds <- n.item - 1+ 2*(1:n.item)



            bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
            bvec[lb_inds] <- -1*templowers
            bvec[ub_inds] <- tempuppers



            # must shift the constraint





            for(m_ind in 1:num_m_vecs){

              # obtain mean vector from t-1 corresponding to m_ind

              m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
              tempmeans <- intersectmat_tmin1[m_inds,1]



              bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans



              # NOTE: The SubsetSimFast and HDR_algoFast functions
              # use the transpose of the constraint matrix as an input

              sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                        bvec_temp,
                                                        N_hdr,
                                                        rho_hdr )

              hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                       bvec_temp,
                                                       c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                       N_hdr )

              #Probability Estimate from subset simulation
              # exp(sub_retFast$logZ)

              #Probability Estimate from HDR
              tempintegralval <- exp(hdr_retFast)




              # tempintegralval <- 1
              #
              # # can probably vectorize this?
              # for(k_index in 1:(lastcol_ind-1)){
              #   ktemp <- k_indvec[k_index]
              #
              #   # tempmean <- intersectmat[ktemp,1]
              #
              #   tempmean <- tempmeans[k_index]
              #   templower <- templowers[k_index]
              #   tempupper <- tempuppers[k_index]
              #
              #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
              #   tempintegralval <- tempintegralval*onedim_int
              #
              # }

              # TEST
              # tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

              # if(tempintegralval == tempintegralval2){
              #   print("Vectorization of qkt integral calculation seems to work.")
              # }else{
              #   print("Line 1677. error in vectorization of qkt integral.")
              # }

              #Save integral result
              # qkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

              # keep adding as loop over m_ind
              qkt_mat[rowind,lastcol_ind] <- qkt_mat[rowind,lastcol_ind] +
                qm_1min1_vec[m_ind]*tempintegralval


            } # end of loop over m_ind



          } # end of loop over rowind (rows of qkt_mat)


          # If ordering does not obey constraint
          #check if ordering obeys rankvec_t

          #n columns of kcomb_vec_mat

          # for a given row,
          # the ordering must agree with rankvec_t (with strict or weak inequality)


          # remove rows that do not obey constraint
          # or set corresponding nkt value to 0

          # possibly uses a lot of memory to create another matrix of ranks

          # how to deal with ties?
          # kcomb_rank_mat <- apply(kcomb_vec_mat, 1, rank)

          # or just loop through all rows

          # ASSUMING NO TIES IN OBSERVED RANKS rankvec_t


          # ACTUALLY, nkt does not involve restricted ranks. Can apply to ALL k

          # keepbools <- rep(NA, nrow(kcomb_vec_mat))
          # strictbools <- rep(NA, nrow(kcomb_vec_mat))
          #
          #
          # for(rowind in 1:nrow(kcomb_vec_mat)){
          #
          #   krow <- kcomb_vec_mat[rowind,]
          #
          #   # TRUE if obeys with weak or strict equality
          #   keepbools[rowind] <- all(rank( krow , ties.method = "min") <= rankvec_t)
          #   strictbools[rowind] <- all(rank( krow , ties.method = "min") == rankvec_t)
          #
          # }
          #
          # #this might not be optimal if want to preserve ordering of combinations
          # kcomb_strict_mat <- kcomb_vec_mat[strictbools, ]
          # kcomb_weak_mat <- kcomb_vec_mat[keepbools & (!strictbools), ]
          #
          #
          #
          # # free up some memory ?
          # rm(kcomb_vec_mat)
          #
          # # perhaps need to keep track of k1, k2, k3, etc
          #
          # n_strict <- nrow(kcomb_strict_mat)
          # n_weak <- nrow(kcomb_weak_mat)
          #
          # #
          # qkt_mat <- rbind(kcomb_strict_mat, kcomb_weak_mat)
          #
          #
          # # free up some memory ?
          # rm(kcomb_strict_mat, kcomb_weak_mat)
          #
          # #last column be integral values
          # qkt_mat <- cbind(qkt_mat, rep(NA, nrow(qkt_mat)))
          #
          # lastcol_ind <- ncol(qkt_mat)
          # # now fill in values of qkt_mat
          #
          # for(rowind in 1:n_strict ){
          #
          #   #obeys constraint exactly, so just take product of univariate normal integrals
          #
          #   tempintegralval <- 1
          #   # Product of pnorm() interval values with
          #   for(k_index in 1:(lastcol_ind-1)){
          #     ktemp <- qkt_mat[rowind,k_index]
          #     tempmean <- intersectmat[ktemp,1]
          #     templower <- intersectmat[ktemp,2]
          #     tempupper <- intersectmat[ktemp,3]
          #
          #     onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
          #     tempintegralval <- tempintegralval*onedim_int
          #
          #   }
          #
          #   qkt_mat[rowind,lastcol_ind] <- tempintegralval#include product here
          #
          # }
          # for(rowind in 1:n_weak ){
          #
          #   #apply method of Gessner et al
          #   qkt_mat[n_strict+ rowind,lastcol_ind] <- notcalculatedyet#include product here
          #
          # }



          qkt_list[[t]] <- qkt_mat

        }else{ # Allow covariates to vary over items, so sets of possible regions are item specific

          #there are n.item*nrow(intersectmat) possible regions

          # create list of vectors of indices for k1, k2, ..., k_{n.item}
          # to be used as input to expand.grid

          #straightforward for itemcovars == FALSE

          K_ind_list <-list()

          for(index_item in 1:n.item){
            K_ind_list[[index_item]] <- 1:nrow(list_item_intersectmats[[index_item]])
          }

          # there are many possible combinations
          # this might produce a huge matrix
          # not the most efficient way of coding this
          kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

          # this line is included to avoid an error later using all.equal
          colnames(kcomb_vec_mat) <- NULL

          qkt_mat <- cbind(kcomb_vec_mat, rep(0, nrow(kcomb_vec_mat)))
          # rm(kcomb_vec_mat)

          # ktemp <- k_indvec[k_index]
          # tempmean <- intersectmat[ktemp,1]

          # tempmean <- tempmeans[k_index]


          temp_intersectmat <- list_item_intersectmats[[k_index]]

          # templower <- list_item_intersectmats[[k_index]][ktemp,2]
          # tempupper <- list_item_intersectmats[[k_index]][ktemp,3]
          #
          # onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)

          k_indvec <- qkt_mat[rowind,1:(lastcol_ind-1)]

          # lowers and uppers are for item-specific regions in time period t

          #


          templowers <- rep(NA, n.item)
          tempuppers <- rep(NA, n.item)

          for(k_index in 1:n.item){

            ktemp <- k_indvec[k_index]

            templowers[ktemp] <- list_item_intersectmats[[k_index]][ktemp,2]
            tempuppers[ktemp] <- list_item_intersectmats[[k_index]][ktemp,3]

          }





          for(rowind in 1:nrow(qkt_mat) ){


            # if ordering does not agree, all integrals will evaluate to zero and can then skip to next
            # NOTE THAT THIS REQUIRES NO ITEM-SPECIFIC COVARIATES
            # OTHERWISE MUST CHECK BOUNDS

            # can probably vectorize this
            # vectorize later if need to increase speed

            krow <- kcomb_vec_mat[rowind,]


            # NEED TO CHECK IF BOUNDS IMPLY KEEP OR REMOVE BECAUSE INTERVALS ARE ITEM SPECIFIC
            # CAN NOT JUST CHECK RANKS OF INTERVAL INDICES

            # DO NOT KEEP CONDITION:
            # z_j > z_i if j lower > i upper

            keepbool <- FALSE

            inds_so_far <- vector(mode = "integer", length = 0)

            for(indrank in 1:n.item){

              if(indrank==n.item){
                # no more comparisons to make
                keepbool <- TRUE
                break
              }
              # MUST BE EDITED IF ALLOW FOR TIES
              i_ind <-  which(rankvec_tmin1 == indrank)

              # if(indrank ==1){
              #   j_ind <- i_ind
              #   next
              # }


              if(   any(templowers[i_ind] > tempuppers[setdiff(1:n.item, inds_so_far)] ) ){
                # at least one higher ranked item j is guaranteed to have z_i > z_j
                # instead of z_i < z_j (so would disagree with ranking)
                # do not continue
                keepbool <- FALSE

                break

              }else{
                # continue
              }

              # j_ind <- i_ind

              inds_so_far <- c(inds_so_far, i_ind)

              if(indrank==n.item){
                keepbool <- TRUE
              }

            }


            if(keepbool == FALSE){
              qkt_mat[rowind,lastcol_ind] <- 0
              next
            }

            # NEED TO CHECK IF BOUNDS AGREE BECAUSE INTERVALS ARE ITEM SPECIFIC
            # CAN NOT JUST CHEK RANKS OF INTERVAL INDICES

            # z_i > z_j if i lower > j upper

            strictbool <- FALSE

            inds_so_far <- vector(mode = "integer", length = 0)

            for(indrank in 1:n.item){

              if(indrank==n.item){
                # no more comparisons to make
                strictbool <- TRUE
                break
              }
              # MUST BE EDITED IF ALLOW FOR TIES
              i_ind <-  which(rankvec_tmin1 == indrank)

              # if(indrank ==1){
              #   j_ind <- i_ind
              #   next
              # }


              if(   all(templowers[setdiff(1:n.item, inds_so_far)] > tempuppers[i_ind] )){
                # good, all higher ranked items j are guaranteed to have z_j > z_i, continue
              }else{
                # cannot guarantee z_i > z_j
                strictbool <- FALSE

                break
              }

              # j_ind <- i_ind

              inds_so_far <- c(inds_so_far, i_ind)

              if(indrank==n.item){
                strictbool <- TRUE
              }

            }


            # keepbool <- all(rank( krow , ties.method = "min") <= rankvec_t)
            #
            # if(keepbool == FALSE){
            #   qkt_mat[rowind,lastcol_ind] <- 0
            #   next
            # }
            #
            # strictbool <- all(rank( krow , ties.method = "min") == rankvec_t)



            # loop over previous time period

            num_m_vecs <- nrow(qkt_list[[t-1]])
            # number of indices/regions
            # should be n.item ?
            num_m_inds <- ncol(qkt_list[[t-1]])

            qm_1min1_vec <- (qkt_list[[t-1]])[,ncol(qkt_list[[t-1]])]

            if(strictbool == TRUE){
              # can calculate relatively straightforward integrals

              for(m_ind in 1:num_m_vecs){

                # obtain mean vector from t-1 corresponding to m_ind
                temp_intersectmat_tmin1 <- list_item_intersectmats_tmin1[[m_ind]]

                m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]

                for(k_index in 1:n.item){

                  ktemp <- m_inds[k_index]

                  tempmean[k_index] <- list_item_intersectmats_tmin1[[k_index]][ktemp,1]

                }
                # tempmeans <- temp_intersectmat_tmin1[m_inds,1]

                # tempintegralval <- 1
                #
                # # can probably vectorize this?
                # for(k_index in 1:(lastcol_ind-1)){
                #   ktemp <- k_indvec[k_index]
                #
                #   # tempmean <- intersectmat[ktemp,1]
                #
                #   tempmean <- tempmeans[k_index]
                #   templower <- templowers[k_index]
                #   tempupper <- tempuppers[k_index]
                #
                #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
                #   tempintegralval <- tempintegralval*onedim_int
                #
                # }

                # TEST
                tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) -
                                           pnorm(templowers, mean = tempmeans, sd = 1) )

                # if(tempintegralval == tempintegralval2){
                #   print("Vectorization of qkt integral calculation seems to work.")
                # }else{
                #   print("Line 1677. error in vectorization of qkt integral.")
                # }

                #Save integral result
                # qkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

                # keep adding as loop over m_ind
                qkt_mat[rowind,lastcol_ind] <- qkt_mat[rowind,lastcol_ind] +
                  qm_1min1_vec[m_ind]*tempintegralval


              } # end of loop over m_ind

              # rest of code is for integrals bounded by the rank constraint

              # so can skip

              next
            }




            # will use constraint implied by ranks in previous time period
            # rankconstraint_tmin1

            # rankconstraint_t

            # obtain constraint implied by templowers and tempuppers


            # corresponds to A_C in the paper
            # number of rows is 2*n.item
            # number of columns is n.item

            # boundconstraints <- matrix(NA,
            #                            nrow = 2*n.item,
            #                            ncol = n.item)
            #
            # # use kroenecker product
            # # there is probably a more efficient way of doing this
            #
            # boundconstraints <- diag(1,n.item, n.item) %x% c(1,-1)


            # t(diag(1,3, 3) %x% c(1,-1))

            # A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)
            #
            # tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)


            #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT




            # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
            # and for each pair of bounds, the first is the negative of the uper bound
            # and the second is the upper bound

            # jumps of 2 from n.item to 3*n.item - 2
            lb_inds <- n.item - 2 + 2*(1:n.item)
            # jumps of 2 from n.item + 1 to 3*n.item - 1
            ub_inds <- n.item - 1+ 2*(1:n.item)



            bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
            bvec[lb_inds] <- -1*templowers
            bvec[ub_inds] <- tempuppers



            # must shift the constraint





            for(m_ind in 1:num_m_vecs){

              # obtain mean vector from t-1 corresponding to m_ind
              # temp_intersectmat_tmin1 <- list_item_intersectmats_tmin1[[m_ind]]

              # obtain mean vector from t-1 corresponding to m_ind
              # temp_intersectmat_tmin1 <- list_item_intersectmats_tmin1[[m_ind]]

              m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]

              for(k_index in 1:n.item){

                ktemp <- m_inds[k_index]

                tempmean[k_index] <- list_item_intersectmats_tmin1[[k_index]][ktemp,1]

              }

              # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
              # tempmeans <- temp_intersectmat_tmin1[m_inds,1]


              bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans

              # NOTE: The SubsetSimFast and HDR_algoFast functions
              # use the transpose of the constraint matrix as an input

              sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                        bvec_temp,
                                                        N_hdr,
                                                        rho_hdr )

              hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                       bvec_temp,
                                                       c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                       N_hdr )

              #Probability Estimate from subset simulation
              # exp(sub_retFast$logZ)

              #Probability Estimate from HDR
              tempintegralval <- exp(hdr_retFast)




              # tempintegralval <- 1
              #
              # # can probably vectorize this?
              # for(k_index in 1:(lastcol_ind-1)){
              #   ktemp <- k_indvec[k_index]
              #
              #   # tempmean <- intersectmat[ktemp,1]
              #
              #   tempmean <- tempmeans[k_index]
              #   templower <- templowers[k_index]
              #   tempupper <- tempuppers[k_index]
              #
              #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
              #   tempintegralval <- tempintegralval*onedim_int
              #
              # }

              # TEST
              # tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

              # if(tempintegralval == tempintegralval2){
              #   print("Vectorization of qkt integral calculation seems to work.")
              # }else{
              #   print("Line 1677. error in vectorization of qkt integral.")
              # }

              #Save integral result
              # qkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

              # keep adding as loop over m_ind
              qkt_mat[rowind,lastcol_ind] <- qkt_mat[rowind,lastcol_ind] +
                qm_1min1_vec[m_ind]*tempintegralval


            } # end of loop over m_ind



          } # end of loop over rowind (rows of qkt_mat)



          qkt_list[[t]] <- qkt_mat

        } # end else statement # Allow covariates to vary over items, so sets of possible regions are item specific



        # update tmin1 intersection matrices
        # for next round
        if(itemcovars == FALSE){
          intersectmat_tmin1 <- intersectmat

        }else{
          list_item_intersectmats_tmin1 <- list_item_intersectmats

        }

        if(t < n.time+1){

          rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t]

          A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)

          tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)

        }


      } # END LOOP OVER t, finished creating qkt_list

      ###### beginning nkt calculations ####################################################

      # loop backwards over time periods

      # begin with special cases t=T and t = T-1

      # t = T

      # obtain ordering for time T
      rankvec_t <- ranks_mat[,  (n.time-1)*n.ranker + indiv]




      ##### Consider creating and storing all rank constraints outside of Gibbs sampler################
      # this will save computational time
      # and possibly require a lot of memory?

      rankconstraint_t <- matrix(0,
                                 nrow = length(rankvec_t)-1,
                                 ncol = length(rankvec_t))


      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1


      }


      rankconstraint_T <- rankconstraint_t

      # The smoothing distribution coincides with the filtering distribution

      # Calculate the necessary values to compute the weights of the mixture distribution


      # nkt_vec is a vector of integrals for regions-specific parameters k
      # the integrals are constrained by the ranker and time specific sets A_{i,t}
      # where A_{i,t} is defined by the ordering of the ranks given by ranker i at time t

      # requires:
      # 1. ranker and time specific rankings
      # 2. vector of mean parameters for all possible regions defined by the sum-of-tree structure


      # create intersection matrices


      # create vector of indices for ranker indiv in time period T
      ind_start <- (n.time - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
      ind_end <- (n.time - 1)*n.ranker*n.item+n.item*indiv
      obs_indices <- ind_start:ind_end

      if(itemcovars == FALSE){


        list_inter_mats <- list()

        for(i in 1:n.trees){

          treeexample1 <- sampler$getTrees(treeNums = i,
                                           chainNums = 1,
                                           sampleNums = 1)

          rebuilt_tree <- rebuildTree2(treeexample1)


          #must use covariates for individual indiv at time period t

          list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],, drop = FALSE] )


        }

        intersectmat <- interNtreesB(list_inter_mats)


      }else{ # itemcovars == TRUE


        list_item_intersectmats <- list()

        for(index_item in 1:n.item){

          obs_one_ind <- (n.time - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

          list_inter_mats <- list()

          for(i in 1:n.trees){

            treeexample1 <- sampler$getTrees(treeNums = i,
                                             chainNums = 1,
                                             sampleNums = 1)

            rebuilt_tree <- rebuildTree2(treeexample1)


            #must use covariates for individual indiv at time period t

            list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,, drop = FALSE] )


          } #end loop over trees

          intersectmat <- interNtreesB(list_inter_mats)

          list_item_intersectmats[[index_item]] <- intersectmat


        } #end loop over items

      } # end else itemcovars == TRUE


      # obtain intersections













      ########### calculate nkt for t = T ########################################


      # If regions vary across time
      # Then nktvec and qkt vec are time-specific
      # NOT JUST THROUGH dependence on observed ranks at time t
      # also through time-specific k

      # if covariates are item-specific, then the
      # combinations of regions, k involve
      # item-specific ranges of regions

      # in either case, must loop through combinations of regions
      # there are some possible symmetries
      # IGNORE SYMMETRIES





      if(itemcovars == FALSE){

        #there are n.item*nrow(intersectmat) possible regions

        # create list of vectors of indices for k1, k2, ..., k_{n.item}
        # to be used as input to expand.grid

        #straightforward for itemcovars == FALSE

        K_ind_list <-list()

        for(index_item in 1:n.item){
          K_ind_list[[index_item]] <- 1:nrow(intersectmat)
        }

        # there are many possible combinations
        # this might produce a huge matrix
        # not the most efficeient way of coding this
        kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

        # this line is included to avoid an error later using all.equal
        colnames(kcomb_vec_mat) <- NULL

        nkt_mat <- cbind(kcomb_vec_mat, rep(NA, nrow(kcomb_vec_mat)))
        rm(kcomb_vec_mat)


        for(rowind in 1:nrow(nkt_mat) ){

          #obtain means
          #vector k1, k2, k3, etc
          k_indvec <- nkt_mat[rowind,1:(lastcol_ind-1)]

          #note: k_indvec can include repeated values
          tempmeans <- intersectmat[k_indvec,1]

          # templowers <- intersectmat[k_indvec,2]
          # tempuppers <- intersectmat[k_indvec,3]


          # Apply methods of Gessner et al

          # create matrix A, vector b

          # for nkt_mat calcultions, the only constraint is the rank order A_t
          # so

          # A matrix is rankconstraint_t
          # original b vector is vector of zeros
          # However must shift the constraints as outlined in the paper
          # the mu vector is tempmeans
          # Therefore the shifted b vector is
          # (rankconstraint_t)%*%tempmeans

          bvec_temp <- (rankconstraint_t)%*%tempmeans



          # NOTE: The SubsetSimFast and HDR_algoFast functions
          # use the transpose of the constraint matrix as an input

          sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                    bvec_temp,
                                                    N_hdr,
                                                    rho_hdr )

          hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                   bvec_temp,
                                                   c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                   N_hdr )

          #Probability Estimate from subset simulation
          # exp(sub_retFast$logZ)

          #Probability Estimate from HDR
          tempintegralval <- exp(hdr_retFast)




          # for(k_index in 1:(lastcol_ind-1)){
          #       ktemp <- nkt_mat[rowind,k_index]
          #       tempmean <- intersectmat[ktemp,1]
          #       templower <- intersectmat[ktemp,2]
          #       tempupper <- intersectmat[ktemp,3]
          #
          #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
          #       tempintegralval <- tempintegralval*onedim_int
          # }

          #Save integral result
          nkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

        }


        # If ordering does not obey constraint
        #check if ordering obeys rankvec_t

        #n columns of kcomb_vec_mat

        # for a given row,
        # the ordering must agree with rankvec_t (with strict or weak inequality)


        # remove rows that do not obey constraint
        # or set corresponding nkt value to 0

        # possibly uses a lot of memory to create another matrix of ranks

        # how to deal with ties?
        # kcomb_rank_mat <- apply(kcomb_vec_mat, 1, rank)

        # or just loop through all rows

        # ASSUMING NO TIES IN OBSERVED RANKS rankvec_t


        # ACTUALLY, nkt does not involve restricted rankes. Can apply to ALL k

        # keepbools <- rep(NA, nrow(kcomb_vec_mat))
        # strictbools <- rep(NA, nrow(kcomb_vec_mat))
        #
        #
        # for(rowind in 1:nrow(kcomb_vec_mat)){
        #
        #   krow <- kcomb_vec_mat[rowind,]
        #
        #   # TRUE if obeys with weak or strict equality
        #   keepbools[rowind] <- all(rank( krow , ties.method = "min") <= rankvec_t)
        #   strictbools[rowind] <- all(rank( krow , ties.method = "min") == rankvec_t)
        #
        # }
        #
        # #this might not be optimal if want to preserve ordering of combinations
        # kcomb_strict_mat <- kcomb_vec_mat[strictbools, ]
        # kcomb_weak_mat <- kcomb_vec_mat[keepbools & (!strictbools), ]
        #
        #
        #
        # # free up some memory ?
        # rm(kcomb_vec_mat)
        #
        # # perhaps need to keep track of k1, k2, k3, etc
        #
        # n_strict <- nrow(kcomb_strict_mat)
        # n_weak <- nrow(kcomb_weak_mat)
        #
        # #
        # nkt_mat <- rbind(kcomb_strict_mat, kcomb_weak_mat)
        #
        #
        # # free up some memory ?
        # rm(kcomb_strict_mat, kcomb_weak_mat)
        #
        # #last column be integral values
        # nkt_mat <- cbind(nkt_mat, rep(NA, nrow(nkt_mat)))
        #
        # lastcol_ind <- ncol(nkt_mat)
        # # now fill in values of nkt_mat
        #
        # for(rowind in 1:n_strict ){
        #
        #   #obeys constraint exactly, so just take product of univariate normal integrals
        #
        #   tempintegralval <- 1
        #   # Product of pnorm() interval values with
        #   for(k_index in 1:(lastcol_ind-1)){
        #     ktemp <- nkt_mat[rowind,k_index]
        #     tempmean <- intersectmat[ktemp,1]
        #     templower <- intersectmat[ktemp,2]
        #     tempupper <- intersectmat[ktemp,3]
        #
        #     onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
        #     tempintegralval <- tempintegralval*onedim_int
        #
        #   }
        #
        #   nkt_mat[rowind,lastcol_ind] <- tempintegralval#include product here
        #
        # }
        # for(rowind in 1:n_weak ){
        #
        #   #apply method of Gessner et al
        #   nkt_mat[n_strict+ rowind,lastcol_ind] <- notcalculatedyet#include product here
        #
        # }


      }else{ # Allow covariates to vary over items, so sets of possible regions are item specific

        #there are n.item*nrow(intersectmat) possible regions

        # create list of vectors of indices for k1, k2, ..., k_{n.item}
        # to be used as input to expand.grid

        #straightforward for itemcovars == FALSE

        K_ind_list <-list()

        for(index_item in 1:n.item){
          K_ind_list[[index_item]] <- 1:nrow(list_item_intersectmats[[index_item]])
        }

        # there are many possible combinations
        # this might produce a huge matrix
        # not the most efficient way of coding this
        kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

        # this line is included to avoid an error later using all.equal
        colnames(kcomb_vec_mat) <- NULL

        nkt_mat <- cbind(kcomb_vec_mat, rep(NA, nrow(kcomb_vec_mat)))
        rm(kcomb_vec_mat)


        for(rowind in 1:nrow(nkt_mat) ){

          #obtain means
          #vector k1, k2, k3, etc

          k_indvec <- nkt_mat[rowind,1:(lastcol_ind-1)]

          #note: k_indvec can include repeated values

          # since covariates can vary over items
          # the means are obtained from item-specific intersectmats

          tempmeans <- rep(NA, length(k_indvec))

          for(ktemp in 1:length(k_indvec)){

            tempmeans[ktemp] <- (list_item_intersectmats[[ktemp]])[k_indvec[ktemp],1]
          }



          # tempmeans <- intersectmat[k_indvec,1]

          # templowers <- intersectmat[k_indvec,2]
          # tempuppers <- intersectmat[k_indvec,3]


          # Apply methods of Gessner et al

          # create matrix A, vector b

          # for nkt_mat calcultions, the only constraint is the rank order A_t
          # so

          # A matrix is rankconstraint_t
          # original b vector is vector of zeros
          # However must shist the constraints as outlined in the paper
          # the mu vector is tempmeans
          # Therefore the shifted b vector is
          # (rankconstraint_t)%*%tempmeans

          bvec_temp <- (rankconstraint_t)%*%tempmeans




          sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                    bvec_temp,
                                                    N_hdr,
                                                    rho_hdr )

          hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                   bvec_temp,
                                                   c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                   N_hdr )

          #Probability Estimate from subset simulation
          # exp(sub_retFast$logZ)

          #Probability Estimate from HDR
          tempintegralval <- exp(hdr_retFast)




          # for(k_index in 1:(lastcol_ind-1)){
          #       ktemp <- nkt_mat[rowind,k_index]
          #       tempmean <- intersectmat[ktemp,1]
          #       templower <- intersectmat[ktemp,2]
          #       tempupper <- intersectmat[ktemp,3]
          #
          #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
          #       tempintegralval <- tempintegralval*onedim_int
          # }

          #Save integral result
          nkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

        }




      } # end else statement # Allow covariates to vary over items, so sets of possible regions are item specific


      intersectmat_T <- NA
      list_item_intersectmats_T <- NA

      if(itemcovars == TRUE){
        intersectmat_T <- intersectmat

      }else{
        list_item_intersectmats_T <- list_item_intersectmats
      }


      nkt_mat_T <- nkt_mat



      ######### calculate wkt for T ###########################################

      # Then calculate weights

      temp_qkt_mat <- qkt_list[[n.time]]

      wkt_vec <- temp_qkt_mat[, ncol(temp_qkt_mat)]*nkt_mat[ ,ncol(nkt_mat)]
      # normalize
      wkt_vec <- wkt_vec/sum(wkt_vec)

      # sample an index vector k
      component_ind <- sample.int(length(wkt_vec),
                                  size = 1,
                                  replace = FALSE,
                                  prob = wkt_vec)

      ####### Sample for T given component ###########################

      # Now draw from corresponding truncated normal distribution
      # with means mu_k
      # and constraint matrix rankconstraint_t

      lastcol_ind <- ncol(nkt_mat)
      k_indvec <- nkt_mat[component_ind,1:(lastcol_ind-1)]


      if(itemcovars == FALSE){

        #note: k_indvec can include repeated values
        tempmeans <- intersectmat[k_indvec,1]


      }else{ # Allow covariates to vary over time

        #note: k_indvec can include repeated values

        # since covariates can vary over items
        # the means are obtained from item-specific intersectmats

        tempmeans <- rep(NA, length(k_indvec))

        for(ktemp in 1:length(k_indvec)){

          tempmeans[ktemp] <- (list_item_intersectmats[[ktemp]])[k_indvec[ktemp],1]
        }


      } # end else statement (obtaining means for item-specific regions)


      bvec_temp <- (rankconstraint_t)%*%tempmeans

      # require an initial value in the domain
      # arbitrarily set lowest to 10/n.item
      # then add 10/n.item for each

      # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

      # z_init <- rep(NA, n.item)
      #
      # # This can probably be vectorized
      # for(z_ind in 1:n.item){
      #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
      # }

      # or is a random sample required?
      # z_init <- rep(0, n.item)
      # z_init<- rnorm(n.item)
      z_init<- rnorm(n = n.item, mean = -1* tempmeans)

      if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
        # in domain
        # print("in domain")
      }else{
        # stop("Error. Initial vector not in domain")

        # perhaps take random samples until a point is found in the doain
        # ElilipticalSliceSampler python function might do something like this
        # at least if there is not any initial value

        while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
          print("not in domain. Sample x0 again")

          # x0 <- rnorm(length(z_init))
          z_init<- rnorm(n.item)

          # x0 <- xnew
        }
      }


      # Take 100 samples, then just use last column
      # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
      z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                  bvec_temp,
                                  Num_lin_ess_samples,
                                  z_init,
                                  nskip = 0)

      #save sample

      Z.mat[,(n.time-1)*n.ranker + indiv] <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans



      ######## Sample Z for T-1 ######################################################

      ######## ranks, intersections for T-1 ######################################################

      # t = T-1

      # obtain ordering for time T-1
      rankvec_t <- ranks_mat[,  (n.time-1-1)*n.ranker + indiv]





      ##### Consider creating and storing all rank constraints outside of Gibbs sampler################
      # this will save computational time
      # and possibly require a lot of memory?

      rankconstraint_t <- matrix(0,
                                 nrow = length(rankvec_t)-1,
                                 ncol = length(rankvec_t))


      # note: ordering of rows is unimportant
      # as long as ordering agrees with the ordering of the mean vector

      # so can begin by filling in first row

      #MUST BE EDITED IF ALLOW FOR TIES
      for(rankind in 1:(length(rankvec_t)-1)){

        rankconstraint_t[rankind, which(rankvec_t == rankind)] <- -1
        rankconstraint_t[rankind, which(rankvec_t == rankind+1)] <- 1

        # rankconstraint_t[rankind, rankvec_t[rankind]] <- -1
        # rankconstraint_t[rankind, rankvec_t[rankind+1]] <- 1

      }



      # The smoothing distribution coincides with the filtering distribution

      # Calculate the necessary values to compute the weights of the mixture distribution


      # nkt_vec is a vector of integrals for regions-specific parameters k
      # the integrals are constrained by the ranker and time specific sets A_{i,t}
      # where A_{i,t} is defined by the ordering of the ranks given by ranker i at time t

      # requires:
      # 1. ranker and time specific rankings
      # 2. vector of mean parameters for all possible regions defined by the sum-of-tree structure


      # create intersection matrices
      # note that intersection matrices can be time period specific if allow for time period specific covariates

      # create vector of indices for ranker indiv in time period T
      ind_start <- (n.time -1 - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
      ind_end <- (n.time -1 - 1)*n.ranker*n.item+n.item*indiv
      obs_indices <- ind_start:ind_end

      if(itemcovars == FALSE){


        list_inter_mats <- list()

        for(i in 1:n.trees){

          treeexample1 <- sampler$getTrees(treeNums = i,
                                           chainNums = 1,
                                           sampleNums = 1)

          rebuilt_tree <- rebuildTree2(treeexample1)


          #must use covariates for individual indiv at time period t

          list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],, drop = FALSE] )


        }

        intersectmat <- interNtreesB(list_inter_mats)


      }else{ # itemcovars == TRUE


        list_item_intersectmats <- list()

        for(index_item in 1:n.item){

          # will need to edit this for t < T-1
          obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

          list_inter_mats <- list()

          for(i in 1:n.trees){

            treeexample1 <- sampler$getTrees(treeNums = i,
                                             chainNums = 1,
                                             sampleNums = 1)

            rebuilt_tree <- rebuildTree2(treeexample1)



            #must use covariates for individual indiv at time period t

            list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,, drop = FALSE] )


          } #end loop over trees

          intersectmat <- interNtreesB(list_inter_mats)

          list_item_intersectmats[[index_item]] <- intersectmat


        } #end loop over items

      } # end else itemcovars == TRUE


      # save old intersections

      intersectmat_Tmin1 <- NA
      list_item_intersectmats_Tmin1 <- NA

      if(itemcovars == TRUE){
        intersectmat_Tmin1 <- intersectmat

      }else{
        list_item_intersectmats_Tmin1 <- list_item_intersectmats
      }






      #will use this for r_{\K^T}^{(T)}


      nkt_mat_T <- nkt_mat




      ###########  calculate nkt for t = T - 1 ########################################


      # If regions vary across time
      # Then nktvec and qkt vec are time-specific
      # NOT JUST THROUGH dependence on observed ranks at time t
      # also through time-specific k

      # if covariates are item-specific, then the
      # combinations of regions, k involve
      # item-specific ranges of regions

      # in either case, must loop through combinations of regions
      # there are some possible symmetries
      # IGNORE SYMMETRIES





      if(itemcovars == FALSE){

        #there are n.item*nrow(intersectmat) possible regions

        # create list of vectors of indices for k1, k2, ..., k_{n.item}
        # to be used as input to expand.grid

        #straightforward for itemcovars == FALSE

        K_ind_list <-list()

        for(index_item in 1:n.item){
          K_ind_list[[index_item]] <- 1:nrow(intersectmat)
        }

        # there are many possible combinations
        # this might produce a huge matrix
        # not the most efficeient way of coding this
        kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

        # this line is included to avoid an error later using all.equal
        colnames(kcomb_vec_mat) <- NULL

        nkt_mat <- cbind(kcomb_vec_mat, rep(NA, nrow(kcomb_vec_mat)))
        rm(kcomb_vec_mat)


        for(rowind in 1:nrow(nkt_mat) ){

          #obtain means
          #vector k1, k2, k3, etc
          k_indvec <- nkt_mat[rowind,1:(lastcol_ind-1)]

          #note: k_indvec can include repeated values
          tempmeans <- intersectmat[k_indvec,1]

          # templowers <- intersectmat[k_indvec,2]
          # tempuppers <- intersectmat[k_indvec,3]


          # Apply methods of Gessner et al

          # create matrix A, vector b

          # for nkt_mat calcultions, the only constraint is the rank order A_t
          # so

          # A matrix is rankconstraint_t
          # original b vector is vector of zeros
          # However must shift the constraints as outlined in the paper
          # the mu vector is tempmeans
          # Therefore the shifted b vector is
          # (rankconstraint_t)%*%tempmeans

          bvec_temp <- (rankconstraint_t)%*%tempmeans



          # NOTE: The SubsetSimFast and HDR_algoFast functions
          # use the transpose of the constraint matrix as an input

          sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                    bvec_temp,
                                                    N_hdr,
                                                    rho_hdr )

          hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                   bvec_temp,
                                                   c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                   N_hdr )

          #Probability Estimate from subset simulation
          # exp(sub_retFast$logZ)

          #Probability Estimate from HDR
          tempintegralval <- exp(hdr_retFast)




          # for(k_index in 1:(lastcol_ind-1)){
          #       ktemp <- nkt_mat[rowind,k_index]
          #       tempmean <- intersectmat[ktemp,1]
          #       templower <- intersectmat[ktemp,2]
          #       tempupper <- intersectmat[ktemp,3]
          #
          #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
          #       tempintegralval <- tempintegralval*onedim_int
          # }

          #Save integral result
          nkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

        }


        # If ordering does not obey constraint
        #check if ordering obeys rankvec_t

        #n columns of kcomb_vec_mat

        # for a given row,
        # the ordering must agree with rankvec_t (with strict or weak inequality)


        # remove rows that do not obey constraint
        # or set corresponding nkt value to 0

        # possibly uses a lot of memory to create another matrix of ranks

        # how to deal with ties?
        # kcomb_rank_mat <- apply(kcomb_vec_mat, 1, rank)

        # or just loop through all rows

        # ASSUMING NO TIES IN OBSERVED RANKS rankvec_t


        # ACTUALLY, nkt does not involve restricted ranks. Can apply to ALL k

        # keepbools <- rep(NA, nrow(kcomb_vec_mat))
        # strictbools <- rep(NA, nrow(kcomb_vec_mat))
        #
        #
        # for(rowind in 1:nrow(kcomb_vec_mat)){
        #
        #   krow <- kcomb_vec_mat[rowind,]
        #
        #   # TRUE if obeys with weak or strict equality
        #   keepbools[rowind] <- all(rank( krow , ties.method = "min") <= rankvec_t)
        #   strictbools[rowind] <- all(rank( krow , ties.method = "min") == rankvec_t)
        #
        # }
        #
        # #this might not be optimal if want to preserve ordering of combinations
        # kcomb_strict_mat <- kcomb_vec_mat[strictbools, ]
        # kcomb_weak_mat <- kcomb_vec_mat[keepbools & (!strictbools), ]
        #
        #
        #
        # # free up some memory ?
        # rm(kcomb_vec_mat)
        #
        # # perhaps need to keep track of k1, k2, k3, etc
        #
        # n_strict <- nrow(kcomb_strict_mat)
        # n_weak <- nrow(kcomb_weak_mat)
        #
        # #
        # nkt_mat <- rbind(kcomb_strict_mat, kcomb_weak_mat)
        #
        #
        # # free up some memory ?
        # rm(kcomb_strict_mat, kcomb_weak_mat)
        #
        # #last column be integral values
        # nkt_mat <- cbind(nkt_mat, rep(NA, nrow(nkt_mat)))
        #
        # lastcol_ind <- ncol(nkt_mat)
        # # now fill in values of nkt_mat
        #
        # for(rowind in 1:n_strict ){
        #
        #   #obeys constraint exactly, so just take product of univariate normal integrals
        #
        #   tempintegralval <- 1
        #   # Product of pnorm() interval values with
        #   for(k_index in 1:(lastcol_ind-1)){
        #     ktemp <- nkt_mat[rowind,k_index]
        #     tempmean <- intersectmat[ktemp,1]
        #     templower <- intersectmat[ktemp,2]
        #     tempupper <- intersectmat[ktemp,3]
        #
        #     onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
        #     tempintegralval <- tempintegralval*onedim_int
        #
        #   }
        #
        #   nkt_mat[rowind,lastcol_ind] <- tempintegralval#include product here
        #
        # }
        # for(rowind in 1:n_weak ){
        #
        #   #apply method of Gessner et al
        #   nkt_mat[n_strict+ rowind,lastcol_ind] <- notcalculatedyet#include product here
        #
        # }


      }else{ # Allow covariates to vary over items, so sets of possible regions are item specific

        #there are n.item*nrow(intersectmat) possible regions

        # create list of vectors of indices for k1, k2, ..., k_{n.item}
        # to be used as input to expand.grid

        #straightforward for itemcovars == FALSE

        K_ind_list <-list()

        for(index_item in 1:n.item){
          K_ind_list[[index_item]] <- 1:nrow(list_item_intersectmats[[index_item]])
        }

        # there are many possible combinations
        # this might produce a huge matrix
        # not the most efficient way of coding this
        kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

        # this line is included to avoid an error later using all.equal
        colnames(kcomb_vec_mat) <- NULL

        nkt_mat <- cbind(kcomb_vec_mat, rep(NA, nrow(kcomb_vec_mat)))
        rm(kcomb_vec_mat)


        for(rowind in 1:nrow(nkt_mat) ){

          #obtain means
          #vector k1, k2, k3, etc

          k_indvec <- nkt_mat[rowind,1:(lastcol_ind-1)]

          #note: k_indvec can include repeated values

          # since covariates can vary over items
          # the means are obtained from item-specific intersectmats

          tempmeans <- rep(NA, length(k_indvec))

          for(ktemp in 1:length(k_indvec)){

            tempmeans[ktemp] <- (list_item_intersectmats[[ktemp]])[k_indvec[ktemp],1]
          }



          # tempmeans <- intersectmat[k_indvec,1]

          # templowers <- intersectmat[k_indvec,2]
          # tempuppers <- intersectmat[k_indvec,3]


          # Apply methods of Gessner et al

          # create matrix A, vector b

          # for nkt_mat calcultions, the only constraint is the rank order A_t
          # so

          # A matrix is rankconstraint_t
          # original b vector is vector of zeros
          # However must shist the constraints as outlined in the paper
          # the mu vector is tempmeans
          # Therefore the shifted b vector is
          # (rankconstraint_t)%*%tempmeans

          bvec_temp <- (rankconstraint_t)%*%tempmeans




          sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                    bvec_temp,
                                                    N_hdr,
                                                    rho_hdr )

          hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                   bvec_temp,
                                                   c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                   N_hdr )

          #Probability Estimate from subset simulation
          # exp(sub_retFast$logZ)

          #Probability Estimate from HDR
          tempintegralval <- exp(hdr_retFast)




          # for(k_index in 1:(lastcol_ind-1)){
          #       ktemp <- nkt_mat[rowind,k_index]
          #       tempmean <- intersectmat[ktemp,1]
          #       templower <- intersectmat[ktemp,2]
          #       tempupper <- intersectmat[ktemp,3]
          #
          #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
          #       tempintegralval <- tempintegralval*onedim_int
          # }

          #Save integral result
          nkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

        }




      } # end else statement # Allow covariates to vary over items, so sets of possible regions are item specific




      nkt_mat_Tmin1 <- nkt_mat




      ######## Calculate mkt_mat for T-1 ######################################################


      rankconstraint_tmin1 <- rank_cons_arr[, , indiv, n.time-1]


      A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)

      tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)


      # For all indices K^T correpsponding to possible sets in time period T
      # calculate r_{\K^T}^{(T)}
      # and r_{\K^T, \K^{(T-1)}}^{(T-1)}

      # First note that r_{\K^T}^{(T)} is nkt_mat for period T row \K, last column


      # For r_{\K^T, \K^{(T-1)}}^{(T-1)}
      # Could probably save values from qkt calculations

      # For now, will just try to save all


      #create mkt mat for time period T-1
      # mkt_mat <- nkt_mat
      #last column contains values
      # mkt_mat[,ncol(mkt_mat)] <- rep(NA, nrow(mkt_mat))

      #actually just need a vector, do not need a new matrix
      mkt_vec <- rep(NA, nrow(nkt_mat))

      # now loop over elements, corresponding to time T-1 and fill in values




      if(itemcovars == FALSE){

        for(k_t_min1 in 1:nrow(nkt_mat_Tmin1)){

          #now will calculate a sum over k^T of products
          # r_{\K^T, \K^{(T-1)}}^{(T-1)} * r_{\K^T}^{(T)}

          # obtain means corresponding to k_t_min1

          # obtain indices
          k_tmin1_indvec <- nkt_mat_Tmin1[k_t_min1,1:(ncol(nkt_mat_Tmin1)-1)]

          # obtain means

          tempmeans <- intersectmat_Tmin1[k_tmin1_indvec,1]



          # assuming intersection matrix is still defined for period T-1?
          temp_sum <- 0

          for(k_t_ind in 1:nrow(nkt_mat_T)){
            # calculate  r_{\K^T, \K^{(T-1)}}^{(T-1)}

            # similar to corresponding integral for qkt

            # obtain lower and upper bounds corresponding to k_t_ind

            # obtain indices
            k_t_indvec <- nkt_mat_T[k_t_ind,1:(ncol(nkt_mat_T)-1)]


            #obtain lower and upper bound vectors
            templowers <- intersectmat_T[k_t_indvec,2]
            tempuppers <- intersectmat_T[k_t_indvec,3]


            krow <- k_t_indvec #kcomb_vec_mat[rowind,]

            # check if time period T regions, indexed by k_t_indvec
            # are guaranteed to satisfy or not satisfy the constraint implied
            # by period T-1 observed ranks

            # current rankvec_t correponds to T-1


            keepbool <- all(rank( krow , ties.method = "min") <= rankvec_t)

            temp_integral <- NA

            if(keepbool == FALSE){
              temp_integral <- 0
              # add nothing to the sum
              next
            }


            strictbool <- all(rank( krow , ties.method = "min") == rankvec_t)

            if(strictbool == TRUE){
              temp_integral <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

              temp_sum <- temp_sum + nkt_mat_T[k_t_ind, ncol(nkt_mat_T)]*temp_integral
              next

            }

            # t(diag(1,3, 3) %x% c(1,-1))

            # A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)
            #
            # tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)


            #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT

            # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
            # and for each pair of bounds, the first is the negative of the uper bound
            # and the second is the upper bound

            # jumps of 2 from n.item to 3*n.item - 2
            lb_inds <- n.item - 2 + 2*(1:n.item)
            # jumps of 2 from n.item + 1 to 3*n.item - 1
            ub_inds <- n.item - 1+ 2*(1:n.item)


            bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
            bvec[lb_inds] <- -1*templowers
            bvec[ub_inds] <- tempuppers

            # must shift the constraint

            # obtain mean vector from t-1 corresponding to m_ind

            # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
            # tempmeans <- intersectmat_tmin1[m_inds,1]

            bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans

            # NOTE: The SubsetSimFast and HDR_algoFast functions
            # use the transpose of the constraint matrix as an input

            sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                      bvec_temp,
                                                      N_hdr,
                                                      rho_hdr )

            hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                     bvec_temp,
                                                     c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                     N_hdr )

            #Probability Estimate from subset simulation
            # exp(sub_retFast$logZ)

            #Probability Estimate from HDR
            temp_integral <- exp(hdr_retFast)


            temp_sum <- temp_sum + nkt_mat_T[k_t_ind, ncol(nkt_mat_T)]*temp_integral


          }


          mkt_vec[k_t_min1] <- temp_sum

        }

      }else{ # if allow for item-specific covariates, i.e. itemcovars == TRUE

        for(k_t_min1 in 1:nrow(nkt_mat_Tmin1)){

          #now will calculate a sum over k^T of products
          # r_{\K^T, \K^{(T-1)}}^{(T-1)} * r_{\K^T}^{(T)}

          # obtain means corresponding to k_t_min1

          # obtain indices
          k_tmin1_indvec <- nkt_mat_Tmin1[k_t_min1,1:(ncol(nkt_mat_Tmin1)-1)]

          # obtain means


          # intersection matrices are item-specific

          # length should be n.item
          tempmeans <- rep(NA, length(k_tmin1_indvec))

          for(ktemp in 1:length(k_tmin1_indvec)){

            tempmeans[ktemp] <- (list_item_intersectmats_Tmin1[[ktemp]])[k_tmin1_indvec[ktemp],1]
          }




          # assuming intersection matrix is still defined for period T-1?
          temp_sum <- 0

          for(k_t_ind in 1:nrow(nkt_mat_T)){
            # calculate  r_{\K^T, \K^{(T-1)}}^{(T-1)}

            # similar to corresponding integral for qkt

            # obtain lower and upper bounds corresponding to k_t_ind

            # obtain indices
            k_t_indvec <- nkt_mat_T[k_t_ind,1:(ncol(nkt_mat_T)-1)]


            #obtain lower and upper bound vectors
            # item-specific time period T bounds

            templowers <- intersectmat_T[k_t_indvec,2]
            tempuppers <- intersectmat_T[k_t_indvec,3]

            templowers <- rep(NA, n.item)
            tempuppers <- rep(NA, n.item)


            for(k_index in 1:length(k_t_indvec)){

              ktemp <- k_indvec[k_index]

              templowers[ktemp] <- (list_item_intersectmats_T[[k_index]])[ktemp,2]
              tempuppers[ktemp] <- (list_item_intersectmats_T[[k_index]])[ktemp,3]

            }



            krow <- k_t_indvec #kcomb_vec_mat[rowind,]




            # krow <- kcomb_vec_mat[rowind,]


            # NEED TO CHECK IF BOUNDS IMPLY KEEP OR REMOVE BECAUSE INTERVALS ARE ITEM SPECIFIC
            # CAN NOT JUST CHECK RANKS OF INTERVAL INDICES

            # DO NOT KEEP CONDITION:
            # z_j > z_i if j lower > i upper

            keepbool <- FALSE

            inds_so_far <- vector(mode = "integer", length = 0)

            for(indrank in 1:n.item){

              if(indrank==n.item){
                # no more comparisons to make
                keepbool <- TRUE
                break
              }

              # current rankvec_t correponds to T-1

              # MUST BE EDITED IF ALLOW FOR TIES
              i_ind <-  which(rankvec_t == indrank)

              # if(indrank ==1){
              #   j_ind <- i_ind
              #   next
              # }


              if(   any(templowers[i_ind] > tempuppers[setdiff(1:n.item, inds_so_far)] ) ){
                # at least one higher ranked item j is guaranteed to have z_i > z_j
                # instead of z_i < z_j (so would disagree with ranking)
                # do not continue
                keepbool <- FALSE

                break

              }else{
                # continue
              }

              # j_ind <- i_ind

              inds_so_far <- c(inds_so_far, i_ind)

              if(indrank==n.item){
                keepbool <- TRUE
              }

            } # end loop over indrank


            if(keepbool == FALSE){
              temp_integral <- 0
              # add nothing to the sum
              next
            }

            # NEED TO CHECK IF BOUNDS AGREE BECAUSE INTERVALS ARE ITEM SPECIFIC
            # CAN NOT JUST CHEK RANKS OF INTERVAL INDICES

            # z_i > z_j if i lower > j upper

            strictbool <- FALSE

            inds_so_far <- vector(mode = "integer", length = 0)

            for(indrank in 1:n.item){

              if(indrank==n.item){
                # no more comparisons to make
                strictbool <- TRUE
                break
              }

              # MUST BE EDITED IF ALLOW FOR TIES
              i_ind <-  which(rankvec_t == indrank)

              # if(indrank ==1){
              #   j_ind <- i_ind
              #   next
              # }


              if(   all(templowers[setdiff(1:n.item, inds_so_far)] > tempuppers[i_ind] )){
                # good, all higher ranked items j are guaranteed to have z_j > z_i, continue
              }else{
                # cannot guarantee z_i > z_j
                strictbool <- FALSE

                break
              }

              # j_ind <- i_ind

              inds_so_far <- c(inds_so_far, i_ind)

              if(indrank==n.item){
                strictbool <- TRUE
              }

            }


            # keepbool <- all(rank( krow , ties.method = "min") <= rankvec_t)
            #
            # if(keepbool == FALSE){
            #   qkt_mat[rowind,lastcol_ind] <- 0
            #   next
            # }
            #
            # strictbool <- all(rank( krow , ties.method = "min") == rankvec_t)



            # loop over previous time period

            # num_m_vecs <- nrow(qkt_list[[t-1]])
            # number of indices/regions
            # should be n.item ?
            # num_m_inds <- ncol(qkt_list[[t-1]])

            # qm_1min1_vec <- (qkt_list[[t-1]])[,ncol(qkt_list[[t-1]])]

            if(strictbool == TRUE){
              # can calculate relatively straightforward integrals

              # TEST
              temp_integral <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) -
                                       pnorm(templowers, mean = tempmeans, sd = 1) )

              temp_sum <- temp_sum + nkt_mat_T[k_t_ind, ncol(nkt_mat_T)]*temp_integral


              # rest of code is for integrals bounded by the rank constraint

              # so can skip

              next
            }








            # t(diag(1,3, 3) %x% c(1,-1))

            # A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)
            #
            # tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)


            #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT

            # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
            # and for each pair of bounds, the first is the negative of the uper bound
            # and the second is the upper bound

            # jumps of 2 from n.item to 3*n.item - 2
            lb_inds <- n.item - 2 + 2*(1:n.item)
            # jumps of 2 from n.item + 1 to 3*n.item - 1
            ub_inds <- n.item - 1+ 2*(1:n.item)


            bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
            bvec[lb_inds] <- -1*templowers
            bvec[ub_inds] <- tempuppers

            # must shift the constraint

            # obtain mean vector from t-1 corresponding to m_ind

            # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
            # tempmeans <- intersectmat_tmin1[m_inds,1]

            bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans

            # NOTE: The SubsetSimFast and HDR_algoFast functions
            # use the transpose of the constraint matrix as an input

            sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                      bvec_temp,
                                                      N_hdr,
                                                      rho_hdr )

            hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                     bvec_temp,
                                                     c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                     N_hdr )

            #Probability Estimate from subset simulation
            # exp(sub_retFast$logZ)

            #Probability Estimate from HDR
            temp_integral <- exp(hdr_retFast)


            temp_sum <- temp_sum + nkt_mat_T[k_t_ind, ncol(nkt_mat_T)]*temp_integral


          } # end loop over k_t_ind in 1:nrow(nkt_mat_T)


          mkt_vec[k_t_min1] <- temp_sum

        } # end sum over k_t_min1 in 1:nrow(nkt_mat_Tmin1)


      } # END # if allow for item-specific covariates, i.e. itemcovars == TRUE




      ####### Calculate wkt for T-1 smoothing distribution ##################


      ######### calculate wktS for T-1 ###########################################

      # Then calculate weights

      temp_qkt_mat <- qkt_list[[n.time-1]]

      wktS_vec <- temp_qkt_mat[, ncol(temp_qkt_mat)]*mkt_vec
      # normalize
      wktS_vec <- wktS_vec/sum(wktS_vec)

      # sample an index vector k
      component_ind <- sample.int(length(wktS_vec),
                                  size = 1,
                                  replace = FALSE,
                                  prob = wktS_vec)

      #
      # ######### calculate wktF for T-1 ###########################################
      #
      # # Then calculate weights
      #
      # # temp_qkt_mat <- qkt_list[[n.time-1]]
      #
      # wktF_vec <- temp_qkt_mat[, ncol(temp_qkt_mat)]*nkt_mat_Tmin1[ ,ncol(nkt_mat_Tmin1)]
      # # normalize
      # wktF_vec <- sum(wktF_vec)
      #
      # # sample an index vector k
      # component_ind <- sample.int(length(wktF_vec),
      #                         size = 1,
      #                         replace = FALSE,
      #                         prob = wktF_vec)
      #
      # lastcol_ind <- ncol(nkt_mat_Tmin1)
      #
      #
      #

      # The component sample is fixed. Just the distribution conditional on the component is sampled by AR or MH

      ####### Sample for T - 1 given component ###########################


      # Sampling from the filtering distribution as proposal distribution for
      # both AR and MH methods
      # There is probably a more efficient way of writing this

      if(smoothing_method == "AR"){

        # Accept-Reject sampling

        #Aside: perhaps useful to know M= nkt/mkt

        print("Perhaps useful to know M = nkt/mkt = ")
        print(nkt_mat_Tmin1[ component_ind,ncol(nkt_mat_Tmin1)] / mkt_vec[component_ind])


        accepted <- FALSE

        while(accepted == FALSE){

          # Sample from the filtering distribution



          ####### Filtering Proposal Sample for T-1 given component ###########################

          # Now draw from corresponding truncated normal distribution
          # with means mu_k
          # and constraint matrix rankconstraint_t

          k_indvec <- nkt_mat_Tmin1[component_ind,1:(lastcol_ind-1)]

          if(itemcovars == FALSE){

            #note: k_indvec can include repeated values
            tempmeans <- intersectmat_Tmin1[k_indvec,1]


          }else{ # Allow covariates to vary over time

            #note: k_indvec can include repeated values

            # since covariates can vary over items
            # the means are obtained from item-specific intersectmats

            tempmeans <- rep(NA, length(k_indvec))

            for(ktemp in 1:length(k_indvec)){

              tempmeans[ktemp] <- (list_item_intersectmats_Tmin1[[ktemp]])[k_indvec[ktemp],1]
            }


          } # end else statement (obtaining means for item-specific regions)

          # current rankconstraint_t corresponds to T-1

          bvec_temp <- (rankconstraint_t)%*%tempmeans

          # require an initial value in the domain
          # arbitrarily set lowest to 10/n.item
          # then add 10/n.item for each

          # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

          # z_init <- rep(NA, n.item)
          #
          # # This can probably be vectorized
          # for(z_ind in 1:n.item){
          #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
          # }

          # or is a random sample required?
          # z_init <- rep(0, n.item)
          # z_init<- rnorm(n.item)
          z_init<- rnorm(n = n.item, mean = -1* tempmeans)

          if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
            # in domain
            # print("in domain")
          }else{
            # stop("Error. Initial vector not in domain")

            # perhaps take random samples until a point is found in the doain
            # ElilipticalSliceSampler python function might do something like this
            # at least if there is not any initial value

            while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
              print("not in domain. Sample x0 again")

              # x0 <- rnorm(length(z_init))
              z_init<- rnorm(n.item)

              # x0 <- xnew
            }
          }


          # Take 100 samples, then just use last column
          # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
          z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                      bvec_temp,
                                      Num_lin_ess_samples,
                                      z_init,
                                      nskip = 0)

          #save Z values sampled from proposal




          z_prop_vec <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans


          ####### Uniform sample ###########################

          # sample from the uniform distribution

          u_temp <- runif(n = 1)


          ####### Calculate Acceptance Prob T-1 ###########################


          #calculate acceptance probability given choice of M = nkt/mkt

          # acceptance probability equals r_t(z_t)
          # here t = T-1

          # first, must obtain means corresponding to predictions given covariates and z_prop_vec
          # and covaraite observations in time period T


          # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

          # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

          obs_inds <- (n.time - 1 )*n.ranker*n.item+n.item*(indiv-1) + 1:n.item

          # Xmat.train

          temp_df <- data.frame(x = cbind( z_prop_vec, Xmat.train[obs_inds, 2:ncol(Xmat.train), drop = FALSE] ) )

          tempmeans <- sampler$predict(temp_df)

          # use period T rank constraint rankconstraint_T
          # for t < T-1 might have to save rankconstraint_t, rankconstraint_tplus1, and maybe rankconstraint_tmin1
          # or even all rank constraints in one big array

          # integral calculation is essentially the same as nkT with different means



          ##### INCLUDING BOTH CALCULATIONS FOR TEST


          bvec_temp <- (rankconstraint_T)%*%tempmeans


          # NOTE: The SubsetSimFast and HDR_algoFast functions
          # use the transpose of the constraint matrix as an input

          sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_T),
                                                    bvec_temp,
                                                    N_hdr,
                                                    rho_hdr )

          hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_T),
                                                   bvec_temp,
                                                   c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                   N_hdr )

          #Probability Estimate from subset simulation
          # exp(sub_retFast$logZ)

          #Probability Estimate from HDR
          tempintegralval <- exp(hdr_retFast)







          # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
          # a second time


          #attempt at alternative to integration


          r_Tmin1_zTmin1 <- NA

          if(itemcovars == FALSE){

            kvectemp <- rep(NA, n.item)

            for(index_item in 1:n.item){

              # find row of intersectmat_T corresponding to
              # z_prop_vec[index_item]

              #ranges for zlag
              zranges <- c(-Inf, (intersectmat_T)[,3])

              tempinds <- which((zranges <z_prop_vec[index_item] ))

              #which is the last one below (count includes -inf, so gives row of correct interval)
              temp_ind <- tempinds[length(tempinds)]

              # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

              kvectemp[index_item] <- temp_ind # intersectmat_T[temp_ind,1]

            }

            # now find corresponding row of # nkt_mat_T

            rowind_temp <- which(apply(nkt_mat_T,
                                       1,
                                       function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")


            #

            r_Tmin1_zTmin1 <- nkt_mat_T[rowind_temp, ncol(nkt_mat_T)]


          }else{
            kvectemp <- rep(NA, n.item)

            for(index_item in 1:n.item){

              # find row of intersectmat_T corresponding to
              # z_prop_vec[index_item]

              #ranges for zlag
              zranges <- c(-Inf, (list_item_intersectmats_T[[index_item]])[,3])

              tempinds <- which((zranges <z_prop_vec[index_item] ))

              #which is the last one below (count includes -inf, so gives row of correct interval)
              temp_ind <- tempinds[length(tempinds)]

              # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

              kvectemp[index_item] <- temp_ind # (list_item_intersectmats_T[[index_item]])[temp_ind,1]

            }

            # now find corresponding row of # nkt_mat_T

            rowind_temp <- which(apply(nkt_mat_T,
                                       1,
                                       function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")


            #

            r_Tmin1_zTmin1 <- nkt_mat_T[rowind_temp, ncol(nkt_mat_T)]

          }


          if(r_Tmin1_zTmin1 == tempintegralval){
            print(" two methods for r_Tmin1_zTmin1 give the same value")

          }else{

            print("r_Tmin1_zTmin1 = ")
            print(r_Tmin1_zTmin1)

            print("tempintegralval = ")
            print(tempintegralval)

            stop(" two methods for r_Tmin1_zTmin1 give diffferent values")



          }


          # accept or reject

          if(u_temp <= r_Tmin1_zTmin1){

            # accept
            Z.mat[,(n.time-1-1)*n.ranker + indiv] <- z_prop_vec
            accepted <- TRUE

          }else{

            # reject
            accepted <- FALSE

          }




        }# end while loop for Accept-Reject

      }else{ # Metropolis-Hastings sampler

        # Essentially the same as Accept-Reject code, except different acceptance probability
        # and not a while loop




        # Sample from the filtering distribution



        ####### Filtering Proposal Sample for T-1 given component ###########################

        # Now draw from corresponding truncated normal distribution
        # with means mu_k
        # and constraint matrix rankconstraint_t

        k_indvec <- nkt_mat_Tmin1[component_ind,1:(lastcol_ind-1)]




        if(itemcovars == FALSE){

          #note: k_indvec can include repeated values
          tempmeans <- intersectmat_Tmin1[k_indvec,1]


        }else{ # Allow covariates to vary over time

          #note: k_indvec can include repeated values

          # since covariates can vary over items
          # the means are obtained from item-specific intersectmats

          tempmeans <- rep(NA, length(k_indvec))

          for(ktemp in 1:length(k_indvec)){

            tempmeans[ktemp] <- (list_item_intersectmats_Tmin1[[ktemp]])[k_indvec[ktemp],1]
          }


        } # end else statement (obtaining means for item-specific regions)

        # current rankconstraint_t corresponds to T-1

        bvec_temp <- (rankconstraint_t)%*%tempmeans

        # require an initial value in the domain
        # arbitrarily set lowest to 10/n.item
        # then add 10/n.item for each

        # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

        # z_init <- rep(NA, n.item)
        #
        # # This can probably be vectorized
        # for(z_ind in 1:n.item){
        #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
        # }

        # or is a random sample required?
        # z_init <- rep(0, n.item)
        # z_init<- rnorm(n.item)
        z_init<- rnorm(n = n.item, mean = -1* tempmeans)

        if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
          # in domain
          # print("in domain")
        }else{
          # stop("Error. Initial vector not in domain")

          # perhaps take random samples until a point is found in the doain
          # ElilipticalSliceSampler python function might do something like this
          # at least if there is not any initial value

          while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
            print("not in domain. Sample x0 again")

            # x0 <- rnorm(length(z_init))
            z_init<- rnorm(n.item)

            # x0 <- xnew
          }
        }


        # Take 100 samples, then just use last column
        # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
        z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                    bvec_temp,
                                    Num_lin_ess_samples,
                                    z_init,
                                    nskip = 0)

        #save Z values sampled from proposal




        z_prop_vec <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans


        ####### Uniform sample ###########################

        # sample from the uniform distribution

        u_temp <- runif(n = 1)


        ####### Calculate Acceptance Prob T-1 ###########################


        #calculate acceptance probability given choice of M = nkt/mkt

        # acceptance probability equals r_t(z_t)
        # here t = T-1

        # first, must obtain means corresponding to predictions given covariates and z_prop_vec
        # and covaraite observations in time period T


        # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

        # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

        obs_inds <- (n.time - 1 )*n.ranker*n.item+n.item*(indiv-1) + 1:n.item

        # Xmat.train

        temp_df <- data.frame(x = cbind( z_prop_vec, Xmat.train[obs_inds, 2:ncol(Xmat.train), drop = FALSE] ) )

        tempmeans <- sampler$predict(temp_df)

        # use period T rank constraint rankconstraint_T
        # for t < T-1 might have to save rankconstraint_t, rankconstraint_tplus1, and maybe rankconstraint_tmin1
        # or even all rank constraints in one big array

        # integral calculation is essentially the same as nkT with different means



        ##### INCLUDING BOTH CALCULATIONS FOR TEST


        bvec_temp <- (rankconstraint_T)%*%tempmeans


        # NOTE: The SubsetSimFast and HDR_algoFast functions
        # use the transpose of the constraint matrix as an input

        sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_T),
                                                  bvec_temp,
                                                  N_hdr,
                                                  rho_hdr )

        hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_T),
                                                 bvec_temp,
                                                 c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                 N_hdr )

        #Probability Estimate from subset simulation
        # exp(sub_retFast$logZ)

        #Probability Estimate from HDR
        tempintegralval <- exp(hdr_retFast)







        # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
        # a second time


        #attempt at alternative to integration


        r_Tmin1_zTmin1 <- NA

        if(itemcovars == FALSE){

          kvectemp <- rep(NA, n.item)

          for(index_item in 1:n.item){

            # find row of intersectmat_T corresponding to
            # z_prop_vec[index_item]

            #ranges for zlag
            zranges <- c(-Inf, (intersectmat_T)[,3])

            tempinds <- which((zranges <z_prop_vec[index_item] ))

            #which is the last one below (count includes -inf, so gives row of correct interval)
            temp_ind <- tempinds[length(tempinds)]

            # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

            kvectemp[index_item] <- temp_ind # intersectmat_T[temp_ind,1]

          }

          # now find corresponding row of # nkt_mat_T

          rowind_temp <- which(apply(nkt_mat_T,
                                     1,
                                     function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")


          #

          r_Tmin1_zTmin1 <- nkt_mat_T[rowind_temp, ncol(nkt_mat_T)]


        }else{
          kvectemp <- rep(NA, n.item)

          for(index_item in 1:n.item){

            # find row of intersectmat_T corresponding to
            # z_prop_vec[index_item]

            #ranges for zlag
            zranges <- c(-Inf, (list_item_intersectmats_T[[index_item]])[,3])

            tempinds <- which((zranges <z_prop_vec[index_item] ))

            #which is the last one below (count includes -inf, so gives row of correct interval)
            temp_ind <- tempinds[length(tempinds)]

            # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

            kvectemp[index_item] <- temp_ind # (list_item_intersectmats_T[[index_item]])[temp_ind,1]

          }

          # now find corresponding row of # nkt_mat_T

          rowind_temp <- which(apply(nkt_mat_T,
                                     1,
                                     function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")


          #

          r_Tmin1_zTmin1 <- nkt_mat_T[rowind_temp, ncol(nkt_mat_T)]

        }


        if(r_Tmin1_zTmin1 == tempintegralval){
          print(" two methods for r_Tmin1_zTmin1 give the same value")

        }else{

          print("r_Tmin1_zTmin1 = ")
          print(r_Tmin1_zTmin1)

          print("tempintegralval = ")
          print(tempintegralval)

          stop(" two methods for r_Tmin1_zTmin1 give diffferent values")



        }


        # for denominator of acceptance ratio,
        # can NOT save values in previous iteration of Gibbs sampler becasuet eh tree structures change.
        # Therefore, must recalculate in each iteration

        #

        z_old_vec <- Z.mat[,(n.time-1-1)*n.ranker + indiv]

        temp_df <- data.frame(x = cbind( z_old_vec, Xmat.train[obs_inds, 2:ncol(Xmat.train), drop = FALSE] ) )

        tempmeans <- sampler$predict(temp_df)

        # use period T rank constraint rankconstraint_T
        # for t < T-1 might have to save rankconstraint_t, rankconstraint_tplus1, and maybe rankconstraint_tmin1
        # or even all rank constraints in one big array

        # integral calculation is essentially the same as nkT with different means



        ##### INCLUDING BOTH CALCULATIONS FOR TEST


        bvec_temp <- (rankconstraint_T)%*%tempmeans


        # NOTE: The SubsetSimFast and HDR_algoFast functions
        # use the transpose of the constraint matrix as an input

        sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_T),
                                                  bvec_temp,
                                                  N_hdr,
                                                  rho_hdr )

        hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_T),
                                                 bvec_temp,
                                                 c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                 N_hdr )

        #Probability Estimate from subset simulation
        # exp(sub_retFast$logZ)

        #Probability Estimate from HDR
        tempintegralval <- exp(hdr_retFast)







        # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
        # a second time


        #attempt at alternative to integration


        r_Tmin1_zTmin1_denom <- NA

        if(itemcovars == FALSE){

          kvectemp <- rep(NA, n.item)

          for(index_item in 1:n.item){

            # find row of intersectmat_T corresponding to
            # z_old_vec[index_item]

            #ranges for zlag
            zranges <- c(-Inf, (intersectmat_T)[,3])

            tempinds <- which((zranges <z_old_vec[index_item] ))

            #which is the last one below (count includes -inf, so gives row of correct interval)
            temp_ind <- tempinds[length(tempinds)]

            # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

            kvectemp[index_item] <- temp_ind # intersectmat_T[temp_ind,1]

          }

          # now find corresponding row of # nkt_mat_T

          rowind_temp <- which(apply(nkt_mat_T,
                                     1,
                                     function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")


          #

          r_Tmin1_zTmin1_denom <- nkt_mat_T[rowind_temp, ncol(nkt_mat_T)]


        }else{
          kvectemp <- rep(NA, n.item)

          for(index_item in 1:n.item){

            # find row of intersectmat_T corresponding to
            # z_old_vec[index_item]

            #ranges for zlag
            zranges <- c(-Inf, (list_item_intersectmats_T[[index_item]])[,3])

            tempinds <- which((zranges <z_old_vec[index_item] ))

            #which is the last one below (count includes -inf, so gives row of correct interval)
            temp_ind <- tempinds[length(tempinds)]

            # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

            kvectemp[index_item] <- temp_ind # (list_item_intersectmats_T[[index_item]])[temp_ind,1]

          }

          # now find corresponding row of # nkt_mat_T

          rowind_temp <- which(apply(nkt_mat_T,
                                     1,
                                     function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")


          #

          r_Tmin1_zTmin1_denom <- nkt_mat_T[rowind_temp, ncol(nkt_mat_T)]

        }


        if(r_Tmin1_zTmin1_denom == tempintegralval){
          print(" two methods for r_Tmin1_zTmin1_denom give the same value")

        }else{

          print("r_Tmin1_zTmin1 = ")
          print(r_Tmin1_zTmin1_denom)

          print("tempintegralval = ")
          print(tempintegralval)

          stop(" two methods for r_Tmin1_zTmin1_denom give diffferent values")

        }


        ratio_temp <- r_Tmin1_zTmin1 / r_Tmin1_zTmin1_denom

        if(u_temp <= ratio_temp){

          # accept
          Z.mat[,(n.time-1-1)*n.ranker + indiv] <- z_prop_vec
          accepted <- TRUE

        }else{

          # reject
          # keep  z value from previous round

          # accepted <- FALSE

        }


        # stop("Metropolis-Hastings code not written yet")

      } # End else statement (corresponding to MH sampler )



      ##////////////////////////////////////////////////////////////////////////////////////
      ##////////////////////////////////////////////////////////////////////////////////////
      ######## Sample Z for t < T-1 ######################################################

      ##////////////////////////////////////////////////////////////////////////////////////
      ##////////////////////////////////////////////////////////////////////////////////////


      # Now sample for all other time periods


      # for t < T-1
      #makes more sense to calculate mkt values beginning at t=1 and increasing









      ######## Calculate mkt values ######################################################
      # Note: also gives all r_t(z_t) values
      # because r_t(z_t) is one of the m_{k,t+1} values


      # If necessary, can put this within the loop over (n.time-2):1

      # smoothing distribution is filtering distribution at time n.time
      # so do not need to calculate mkt at time T
      # therefore list is of length n.time -1

      # IF NEED TO SAVE MEMORY, JUST ADD A COLUMN TO ELEMENTS OF qkt_list ?
      # Or perhaps this does not save memory if just save mkt vectors

      mkt_list <- vector(mode = "list", length = n.time-1)

      mkt_list[[n.time-1]] <- mkt_vec


      for(t in 1:(n.time -2)){


        rankvec_temp <- ranks_mat[,  (t-1)*n.ranker + indiv]

        rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t]

        A_Cktmin1_constraint <- rbind(rankconstraint_tmin1, boundconstraints)

        tA_Cktmin1_constraint <- t(A_Cktmin1_constraint)

        # require all possible regions for each time period.
        # Can use qkt_list for this

        k_index_matrix_t <- qkt_list[[t]][,1:(ncol(qkt_list[[t]])-1)  ]

        num_k_t <- nrow(k_index_matrix_t)

        # two options:

        # 1. Save all save all r_{\k^{t+1},\k^{t}}^{(t)} for all \k^{t}
        # then iterate forward the summations to sum over \k^T
        # 2. Separately iterate over summations for each \k^{t}
        # actually a bit more complicated than this


        # will try first option because this involve less repetition of the same integrals.
        # However, if really wanted to avoid repetition of integrals
        # would save big multidimensional array outside of all loops of all possible values of
        # r_{\k^{t+1},\k^{t}}^{(t)} for all t

        k_index_matrix_tp1 <- qkt_list[[t+1]][,1:(ncol(qkt_list[[t+1]])-1)  ]

        num_ktp1 <- nrow(qkt_list[[t+1]])


        rk_t_tp1_mat <- matrix(NA,
                               nrow = num_k_t,
                               ncol = num_ktp1)




        for(kt_ind in 1:num_k_t){

          krow_t <- k_index_matrix_t[kt_ind, ]

          if(itemcovars == FALSE){
            tempmeans <- Biglist_intersectmats[[t]][krow_t,1]
          }else{ #itemcovars == TRUE
            # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

            temp_list_intersectmat_t <- Biglist_list_item_intersectmats[[t]]

            for(k_index in 1:n.item){
              ktemp <- krow_t[k_index]
              tempmeans[k_index] <- temp_list_intersectmat_t[[k_index]][ktemp,1]
            }
            # obtain mean vector from t-1 corresponding to m_ind
          } # end else




          for(ktp1_ind in 1:num_ktp1 ){


            krow_tp1 <- k_index_matrix_tp1[ktp1_ind, ]#kcomb_vec_mat[rowind,]

            if(itemcovars == FALSE){

              # must agree with period t ranks

              keepbool <- all(rank( krow_tp1 , ties.method = "min") <= rankvec_temp)

              if(keepbool == FALSE){
                # qkt_mat[rowind,lastcol_ind] <- 0
                # integral is zero
                rk_t_tp1_mat[kt_ind, ktp1_ind] <- 0
                next
              }

              strictbool <- all(rank( krow_tp1 , ties.method = "min") == rankvec_temp)

              # k_indvec <- qkt_mat[rowind,1:(lastcol_ind-1)]


              # MUST OBTAIN INTERSECT MATRIX for t+1 (or append relevant elements to qkt)
              # might as well save within the qkt calcualtions

              templowers <- Biglist_intersectmats[[t+1]][krow_tp1,2]
              tempuppers <- Biglist_intersectmats[[t+1]][krow_tp1,3]

              # loop over previous time period

              # num_m_vecs <- nrow(qkt_list[[t-1]])
              # number of indices/regions
              # should be n.item ?
              # num_m_inds <- ncol(qkt_list[[t-1]])

              # qm_1min1_vec <- (qkt_list[[t-1]])[,ncol(qkt_list[[t-1]])]

              if(strictbool == TRUE){

                # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]

                # period t intersect matrix
                # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

                # tempintegralval <- 1
                #
                # # can probably vectorize this?
                # for(k_index in 1:(lastcol_ind-1)){
                #   ktemp <- k_indvec[k_index]
                #
                #   # tempmean <- intersectmat[ktemp,1]
                #
                #   tempmean <- tempmeans[k_index]
                #   templower <- templowers[k_index]
                #   tempupper <- tempuppers[k_index]
                #
                #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
                #   tempintegralval <- tempintegralval*onedim_int
                #
                # }

                # TEST
                tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

                rk_t_tp1_mat[kt_ind, ktp1_ind] <- tempintegralval
                # rest of code is for integrals bounded by the rank constraint

                # so can skip

                next
              }


              #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT


              # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
              # and for each pair of bounds, the first is the negative of the uper bound
              # and the second is the upper bound

              # jumps of 2 from n.item to 3*n.item - 2
              lb_inds <- n.item - 2 + 2*(1:n.item)
              # jumps of 2 from n.item + 1 to 3*n.item - 1
              ub_inds <- n.item - 1+ 2*(1:n.item)


              bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
              bvec[lb_inds] <- -1*templowers
              bvec[ub_inds] <- tempuppers


              # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
              # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

              bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans

              # NOTE: The SubsetSimFast and HDR_algoFast functions
              # use the transpose of the constraint matrix as an input

              sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                        bvec_temp,
                                                        N_hdr,
                                                        rho_hdr )

              hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                       bvec_temp,
                                                       c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                       N_hdr )

              #Probability Estimate from subset simulation
              # exp(sub_retFast$logZ)

              #Probability Estimate from HDR
              tempintegralval <- exp(hdr_retFast)

              rk_t_tp1_mat[kt_ind, ktp1_ind] <- tempintegralval

            }else{ # itemcovars ==TRUE

              # Biglist_list_item_intersectmats

              # k_indvec <- qkt_mat[rowind,1:(lastcol_ind-1)]
              # krow_tp1

              # lowers and uppers are for item-specific regions in time period t

              #

              list_item_intersectmats <- Biglist_list_item_intersectmats[[t+1]]

              templowers <- rep(NA, n.item)
              tempuppers <- rep(NA, n.item)

              for(k_index in 1:n.item){

                ktemp <- krow_tp1[k_index]

                templowers[ktemp] <- list_item_intersectmats[[k_index]][ktemp,2]
                tempuppers[ktemp] <- list_item_intersectmats[[k_index]][ktemp,3]

              }

              # DO NOT KEEP CONDITION:
              # z_j > z_i if j lower > i upper

              keepbool <- FALSE

              inds_so_far <- vector(mode = "integer", length = 0)

              for(indrank in 1:n.item){

                if(indrank==n.item){
                  # no more comparisons to make
                  keepbool <- TRUE
                  break
                }
                # MUST BE EDITED IF ALLOW FOR TIES
                i_ind <-  which(rankvec_temp == indrank)

                # if(indrank ==1){
                #   j_ind <- i_ind
                #   next
                # }

                if(   any(templowers[i_ind] > tempuppers[setdiff(1:n.item, inds_so_far)] ) ){
                  # at least one higher ranked item j is guaranteed to have z_i > z_j
                  # instead of z_i < z_j (so would disagree with ranking)
                  # do not continue
                  keepbool <- FALSE

                  break

                }else{
                  # continue
                }

                # j_ind <- i_ind

                inds_so_far <- c(inds_so_far, i_ind)

                if(indrank==n.item){
                  keepbool <- TRUE
                }

              }


              if(keepbool == FALSE){
                # qkt_mat[rowind,lastcol_ind] <- 0
                # integral is zero
                rk_t_tp1_mat[kt_ind, ktp1_ind] <- 0
                next
              }

              # NEED TO CHECK IF BOUNDS AGREE BECAUSE INTERVALS ARE ITEM SPECIFIC
              # CAN NOT JUST CHEK RANKS OF INTERVAL INDICES

              # z_i > z_j if i lower > j upper

              strictbool <- FALSE

              inds_so_far <- vector(mode = "integer", length = 0)

              for(indrank in 1:n.item){

                if(indrank==n.item){
                  # no more comparisons to make
                  strictbool <- TRUE
                  break
                }
                # MUST BE EDITED IF ALLOW FOR TIES
                i_ind <-  which(rankvec_temp == indrank)

                # if(indrank ==1){
                #   j_ind <- i_ind
                #   next
                # }


                if(   all(templowers[setdiff(1:n.item, inds_so_far)] > tempuppers[i_ind] )){
                  # good, all higher ranked items j are guaranteed to have z_j > z_i, continue
                }else{
                  # cannot guarantee z_i > z_j
                  strictbool <- FALSE

                  break
                }

                # j_ind <- i_ind

                inds_so_far <- c(inds_so_far, i_ind)

                if(indrank==n.item){
                  strictbool <- TRUE
                }

              } # end indrank loop


              # keepbool <- all(rank( krow , ties.method = "min") <= rankvec_t)
              #
              # if(keepbool == FALSE){
              #   qkt_mat[rowind,lastcol_ind] <- 0
              #   next
              # }
              #
              # strictbool <- all(rank( krow , ties.method = "min") == rankvec_t)

              # loop over previous time period

              if(strictbool == TRUE){
                # can calculate relatively straightforward integrals

                # TEST
                tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) -
                                           pnorm(templowers, mean = tempmeans, sd = 1) )

                rk_t_tp1_mat[kt_ind, ktp1_ind] <- tempintegralval
                # rest of code is for integrals bounded by the rank constraint

                # so can skip

                next
              }

              # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
              # and for each pair of bounds, the first is the negative of the uper bound
              # and the second is the upper bound

              # jumps of 2 from n.item to 3*n.item - 2
              lb_inds <- n.item - 2 + 2*(1:n.item)
              # jumps of 2 from n.item + 1 to 3*n.item - 1
              ub_inds <- n.item - 1+ 2*(1:n.item)

              bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
              bvec[lb_inds] <- -1*templowers
              bvec[ub_inds] <- tempuppers


              # must shift the constraint

              bvec_temp <- bvec + A_Cktmin1_constraint%*%tempmeans

              # NOTE: The SubsetSimFast and HDR_algoFast functions
              # use the transpose of the constraint matrix as an input

              sub_retFast <- LinConGauss::SubsetSimFast(tA_Cktmin1_constraint,
                                                        bvec_temp,
                                                        N_hdr,
                                                        rho_hdr )

              hdr_retFast <- LinConGauss::HDR_algoFast(tA_Cktmin1_constraint,
                                                       bvec_temp,
                                                       c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                       N_hdr )

              #Probability Estimate from subset simulation
              # exp(sub_retFast$logZ)

              #Probability Estimate from HDR
              tempintegralval <- exp(hdr_retFast)

              rk_t_tp1_mat[kt_ind, ktp1_ind] <- tempintegralval

            } # end else statement

            # rk_t_tp1_mat[kt_ind, ktp1_ind] <- TO BE CALCULATED

          } # end loop over ktp1_ind in 1:num_ktp1

          # rk_t_tp1_vec[kt_ind] <- TO BE CALCULATED

          # mkt_vec <- rep(NA, num_k_t)
          #
          # mkt_vec <- TO BE CALCULATED
          #
          # mkt_list[[t]] <- mkt_vec


        } # end loop over kt_ind in 1:num_kt



        # now must iterate forwards in time to create  mkt_vec

        # from t+2 up to T

        rankvec_temp <- ranks_mat[,  (t-1)*n.ranker + indiv]



        # require all possible regions for each time period.
        # Can use qkt_list for this

        k_index_matrix_t <- qkt_list[[t]][,1:(ncol(qkt_list[[t]])-1)  ]

        num_k_t <- nrow(k_index_matrix_t)


        prev_mat <- rk_t_tp1_mat

        new_rk_t_pp1_mat <- NA

        for(p_ind in (t+1):(n.time-1)){

          #loop over k_pplus1
          rankvec_temp <- ranks_mat[,  (p_ind-1)*n.ranker + indiv]

          rankconstraint_p <- rank_cons_arr[, , indiv, p_ind]

          A_Ckp_constraint <- rbind(rankconstraint_p, boundconstraints)

          tA_Ckp_constraint <- t(A_Ckp_constraint)

          # require all possible regions for each time period.
          # Can use qkt_list for this

          k_index_matrix_p <- qkt_list[[p_ind]][,1:(ncol(qkt_list[[p_ind]])-1)  ]

          num_k_p <- nrow(k_index_matrix_p)

          # two options:

          # 1. Save all save all r_{\k^{t+1},\k^{t}}^{(t)} for all \k^{t}
          # then iterate forward the summations to sum over \k^T
          # 2. Separately iterate over summations for each \k^{t}
          # actually a bit more complicated than this


          # will try first option because this involve less repetition of the same integrals.
          # However, if really wanted to avoid repetition of integrals
          # would save big multidimensional array outside of all loops of all possible values of
          # r_{\k^{t+1},\k^{t}}^{(t)} for all t

          k_index_matrix_pp1 <- qkt_list[[p_ind+1]][,1:(ncol(qkt_list[[p_ind+1]])-1)  ]

          num_kpp1 <- nrow(qkt_list[[p_ind+1]])




          for(kpp1_ind in 1:num_kpp1){

            # num_k_t rows is correct
            new_rk_t_pp1_mat <- matrix(0,
                                       nrow = num_k_t,
                                       ncol = num_kpp1)

            if(itemcovars == FALSE){

              # must agree with period t ranks
              krow_pp1 <- k_index_matrix_pp1[kpp1_ind, ]#kcomb_vec_mat[rowind,]

              keepbool <- all(rank( krow_pp1 , ties.method = "min") <= rankvec_temp)
              strictbool <- all(rank( krow_pp1 , ties.method = "min") == rankvec_temp)


              templowers <- Biglist_intersectmats[[p+1]][krow_pp1,2]
              tempuppers <- Biglist_intersectmats[[p+1]][krow_pp1,3]

            }else{

              list_item_intersectmats <- Biglist_list_item_intersectmats[[p+1]]

              templowers <- rep(NA, n.item)
              tempuppers <- rep(NA, n.item)

              for(k_index in 1:n.item){

                ktemp <- krow_pp1[k_index]

                templowers[ktemp] <- list_item_intersectmats[[k_index]][ktemp,2]
                tempuppers[ktemp] <- list_item_intersectmats[[k_index]][ktemp,3]

              }

              keepbool <- FALSE

              inds_so_far <- vector(mode = "integer", length = 0)

              for(indrank in 1:n.item){

                if(indrank==n.item){
                  # no more comparisons to make
                  keepbool <- TRUE
                  break
                }
                # MUST BE EDITED IF ALLOW FOR TIES
                i_ind <-  which(rankvec_temp == indrank)

                # if(indrank ==1){
                #   j_ind <- i_ind
                #   next
                # }

                if(   any(templowers[i_ind] > tempuppers[setdiff(1:n.item, inds_so_far)] ) ){
                  # at least one higher ranked item j is guaranteed to have z_i > z_j
                  # instead of z_i < z_j (so would disagree with ranking)
                  # do not continue
                  keepbool <- FALSE

                  break

                }else{
                  # continue
                }

                # j_ind <- i_ind

                inds_so_far <- c(inds_so_far, i_ind)

                if(indrank==n.item){
                  keepbool <- TRUE
                }

              }



              # NEED TO CHECK IF BOUNDS AGREE BECAUSE INTERVALS ARE ITEM SPECIFIC
              # CAN NOT JUST CHEK RANKS OF INTERVAL INDICES

              # z_i > z_j if i lower > j upper

              strictbool <- FALSE

              inds_so_far <- vector(mode = "integer", length = 0)

              for(indrank in 1:n.item){

                if(indrank==n.item){
                  # no more comparisons to make
                  strictbool <- TRUE
                  break
                }
                # MUST BE EDITED IF ALLOW FOR TIES
                i_ind <-  which(rankvec_temp == indrank)

                # if(indrank ==1){
                #   j_ind <- i_ind
                #   next
                # }


                if(   all(templowers[setdiff(1:n.item, inds_so_far)] > tempuppers[i_ind] )){
                  # good, all higher ranked items j are guaranteed to have z_j > z_i, continue
                }else{
                  # cannot guarantee z_i > z_j
                  strictbool <- FALSE

                  break
                }

                # j_ind <- i_ind

                inds_so_far <- c(inds_so_far, i_ind)

                if(indrank==n.item){
                  strictbool <- TRUE
                }

              }

            } # end else itemcovars == TRUE


            for(kp_ind in 1: num_k_p){


              krow_p <- k_index_matrix_p[kp_ind, ]
              if(itemcovars == FALSE){

                tempmeans <- Biglist_intersectmats[[p]][krow_p,1]
              }else{ # itemcovars == TRUE
                # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

                temp_list_intersectmat_p <- Biglist_list_item_intersectmats[[p]]

                for(k_index in 1:n.item){

                  ktemp <- krow_p[k_index]

                  tempmean[k_index] <- temp_list_intersectmat_p[[k_index]][ktemp,1]

                }
                # obtain mean vector from t-1 corresponding to m_ind

              } # end else statement itemcovars == TRUE


              # calculate the scalar_{\K^{p+1}, \K^p }^{(p)}



              if(itemcovars == FALSE){

                # must agree with period t ranks

                # keepbool <- all(rank( krow_pp1 , ties.method = "min") <= rankvec_temp)

                if(keepbool == FALSE){
                  # qkt_mat[rowind,lastcol_ind] <- 0
                  # integral is zero

                  #add zero
                  # r_kpp1_kp_p <- 0
                  # new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]

                  next
                }

                # strictbool <- all(rank( krow_pp1 , ties.method = "min") == rankvec_temp)
                #
                #
                # templowers <- Biglist_intersectmats[[p+1]][krow_pp1,2]
                # tempuppers <- Biglist_intersectmats[[p+1]][krow_pp1,3]

                if(strictbool == TRUE){

                  # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]

                  # period t intersect matrix
                  # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

                  # tempintegralval <- 1
                  #
                  # # can probably vectorize this?
                  # for(k_index in 1:(lastcol_ind-1)){
                  #   ktemp <- k_indvec[k_index]
                  #
                  #   # tempmean <- intersectmat[ktemp,1]
                  #
                  #   tempmean <- tempmeans[k_index]
                  #   templower <- templowers[k_index]
                  #   tempupper <- tempuppers[k_index]
                  #
                  #   onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
                  #   tempintegralval <- tempintegralval*onedim_int
                  #
                  # }

                  # TEST
                  tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) - pnorm(templowers, mean = tempmeans, sd = 1) )

                  r_kpp1_kp_p <- tempintegralval

                  new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]


                  # rest of code is for integrals bounded by the rank constraint

                  # so can skip

                  next
                }


                #EDIT ALL GESSNER ET AL CODE SO THAT IT USES THE TRANSPOSE AS INPUT


                # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
                # and for each pair of bounds, the first is the negative of the uper bound
                # and the second is the upper bound

                # jumps of 2 from n.item to 3*n.item - 2
                lb_inds <- n.item - 2 + 2*(1:n.item)
                # jumps of 2 from n.item + 1 to 3*n.item - 1
                ub_inds <- n.item - 1+ 2*(1:n.item)


                bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
                bvec[lb_inds] <- -1*templowers
                bvec[ub_inds] <- tempuppers


                # m_inds <- (qkt_list[[t-1]])[m_ind,1:(num_m_inds-1)]
                # tempmeans <- Biglist_intersectmats[[t]][krow_t,1]

                # rankconstraint_p <- rank_cons_arr[, , indiv, p]
                #
                # A_Ckp_constraint <- rbind(rankconstraint_p, boundconstraints)
                #
                # tA_Ckp_constraint <- t(A_Ckp_constraint)


                bvec_temp <- bvec + A_Ckp_constraint%*%tempmeans


                # NOTE: The SubsetSimFast and HDR_algoFast functions
                # use the transpose of the constraint matrix as an input

                sub_retFast <- LinConGauss::SubsetSimFast(tA_Ckp_constraint,
                                                          bvec_temp,
                                                          N_hdr,
                                                          rho_hdr )

                hdr_retFast <- LinConGauss::HDR_algoFast(tA_Ckp_constraint,
                                                         bvec_temp,
                                                         c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                         N_hdr )

                #Probability Estimate from subset simulation
                # exp(sub_retFast$logZ)

                #Probability Estimate from HDR
                tempintegralval <- exp(hdr_retFast)

                r_kpp1_kp_p <- tempintegralval

                new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]



              }else{ # itemcovars ==TRUE

                # Biglist_list_item_intersectmats
                # k_indvec <- qkt_mat[rowind,1:(lastcol_ind-1)]
                # krow_tp1
                # lowers and uppers are for item-specific regions in time period t

                if(keepbool == FALSE){
                  # qkt_mat[rowind,lastcol_ind] <- 0
                  # integral is zero

                  # r_kpp1_kp_p<- 0
                  # new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]

                  next
                }

                # loop over previous time period

                if(strictbool == TRUE){
                  # can calculate relatively straightforward integrals

                  # TEST
                  tempintegralval <- prod( pnorm(tempuppers, mean = tempmeans, sd = 1) -
                                             pnorm(templowers, mean = tempmeans, sd = 1) )

                  # rk_t_tp1_mat[kt_ind, ktp1_ind] <- tempintegralval

                  r_kpp1_kp_p<- tempintegralval
                  new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]

                  # rest of code is for integrals bounded by the rank constraint

                  # so can skip

                  next
                }

                # bvec contains all zeros for rank constraint ( so n.item -1 zeros)
                # and for each pair of bounds, the first is the negative of the uper bound
                # and the second is the upper bound

                # jumps of 2 from n.item to 3*n.item - 2
                lb_inds <- n.item - 2 + 2*(1:n.item)
                # jumps of 2 from n.item + 1 to 3*n.item - 1
                ub_inds <- n.item - 1+ 2*(1:n.item)

                bvec <- c(rep(0, n.item-1), rep(NA, 2*n.item))
                bvec[lb_inds] <- -1*templowers
                bvec[ub_inds] <- tempuppers


                # must shift the constraint

                bvec_temp <- bvec + tA_Ckpmin1_constraint%*%tempmeans

                # NOTE: The SubsetSimFast and HDR_algoFast functions
                # use the transpose of the constraint matrix as an input

                sub_retFast <- LinConGauss::SubsetSimFast(tA_Ckpmin1_constraint,
                                                          bvec_temp,
                                                          N_hdr,
                                                          rho_hdr )

                hdr_retFast <- LinConGauss::HDR_algoFast(tA_Ckpmin1_constraint,
                                                         bvec_temp,
                                                         c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                         N_hdr )

                #Probability Estimate from subset simulation
                # exp(sub_retFast$logZ)

                #Probability Estimate from HDR
                tempintegralval <- exp(hdr_retFast)

                r_kpp1_kp_p<- tempintegralval
                new_rk_t_pp1_mat[ ,kpp1_ind ] <- new_rk_t_pp1_mat[ ,kpp1_ind ] + r_kpp1_kp_p*prev_mat[,kp_ind]

                # rk_t_tp1_mat[kt_ind, ktp1_ind] <- tempintegralval

              }


              # r_kpp1_kp_p <- TO BE CALCULATED

              # multiply by prev_mat column for kp_ind and add to the
              # kpp1_ind column of new mat


              # new_rk_t_pp1_mat[ ,kpp1_ind ] <- r_kpp1_kp_p*prev_mat[,kp_ind]

            } # end loop over kp_ind in 1: num_k_p

          } # end loop over kpp1_ind in 1:num_kpp1

          prev_mat <- new_rk_t_pp1_mat


        } # end loop over p_ind

        # now for time period T

        rankvec_temp <- ranks_mat[,  (n.time-1)*n.ranker + indiv]



        # require all possible regions for each time period.
        # Can use qkt_list for this

        k_index_matrix_T <- qkt_list[[n.time]][,1:(ncol(qkt_list[[n.time]])-1)  ]

        num_k_T <- nrow(k_index_matrix_T)

        for(kT_ind in 1:num_k_T){

          # calculate r_{\K^T}^{(T)} = nkT  =mkT
          # equal to nkT, so does not need to be calculated again
          rkT <- nkt_mat_T[kT_ind, ncol(nkt_mat_T)]

          new_rk_t_pp1_mat[, kT_ind] <- rkT*new_rk_t_pp1_mat[, kT_ind]

        }


        # mkt_vec <- rowSums(new_rk_t_pp1_mat)
        mkt_vec <- apply(new_rk_t_pp1_mat,1,sum)

        mkt_list[[t]] <- mkt_vec


      } # end loop over time periods t




      ###### Begin main Z loop ###############


      # rkt_tmin1_list <- list()


      # Loop for
      # t < T-1

      # save intersection matrices from previous time period

      intersectmat_tplus1 <- NA
      list_item_intersectmats_Tplus1 <- NA

      if(itemcovars == FALSE){
        intersectmat_tplus1 <- intersectmat_Tmin1

      }else{
        list_item_intersectmats_Tplus1 <- list_item_intersectmats_Tmin1

      }



      nkt_tplus1 <-  nkt_mat_Tmin1


      for(t in (n.time-2):1){

        # obtain ordering for time t
        rankvec_t <- ranks_mat[,  (t-1)*n.ranker + indiv]

        rankvec_tmin1 <- ranks_mat[,  (t-1-1)*n.ranker + indiv]

        rankvec_tplus1 <- ranks_mat[,  (t)*n.ranker + indiv]


        #EDIT THIS IF rank_cons_arr uses up too much memory

        rankconstraint_t <-         rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t] #rank_cons_arr[[t]]
        rankconstraint_tmin1 <-         rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t-1] #rank_cons_arr[[t-1]]
        # perhaps unnecessary
        rankconstraint_tplus1 <-         rankconstraint_tmin1 <- rank_cons_arr[, , indiv, t+1] #rank_cons_arr[[t+1]]



        ######## obtain intersection matrices ########



        # The smoothing distribution coincides with the filtering distribution

        # Calculate the necessary values to compute the weights of the mixture distribution


        # nkt_vec is a vector of integrals for regions-specific parameters k
        # the integrals are constrained by the ranker and time specific sets A_{i,t}
        # where A_{i,t} is defined by the ordering of the ranks given by ranker i at time t

        # requires:
        # 1. ranker and time specific rankings
        # 2. vector of mean parameters for all possible regions defined by the sum-of-tree structure


        # create intersection matrices
        # note that intersection matrices can be time period specific if allow for time period specific covariates

        # # create vector of indices for ranker indiv in time period T
        # ind_start <- (t - 1)*n.ranker*n.item+n.item*(indiv-1) + 1
        # ind_end <- (t - 1)*n.ranker*n.item+n.item*indiv
        # obs_indices <- ind_start:ind_end

        if(itemcovars == FALSE){
          intersectmat <- Biglist_intersectmats[[t]]
        }else{
          list_item_intersectmats <- Biglist_list_item_intersectmats[[t]]
        }

        # if(itemcovars == FALSE){
        #
        #   list_inter_mats <- list()
        #
        #   for(i in 1:n.trees){
        #
        #     treeexample1 <- sampler$getTrees(treeNums = i,
        #                                       chainNums = 1,
        #                                       sampleNums = 1)
        #
        #     rebuilt_tree <- rebuildTree2(treeexample1, sampler)
        #
        #
        #     #must use covariates for individual indiv at time period t
        #
        #     list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_indices[1],, drop = FALSE] )
        #
        #
        #   }
        #
        #   intersectmat <- interNtreesB(list_inter_mats)
        #
        #
        # }else{ # itemcovars == TRUE
        #
        #
        #   list_item_intersectmats <- list()
        #
        #   for(index_item in 1:n.item){
        #
        #     # will need to edit this for t < T-1
        #     obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item
        #
        #     list_inter_mats <- list()
        #
        #     for(i in 1:n.trees){
        #
        #       treeexample1 <- sampler$getTrees(treeNums = i,
        #                                         chainNums = 1,
        #                                         sampleNums = 1)
        #
        #       rebuilt_tree <- rebuildTree2(treeexample1, sampler)
        #
        #
        #       #must use covariates for individual indiv at time period t
        #
        #       list_inter_mats[[i]] <- getPredictionsRangesForTree3(rebuilt_tree, Xmat.train[obs_one_ind,, drop = FALSE] )
        #
        #
        #     } #end loop over trees
        #
        #     intersectmat <- interNtreesB(list_inter_mats)
        #
        #     list_item_intersectmats[[index_item]] <- intersectmat
        #
        #
        #   } #end loop over items
        #
        # } # end else itemcovars == TRUE



        ###########  calculate nkt for t < T - 1 ########################################

        # If regions vary across time
        # Then nktvec and qkt vec are time-specific
        # NOT JUST THROUGH dependence on observed ranks at time t
        # also through time-specific k

        # if covariates are item-specific, then the
        # combinations of regions, k involve
        # item-specific ranges of regions

        # in either case, must loop through combinations of regions
        # there are some possible symmetries
        # IGNORE SYMMETRIES


        if(itemcovars == FALSE){

          #there are n.item*nrow(intersectmat) possible regions

          # create list of vectors of indices for k1, k2, ..., k_{n.item}
          # to be used as input to expand.grid

          #straightforward for itemcovars == FALSE

          K_ind_list <-list()

          for(index_item in 1:n.item){
            K_ind_list[[index_item]] <- 1:nrow(intersectmat)
          }

          # there are many possible combinations
          # this might produce a huge matrix
          # not the most efficeient way of coding this
          kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

          # this line is included to avoid an error later using all.equal
          colnames(kcomb_vec_mat) <- NULL

          nkt_mat <- cbind(kcomb_vec_mat, rep(NA, nrow(kcomb_vec_mat)))
          rm(kcomb_vec_mat)


          for(rowind in 1:nrow(nkt_mat) ){

            #obtain means
            #vector k1, k2, k3, etc
            k_indvec <- nkt_mat[rowind,1:(lastcol_ind-1)]

            #note: k_indvec can include repeated values
            tempmeans <- intersectmat[k_indvec,1]

            # templowers <- intersectmat[k_indvec,2]
            # tempuppers <- intersectmat[k_indvec,3]


            # Apply methods of Gessner et al

            # create matrix A, vector b

            # for nkt_mat calcultions, the only constraint is the rank order A_t
            # so

            # A matrix is rankconstraint_t
            # original b vector is vector of zeros
            # However must shift the constraints as outlined in the paper
            # the mu vector is tempmeans
            # Therefore the shifted b vector is
            # (rankconstraint_t)%*%tempmeans

            bvec_temp <- (rankconstraint_t)%*%tempmeans



            # NOTE: The SubsetSimFast and HDR_algoFast functions
            # use the transpose of the constraint matrix as an input

            sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                      bvec_temp,
                                                      N_hdr,
                                                      rho_hdr )

            hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                     bvec_temp,
                                                     c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                     N_hdr )

            #Probability Estimate from subset simulation
            # exp(sub_retFast$logZ)

            #Probability Estimate from HDR
            tempintegralval <- exp(hdr_retFast)




            # for(k_index in 1:(lastcol_ind-1)){
            #       ktemp <- nkt_mat[rowind,k_index]
            #       tempmean <- intersectmat[ktemp,1]
            #       templower <- intersectmat[ktemp,2]
            #       tempupper <- intersectmat[ktemp,3]
            #
            #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
            #       tempintegralval <- tempintegralval*onedim_int
            # }

            #Save integral result
            nkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

          }

        }else{ # Allow covariates to vary over items, so sets of possible regions are item specific

          #there are n.item*nrow(intersectmat) possible regions

          # create list of vectors of indices for k1, k2, ..., k_{n.item}
          # to be used as input to expand.grid

          #straightforward for itemcovars == FALSE

          K_ind_list <-list()

          for(index_item in 1:n.item){
            K_ind_list[[index_item]] <- 1:nrow(list_item_intersectmats[[index_item]])
          }

          # there are many possible combinations
          # this might produce a huge matrix
          # not the most efficient way of coding this
          kcomb_vec_mat <- as.matrix(expand.grid(K_ind_list))

          # this line is included to avoid an error later using all.equal
          colnames(kcomb_vec_mat) <- NULL

          nkt_mat <- cbind(kcomb_vec_mat, rep(NA, nrow(kcomb_vec_mat)))
          rm(kcomb_vec_mat)


          for(rowind in 1:nrow(nkt_mat) ){

            #obtain means
            #vector k1, k2, k3, etc

            k_indvec <- nkt_mat[rowind,1:(lastcol_ind-1)]

            #note: k_indvec can include repeated values

            # since covariates can vary over items
            # the means are obtained from item-specific intersectmats

            tempmeans <- rep(NA, length(k_indvec))

            for(ktemp in 1:length(k_indvec)){

              tempmeans[ktemp] <- (list_item_intersectmats[[ktemp]])[k_indvec[ktemp],1]
            }


            # Apply methods of Gessner et al

            # create matrix A, vector b

            # for nkt_mat calcultions, the only constraint is the rank order A_t
            # so

            # A matrix is rankconstraint_t
            # original b vector is vector of zeros
            # However must shist the constraints as outlined in the paper
            # the mu vector is tempmeans
            # Therefore the shifted b vector is
            # (rankconstraint_t)%*%tempmeans

            bvec_temp <- (rankconstraint_t)%*%tempmeans




            sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_t),
                                                      bvec_temp,
                                                      N_hdr,
                                                      rho_hdr )

            hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_t),
                                                     bvec_temp,
                                                     c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
                                                     N_hdr )

            #Probability Estimate from subset simulation
            # exp(sub_retFast$logZ)

            #Probability Estimate from HDR
            tempintegralval <- exp(hdr_retFast)




            # for(k_index in 1:(lastcol_ind-1)){
            #       ktemp <- nkt_mat[rowind,k_index]
            #       tempmean <- intersectmat[ktemp,1]
            #       templower <- intersectmat[ktemp,2]
            #       tempupper <- intersectmat[ktemp,3]
            #
            #       onedim_int <- pnorm(tempupper, mean = tempmean, sd = 1) - pnorm(templower, mean = tempmean, sd = 1)
            #       tempintegralval <- tempintegralval*onedim_int
            # }

            #Save integral result
            nkt_mat[ rowind,lastcol_ind] <- tempintegralval#include product here

          } # end loop over rowind in 1:nrow(nkt_mat)


        } # end else statement # Allow covariates to vary over items, so sets of possible regions are item specific



        ######### calculate wktS for t < T-1 ###########################################

        # Then calculate weights

        temp_qkt_mat <- qkt_list[[t]]

        mkt_vec <- mkt_list[[t]]
        wktS_vec <- temp_qkt_mat[, ncol(temp_qkt_mat)]*mkt_vec
        # normalize
        wktS_vec <- wktS_vec/sum(wktS_vec)

        # sample an index vector k
        component_ind <- sample.int(length(wktS_vec),
                                    size = 1,
                                    replace = FALSE,
                                    prob = wktS_vec)


        ####### Sample for t < T - 1 given component ###########################


        # Sampling from the filtering distribution as proposal distribution for
        # both AR and MH methods
        # There is probably a more efficient way of writing this

        if(itemcovars == FALSE){
          intersectmat <- Biglist_intersectmats[[t]]
        }else{
          list_item_intersectmats <- Biglist_list_item_intersectmats[[t]]
        }

        if(smoothing_method == "AR"){

          # Accept-Reject sampling

          #Aside: perhaps useful to know M= nkt/mkt

          print("Perhaps useful to know M = nkt/mkt = ")
          print(nkt_mat[ component_ind,ncol(nkt_mat)] / mkt_vec[ component_ind])


          accepted <- FALSE

          while(accepted == FALSE){

            # Sample from the filtering distribution



            ####### AR Filtering Proposal Sample for t < T-1 given component ###########################

            # Now draw from corresponding truncated normal distribution
            # with means mu_k
            # and constraint matrix rankconstraint_t

            # k_indvec <- nkt_mat[component_ind,1:(lastcol_ind-1)]

            # or
            k_indvec <- qkt_list[[t]][component_ind,1:(lastcol_ind-1)]


            if(itemcovars == FALSE){

              #note: k_indvec can include repeated values
              tempmeans <- intersectmat[k_indvec,1]

            }else{ # Allow covariates to vary over time

              #note: k_indvec can include repeated values

              # since covariates can vary over items
              # the means are obtained from item-specific intersectmats

              tempmeans <- rep(NA, length(k_indvec))

              for(ktemp in 1:length(k_indvec)){

                tempmeans[ktemp] <- (list_item_intersectmats[[ktemp]])[k_indvec[ktemp],1]
              }


            } # end else statement (obtaining means for item-specific regions)

            # current rankconstraint_t corresponds to T-1

            bvec_temp <- (rankconstraint_t)%*%tempmeans

            # require an initial value in the domain
            # arbitrarily set lowest to 10/n.item
            # then add 10/n.item for each

            # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

            # z_init <- rep(NA, n.item)
            #
            # # This can probably be vectorized
            # for(z_ind in 1:n.item){
            #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
            # }

            # or is a random sample required?
            # z_init <- rep(0, n.item)
            # z_init<- rnorm(n.item)
            z_init<- rnorm(n = n.item, mean = -1* tempmeans)

            if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
              # in domain
              # print("in domain")
            }else{
              # stop("Error. Initial vector not in domain")

              # perhaps take random samples until a point is found in the domain
              # ElilipticalSliceSampler python function might do something like this
              # at least if there is not any initial value

              while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
                print("not in domain. Sample x0 again")

                # x0 <- rnorm(length(z_init))
                z_init<- rnorm(n.item)

                # x0 <- xnew
              }
            }


            # Take 100 samples, then just use last column
            # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
            z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                        bvec_temp,
                                        Num_lin_ess_samples,
                                        z_init,
                                        nskip = 0)

            #save Z values sampled from proposal




            z_prop_vec <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans


            ####### AR Uniform sample ###########################

            # sample from the uniform distribution

            u_temp <- runif(n = 1)


            ####### AR Calculate Acceptance Prob t < T-1 ###########################


            #calculate acceptance probability given choice of M = nkt/mkt

            # acceptance probability equals r_t(z_t)
            # here t = T-1

            # first, must obtain means corresponding to predictions given covariates and z_prop_vec
            # and covaraite observations in time period T


            # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            # obs_one_ind <- (n.time - 1 - 1)*n.ranker*n.item+n.item*(indiv-1) + index_item

            obs_inds <- (t - 1 )*n.ranker*n.item+n.item*(indiv-1) + 1:n.item

            # Xmat.train

            # temp_df <- data.frame(x = cbind( z_prop_vec,
            #                                  Xmat.train[obs_inds, 2:ncol(Xmat.train), drop = FALSE] ) )
            #
            # tempmeans <- sampler$predict(temp_df)
            #
            # # use period T rank constraint rankconstraint_T
            # # for t < T-1 might have to save rankconstraint_t, rankconstraint_tplus1, and maybe rankconstraint_tmin1
            # # or even all rank constraints in one big array
            #
            # # integral calculation is essentially the same as nkT with different means
            #
            #
            #
            # ##### INCLUDING BOTH CALCULATIONS FOR TEST
            #
            #
            # bvec_temp <- (rankconstraint_T)%*%tempmeans
            #
            #
            # # NOTE: The SubsetSimFast and HDR_algoFast functions
            # # use the transpose of the constraint matrix as an input
            #
            # sub_retFast <- LinConGauss::SubsetSimFast(t(rankconstraint_T),
            #                                           bvec_temp,
            #                                           N_hdr,
            #                                           rho_hdr )
            #
            # hdr_retFast <- LinConGauss::HDR_algoFast(t(rankconstraint_T),
            #                                          bvec_temp,
            #                                          c(sub_retFast$shift_seq[1:(length(sub_retFast$shift_seq)-1)],0),
            #                                          N_hdr )
            #
            # #Probability Estimate from subset simulation
            # # exp(sub_retFast$logZ)
            #
            # #Probability Estimate from HDR
            # tempintegralval <- exp(hdr_retFast)
            #
            #
            #




            # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
            # a second time


            #attempt at alternative to integration


            r_t_zt <- NA

            if(itemcovars == FALSE){

              kvectemp <- rep(NA, n.item)

              intersectmat_tplus1 <- Biglist_intersectmats[[t+1]]

              for(index_item in 1:n.item){

                # find row of intersectmat_T corresponding to
                # z_prop_vec[index_item]



                #ranges for zlag
                zranges <- c(-Inf, (intersectmat_tplus1)[,3])

                tempinds <- which((zranges < z_prop_vec[index_item] ))

                #which is the last one below (count includes -inf, so gives row of correct interval)
                temp_ind <- tempinds[length(tempinds)]

                # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

                kvectemp[index_item] <- temp_ind # intersectmat_tplus1[temp_ind,1]

              }

              # now find corresponding element of # mvec

              qkt_tp1_temp <- qkt_list[[t+1]]



              rowind_temp <- which(apply(qkt_tp1_temp,
                                         1,
                                         function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")

              mvec_tp1 <- mkt_list[[t+1]]

              r_t_zt <- mvec_tp1[rowind_temp]


            }else{ #itemcovars == TRUE
              kvectemp <- rep(NA, n.item)

              list_item_intersectmats_tplus1 <- Biglist_list_item_intersectmats[[t+1]]

              for(index_item in 1:n.item){

                # find row of intersectmat_T corresponding to
                # z_prop_vec[index_item]

                #ranges for zlag
                zranges <- c(-Inf, (list_item_intersectmats_tplus1[[index_item]])[,3])

                tempinds <- which((zranges < z_prop_vec[index_item] ))

                #which is the last one below (count includes -inf, so gives row of correct interval)
                temp_ind <- tempinds[length(tempinds)]

                # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

                kvectemp[index_item] <- temp_ind # (list_item_intersectmats_tplus1[[index_item]])[temp_ind,1]

              }

              # now find corresponding element of # mvec

              qkt_tp1_temp <- qkt_list[[t+1]]



              rowind_temp <- which(apply(qkt_tp1_temp,
                                         1,
                                         function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")

              mvec_tp1 <- mkt_list[[t+1]]

              r_t_zt <- mvec_tp1[rowind_temp]

            }


            # accept or reject

            if(u_temp <= r_t_zt){

              # accept
              Z.mat[,(t-1)*n.ranker + indiv] <- z_prop_vec
              accepted <- TRUE

            }else{

              # reject
              accepted <- FALSE

            }



          }# end while loop for Accept-Reject

        }else{ # Metropolis-Hastings sampler

          # Essentially the same as Accept-Reject code, except different acceptance probability
          # and not a while loop


          # Sample from the filtering distribution

          ####### MH Filtering Proposal Sample for t<- T-1 given component ###########################

          # Now draw from corresponding truncated normal distribution
          # with means mu_k
          # and constraint matrix rankconstraint_t



          # k_indvec <- nkt_mat_Tmin1[component_ind,1:(lastcol_ind-1)]


          k_indvec <- qkt_list[[t]][component_ind,1:(lastcol_ind-1)]


          if(itemcovars == FALSE){

            #note: k_indvec can include repeated values
            tempmeans <- intersectmat[k_indvec,1]


          }else{ # Allow covariates to vary over time

            #note: k_indvec can include repeated values

            # since covariates can vary over items
            # the means are obtained from item-specific intersectmats

            tempmeans <- rep(NA, length(k_indvec))

            for(ktemp in 1:length(k_indvec)){

              tempmeans[ktemp] <- (list_item_intersectmats[[ktemp]])[k_indvec[ktemp],1]
            }


          } # end else statement (obtaining means for item-specific regions)

          # current rankconstraint_t corresponds to T-1

          bvec_temp <- (rankconstraint_t)%*%tempmeans

          # require an initial value in the domain
          # arbitrarily set lowest to 10/n.item
          # then add 10/n.item for each

          # CHECK IF RESULTS SENSITIVE TO STARTING VALUE

          # z_init <- rep(NA, n.item)
          #
          # # This can probably be vectorized
          # for(z_ind in 1:n.item){
          #   z_init[which(rankvec_t == z_ind) ] <- z_ind*(1/n.item)
          # }

          # or is a random sample required?
          # z_init <- rep(0, n.item)
          # z_init<- rnorm(n.item)
          z_init<- rnorm(n = n.item, mean = -1* tempmeans)

          if(all(rankconstraint_t %*% z_init + bvec_temp > 0)){
            # in domain
            # print("in domain")
          }else{
            # stop("Error. Initial vector not in domain")

            # perhaps take random samples until a point is found in the doain
            # ElilipticalSliceSampler python function might do something like this
            # at least if there is not any initial value

            while(!(all(rankconstraint_t %*% z_init + bvec_temp > 0))){
              print("not in domain. Sample x0 again")

              # x0 <- rnorm(length(z_init))
              z_init<- rnorm(n.item)

              # x0 <- xnew
            }
          }


          # Take 100 samples, then just use last column
          # CHECK IF SAMPLER VALID WITH JUST ONE SAMPLE
          z_sample_temp <- LinESSFast(t(rankconstraint_t),
                                      bvec_temp,
                                      Num_lin_ess_samples,
                                      z_init,
                                      nskip = 0)

          #save Z values sampled from proposal

          z_prop_vec <- z_sample_temp[,ncol(z_sample_temp)] + tempmeans


          ####### MH Uniform sample ###########################

          # sample from the uniform distribution

          u_temp <- runif(n = 1)

          ####### MH Calculate Acceptance Prob t < T-1 ###########################


          #calculate acceptance probability given choice of M = nkt/mkt

          # acceptance probability equals r_t(z_t)
          # here t = T-1

          # first, must obtain means corresponding to predictions given covariates and z_prop_vec
          # and covaraite observations in time period T



          # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
          # a second time


          #attempt at alternative to integration



          r_t_zt <- NA

          if(itemcovars == FALSE){

            kvectemp <- rep(NA, n.item)

            intersectmat_tplus1 <- Biglist_intersectmats[[t+1]]

            for(index_item in 1:n.item){

              # find row of intersectmat_T corresponding to
              # z_prop_vec[index_item]



              #ranges for zlag
              zranges <- c(-Inf, (intersectmat_tplus1)[,3])

              tempinds <- which((zranges < z_prop_vec[index_item] ))

              #which is the last one below (count includes -inf, so gives row of correct interval)
              temp_ind <- tempinds[length(tempinds)]

              # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

              kvectemp[index_item] <- temp_ind # intersectmat_tplus1[temp_ind,1]

            }

            # now find corresponding element of # mvec

            qkt_tp1_temp <- qkt_list[[t+1]]



            rowind_temp <- which(apply(qkt_tp1_temp,
                                       1,
                                       function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")

            mvec_tp1 <- mkt_list[[t+1]]

            r_t_zt <- mvec_tp1[rowind_temp]


          }else{
            kvectemp <- rep(NA, n.item)

            list_item_intersectmats_tplus1 <- Biglist_list_item_intersectmats[[t+1]]

            for(index_item in 1:n.item){

              # find row of intersectmat_T corresponding to
              # z_prop_vec[index_item]

              #ranges for zlag
              zranges <- c(-Inf, (list_item_intersectmats_tplus1[[index_item]])[,3])

              tempinds <- which((zranges < z_prop_vec[index_item] ))

              #which is the last one below (count includes -inf, so gives row of correct interval)
              temp_ind <- tempinds[length(tempinds)]

              # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

              kvectemp[index_item] <- temp_ind # (list_item_intersectmats_tplus1[[index_item]])[temp_ind,1]

            }

            # now find corresponding element of # mvec

            qkt_tp1_temp <- qkt_list[[t+1]]



            rowind_temp <- which(apply(qkt_tp1_temp,
                                       1,
                                       function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")

            mvec_tp1 <- mkt_list[[t+1]]

            r_t_zt <- mvec_tp1[rowind_temp]

          }



          # for denominator of acceptance ratio,
          # can NOT save values in previous iteration of Gibbs sampler because the tree structures change.
          # Therefore, must recalculate in each iteration

          #

          z_old_vec <- Z.mat[,(t-1)*n.ranker + indiv]




          # alternatively, can directly find indices corresponding to the terminal node to avoid calculating the integral
          # a second time


          #attempt at alternative to integration



          r_t_zt_denom <- NA

          if(itemcovars == FALSE){

            kvectemp <- rep(NA, n.item)

            intersectmat_tplus1 <- Biglist_intersectmats[[t+1]]

            for(index_item in 1:n.item){

              # find row of intersectmat_T corresponding to
              # z_old_vec[index_item]



              #ranges for zlag
              zranges <- c(-Inf, (intersectmat_tplus1)[,3])

              tempinds <- which((zranges < z_old_vec[index_item] ))

              #which is the last one below (count includes -inf, so gives row of correct interval)
              temp_ind <- tempinds[length(tempinds)]

              # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

              kvectemp[index_item] <- temp_ind# intersectmat_tplus1[temp_ind,1]

            }

            # now find corresponding element of # mvec

            qkt_tp1_temp <- qkt_list[[t+1]]



            rowind_temp <- which(apply(qkt_tp1_temp,
                                       1,
                                       function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")

            mvec_tp1 <- mkt_list[[t+1]]

            r_t_zt_denom <- mvec_tp1[rowind_temp]


          }else{
            kvectemp <- rep(NA, n.item)

            list_item_intersectmats_tplus1 <- Biglist_list_item_intersectmats[[t+1]]

            for(index_item in 1:n.item){

              # find row of intersectmat_T corresponding to
              # new_rk_t_pp1_mat[index_item]

              #ranges for zlag
              zranges <- c(-Inf, (list_item_intersectmats_tplus1[[index_item]])[,3])

              tempinds <- which((zranges < new_rk_t_pp1_mat[index_item] ))

              #which is the last one below (count includes -inf, so gives row of correct interval)
              temp_ind <- tempinds[length(tempinds)]

              # ypredvec[i-1] <- ypredvec[i-1] + intersectmat[temp_ind,1]

              kvectemp[index_item] <-  temp_ind#(list_item_intersectmats_tplus1[[index_item]])[temp_ind,1]

            }

            # now find corresponding element of # mvec

            qkt_tp1_temp <- qkt_list[[t+1]]



            rowind_temp <- which(apply(qkt_tp1_temp,
                                       1,
                                       function(x) all.equal(x[1:n.item], kvectemp)) == "TRUE")

            mvec_tp1 <- mkt_list[[t+1]]

            r_t_zt_denom <- mvec_tp1[rowind_temp]

          }



          ratio_temp <- r_Tmin1_zTmin1 / r_Tmin1_zTmin1_denom

          if(u_temp <= ratio_temp){

            # accept
            Z.mat[,(t-1)*n.ranker + indiv] <- z_prop_vec
            accepted <- TRUE

          }else{

            # reject
            # keep  z value from previous round

            # accepted <- FALSE

          }


          # stop("Metropolis-Hastings code not written yet")

        } # End else statement (corresponding to MH sampler )



        # End of loop over t
        # update intersection matrices

        if(itemcovars == FALSE){
          intersectmat_tplus1 <- intersectmat

        }else{
          list_item_intersectmats_Tplus1 <- list_item_intersectmats

        }


        nkt_tplus1 <-  nkt_mat


      } # end loop over t in (n.time-2):1



      ########### sample from the predictive distribution #####################

      ####### First calculate all q_k_tp1 ##########################


      Z.mat[,(t-1)*n.ranker + indiv]



      for(h in 1:num_horizon){




        Z.mat.test[,(h-1)*n.ranker + indiv]

      }





    } # end loop over individuals indiv in 1:n.ranker




    ##################### Old Code for Latent outcome samples ##################################################################
    #
    #
    #     if(nrow(X.train)==n.item){
    #       stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #       #each n.ranker values of u should be equal,
    #       #so just take one mu value from each of these
    #       #this keeps the dimension of mu equal to n.item
    #       #so a new Gibbs sampler update does not have to be written for Z
    #       Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                            weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #       if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    #     }else{
    #       if(nrow(X.train)==n.item*n.ranker*n.time){
    #
    #         if(seq_z_draws==1){
    #           for(t in 1:n.time){
    #
    #             # update mu for period t-1
    #
    #             #Zlag always zero in period t==0
    #
    #             # Z in period 0 is unaffected since set to zero by default
    #             #thereofre mu unaffected in period 0 (can draw anyway for now)
    #
    #             if(t==1){
    #
    #               # print("t = ")
    #               # print(t)
    #               # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
    #               # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])
    #
    #               mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])
    #               # Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[1:(n.item*n.ranker)] <- sampler$predict(Xmat.train[1:(n.item*n.ranker),])
    #
    #             }else{
    #               mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(Xmat.train[1:(n.item*n.ranker),])
    #
    #               # Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #               #                                                                             ncol =  ncol(X.train) + num_lags ,
    #               #                                                                             byrow = TRUE )))
    #               # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(Xmat.train[1:(n.item*n.ranker),])
    #             }
    #
    #
    #
    #             Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                     Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                     mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                     weight.vec = rep(1, n.ranker),
    #                                                                                     n.ranker = n.ranker,
    #                                                                                     n.item = n.item)
    #
    #             #update mu for period t to be used as lag for next period
    #             #require that this is consistent with the tree structure
    #
    #
    #             Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #             for(t1 in 1:num_lags){
    #               init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #               # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #               Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #             }
    #
    #             condition <- 1
    #
    #             for(j in 1:num_lags){
    #               # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #               #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #               condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #             }
    #             while (condition==0) {
    #               # print("t = ")
    #               # print(t)
    #               # print("new z values not consistent with tree structure, must draw again")
    #
    #
    #               #perhaps this can be rewritten to just re-draw the relevant column?
    #               Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
    #                                                                                       Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
    #                                                                                       mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
    #                                                                                       weight.vec = rep(1, n.ranker),
    #                                                                                       n.ranker = n.ranker,
    #                                                                                       n.item = n.item )
    #
    #               Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
    #
    #               for(t1 in 1:num_lags){
    #                 init_Z_t0 <- rep(0, t1*n.item*n.ranker)
    #                 # init_Z_t0 <- rnorm(t*n.item*n.ranker)
    #
    #                 Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])
    #
    #               }
    #
    #               condition <- 1
    #
    #               for(j in 1:num_lags){
    #                 # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #                 #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
    #                 condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))
    #
    #               }
    #
    #
    #
    #             }
    #           }#end of loop over t
    #
    #           #end of seq_z_draws==1 code
    #         }else{
    #           Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                                     Z.mat = Z.mat,
    #                                                     mu = mu,
    #                                                     weight.vec = rep(1, n.ranker*n.time),
    #                                                     n.ranker = n.ranker*n.time,
    #                                                     n.item = n.item )
    #
    #         }
    #
    #
    #       }else{
    #         stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #       }
    #     }

    ##################### END Old Code for Latent outcome samples ##################################################################


    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{
    for(j in 1:num_lags){
      # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)

      while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {

        if(seq_z_draws==1){
          stop("updates still not consistent with tree structure")
        }
        print("new z values not consistent with tree structure, must draw again")

        # If this error message occurs
        # Check the conditions in the dbart package for setPredictor == FALSE
        # And if this is hypothetically possible, even with draws formt he smoothing distribution,
        # and if it is not a bug
        # then need to go back to beginning of this iteration of the Gibbs sampler
        # and sample Zmat again
        stop("new z values not consistent with tree structure, must draw again")


        # #perhaps this can be rewritten to just re-draw the relevant column?
        # Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                           Z.mat = Z.mat,
        #                                           mu = mu,
        #                                           weight.vec = rep(1, n.ranker*n.time),
        #                                           n.ranker = n.ranker*n.time,
        #                                           n.item = n.item )
        #
        # Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)
        #
        # for(t in 1:num_lags){
        #   init_Z_t0 <- rep(0, t*n.item*n.ranker)
        #   # init_Z_t0 <- rnorm(t*n.item*n.ranker)
        #
        #   Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])
        #
        # }
        #
        # #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j

      }
    }
    # }

    # if(nrow(X.test)>0){
    #
    #
    #   for(j in 1:num_lags){
    #
    #     #perhaps this should be removed for when Z is updated properly below
    #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
    #
    #   }
    #
    # }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    ##################### Sample sum-of-trees ##################################################


    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)

    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # mutemp <- sampler$predict(Xmat.train)
    # print("sigma = ")
    # print(samplestemp$sigma)



    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]




      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("iteration number")
        print(iter)
        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)
        stop("mutemp[1]!= mutemp[n.item+1]")
      }


      #mu = mutemp[(1:n.item)*n.ranker]
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu = mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    ##################### Store iteration output ##################################################


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta


    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }

      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      temp_test_mat <- data.frame(x = temp_test_mat)
      colnames(temp_test_mat) <- colnames(Xmat.test)

      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )


      if(iter < 5){
        print("temp_test_mat = " )
        print(temp_test_mat)
      }

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }


        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){


          if(num_lags ==1){
            temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
                                                   as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                       (num_lags+1):(ncol(Xmat.test))]) ))

          }else{
            temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
                                                   temp_test_mat[,1:(num_lags-1)] ,
                                                   as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                       (num_lags+1):(ncol(Xmat.test))]) ))

          }
        }

        colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }

      # if(nrow(X.test)>0){
      #
      #
      #   for(j in 1:num_lags){
      #
      #     #perhaps this should be removed for when Z is updated properly below
      #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
      #
      #   }
      #
      # }


      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }


  return(draw)
}





#' Auto-regressive BART model for Bayesian Analysis of Rank-Order data with entities' Covariates
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARRObart <- function(pair.comp.ten,
                     X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                     X.test = matrix(NA, nrow =0, ncol = 0),
                     # tau2.alpha = 5^2,
                     # nu.alpha = 3,
                     # tau2.beta = 5^2,
                     # nu.beta = 3,
                     n.item = dim(pair.comp.ten)[1],
                     n.rankerbytime = dim(pair.comp.ten)[3],
                     n.ranker,
                     n.time,
                     p.cov = ncol(X.train),
                     iter.max = 5000,
                     para.expan = TRUE,
                     print.opt = 100,
                     initial.list = NULL,
                     n.trees = 50L,
                     n.burn = 0L,
                     n.samples = 1L,
                     n.thin = 1L,
                     n.chains = 1,
                     n.threads = 1L,#guessNumCores(),
                     printEvery = 100L,
                     printCutoffs = 0L,
                     rngKind = "default",
                     rngNormalKind = "default",
                     rngSeed = NA_integer_,
                     updateState = FALSE,
                     num_lags = 1,
                     diff_num_test_rankers = 0,
                     num_test_periods = 0,
                     keep_zmat = FALSE,
                     noise_in_pred = 0,
                     seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  length_mu <- 1

  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)

      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max))#,
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(nrow(X.test) >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }
  }






  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(nrow(X.test) >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )


      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")





        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat, X.train) )

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = cbind( Zlag.mat.test, X.test ) )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }



    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")


    if(nrow(X.test )==0){
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        #test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1),
                        sigma=1 #check if this is the correct approach for setting the variance to 1
      )

    }else{
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
                        sigma=1 #
      )

    }

    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)

    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train = ")
        print(Xmat.train)
        print("Z.mat = ")
        print(Z.mat)

        print("samplestemp$sigma = ")
        print(samplestemp$sigma)
        print("samplestemp$varcount = ")
        print(samplestemp$varcount)

        print("samplestemp$train[,1] = ")
        print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
  }
  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  if( nrow(X.test) > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec
        }



        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
                                                 as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

        }else{
          temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                                 as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )))

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]
      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  # Begin Gibbs sampler
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){

    ################## Begin Gibbs Sampler #####################################

    if(nrow(X.train)==n.item){
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
                                           weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){

        if(seq_z_draws==1){
          for(t in 1:n.time){

            # update mu for period t-1

            #Zlag always zero in period t==0

            # Z in period 0 is unaffected since set to zero by default
            #thereofre mu unaffected in period 0 (can draw anyway for now)

            if(t==1){

              # print("t = ")
              # print(t)
              # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
              # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])

              mu[1:(n.item*n.ranker)] <- samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1]  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])
              # Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
              #                                                                             ncol =  ncol(X.train) + num_lags ,
              #                                                                             byrow = TRUE )))
              # mu[1:(n.item*n.ranker)] <- sampler$predict(Xmat.train[1:(n.item*n.ranker),])

            }else{
              mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  samplestemp$train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker),1] # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

              # Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
              #                                                                             ncol =  ncol(X.train) + num_lags ,
              #                                                                             byrow = TRUE )))
              # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(Xmat.train[1:(n.item*n.ranker),])
            }



            Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
                                                                                    Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
                                                                                    mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
                                                                                    weight.vec = rep(1, n.ranker),
                                                                                    n.ranker = n.ranker,
                                                                                    n.item = n.item)

            #update mu for period t to be used as lag for next period
            #require that this is consistent with the tree structure


            Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

            for(t1 in 1:num_lags){
              init_Z_t0 <- rep(0, t1*n.item*n.ranker)
              # init_Z_t0 <- rnorm(t*n.item*n.ranker)

              Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

            }

            condition <- 1

            for(j in 1:num_lags){
              # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
              #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
              condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))

            }
            while (condition==0) {
              # print("t = ")
              # print(t)
              # print("new z values not consistent with tree structure, must draw again")


              #perhaps this can be rewritten to just re-draw the relevant column?
              Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
                                                                                      Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
                                                                                      mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
                                                                                      weight.vec = rep(1, n.ranker),
                                                                                      n.ranker = n.ranker,
                                                                                      n.item = n.item )

              Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

              for(t1 in 1:num_lags){
                init_Z_t0 <- rep(0, t1*n.item*n.ranker)
                # init_Z_t0 <- rnorm(t*n.item*n.ranker)

                Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

              }

              condition <- 1

              for(j in 1:num_lags){
                # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
                #perhaos this can be edited so that only the relevant time period is updated withinthte lag vector
                condition <- condition*(1-(sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE))

              }



            }
          }#end of loop over t

          #end of seq_z_draws==1 code
        }else{
          Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
                                                    Z.mat = Z.mat,
                                                    mu = mu,
                                                    weight.vec = rep(1, n.ranker*n.time),
                                                    n.ranker = n.ranker*n.time,
                                                    n.item = n.item )

        }


      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }
    }



    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }





    #THEN use SetPredictor

    # if (i <= n_warmup) {
    #   for(j in 1:num_lags){
    #     sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)
    #     }
    # } else{
    for(j in 1:num_lags){
      # sampler$setPredictor(x = Zlag.mat[,j], column = j, forceUpdate = TRUE)

      while (sampler$setPredictor(x = Zlag.mat[,j], column = j) == FALSE) {

        if(seq_z_draws==1){
          stop("updates still not consistent with tree structure")
        }
        print("new z values not consistent with tree structure, must draw again")

        #perhaps this can be rewritten to just re-draw the relevant column?
        Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
                                                  Z.mat = Z.mat,
                                                  mu = mu,
                                                  weight.vec = rep(1, n.ranker*n.time),
                                                  n.ranker = n.ranker*n.time,
                                                  n.item = n.item )

        Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

        for(t in 1:num_lags){
          init_Z_t0 <- rep(0, t*n.item*n.ranker)
          # init_Z_t0 <- rnorm(t*n.item*n.ranker)

          Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

        }

        #check that Zmat and  Zlag.mat are updated outside the while loop and for-loop over j

      }
    }
    # }

    if(nrow(X.test)>0){


      for(j in 1:num_lags){

        #perhaps this should be removed for when Z is updated properly below
        sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)

      }

    }

    #//////////////////////////////////////////////////////////////////////////
    #
    #
    #
    #//////////////////////////////////////////////////////////////////////////

    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }



    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)

    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # mutemp <- sampler$predict(Xmat.train)
    # print("sigma = ")
    # print(samplestemp$sigma)



    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]




      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("iteration number")
        print(iter)
        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)
        stop("mutemp[1]!= mutemp[n.item+1]")
      }


      #mu = mutemp[(1:n.item)*n.ranker]
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        mu = mutemp
      }else{
        stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }

    }



    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }
    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta


    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1)*n.item*n.ranker)]
        }

      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      temp_test_mat <- data.frame(x = temp_test_mat)
      colnames(temp_test_mat) <- colnames(Xmat.test)

      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )


      if(iter < 5){
        print("temp_test_mat = " )
        print(temp_test_mat)
      }

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }


        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){


          if(num_lags ==1){
            temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
                                                   as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                       (num_lags+1):(ncol(Xmat.test))]) ))

          }else{
            temp_test_mat <-  data.frame(  cbind(  temp_test_preds[ , t1] ,
                                                   temp_test_mat[,1:(num_lags-1)] ,
                                                   as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,
                                                                       (num_lags+1):(ncol(Xmat.test))]) ))

          }
        }

        colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }

      # if(nrow(X.test)>0){
      #
      #
      #   for(j in 1:num_lags){
      #
      #     #perhaps this should be removed for when Z is updated properly below
      #     sampler$setTestPredictor(x = Zlag.mat.test[,j], column = j)
      #
      #   }
      #
      # }


      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }
  return(draw)
}




dt_ls <- function(x, df=1, mu=0, sigma=1) (1/sigma) * dt((x - mu)/sigma, df)



#' @title Nonparametric BART model for Bayesian Analysis of Rank-Order data with entities' Covariates
#'
#' @description Bayesian Additive Regression Tree Model for rank-order data with mixture of Gaussian distributions for the latent error term.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific covariate values, then the matrix should have N*M rows where M is the number of rankers. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data. (assumes no structure to input data)
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param lambda0 Lambda parameter for the base distribution for the error term.
#' @param nu0 nu parameter for sigma prior in base distribution G_0
#' @param sigest Estiamted standard deviation of outcome or error (used for setting base distirbution parameters).
#' @param sigquant Parameter for setting lambda0 (if NA). lambda0 set such that the sigquant quantile of the base distribution of sigma is the standard deviation of the outcome (as estimated by Maximum Likelihood assuming censored normal outcome).
#' @param alpha_prior The prior for the alpha parameter of the Dirichlet Process mixture of normals. If "vh" then apply the Gamma(c1,c2) prior of van Hasselt (2011) and Escobar (1994). If "george", then apply the prior of George (2019), McCulloch (2021), Conley (2008), and Antoniak (1974).
#' @param c1 If alpha_prior == "vh", then c1 is the shape parameter of the Gamma distribution.
#' @param c2 If alpha_prior == "vh", then c2 is the rate parameter of the Gamma distribution.
#' @param alpha_gridsize If alpha_prior = "george", this is the size of the grid to use for the discretized samples of alpha
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
RObartnp <- function(pair.comp.ten,
                     X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                     X.test = matrix(NA, nrow =0, ncol = 0),
                     # tau2.alpha = 5^2,
                     # nu.alpha = 3,
                     # tau2.beta = 5^2,
                     # nu.beta = 3,
                     n.item = dim(pair.comp.ten)[1],
                     n.ranker = dim(pair.comp.ten)[3],
                     p.cov = ncol(X.train),
                     iter.max = 5000,
                     para.expan = TRUE,
                     print.opt = 100,
                     initial.list = NULL,
                     n.trees = 50L,
                     n.burn = 0L,
                     n.samples = 1L,
                     n.thin = 1L,
                     n.chains = 1,
                     n.threads = 1L,#guessNumCores(),
                     printEvery = 100L,
                     printCutoffs = 0L,
                     rngKind = "default",
                     rngNormalKind = "default",
                     rngSeed = NA_integer_,
                     updateState = FALSE,
                     num_lags = 1,
                     diff_num_test_rankers = 0,
                     keep_zmat = FALSE,
                     lambda0 = NA,
                     sigest = NA,
                     nu0=10,
                     sigquant = 0.95,
                     alpha_prior = "vh",
                     c1 = 2,
                     c2 = 2,
                     alpha_gridsize = 100L,
                     ranker_components = TRUE,
                     sparse = FALSE,
                     alpha_a_y = 0.5,
                     alpha_b_y = 1,
                     alpha_split_prior = TRUE){
  ## store MCMC draws

  # print("begin function")

  length_mu <- 1

  if(nrow(X.train)==n.item){
    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.ranker){
      length_mu <- n.item*n.ranker
    }else{
      stop("nrow(X.train) not equal to n.item or n.ranker")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- n.ranker#1

  if(nrow(X.test) >0 ){
    if(diff_num_test_rankers==1){
      length_mu_test <- nrow(X.test)
      num_test_rankers <- length_mu_test/n.item
      if(num_test_rankers%%1 !=0){
        print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
      }
    }else{
      if(nrow(X.train)==n.item){
        length_mu_test <- n.item*n.ranker

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }
    }
  }


  if((ranker_components == TRUE) & (nrow(X.train) == n.item)){
    tempmulength <- n.item*n.ranker
  }else{
    tempmulength <- length_mu

  }

  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(tempmulength, iter.max)),
    alphamixing = rep(NA, iter.max)#,
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max))
  }

  if(nrow(X.test) >0 ){

    # if(keep_zmat==TRUE){
    #   draw$Z.mat.test = array(NA, dim = c(n.item, num_test_rankers, iter.max))
    # }
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))

  }






  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){
      Xmat.train <- data.frame(y = as.vector(Z.mat), x = matrix( rep( t( X.train ) , n.ranker ) , ncol =  ncol(X.train) , byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        Xmat.test <- data.frame(x = matrix( rep( t( X.test ) , n.ranker ) , ncol =  ncol(X.test) , byrow = TRUE ))
        #colnames(Xmat.test) <- c("x","z","w")
      }
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Xmat.train <- data.frame(y = as.vector(Z.mat), X.train)
        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(X.test)
        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }


    if((ranker_components == FALSE ) & (nrow(X.train) !=n.item) & (n.ranker >1)){
      stop("Code does not currently support (ranker_components == FALSE ) & (nrow(X.train) !=n.item) & (n.ranker >1).")
    }


    num_obs_ztrain <- n.item*n.ranker#length(as.vector(Z.mat))#nrow(X.train)
    num_obs_ztest <- n.item*num_test_rankers

    # set hyperparameter values for error term

    alpha <- rgamma(n = 1, shape = c1, rate = c2)
    alpha <- c1/c2
    mu0 <-  0


    if(is.na(lambda0)) {
      if(is.na(sigest)) {
        # not clear how to set this since latent variable
        sigest <- 1
      }
      qchi = qchisq(1.0-sigquant,nu0)
      lambda0 = (sigest*sigest*qchi)/nu0 #lambda parameter for sigma prior
    } else {
      sigest=sqrt(lambda0)
    }





    k_s <- 10 # using default from fully nonparametric BART paper

    #not obvous how to set this
    #could set to maximum of linear model residuals

    #not clear how to set this because only have latent variable
    #emax <- max(y-mu0)
    emax <- 3 #arbitrary (a reasonable maximum for a few hundred standard normal draws)

    k0 <- ( ( k_s*sqrt(lambda0))/emax )^2

    # print("nu0/2 = ")
    # print(nu0/2)
    #
    # print("nu0*lambda0/2 = ")
    # print(nu0*lambda0/2)

    sigma_init <- sqrt(1/rgamma(n = 1,
                                shape =  nu0/2,
                                rate = nu0*lambda0/2))

    # mu_init <- rnorm(1, mean = mu0, sd = sigma_init/sqrt(k0))
    mu_init <- 0 # rnorm(1, mean = mu0, sd = sigma_init/sqrt(k0))

    # sigma1_vec_train <- rep(sigma_init, num_obs_ztrain)
    # sigma1_vec_test <- rep(sigma_init, num_obs_ztest)
    #
    # mu1_vec_train <- rep(mu_init,num_obs_ztrain)
    # mu1_vec_test <- rep(mu_init,num_obs_ztest)


    if(ranker_components == FALSE ){
      length_mu1 <- n.item
    }else{
      length_mu1 <- n.item*n.ranker
    }

    if(nrow(X.test) >0 ){
      if(ranker_components == FALSE ){
        length_mu1test <- n.item
      }else{
        length_mu1test <- n.item*n.ranker
      }
    }

    sigma1_vec_train <- rep(sigma_init, length_mu1)
    # sigma1_vec_test <- rep(sigma_init, length_mu_test)

    mu1_vec_train <- rep(mu_init,length_mu1)
    # mu1_vec_test <- rep(mu_init,length_mu_test)
    varthetamat <- cbind(mu1_vec_train, sigma1_vec_train)


    if(nrow(X.test) >0 ){
      sigma1_vec_test <- rep(sigma_init, length_mu1test)
      mu1_vec_test <- rep(mu_init,length_mu1test)
      varthetamat_test <- cbind(mu1_vec_test, sigma1_vec_test)

    }

    # mu2_vec_train <- rep(0,n)
    # mu2_vec_test <- rep(0,ntest)

    # print("Line 301")


    weightstemp_y  <- 1/(sigma1_vec_train^2)

    p_y <- ncol(Xmat.train) - 1 # subtracting 1 outcome is a column of Xmat.train

    if(sparse){
      s_y <- rep(1 / p_y, p_y) # probability vector to be used during the growing process for DART feature weighting
      rho_y <- p_y # For DART

      if(alpha_split_prior){
        alpha_s_y <- p_y
      }else{
        alpha_s_y <- 1
      }
      alpha_scale_y <- p_y


      var_count_y <- rep(0, p_y)

      draw$alpha_s_y_store <- rep(NA, iter.max)
      draw$var_count_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
      draw$s_prob_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
    }


    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))

    # print("begin dbarts")


    if(nrow(X.test )==0){
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        #test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1),
                        sigma=1 #check if this is the correct approach for setting the variance to 1
      )

    }else{
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
                        sigma=1 #
      )

    }

    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)

    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }


    if(ranker_components == FALSE ){
      tempy <- as.vector(Z.mat) - rep(mu1_vec_train,n.ranker)
    }else{
      if(length(as.vector(Z.mat)) != length(mu1_vec_train)){
        stop("length(as.vector(Z.mat)) != length(mu1_vec_train)")
      }
      tempy <- as.vector(Z.mat) - mu1_vec_train
    }

    sampler$setResponse(y = tempy)

    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y <- rep(0, p_y)
      var_count_y[tempcounts$x] <- tempcounts$N
    }


    sampler$setSigma(sigma = 1)
    sampler$setWeights(weights = weightstemp_y)



    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples


    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y[tempcounts$x] <- tempcounts$N
    }


    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      if(ranker_components==TRUE){
        mu <- mutemp

      }else{
        # if(mutemp[1]!= mutemp[n.item+1]){
        if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
          print("initiating mu")
          print("Xmat.train = ")
          print(Xmat.train)
          print("Z.mat = ")
          print(Z.mat)

          print("samplestemp$sigma = ")
          print(samplestemp$sigma)
          print("samplestemp$varcount = ")
          print(samplestemp$varcount)

          print("samplestemp$train[,1] = ")
          print(samplestemp$train[,1])

          print("n.item = ")
          print(n.item)
          print("mutemp = ")
          print(mutemp)

          # print("mupreds= ")
          # print(mupreds)

          stop("mutemp[1]!= mutemp[n.item+1]")
        }

        #mu = mutemp[(1:n.item)]
        mu = mutemp[n.item+(1:n.item)]

        #mu = mutemp[(1:n.item)*n.ranker]
      }
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item or n.ranker")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
  }

  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta

  draw$alphamixing[1] <- alpha

  if( nrow(X.test) >0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      mutest <- samplestemp$test[,1]
      draw$mu_test[,1] <- mutest

    }else{
      mutest <- initial.list$mu_test
      draw$mu_test[,1] <- mutest
    }

  }


  temp_loop_len <- num_obs_ztrain

  if(ranker_components==TRUE){
    temp_loop_len <- num_obs_ztrain
  }else{
    temp_loop_len <- num_obs_ztrain/n.ranker

  }


  if( nrow(X.test) >0 ){
    # must draw test parameter values
    test_clusts <-  sample(0:temp_loop_len,
                           size = num_obs_ztest,
                           replace = TRUE,
                           prob = c(alpha/(alpha+temp_loop_len),
                                    rep(1/(alpha+temp_loop_len) ,
                                        temp_loop_len) ))


    if(sum(test_clusts >0)==0){
      # skip
    }else{
      sigma1_vec_test[test_clusts > 0] <- sigma1_vec_train[test_clusts[test_clusts > 0]  ]
      mu1_vec_test[test_clusts > 0] <- mu1_vec_train[test_clusts[test_clusts > 0]  ]
    }

    if(sum(test_clusts ==0)==0){
      # skip
    }else{
      # draw from prior
      numzeros <- sum(test_clusts ==0)

      sigma1_vec_test[test_clusts ==0] <- sqrt(1/rgamma(n = numzeros, shape =  nu0/2, rate = nu0*lambda0/2) )

      mu1_vec_test[test_clusts ==0] <- rnorm(n = numzeros, mean = mu0, sd = sigma1_vec_test[test_clusts ==0]/sqrt(k0))

    }
  }




  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      # stop("NP Code not written for nrow(X.train)==n.item.")

      Z.mat <- GibbsUpLatentGivenRankGroupnp(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat,
                                             mu = mu + mu1_vec_train,
                                             sigvec = sigma1_vec_train,
                                             n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Z.mat <- GibbsUpLatentGivenRankindividualnp(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat,
                                                    mu = mu + mu1_vec_train,
                                                    sigvec = sigma1_vec_train,
                                                    n.ranker = n.ranker,
                                                    n.item = n.item )
      }else{
        #stop("nrow(X.train) not equal to n.item or n.ranker")
      }
    }


    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }



    weightstemp_y  <- 1/(sigma1_vec_train^2)



    if(ranker_components == FALSE ){
      tempy <- as.vector(Z.mat) - rep(mu1_vec_train,n.ranker)
    }else{
      tempy <- as.vector(Z.mat) - mu1_vec_train
    }

    sampler$setResponse(y = tempy)

    # set the response.
    # Check that 0 is a reasonable initial value
    # perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat) - mu1_vec_train)
    # sampler$setSigma(sigma = 1)
    # sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)

    sampler$setSigma(sigma = 1)
    sampler$setWeights(weights = weightstemp_y)

    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    # mutesttemp <- samplestemp$test[,1]

    #suppose there are a number of samples

    # mutemp <- sampler$predict(Xmat.train)
    # print("sigma = ")
    # print(samplestemp$sigma)

    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }


    if(nrow(X.train)==n.item){



      if(ranker_components==TRUE){
        mu <- mutemp

      }else{
        #each n.ranker values of u should be equal,
        #so just take one mu value from each of these
        #this keeps the dimension of mu equal to n.item
        #so a new Gibbs sampler update does not have to be written for Z

        #mu = mutemp[(1:n.item)]
        mu = mutemp[n.item+(1:n.item)]


        # if(mutemp[1]!= mutemp[n.item+1]){
        if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
          print("iteration number")
          print(iter)
          print("n.item = ")
          print(n.item)
          print("mutemp = ")
          print(mutemp)
          stop("mutemp[1]!= mutemp[n.item+1]")
        }



      }    #mu = mutemp[(1:n.item)*n.ranker]
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        mu = mutemp
      }else{
        stop("nrow(X.train) not equal to n.item or n.ranker")
      }

    }

    if (sparse & (iter > floor(n.burnin * 0.5))) {
      # s_update_z <- update_s(var_count_z, p_z, alpha_s_z)
      # s_z <- s_update_z[[1]]

      s_update_y <- update_s(var_count_y, p_y, alpha_s_y)
      s_y <- s_update_y[[1]]

      if(alpha_split_prior){
        # alpha_s_z <- update_alpha(s_z, alpha_scale_z, alpha_a_z, alpha_b_z, p_z, s_update_z[[2]])
        alpha_s_y <- update_alpha(s_y, alpha_scale_y, alpha_a_y, alpha_b_y, p_y, s_update_y[[2]])
      }
    }

    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta

    draw$alphamixing[iter] <- alpha

    if( nrow(X.test) >0 ){
      draw$mu_test[,iter] <- samplestemp$test[,1]
    }



    # add Zmat test draws?

    ######### 4 draw components of mixture ####################
    # print(" 4 draw components of mixture")

    temp_loop_len <- num_obs_ztrain

    if(ranker_components==TRUE){
      temp_loop_len <- num_obs_ztrain
    }else{
      temp_loop_len <- num_obs_ztrain/n.ranker

    }

    qi0vec <- alpha*dt_ls(as.vector(Z.mat)[1:temp_loop_len],
                          df = nu0,
                          mu = mu[1:temp_loop_len],
                          sigma =  lambda0*(1 + (1/k0)) )

    #loop over individuals for updates
    for(i in 1:temp_loop_len){

      # qi0 <- alpha*dt_ls(as.vector(Z.mat)[i],
      #                    df = nu0,
      #                    mu = mu[i],
      #                    sigma =  lambda0*(1 + (1/k0)) )


      qi0 <- qi0vec[i]

      # print("qi0 = ")
      # print(qi0)
      #
      #
      # print("mu[i] = ")
      # print(mu[i])
      #
      # print("i = ")
      # print(i)
      #
      # print("mu = ")
      # print(mu)
      #
      # print("as.vector(Z.mat)[i] = ")
      # print(as.vector(Z.mat)[i])
      #
      #
      # print("alpha = ")
      # print(alpha)


      varthetamattemp <- varthetamat[-i,, drop = FALSE]
      # vartheta_unique_mat <- unique(varthetamattemp)

      # tempcol <- varthetamattemp[,1, drop = FALSE]
      #
      # ux = sort(unique(tempcol)) #vartheta_unique_mat[,1, drop = FALSE] #sort(unique(tempcol))
      # idx = match(tempcol, ux)
      # tempuniinds <- unique(idx)
      # tempord <- order(ux[tempuniinds])

      tempcol <- varthetamattemp[,1, drop = FALSE]

      # THERE IS PROBABLY A MUCH FASTER WAY OF DOING THIS JUST BY UPDATING IN ITERATION
      # BY ACCOUNTING FOR LAST INCLUDED NUMBER AND DROPPPED ROW i

      tempord <- order(tempcol, method = "radix")
      tempsort <- tempcol[tempord]
      tempuniinds <- tempord[!duplicated(tempsort)]
      # tempuniinds <- unique(match(tempsort,tempcol))
      counts_ord <- rle2(tempsort)[,2]
      vartheta_unique_mat <- varthetamattemp[tempuniinds, , drop = FALSE]


      #also try split(seq_along(vec), vec)


      # tempord <- order(unique(varthetamattemp[,1 , drop = FALSE]))
      #         tempord <- order(vartheta_unique_mat[,1 , drop = FALSE])


      # print("vartheta_unique_mat = ")
      # print(vartheta_unique_mat)


      # print("tempord = ")
      # print(tempord)
      #          vartheta_unique_mat <- vartheta_unique_mat[tempord, , drop = FALSE]


      # print("vartheta_unique_mat = ")
      # print(vartheta_unique_mat)

      #       tempcol <- varthetamattemp[,1, drop = FALSE]

      # counts_ord <- table(varthetamattemp[,1, drop = FALSE])

      #        ux = vartheta_unique_mat[,1, drop = FALSE] #sort(unique(tempcol))
      # ux = sort(unique(tempcol))
      # print("ux = ")
      # print(ux)
      #        idx = match(tempcol, ux)

      # print("idx = ")
      # print(idx)
      #
      # print("length(ux)")
      # print(length(ux))
      # counts_ord = tabulate(idx, nbins=length(ux))


      num_unique <- nrow(vartheta_unique_mat)

      # print("counts_ord = ")
      # print(counts_ord)

      # print("num_unique = ")
      # print(num_unique)

      if( sum(counts_ord) != temp_loop_len-1 ){
        print("counts_ord = ")
        print(counts_ord)
        print("num_unique = ")
        print(num_unique)
        print("n-1 = ")
        print(temp_loop_len-1)
        print("sum(counts_ord) = ")
        print(sum(counts_ord))

        stop("Bug in count of unique values")
      }

      if( length(counts_ord) != num_unique ){
        print("counts_ord = ")
        print(counts_ord)
        print("num_unique = ")
        print(num_unique)

        stop("Bug in count of unique values")
      }

      q_rs <- rep(NA, nrow(vartheta_unique_mat))

      q_rs <- counts_ord*fastnormdens(as.vector(Z.mat)[i],
                                      mean = mu[i] + vartheta_unique_mat[,1],
                                      sd =  vartheta_unique_mat[,2])

      # print("q_rs = ")
      # print(q_rs)
      #
      # print("counts_ord = ")
      # print(counts_ord)
      # print("as.vector(Z.mat)[i] = ")
      # print(as.vector(Z.mat)[i])
      #
      # print("counts_ord = ")
      # print(counts_ord)
      # print("vartheta_unique_mat[,1]= ")
      # print(vartheta_unique_mat[,1])


      # for(j in 1:num_unique){
      #   q_rs[j] <- counts_ord[j]*fastnormdens(as.vector(Z.mat)[i],
      #                                  mean = vartheta_unique_mat[j,1],
      #                                  sd =  vartheta_unique_mat[j,2])
      # }

      tempdemon <- qi0 + sum(q_rs)

      qi0 <- qi0/tempdemon
      q_rs <- q_rs/tempdemon


      # print("q_rs = ")
      # print(q_rs)
      # print("qi0 = ")
      # print(qi0)


      rprime <- sample(0:num_unique, size = 1, replace = TRUE, prob = c(qi0, q_rs))

      if(rprime>0){
        varthetamat[i,] <- vartheta_unique_mat[rprime,]
        mu1_vec_train[i] <- varthetamat[i,1]
        sigma1_vec_train[i] <- varthetamat[i,2]

      }else{
        varthetamat[i,2] <- sqrt(1/rgamma(n = 1,
                                          shape =  (nu0+1)/2,
                                          rate = (nu0*lambda0/2) + (as.vector(Z.mat)[i] -  mu[i] )^2/( 2*(1 + 1/k0))  ) )

        varthetamat[i,1] <- rnorm(n=1,
                                  mean =  (as.vector(Z.mat)[i] -  mu[i] )/(k0+1) ,
                                  sd =  varthetamat[i,2]/sqrt(k0+1) )

        mu1_vec_train[i] <- varthetamat[i,1]
        sigma1_vec_train[i] <- varthetamat[i,2]


      }


    }



    ######### 5 mixing step ##########################
    # print("5 mixing step")


    vartheta_unique_mat <- unique(varthetamat)

    for(j in 1:nrow(vartheta_unique_mat)){

      clust_inds <- which(varthetamat[,1, drop = FALSE] == vartheta_unique_mat[j,1])

      n_j <- length(clust_inds)

      clust_mean <- mean(as.vector(Z.mat)[clust_inds] -  mu[clust_inds])

      varthetamat[clust_inds,2] <- sqrt(1/rgamma(n = 1, #n_j,
                                                 shape =  (nu0+n_j)/2,
                                                 rate = (nu0*lambda0/2) + sum((as.vector(Z.mat)[clust_inds] -  mu[clust_inds] - clust_mean )^2)/2 +
                                                   (k0*n_j/( k0 + n_j) )*( clust_mean^2 / 2) ) )

      varthetamat[clust_inds,1] <- rnorm(n= 1, #n_j,
                                         mean =  (n_j * clust_mean )/(k0+n_j) ,
                                         sd =  varthetamat[clust_inds,2]/sqrt(k0+n_j) )

      mu1_vec_train[clust_inds] <- varthetamat[clust_inds,1]
      sigma1_vec_train[clust_inds] <- varthetamat[clust_inds,2]


    }



    ######### 6 sample alpha ######################
    # print("6 sample alpha")

    vartheta_unique_mat <- unique(varthetamat)


    # This step can be implemented using the prior of van Hasselt (2011)
    # or the prior of George et al. (2019), McCulloch et al. (2021) ans Conley et al. (2008)

    # count number of unique mixture components
    # there is probably a more efficient way of doing this

    # create a matrix in which each row contains all of an individual's mixture component parameters

    # varthetamat <- cbind(mu1_vec_train, mu2_vec_train, phi1_vec_train, gamma1_vec_train)
    # varthetamat_test <- cbind(mu1_vec_test, mu2_vec_test, phi1_vec_test, gamma1_vec_test)

    #obtain the unique rows (components)
    vartheta_unique_mat <- unique(varthetamat)

    #number of unique components
    k_uniq <- nrow(vartheta_unique_mat)


    if(alpha_prior == "vh"){

      #########  VH Step 6 a: Sample auxiliary variable kappa  ######################################################

      kappa_aux = rbeta(n = 1, shape1 = alpha+1,
                        shape2 = temp_loop_len #num_obs_ztrain
      )

      #########  VH Step 6 b: Sample alpha from a mixture of gamma distributions  ######################################################

      #obtain the mixing probability
      p_kappa <- (c1+k_uniq-1)/(temp_loop_len*#num_obs_ztrain*
                                  (c2-log(kappa_aux))+c1+k_uniq-1)

      #sample a mixture component
      mix_draw <- rbinom(1,1,p_kappa)

      # draw alpha from the drawn component
      if(mix_draw==1){
        alpha <- rgamma(1,shape = c1 + k_uniq, rate = c2 - log(kappa_aux))
      }else{
        alpha <- rgamma(1,shape = c1 + k_uniq - 1, rate = c2 - log(kappa_aux))

      }




    }else{
      if(alpha_prior == "george"){

        #Calculate alpha_min and alpha_max
        Imin <- 1
        Imax <- floor(0.1*n)

        #consider IVBART prior
        # Imin <- 2
        # Imax <- floor(0.1*n)+1


        if(floor(0.1*n)<=1){
          stop("Not enough observations for Prior of George et al. (2019)")
        }

        psiprior <- 0.5

        # from ivbart package code
        # https://github.com/rsparapa/bnptools/blob/master/ivbart/R/amode.R
        egamm = 0.5772156649
        # tempmin= digamma(Imin) - log(egamm+log(n))
        # tempmax= digamma(Imax) - log(egamm+log(n))
        tempmin= digamma(Imin) - log(egamm+log(temp_loop_len))
        tempmax= digamma(Imax) - log(egamm+log(temp_loop_len))

        alpha_min <- exp(tempmin)
        alpha_max <- exp(tempmax)
        alpha_values =  seq(from=alpha_min,to=alpha_max,length.out=alpha_gridsize)
        temp_aprior = 1 - (alpha_values-alpha_min)/(alpha_max-alpha_min)
        temp_aprior = temp_aprior^psiprior
        # temp_aprior = temp_aprior/sum(temp_aprior)


        log_tempvals <- k_uniq*log(alpha_values) + lgamma(alpha_values) - lgamma(temp_loop_len + #num_obs_ztrain#n+
                                                                                   alpha_values)

        # print("log_tempvals = ")
        # print(log_tempvals)
        # print("temp_aprior = ")
        # print(temp_aprior)

        temp_kgivenalpha <- exp(log_tempvals)

        # temp_kgivenalpha <- ((alpha_values)^(k_uniq))*gamma(alpha_values)/gamma(n+alpha_values)
        temp_alpha_postprobs <- temp_kgivenalpha*temp_aprior


        # print("temp_kgivenalpha = ")
        # print(temp_kgivenalpha)


        # print("gamma(alpha_values) = ")
        # print(gamma(alpha_values))
        #
        #
        # print("gamma(n+alpha_values) = ")
        # print(gamma(n+alpha_values))
        #
        #
        # print("alpha_values = ")
        # print(alpha_values)
        #
        # print("temp_kgivenalpha = ")
        # print(temp_kgivenalpha)

        # print("temp_aprior = ")
        # print(temp_aprior)
        #
        # print("temp_alpha_postprobs = ")
        # print(temp_alpha_postprobs)

        post_probs_alphs = temp_alpha_postprobs/sum(temp_alpha_postprobs)

        # print("post_probs_alphs = ")
        # print(post_probs_alphs)

        #sample from 1 to alpha_gridsize
        index_alpha <- sample.int(n = alpha_gridsize, size = 1, prob = post_probs_alphs, replace = TRUE)

        alpha <- alpha_values[index_alpha]


      }else{
        stop("Alpha prior must be vh or george")
      }

    }




    ########### draw y value predictions ##############################
    # not sure where to make these draws (relative to other steps)
    # print("draw y value predictions ")

    if( nrow(X.test) >0 ){
      # must draw test parameter values
      test_clusts <-  sample(0:temp_loop_len,
                             size = num_obs_ztest,
                             replace = TRUE,
                             prob = c(alpha/(alpha+temp_loop_len),
                                      rep(1/(alpha+temp_loop_len) ,
                                          temp_loop_len) ))

      if(sum(test_clusts >0)==0){
        # skip
      }else{
        sigma1_vec_test[test_clusts > 0] <- sigma1_vec_train[test_clusts[test_clusts > 0]  ]
        mu1_vec_test[test_clusts > 0] <- mu1_vec_train[test_clusts[test_clusts > 0]  ]
      }

      if(sum(test_clusts ==0)==0){
        # skip
      }else{
        # draw from prior
        numzeros <- sum(test_clusts ==0)

        sigma1_vec_test[test_clusts ==0] <- sqrt(1/rgamma(n = numzeros,
                                                          shape =  nu0/2,
                                                          rate = nu0*lambda0/2) )

        mu1_vec_test[test_clusts ==0] <- rnorm(n = numzeros,
                                               mean = mu0,
                                               sd = sigma1_vec_test[test_clusts ==0]/sqrt(k0))

      }
    }


    if(sparse){
      draw$alpha_s_y_store[iter] <- alpha_s_y
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_y_store[iter,] <- var_count_y
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_y_store[iter,] <- s_y
      # draw$s_prob_z_store[iter,] <- s_z
    }

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }
  return(draw)
}




#' BART model for Bayesian Analysis of Rank-Order data with entities' covariates
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific covariate values, then the matrix should have N*M rows where M is the number of rankers. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data. (assumes no structure to input data)
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param tree_power Tree prior parameter for outcome model.
#' @param tree_base Tree prior parameter for outcome model.
#' @param sparse If equal to TRUE, use Linero Dirichlet prior on splitting probabilities
#' @param alpha_a_y Linero alpha prior parameter for outcome equation splitting probabilities
#' @param alpha_b_y Linero alpha prior parameter for outcome equation splitting probabilities
#' @param alpha_split_prior If TRUE, set hyperprior for Linero alpha parameter
#' @param n.burnin Number of burn-in iterations. Burn-in iterations are NOT removed. This option is just used to determine the number of iterations past which splitting probabilities are sampled when sparse = TRUE.
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
RObart <- function(pair.comp.ten,
                   X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                   X.test = matrix(NA, nrow =0, ncol = 0),
                   # tau2.alpha = 5^2,
                   # nu.alpha = 3,
                   # tau2.beta = 5^2,
                   # nu.beta = 3,
                   n.item = dim(pair.comp.ten)[1],
                   n.ranker = dim(pair.comp.ten)[3],
                   p.cov = ncol(X.train),
                   iter.max = 5000,
                   # para.expan = TRUE,
                   print.opt = 100,
                   initial.list = NULL,
                   n.trees = 50L,
                   n.burn = 0L,
                   n.samples = 1L,
                   n.thin = 1L,
                   n.chains = 1,
                   n.threads = 1L,#guessNumCores(),
                   printEvery = 100L,
                   printCutoffs = 0L,
                   rngKind = "default",
                   rngNormalKind = "default",
                   rngSeed = NA_integer_,
                   updateState = TRUE, # FALSE,
                   num_lags = 1,
                   diff_num_test_rankers = 0,
                   keep_zmat = FALSE,
                   tree_power = 2,
                   tree_base = 0.95,
                   sparse = FALSE,
                   alpha_a_y = 0.5,
                   alpha_b_y = 1,
                   alpha_split_prior = TRUE,
                   n.burnin = floor(dim(pair.comp.ten)[1]/2)){
  ## store MCMC draws

  # print("begin function")

  length_mu <- 1

  if(nrow(X.train)==n.item){
    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.ranker){
      length_mu <- n.item*n.ranker
    }else{
      stop("nrow(X.train) not equal to n.item or n.ranker")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- 1

  if(nrow(X.test) >0 ){
    if(diff_num_test_rankers==1){
      length_mu_test <- nrow(X.test)
      num_test_rankers <- length_mu_test/n.item
      if(num_test_rankers%%1 !=0){
        print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
      }
    }else{
      if(nrow(X.train)==n.item){
        length_mu_test <- n.item*n.ranker

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }
    }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max))#,
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max))
  }

  if(nrow(X.test) >0 ){

    # if(keep_zmat==TRUE){
    #   draw$Z.mat.test = array(NA, dim = c(n.item, num_test_rankers, iter.max))
    # }
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))

  }






  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){
      Xmat.train <- data.frame(y = as.vector(Z.mat), x = matrix( rep( t( X.train ) , n.ranker ) , ncol =  ncol(X.train) , byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        Xmat.test <- data.frame(x = matrix( rep( t( X.test ) , n.ranker ) , ncol =  ncol(X.test) , byrow = TRUE ))
        #colnames(Xmat.test) <- c("x","z","w")
      }
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Xmat.train <- data.frame(y = as.vector(Z.mat), X.train)
        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(X.test)
        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }

    p_y <- ncol(Xmat.train) - 1 # subtracting 1 outcome is a column of Xmat.train

    if(sparse){
      s_y <- rep(1 / p_y, p_y) # probability vector to be used during the growing process for DART feature weighting
      rho_y <- p_y # For DART

      if(alpha_split_prior){
        alpha_s_y <- p_y
      }else{
        alpha_s_y <- 1
      }
      alpha_scale_y <- p_y


      var_count_y <- rep(0, p_y)

      draw$alpha_s_y_store <- rep(NA, iter.max)
      draw$var_count_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
      draw$s_prob_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
    }


    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))

    # print("begin dbarts")


    if(nrow(X.test )==0){
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        #test = Xmat.test,
                        control = control,
                        tree.prior = dbarts:::cgm(power = tree_power, base =  tree_base,  split.probs = rep(1 / p_y, p_y)),
                        resid.prior = fixed(1),
                        sigma=1 #check if this is the correct approach for setting the variance to 1
      )

    }else{
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        test = Xmat.test,
                        control = control,
                        tree.prior = dbarts:::cgm(power = tree_power, base =  tree_base,  split.probs = rep(1 / p_y, p_y)),
                        resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
                        sigma=1 #
      )

    }

    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)
    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }

    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)



    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y <- rep(0, p_y)
      var_count_y[tempcounts$x] <- tempcounts$N
    }



    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train = ")
        print(Xmat.train)
        print("Z.mat = ")
        print(Z.mat)

        print("samplestemp$sigma = ")
        print(samplestemp$sigma)
        print("samplestemp$varcount = ")
        print(samplestemp$varcount)

        print("samplestemp$train[,1] = ")
        print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item or n.ranker")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    stop("code for non-zero initial list not yet written")
    Z.mat <- initial.list$Z.mat
    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
  }

  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  if( nrow(X.test) >0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      draw$mu_test[,1] <- samplestemp$test[,1]

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }



  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
                                           weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker){

        if(any(is.na(Z.mat))){stop("NA in Z.mat")}
        if(any(is.na(mu))){stop("NA in mu")}


        Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu, weight.vec = rep(1, n.ranker), n.ranker = n.ranker,
                                                  n.item = n.item )
      }else{
        #stop("nrow(X.train) not equal to n.item or n.ranker")
      }
    }


    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }



    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)


    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }

    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # mutemp <- sampler$predict(Xmat.train)
    # print("sigma = ")
    # print(samplestemp$sigma)

    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y[tempcounts$x] <- tempcounts$N
    }

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]




      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("iteration number")
        print(iter)
        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)
        stop("mutemp[1]!= mutemp[n.item+1]")
      }


      #mu = mutemp[(1:n.item)*n.ranker]
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        mu = mutemp
      }else{
        stop("nrow(X.train) not equal to n.item or n.ranker")
      }

    }

    if (sparse & (iter > floor(n.burnin * 0.5))) {
      # s_update_z <- update_s(var_count_z, p_z, alpha_s_z)
      # s_z <- s_update_z[[1]]

      s_update_y <- update_s(var_count_y, p_y, alpha_s_y)
      s_y <- s_update_y[[1]]

      if(alpha_split_prior){
        # alpha_s_z <- update_alpha(s_z, alpha_scale_z, alpha_a_z, alpha_b_z, p_z, s_update_z[[2]])
        alpha_s_y <- update_alpha(s_y, alpha_scale_y, alpha_a_y, alpha_b_y, p_y, s_update_y[[2]])
      }
    }

    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta

    if( nrow(X.test) >0 ){
      draw$mu_test[,iter] <- samplestemp$test[,1]
    }

    if(sparse){
      draw$alpha_s_y_store[iter] <- alpha_s_y
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_y_store[iter,] <- var_count_y
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_y_store[iter,] <- s_y
      # draw$s_prob_z_store[iter,] <- s_z
    }

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }
  return(draw)
}



#' BART model for Bayesian Analysis of Rank-Order data with entities' covariates, with item-specific intercepts
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific covariate values, then the matrix should have N*M rows where M is the number of rankers. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data. (assumes no structure to input data)
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param test_items_ordered If TRUE, assumes test matrix corresponds to same itesms as training matrix an dthey are in the same order. i.e. the test data corresponds to new rankers, but the same items in the same order.
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
RObart_intercepts <- function(pair.comp.ten,
                              X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                              X.test = matrix(NA, nrow =0, ncol = 0),
                              tau2.alpha = 5^2,
                              nu.alpha = 3,
                              # tau2.beta = 5^2,
                              # nu.beta = 3,
                              n.item = dim(pair.comp.ten)[1],
                              n.ranker = dim(pair.comp.ten)[3],
                              p.cov = ncol(X.train),
                              iter.max = 5000,
                              para.expan = FALSE,#TRUE,
                              print.opt = 100,
                              initial.list = NULL,
                              n.trees = 50L,
                              n.burn = 0L,
                              n.samples = 1L,
                              n.thin = 1L,
                              n.chains = 1,
                              n.threads = 1L,#guessNumCores(),
                              printEvery = 100L,
                              printCutoffs = 0L,
                              rngKind = "default",
                              rngNormalKind = "default",
                              rngSeed = NA_integer_,
                              updateState = FALSE,
                              num_lags = 1,
                              diff_num_test_rankers = 0,
                              keep_zmat = FALSE,
                              test_items_ordered = TRUE,
                              sparse = TRUE,
                              alpha_a_y = 0.5,
                              alpha_b_y = 1,
                              alpha_split_prior = TRUE){
  ## store MCMC draws

  # print("begin function")

  length_mu <- 1

  if(nrow(X.train)==n.item){
    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.ranker){
      length_mu <- n.item*n.ranker
    }else{
      stop("nrow(X.train) not equal to n.item or n.ranker")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- 1

  if(nrow(X.test) >0 ){
    if(diff_num_test_rankers==1){
      length_mu_test <- nrow(X.test)
      num_test_rankers <- length_mu_test/n.item
      if(num_test_rankers%%1 !=0){
        print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
      }
    }else{
      if(nrow(X.train)==n.item){
        length_mu_test <- n.item*n.ranker

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }
    }
  }


  if((nrow(X.test) > 0 ) & (test_items_ordered == TRUE)){
    num_test_rankers <- nrow(X.test)/n.item
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    alphaintercepts = array(NA, dim = c(n.item, iter.max)),
    mu_plus_alpha = array(NA, dim = c(length_mu, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max))#,
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max))
  }

  if(nrow(X.test) >0 ){

    # if(keep_zmat==TRUE){
    #   draw$Z.mat.test = array(NA, dim = c(n.item, num_test_rankers, iter.max))
    # }
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
    draw$mu_plus_alpha_test <- array(NA, dim = c(length_mu_test, iter.max))

  }






  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    alphaintercepts = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){
      Xmat.train <- data.frame(y = as.vector(Z.mat), x = matrix( rep( t( X.train ) , n.ranker ) , ncol =  ncol(X.train) , byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        Xmat.test <- data.frame(x = matrix( rep( t( X.test ) , n.ranker ) , ncol =  ncol(X.test) , byrow = TRUE ))
        #colnames(Xmat.test) <- c("x","z","w")
      }
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Xmat.train <- data.frame(y = as.vector(Z.mat), X.train)
        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(X.test)
        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }


    p_y <- ncol(Xmat.train) - 1 # subtracting 1 outcome is a column of Xmat.train

    if(sparse){
      s_y <- rep(1 / p_y, p_y) # probability vector to be used during the growing process for DART feature weighting
      rho_y <- p_y # For DART

      if(alpha_split_prior){
        alpha_s_y <- p_y
      }else{
        alpha_s_y <- 1
      }
      alpha_scale_y <- p_y


      var_count_y <- rep(0, p_y)

      draw$alpha_s_y_store <- rep(NA, iter.max)
      draw$var_count_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
      draw$s_prob_y_store <- matrix(0, ncol = p_y, nrow = iter.max)
    }


    control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
                             keepTrees = TRUE,
                             n.trees = n.trees,
                             n.burn = n.burn,
                             n.samples = n.samples,
                             n.thin = n.thin,
                             n.chains = n.chains,
                             n.threads = n.threads,
                             printEvery = printEvery,
                             printCutoffs = printCutoffs,
                             rngKind = rngKind,
                             rngNormalKind = rngNormalKind,
                             rngSeed = rngSeed)


    # print(colnames(Xmat.train))

    # print("begin dbarts")


    if(nrow(X.test )==0){
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        #test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1),
                        sigma=1 #check if this is the correct approach for setting the variance to 1
      )

    }else{
      sampler <- dbarts(y ~ .,
                        data = Xmat.train,
                        test = Xmat.test,
                        control = control,
                        resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
                        sigma=1 #
      )

    }

    # print("error after dbarts")

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = as.vector(Z.mat))
    # sampler$setSigma(sigma = 1)

    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)
    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }


    #mu = as.vector( alpha + X.mat %*% beta )
    sampler$sampleTreesFromPrior()
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples




    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y <- rep(0, p_y)
      var_count_y[tempcounts$x] <- tempcounts$N
    }



    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train = ")
        print(Xmat.train)
        print("Z.mat = ")
        print(Z.mat)

        print("samplestemp$sigma = ")
        print(samplestemp$sigma)
        print("samplestemp$varcount = ")
        print(samplestemp$varcount)

        print("samplestemp$train[,1] = ")
        print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item or n.ranker")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    alphaintercepts = initial.list$alphaintercepts
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
  }

  draw$alphaintercepts[,1] = alphaintercepts
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta

  alphafullvec <- rep(alphaintercepts,n.ranker)
  draw$mu_plus_alpha[,1] <- mu + alphafullvec

  if( nrow(X.test) >0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      draw$mu_test[,1] <- samplestemp$test[,1]

      draw$mu_plus_alpha_test[,1] <- draw$mu_test[,1] + rep(alphaintercepts,num_test_rankers)

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }




  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      #each n.ranker values of mu should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu+alphaintercepts,
                                           weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat,
                                                  mu = mu+alphafullvec,
                                                  weight.vec = rep(1, n.ranker), n.ranker = n.ranker,
                                                  n.item = n.item )
      }else{
        #stop("nrow(X.train) not equal to n.item or n.ranker")
      }
    }


    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence

    Zmin_mu <- as.matrix(as.vector(Z.mat) - mu,
                         nrow = nrow(Z.mat),
                         nrow = ncol(Z.mat))


    mean.para.update <- GibbsUpMuGivenLatentIndNoCov(Z.mat = Zmin_mu, #X.mat = Xmat.train,
                                                     weight.vec = rep(1, n.ranker),
                                                     sigma2.alpha = sigma2.alpha, #sigma2.beta = sigma2.beta,
                                                     n.ranker = n.ranker,
                                                     n.item = n.item,#p.cov = p.cov,
                                                     para.expan = FALSE#para.expan
    )


    # CHECK WHETHER TO IMPLEMENT THIS STEP?
    # Z.mat = Z.mat/mean.para.update$theta


    alphaintercepts <- mean.para.update$alpha

    alphafullvec <- rep(alphaintercepts,n.ranker)


    sigma2.alpha = GibbsUpsigma2(alphaintercepts, nu.alpha, tau2.alpha)


    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    # Zmin_alpha <- as.matrix(as.vector(Z.mat) - alphafullvec,
    #                      nrow = nrow(Z.mat),
    #                      nrow = ncol(Z.mat))

    Zmin_alphavec <- as.vector(Z.mat) - alphafullvec

    #set the response.
    #Check that 0 is a reasonable initial value
    #perhaps makes more sense to use initial values of Z
    sampler$setResponse(y = Zmin_alphavec)
    # sampler$setSigma(sigma = 1)
    #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)


    if(sparse){
      tempmodel <- sampler$model
      tempmodel@tree.prior@splitProbabilities <- s_y
      sampler$setModel(newModel = tempmodel)
    }



    #mu = as.vector( alpha + X.mat %*% beta )
    samplestemp <- sampler$run()

    mutemp <- samplestemp$train[,1]
    #suppose there are a number of samples

    # mutemp <- sampler$predict(Xmat.train)
    # print("sigma = ")
    # print(samplestemp$sigma)

    if(sparse){
      tempcounts <- fcount(sampler$getTrees()$var)
      tempcounts <- tempcounts[tempcounts$x != -1, ]
      var_count_y[tempcounts$x] <- tempcounts$N
    }

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]




      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("iteration number")
        print(iter)
        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)
        stop("mutemp[1]!= mutemp[n.item+1]")
      }


      #mu = mutemp[(1:n.item)*n.ranker]
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        mu = mutemp
      }else{
        stop("nrow(X.train) not equal to n.item or n.ranker")
      }

    }



    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] <- mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta
    draw$alphaintercepts[,iter] <- alphaintercepts
    draw$mu_plus_alpha[,iter] <- mu + alphafullvec

    if( nrow(X.test) >0 ){
      draw$mu_test[,iter] <- samplestemp$test[,1]
      draw$mu_plus_alpha_test[,iter] <- draw$mu_test[,iter] + rep(alphaintercepts,num_test_rankers)

    }

    if(sparse){
      draw$alpha_s_y_store[iter] <- alpha_s_y
      # draw$alpha_s_z_store[iter] <- alpha_s_z
      draw$var_count_y_store[iter,] <- var_count_y
      # draw$var_count_z_store[iter,] <- var_count_z
      draw$s_prob_y_store[iter,] <- s_y
      # draw$s_prob_z_store[iter,] <- s_z
    }

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }
  return(draw)
}



#' Soft BART model for Bayesian Analysis of Rank-Order data with entities' covariates, with Dirichlet hyperprior on splitting probabilities for sparsity
#'
#' Implement the Soft Bayesian model for rank-order data with ranked entities' covariate information, with Dirichlet hyperprior on splitting probabilities for sparsity.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @import SoftBart
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific covariate values, then the matrix should have N*M rows where M is the number of rankers. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data. (assumes no structure to input data)
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
SoftRObart <- function(pair.comp.ten,
                       X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                       X.test = matrix(NA, nrow =0, ncol = 0),
                       # tau2.alpha = 5^2,
                       # nu.alpha = 3,
                       # tau2.beta = 5^2,
                       # nu.beta = 3,
                       n.item = dim(pair.comp.ten)[1],
                       n.ranker = dim(pair.comp.ten)[3],
                       p.cov = ncol(X.train),
                       iter.max = 5000,
                       para.expan = TRUE,
                       print.opt = 100,
                       initial.list = NULL,
                       n.trees = 50L,
                       n.burn = 0L,
                       n.samples = 1L,
                       n.thin = 1L,
                       n.chains = 1,
                       n.threads = 1L,#guessNumCores(),
                       printEvery = 100L,
                       printCutoffs = 0L,
                       rngKind = "default",
                       rngNormalKind = "default",
                       rngSeed = NA_integer_,
                       updateState = FALSE,
                       num_lags = 1,
                       diff_num_test_rankers = 0,
                       keep_zmat = FALSE,
                       SB_group = NULL,
                       SB_alpha = 1,
                       SB_beta = 2,
                       SB_gamma = 0.95,
                       SB_k = 2,
                       SB_sigma_hat = NULL,
                       SB_shape = 1,
                       SB_width = 0.1,
                       # SB_num_tree = 20,
                       SB_alpha_scale = NULL,
                       SB_alpha_shape_1 = 0.5,
                       SB_alpha_shape_2 = 1,
                       SB_tau_rate = 10,
                       SB_num_tree_prob = NULL,
                       SB_temperature = 1,
                       SB_weights = NULL,
                       SB_normalize_Y = TRUE){
  ## store MCMC draws

  # print("begin function")

  length_mu <- 1

  if(nrow(X.train)==n.item){
    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.ranker){
      length_mu <- n.item*n.ranker
    }else{
      stop("nrow(X.train) not equal to n.item or n.ranker")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- 1

  if(nrow(X.test) >0 ){
    if(diff_num_test_rankers==1){
      length_mu_test <- nrow(X.test)
      num_test_rankers <- length_mu_test/n.item
      if(num_test_rankers%%1 !=0){
        print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
      }
    }else{
      if(nrow(X.train)==n.item){
        length_mu_test <- n.item*n.ranker

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }
    }
  }

  make_01_norm <- function(x) {
    a <- min(x)
    b <- max(x)
    return(function(y0) (y0 - a) / (b - a))
  }

  ecdfs   <- list()
  for(i in 1:ncol(X.train)) {
    ecdfs[[i]] <- ecdf(X.train[,i])
    if(length(unique(X.train[,i])) == 1) ecdfs[[i]] <- identity
    if(length(unique(X.train[,i])) == 2) ecdfs[[i]] <- make_01_norm(X.train[,i])
  }
  for(i in 1:ncol(X.train)) {
    X.train[,i] <- ecdfs[[i]](X.train[,i])
    X.test[,i] <- ecdfs[[i]](X.test[,i])
  }





  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    #alpha = array(NA, dim = c(n.item, iter.max)),
    #beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max))#,
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    # sigma2.alpha = rep(NA, iter.max),
    # sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max))
  }

  if(nrow(X.test) >0 ){

    # if(keep_zmat==TRUE){
    #   draw$Z.mat.test = array(NA, dim = c(n.item, num_test_rankers, iter.max))
    # }
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))

  }






  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){
      Xmat.train <- data.frame(y = as.vector(Z.mat), x = matrix( rep( t( X.train ) , n.ranker ) , ncol =  ncol(X.train) , byrow = TRUE ))

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        Xmat.test <- data.frame(x = matrix( rep( t( X.test ) , n.ranker ) , ncol =  ncol(X.test) , byrow = TRUE ))
        #colnames(Xmat.test) <- c("x","z","w")
      }
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Xmat.train <- data.frame(y = as.vector(Z.mat),x = X.train)
        if(nrow(X.test)>0 ){
          Xmat.test  <- data.frame(x = X.test)
        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }



    # control <- dbartsControl(updateState = updateState, verbose = FALSE,  keepTrainingFits = TRUE,
    #                          keepTrees = TRUE,
    #                          n.trees = n.trees,
    #                          n.burn = n.burn,
    #                          n.samples = n.samples,
    #                          n.thin = n.thin,
    #                          n.chains = n.chains,
    #                          n.threads = n.threads,
    #                          printEvery = printEvery,
    #                          printCutoffs = printCutoffs,
    #                          rngKind = rngKind,
    #                          rngNormalKind = rngNormalKind,
    #                          rngSeed = rngSeed)
    #
    #
    # # print(colnames(Xmat.train))
    #
    # # print("begin dbarts")
    #
    #
    # if(nrow(X.test )==0){
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     #test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1),
    #                     sigma=1 #check if this is the correct approach for setting the variance to 1
    #   )
    #
    # }else{
    #   sampler <- dbarts(y ~ .,
    #                     data = Xmat.train,
    #                     test = Xmat.test,
    #                     control = control,
    #                     resid.prior = fixed(1), #this was suggested by the dbarts package author. I assume this is sufficient
    #                     sigma=1 #
    #   )
    #
    # }


    hypers <- Hypers(as.matrix(Xmat.train[,2:ncol(Xmat.train)]),
                     as.vector(Xmat.train$y),
                     num_tree = n.trees, #sigma_hat = 1,
                     group = SB_group,
                     alpha = SB_alpha,
                     beta = SB_beta,
                     gamma = SB_gamma,
                     k = SB_k,
                     # sigma_hat = NULL,
                     shape = SB_shape,
                     width = SB_width,
                     # num_tree = 20,
                     alpha_scale = SB_alpha_scale,
                     alpha_shape_1 = SB_alpha_shape_1,
                     alpha_shape_2 = SB_alpha_shape_2,
                     tau_rate = SB_tau_rate,
                     num_tree_prob = SB_num_tree_prob,
                     temperature = SB_temperature,
                     weights = SB_weights,
                     normalize_Y = SB_normalize_Y
    )


    opts <- Opts(update_sigma = TRUE, num_print = print.opt)

    sampler_forest <- MakeForest(hypers, opts)

    sampler_forest$set_sigma(1)





    # # print("error after dbarts")
    #
    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    #
    # #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # sampler$sampleTreesFromPrior()
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]



    mutemp <- t(sampler_forest$do_gibbs(as.matrix(Xmat.train[,2:ncol(Xmat.train)]),
                                      as.vector(Xmat.train$y),
                                      as.matrix(Xmat.train[,2:ncol(Xmat.train)]),
                                      1))
    # mutest <- sampler_forest$do_predict(Xmat.test$x)




    #suppose there are a number of samples

    # print("sigma = ")
    # print(samplestemp$sigma)

    # mupreds <- sampler$predict(Xmat.train)

    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("initiating mu")
        print("Xmat.train = ")
        print(Xmat.train)
        print("Z.mat = ")
        print(Z.mat)

        print("samplestemp$sigma = ")
        print(samplestemp$sigma)
        print("samplestemp$varcount = ")
        print(samplestemp$varcount)

        print("samplestemp$train[,1] = ")
        print(samplestemp$train[,1])

        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)

        # print("mupreds= ")
        # print(mupreds)

        stop("mutemp[1]!= mutemp[n.item+1]")
      }

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]

      #mu = mutemp[(1:n.item)*n.ranker]

    }else{
      if(nrow(X.train)==n.item*n.ranker){
        mu <- mutemp
      }else{
        stop("nrow(X.train) not equal to n.item or n.ranker")
      }

    }


    ## initial values for sigma2.alpha and sigma2.beta
    # sigma2.alpha = tau2.alpha
    # sigma2.beta = tau2.beta

  }else{
    Z.mat <- initial.list$Z.mat
    # alpha = initial.list$alpha
    # beta = initial.list$beta
    mu <- initial.list$mu #as.vector( alpha + X.mat %*% beta )
    # sigma2.alpha = initial.list$sigma2.alpha
    # sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  #
  #   print("Z.mat = ")
  #   print(Z.mat)
  #
  #
  #   print("dim(draw$Z.mat) = ")
  #
  #   print(dim(draw$Z.mat))

  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] <- Z.mat
  }

  # draw$alpha[,1] = alpha
  # draw$beta[,1] = beta
  draw$mu[,1] <- mu
  # draw$sigma2.alpha[1] = sigma2.alpha
  # draw$sigma2.beta[1] = sigma2.beta


  if( nrow(X.test) >0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])
      draw$mu_test[,1] <- sampler_forest$do_predict(as.matrix(Xmat.test))

      # draw$mu_test[,1] <- samplestemp$test[,1]

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }



  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
                                           weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu, weight.vec = rep(1, n.ranker), n.ranker = n.ranker,
                                                  n.item = n.item )
      }else{
        #stop("nrow(X.train) not equal to n.item or n.ranker")
      }
    }


    # update Z.mat given (alpha, beta) or equivalently mu

    # update (alpha, beta) or equivalently mu
    # omitting the theta step for now,
    # although this would ideally be edited for BART and included to speed up convergence



    #
    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item,
    #                                              p.cov = p.cov, para.expan = para.expan)
    #
    #     ### for check only
    #     Z.mat = Z.mat/mean.para.update$theta
    #
    #     alpha = mean.para.update$alpha
    #     beta = mean.para.update$beta

    # mu = as.vector( alpha + X.mat %*% beta )
    #
    # # update hyper para sigma2.alpha and sigma2.beta
    # sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    sampler_forest$set_sigma(1)

    mutemp <- t(sampler_forest$do_gibbs(as.matrix(Xmat.train[,2:ncol(Xmat.train)]),
                                      as.vector(Z.mat),
                                      as.matrix(Xmat.train[,2:ncol(Xmat.train)]),
                                      1))

    # #set the response.
    # #Check that 0 is a reasonable initial value
    # #perhaps makes more sense to use initial values of Z
    # sampler$setResponse(y = as.vector(Z.mat))
    # # sampler$setSigma(sigma = 1)
    # #sampler$setPredictor(x= Xmat.train, column = 1, forceUpdate = TRUE)
    #
    # #mu = as.vector( alpha + X.mat %*% beta )
    # samplestemp <- sampler$run()
    #
    # mutemp <- samplestemp$train[,1]
    # #suppose there are a number of samples
    #
    # # mutemp <- sampler$predict(Xmat.train)
    # # print("sigma = ")
    # # print(samplestemp$sigma)



    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z

      #mu = mutemp[(1:n.item)]
      mu = mutemp[n.item+(1:n.item)]




      # if(mutemp[1]!= mutemp[n.item+1]){
      if(mutemp[n.item+1]!= mutemp[n.item+n.item+1]){
        print("iteration number")
        print(iter)
        print("n.item = ")
        print(n.item)
        print("mutemp = ")
        print(mutemp)
        stop("mutemp[1]!= mutemp[n.item+1]")
      }


      #mu = mutemp[(1:n.item)*n.ranker]
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        mu = mutemp
      }else{
        stop("nrow(X.train) not equal to n.item or n.ranker")
      }

    }



    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    # draw$alpha[,iter] = alpha
    # draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$sigma2.alpha[iter] = sigma2.alpha
    # draw$sigma2.beta[iter] = sigma2.beta

    if( nrow(X.test) >0 ){
      # draw$mu_test[,iter] <- samplestemp$test[,1]
      draw$mu_test[,iter]  <- sampler_forest$do_predict(as.matrix(Xmat.test))

    }


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }
  return(draw)
}




#' Auto-regressive linear model for Bayesian Analysis of Rank-Order data with entities' Covariates. Full condtional z Sampler.
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARBayesRankCov_partial <- function(pair.comp.ten,
                                   X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                   X.test = matrix(NA, nrow =0, ncol = 0),
                                   tau2.alpha = 5^2,
                                   nu.alpha = 3,
                                   tau2.beta = 5^2,
                                   nu.beta = 3,
                                   n.item = dim(pair.comp.ten)[1],
                                   n.rankerbytime = dim(pair.comp.ten)[3],
                                n.ranker,
                                n.time,
                                p.cov = ncol(X.train),
                                iter.max = 5000,
                                para.expan = TRUE,
                                print.opt = 100,
                                initial.list = NULL,
                                n.trees = 50L,
                                n.burn = 0L,
                                n.samples = 1L,
                                n.thin = 1L,
                                n.chains = 1,
                                n.threads = guessNumCores(),
                                printEvery = 100L,
                                printCutoffs = 0L,
                                rngKind = "default",
                                rngNormalKind = "default",
                                rngSeed = NA_integer_,
                                updateState = FALSE,
                                num_lags = 1,
                                diff_num_test_rankers = 0,
                                num_test_periods = 0,
                                keep_zmat = FALSE,
                                noise_in_pred = 0,
                                seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }
  if(num_lags >1){
    stop("Current implementation only allows for 1 lag of the latent outcome.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  length_mu <- 1

  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }


  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(p.cov + num_lags, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    mu_noZgamma = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    gamcoef = rep(NA, iter.max),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(nrow(X.test) >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
    draw$mu_noZgamma_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }

  }




  ###### Initialize Values ############

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      # tempsort <- sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE )
      #
      # Z.mat[ tempsort$ix , j] <-
      #   qnorm(  tempsort$x   /(n.item+1)) +
      #   rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(nrow(X.test) >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )


      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")





        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <-  cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }




    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, p.cov + num_lags)
    mu = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train) %*% beta )
    mu_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test) %*% beta )


    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )
    mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta

    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")



    # draw$Z.mat[,,1] <- Z.mat
    # draw$alpha[,1] = alpha
    # draw$beta[,1] = beta
    # draw$mu[,1] <- mu
    # draw$sigma2.alpha[1] = sigma2.alpha
    # draw$sigma2.beta[1] = sigma2.beta


    ## store initial value
    if(keep_zmat==TRUE){
      draw$Z.mat[,,1] = Z.mat
    }


    draw$alpha[,1] = alpha
    draw$beta[,1] = beta
    draw$mu[,1] = mu
    draw$mu_test[,1] = mu_test
    draw$sigma2.alpha[1] = sigma2.alpha
    draw$sigma2.beta[1] = sigma2.beta

    draw$mu_noZgamma[,1] = mu_noZgamma
    draw$mu_noZgamma_test[,1] = mu_noZgamma_test
    draw$gamcoef[1] = gamcoef




  }# ending  if statement if is null initial list




  if( nrow(X.test) > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA,
                                nrow = n.item*n.ranker,
                                ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- rep(alpha, n.ranker) + temp_test_mat %*% beta   #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] ,
                                      as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

        }else{
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                      as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ############# Begin Gibbs sampler#########################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      # Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
      #                                      weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){

        # if(seq_z_draws==1){
        for(t in 1:n.time){




          # update mu for period t-1

          #Zlag always zero in period t==0

          # Z in period 0 is unaffected since set to zero by default
          #therefore mu unaffected in period 0 (can draw anyway for now)

          Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat


          if(t==1){
            # mu[1:(n.item*n.ranker)] <- (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta ))  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])

            for(indiv in 1:n.ranker){

              # tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

              temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

              # tempmu <- mu[1:(n.item*n.ranker)]
              # tempmu_noZgamma <- mu_noZgamma[1:(n.item*n.ranker)]
              #
              # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]


              tempmu <- mu[(t-1)*(n.item*n.ranker) +
                             n.item*(indiv-1) +
                             1:(n.item)]

              tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                               n.item*(indiv-1) +
                                               1:(n.item)]


              tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                                 n.item*(indiv-1) +
                                 1:(n.item)]

              tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                   n.item*(indiv-1) +
                                                   1:(n.item)]

              tempz <- Z.mat[,(t-1)*n.ranker + indiv]

              tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]

              # draw item by item

              # calculate mean
              # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
              tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma  )/((gamcoef^2)*(1+gamcoef^2)+1)

              # calculate variance
              tempvar <- (gamcoef^2)*(1+gamcoef^2)+1

              for(item_ind in 1:n.item){
                # temp_z_i <- tempz[item_ind]
                # temprank_i <- tempranks[item_ind]


                set1 = which( temppaircomps[item_ind, ] == 1)
                set0 = which( temppaircomps[item_ind, ] == 0)

                if(length(set1) > 0){
                  tempupper = min(tempz[set1])
                }else{
                  tempupper = Inf
                }

                if(length(set0) > 0){
                  templower = max(tempz[set0])
                }else{
                  templower = -Inf
                }



                # # find bounds for truncated normal distribution
                # # need observed ranks for this
                # if(temprank_i==1){
                #   templower <- -Inf
                # }else{
                #   templower <- max(tempz[tempranks < temprank_i])
                # }
                #
                # if(temprank_i==n.item){
                #   tempupper <- Inf
                # }else{
                #   tempupper <- min(tempz[tempranks > temprank_i])
                # }


                # # calculate mean
                # # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                # tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1[item_ind]-tempmu_noZgamma_tp1[item_ind]) +tempmu_noZgamma[item_ind]  )/((gamcoef^2)*(1+gamcoef^2)+1)
                #
                # # calculate variance
                # tempvar <- (gamcoef^2)*(1+gamcoef^2)+1


                temp_z_i <- rtruncnorm(n = 1,
                                       a = templower,
                                       b = tempupper,
                                       mean = tempmean[item_ind],
                                       sd = tempvar)

                tempz[item_ind] <- temp_z_i
                Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                # Is it then necessary to update z_tm1 and z_tm1*gamma in mu calcalcutions for draw of z in next period (t=2)?
                # Check also ARROBART code for this
                # Z.mat updated, therefore z_tm1 will be the updated values in next iteration over t
                # therefore all is fine as long as use noZgamma mu values

              }
            }

          }else{
            if(t==n.time){
              # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])
              for(indiv in 1:n.ranker){
                # tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]
                temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

                # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

                tempmu <- mu[(t-1)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

                tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

                tempz <- Z.mat[,(t-1)*n.ranker + indiv]

                # tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
                tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

                # draw item by item

                # calculate mean
                # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                tempmean <- tempmu_noZgamma + gamcoef*tempz_tm1

                # calculate variance
                tempvar <- 1

                for(item_ind in 1:n.item){
                  # temp_z_i <- tempz[item_ind]
                  # temprank_i <- tempranks[item_ind]


                  set1 = which( temppaircomps[item_ind, ] == 1)
                  set0 = which( temppaircomps[item_ind, ] == 0)

                  if(length(set1) > 0){
                    tempupper = min(tempz[set1])
                  }else{
                    tempupper = Inf
                  }

                  if(length(set0) > 0){
                    templower = max(tempz[set0])
                  }else{
                    templower = -Inf
                  }

                  # # find bounds for truncated normal distribution
                  # # need observed ranks for this
                  # if(temprank_i==1){
                  #   templower <- -Inf
                  # }else{
                  #   templower <- max(tempz[tempranks < temprank_i])
                  # }
                  #
                  # if(temprank_i==n.item){
                  #   tempupper <- Inf
                  # }else{
                  #   tempupper <- min(tempz[tempranks > temprank_i])
                  # }

                  temp_z_i <- rtruncnorm(n = 1,
                                         a = templower,
                                         b = tempupper,
                                         mean = tempmean[item_ind],
                                         sd = tempvar)

                  tempz[item_ind] <- temp_z_i
                  Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                }

              } # end loop over individuals
            }else{
              # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

              for(indiv in 1:n.ranker){
                # tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]
                temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

                # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

                tempmu <- mu[(t-1)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

                tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

                tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                                   n.item*(indiv-1) +
                                   1:(n.item)]

                tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                     n.item*(indiv-1) +
                                                     1:(n.item)]

                tempz <- Z.mat[,(t-1)*n.ranker + indiv]

                tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
                tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

                # draw item by item

                # calculate mean
                # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                tempmean <- (  gamcoef*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma + gamcoef*tempz_tm1 )/(1+gamcoef^2)

                # calculate variance
                tempvar <- 1+gamcoef^2

                for(item_ind in 1:n.item){
                  # temp_z_i <- tempz[item_ind]
                  # temprank_i <- tempranks[item_ind]

                  set1 = which( temppaircomps[item_ind, ] == 1)
                  set0 = which( temppaircomps[item_ind, ] == 0)

                  if(length(set1) > 0){
                    tempupper = min(tempz[set1])
                  }else{
                    tempupper = Inf
                  }

                  if(length(set0) > 0){
                    templower = max(tempz[set0])
                  }else{
                    templower = -Inf
                  }

                  # # find bounds for truncated normal distribution
                  # # need observed ranks for this
                  # if(temprank_i==1){
                  #   templower <- -Inf
                  # }else{
                  #   templower <- max(tempz[tempranks < temprank_i])
                  # }
                  #
                  # if(temprank_i==n.item){
                  #   tempupper <- Inf
                  # }else{
                  #   tempupper <- min(tempz[tempranks > temprank_i])
                  # }

                  temp_z_i <- rtruncnorm(n = 1,
                                         a = templower,
                                         b = tempupper,
                                         mean = tempmean[item_ind],
                                         sd = tempvar)

                  tempz[item_ind] <- temp_z_i
                  Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                }


              } # end loop over individuals

            } #end else statement (for t value not 1 or n.time)
          } # end else statement (for t value not 1)


          # Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
          #                                                                         Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
          #                                                                         mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
          #                                                                         weight.vec = rep(1, n.ranker),
          #                                                                         n.ranker = n.ranker,
          #                                                                         n.item = n.item)

          #update mu for period t to be used as lag for next period
          #require that this is consistent with the tree structure


          # mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
          #                                            weight.vec = rep(1, n.ranker*n.time),
          #                                            sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
          #                                            n.ranker = n.ranker*n.time,
          #                                            n.item = n.item,
          #                                            p.cov = p.cov+num_lags,
          #                                            para.expan = para.expan)


          # NOT REALLY NECESSARY TO UPDATE Z MATRIX WITHIN LOOP OVER T BUT KEEPING IT HERE ANYWAY
          # MAYBE CODE CAN BE MADE MORE EFFICIENT

          ### for check only
          # Z.mat = Z.mat/mean.para.update$theta

          Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

          for(t1 in 1:num_lags){
            init_Z_t0 <- rep(0, t1*n.item*n.ranker)
            # init_Z_t0 <- rnorm(t*n.item*n.ranker)

            Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

          }


          #update predictor matrix


        }#end of loop over t

        #end of seq_z_draws==1 code
        # }else{
        #
        #
        #   Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                             Z.mat = Z.mat,
        #                                             mu = mu,
        #                                             weight.vec = rep(1, n.ranker*n.time),
        #                                             n.ranker = n.ranker*n.time,
        #                                             n.item = n.item )
        #
        #   mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
        #                                              weight.vec = rep(1, n.ranker*n.time),
        #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
        #                                              n.ranker = n.ranker*n.time,
        #                                              n.item = n.item,
        #                                              p.cov = p.cov+num_lags,
        #                                              para.expan = para.expan)
        #
        #   ### for check only
        #   Z.mat = Z.mat/mean.para.update$theta
        #
        # }



      }else{
        #stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }
    } # end else statement checking number of rows of X.train





    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }


    Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat
    # Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test

    mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                               weight.vec = rep(1, n.ranker*n.time),
                                               sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                               n.ranker = n.ranker*n.time,
                                               n.item = n.item,
                                               p.cov = p.cov+num_lags,
                                               para.expan = para.expan)




    # create Z lag test matrix




    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( rep(alpha, n.ranker*n.time) + (Xmat.train) %*% beta )
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )

    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    }









    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta


    draw$mu_noZgamma[,iter] = mu_noZgamma
    draw$gamcoef[iter] = gamcoef


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }



    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }
      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      # temp_test_mat <- as.data.frame(temp_test_mat)
      # colnames(temp_test_mat) <- colnames(Xmat.test)


      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- rep(alpha, n.ranker) + as.matrix(temp_test_mat) %*% beta  #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){

          if(num_lags ==1){
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] ,
                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

          }else{
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

          }
        }

        # colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,iter] <- temp_mu_test
      mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )
      draw$mu_noZgamma_test[,iter] = mu_noZgamma_test

      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )
    # draw$mu_test[,iter] = mutest


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # # print iteration number
    # if(iter %% print.opt == 0){
    #   print(paste("Gibbs Iteration", iter))
    #   # print(c(sigma2.alpha, sigma2.beta))
    # }

  }
  return(draw)
}


#' Auto-regressive linear model for Bayesian Analysis of Rank-Order data with entities' Covariates. Full condtional z Sampler.
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARBayesRankCov_topk <- function(ranks_mat ,
                                    X.train = matrix(NA, nrow =dim(ranks_mat)[1], ncol = 0),
                                    X.test = matrix(NA, nrow =0, ncol = 0),
                                    tau2.alpha = 5^2,
                                    nu.alpha = 3,
                                    tau2.beta = 5^2,
                                    nu.beta = 3,
                                    n.item = dim(ranks_mat)[1],
                                    n.rankerbytime = dim(ranks_mat)[2],
                                    n.ranker,
                                    n.time,
                                    p.cov = ncol(X.train),
                                    iter.max = 5000,
                                    para.expan = TRUE,
                                    print.opt = 100,
                                    initial.list = NULL,
                                    n.trees = 50L,
                                    n.burn = 0L,
                                    n.samples = 1L,
                                    n.thin = 1L,
                                    n.chains = 1,
                                    n.threads = guessNumCores(),
                                    printEvery = 100L,
                                    printCutoffs = 0L,
                                    rngKind = "default",
                                    rngNormalKind = "default",
                                    rngSeed = NA_integer_,
                                    updateState = FALSE,
                                    num_lags = 1,
                                    diff_num_test_rankers = 0,
                                    num_test_periods = 0,
                                    keep_zmat = FALSE,
                                    noise_in_pred = 0,
                                    seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }
  if(num_lags >1){
    stop("Current implementation only allows for 1 lag of the latent outcome.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  length_mu <- 1

  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  # ranks_mat <- matrix(NA,
  #                     ncol = n.ranker*n.time,
  #                     nrow = n.item )
  #
  #
  # #n.item by n.item
  #
  # for(t in 1:n.time){
  #
  #   for(indiv in 1:n.ranker){
  #     pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]
  #
  #     # 1 corresponding to "highest rank" . i.e. highest utility ite,
  #     # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1
  #
  #     # 1 corresponding to "lowest rank". i.e. lowest utility item
  #
  #     up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
  #
  #
  #     ranks_mat[, (t-1)*n.ranker + indiv] <- up.order
  #
  #   }
  # }


  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(p.cov + num_lags, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    mu_noZgamma = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    gamcoef = rep(NA, iter.max),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(nrow(X.test) >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
    draw$mu_noZgamma_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }

  }




  ###### Initialize Values ############

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){

      tempsort <- sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE )

      Z.mat[ tempsort$ix , j] <-
        qnorm(  tempsort$x   /(n.item+1)) +
        rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(nrow(X.test) >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )


      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")





        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <-  cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }




    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, p.cov + num_lags)
    mu = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train) %*% beta )
    mu_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test) %*% beta )


    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )
    mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta

    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")



    # draw$Z.mat[,,1] <- Z.mat
    # draw$alpha[,1] = alpha
    # draw$beta[,1] = beta
    # draw$mu[,1] <- mu
    # draw$sigma2.alpha[1] = sigma2.alpha
    # draw$sigma2.beta[1] = sigma2.beta


    ## store initial value
    if(keep_zmat==TRUE){
      draw$Z.mat[,,1] = Z.mat
    }


    draw$alpha[,1] = alpha
    draw$beta[,1] = beta
    draw$mu[,1] = mu
    draw$mu_test[,1] = mu_test
    draw$sigma2.alpha[1] = sigma2.alpha
    draw$sigma2.beta[1] = sigma2.beta

    draw$mu_noZgamma[,1] = mu_noZgamma
    draw$mu_noZgamma_test[,1] = mu_noZgamma_test
    draw$gamcoef[1] = gamcoef




  }# ending  if statement if is null initial list




  if( nrow(X.test) > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA,
                                nrow = n.item*n.ranker,
                                ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- rep(alpha, n.ranker) + temp_test_mat %*% beta   #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] ,
                                      as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

        }else{
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                      as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ############# Begin Gibbs sampler#########################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      # Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
      #                                      weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){

        # if(seq_z_draws==1){
        for(t in 1:n.time){




          # update mu for period t-1

          #Zlag always zero in period t==0

          # Z in period 0 is unaffected since set to zero by default
          #therefore mu unaffected in period 0 (can draw anyway for now)

          Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat


          if(t==1){
            # mu[1:(n.item*n.ranker)] <- (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta ))  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])

            for(indiv in 1:n.ranker){

              tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]


              # tempmu <- mu[1:(n.item*n.ranker)]
              # tempmu_noZgamma <- mu_noZgamma[1:(n.item*n.ranker)]
              #
              # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]


              tempmu <- mu[(t-1)*(n.item*n.ranker) +
                             n.item*(indiv-1) +
                             1:(n.item)]

              tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                               n.item*(indiv-1) +
                                               1:(n.item)]


              tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                                 n.item*(indiv-1) +
                                 1:(n.item)]

              tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                   n.item*(indiv-1) +
                                                   1:(n.item)]

              tempz <- Z.mat[,(t-1)*n.ranker + indiv]

              tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]

              # draw item by item

              # calculate mean
              # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
              tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma  )/((gamcoef^2)*(1+gamcoef^2)+1)

              # calculate variance
              tempvar <- (gamcoef^2)*(1+gamcoef^2)+1

              for(item_ind in 1:n.item){
                # temp_z_i <- tempz[item_ind]
                temprank_i <- tempranks[item_ind]

                # find bounds for truncated normal distribution
                # need observed ranks for this
                if(temprank_i==1){
                  templower <- -Inf
                }else{
                  templower <- max(tempz[tempranks < temprank_i])
                }

                if(temprank_i==n.item){
                  tempupper <- Inf
                }else{
                  tempupper <- min(tempz[tempranks > temprank_i])
                }
                # # calculate mean
                # # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                # tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1[item_ind]-tempmu_noZgamma_tp1[item_ind]) +tempmu_noZgamma[item_ind]  )/((gamcoef^2)*(1+gamcoef^2)+1)
                #
                # # calculate variance
                # tempvar <- (gamcoef^2)*(1+gamcoef^2)+1


                temp_z_i <- rtruncnorm(n = 1,
                                       a = templower,
                                       b = tempupper,
                                       mean = tempmean[item_ind],
                                       sd = tempvar)

                tempz[item_ind] <- temp_z_i
                Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                # Is it then necessary to update z_tm1 and z_tm1*gamma in mu calcalcutions for draw of z in next period (t=2)?
                # Check also ARROBART code for this
                # Z.mat updated, therefore z_tm1 will be the updated values in next iteration over t
                # therefore all is fine as long as use noZgamma mu values

              }
            }

          }else{
            if(t==n.time){
              # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])
              for(indiv in 1:n.ranker){
                tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

                # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

                tempmu <- mu[(t-1)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

                tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

                tempz <- Z.mat[,(t-1)*n.ranker + indiv]

                # tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
                tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

                # draw item by item

                # calculate mean
                # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                tempmean <- tempmu_noZgamma + gamcoef*tempz_tm1

                # calculate variance
                tempvar <- 1

                for(item_ind in 1:n.item){
                  # temp_z_i <- tempz[item_ind]
                  temprank_i <- tempranks[item_ind]

                  # find bounds for truncated normal distribution
                  # need observed ranks for this
                  if(temprank_i==1){
                    templower <- -Inf
                  }else{
                    templower <- max(tempz[tempranks < temprank_i])
                  }

                  if(temprank_i==n.item){
                    tempupper <- Inf
                  }else{
                    tempupper <- min(tempz[tempranks > temprank_i])
                  }

                  temp_z_i <- rtruncnorm(n = 1,
                                         a = templower,
                                         b = tempupper,
                                         mean = tempmean[item_ind],
                                         sd = tempvar)

                  tempz[item_ind] <- temp_z_i
                  Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                }

              } # end loop over individuals
            }else{
              # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

              for(indiv in 1:n.ranker){
                tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

                # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

                tempmu <- mu[(t-1)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

                tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

                tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                                   n.item*(indiv-1) +
                                   1:(n.item)]

                tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                     n.item*(indiv-1) +
                                                     1:(n.item)]

                tempz <- Z.mat[,(t-1)*n.ranker + indiv]

                tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
                tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

                # draw item by item

                # calculate mean
                # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                tempmean <- (  gamcoef*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma + gamcoef*tempz_tm1 )/(1+gamcoef^2)

                # calculate variance
                tempvar <- 1+gamcoef^2

                for(item_ind in 1:n.item){
                  # temp_z_i <- tempz[item_ind]
                  temprank_i <- tempranks[item_ind]

                  # find bounds for truncated normal distribution
                  # need observed ranks for this
                  if(temprank_i==1){
                    templower <- -Inf
                  }else{
                    templower <- max(tempz[tempranks < temprank_i])
                  }

                  if(temprank_i==n.item){
                    tempupper <- Inf
                  }else{
                    tempupper <- min(tempz[tempranks > temprank_i])
                  }

                  temp_z_i <- rtruncnorm(n = 1,
                                         a = templower,
                                         b = tempupper,
                                         mean = tempmean[item_ind],
                                         sd = tempvar)

                  tempz[item_ind] <- temp_z_i
                  Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                }


              } # end loop over individuals

            } #end else statement (for t value not 1 or n.time)
          } # end else statement (for t value not 1)


          # Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
          #                                                                         Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
          #                                                                         mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
          #                                                                         weight.vec = rep(1, n.ranker),
          #                                                                         n.ranker = n.ranker,
          #                                                                         n.item = n.item)

          #update mu for period t to be used as lag for next period
          #require that this is consistent with the tree structure


          # mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
          #                                            weight.vec = rep(1, n.ranker*n.time),
          #                                            sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
          #                                            n.ranker = n.ranker*n.time,
          #                                            n.item = n.item,
          #                                            p.cov = p.cov+num_lags,
          #                                            para.expan = para.expan)


          # NOT REALLY NECESSARY TO UPDATE Z MATRIX WITHIN LOOP OVER T BUT KEEPING IT HERE ANYWAY
          # MAYBE CODE CAN BE MADE MORE EFFICIENT

          ### for check only
          # Z.mat = Z.mat/mean.para.update$theta

          Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

          for(t1 in 1:num_lags){
            init_Z_t0 <- rep(0, t1*n.item*n.ranker)
            # init_Z_t0 <- rnorm(t*n.item*n.ranker)

            Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

          }


          #update predictor matrix


        }#end of loop over t

        #end of seq_z_draws==1 code
        # }else{
        #
        #
        #   Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                             Z.mat = Z.mat,
        #                                             mu = mu,
        #                                             weight.vec = rep(1, n.ranker*n.time),
        #                                             n.ranker = n.ranker*n.time,
        #                                             n.item = n.item )
        #
        #   mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
        #                                              weight.vec = rep(1, n.ranker*n.time),
        #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
        #                                              n.ranker = n.ranker*n.time,
        #                                              n.item = n.item,
        #                                              p.cov = p.cov+num_lags,
        #                                              para.expan = para.expan)
        #
        #   ### for check only
        #   Z.mat = Z.mat/mean.para.update$theta
        #
        # }



      }else{
        #stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }
    } # end else statement checking number of rows of X.train





    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }


    Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat
    # Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test

    mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                               weight.vec = rep(1, n.ranker*n.time),
                                               sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                               n.ranker = n.ranker*n.time,
                                               n.item = n.item,
                                               p.cov = p.cov+num_lags,
                                               para.expan = para.expan)




    # create Z lag test matrix




    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( rep(alpha, n.ranker*n.time) + (Xmat.train) %*% beta )
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )

    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    }









    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta


    draw$mu_noZgamma[,iter] = mu_noZgamma
    draw$gamcoef[iter] = gamcoef


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }



    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }
      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      # temp_test_mat <- as.data.frame(temp_test_mat)
      # colnames(temp_test_mat) <- colnames(Xmat.test)


      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- rep(alpha, n.ranker) + as.matrix(temp_test_mat) %*% beta  #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){

          if(num_lags ==1){
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] ,
                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

          }else{
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

          }
        }

        # colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,iter] <- temp_mu_test
      mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )
      draw$mu_noZgamma_test[,iter] = mu_noZgamma_test

      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )
    # draw$mu_test[,iter] = mutest


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # # print iteration number
    # if(iter %% print.opt == 0){
    #   print(paste("Gibbs Iteration", iter))
    #   # print(c(sigma2.alpha, sigma2.beta))
    # }

  }
  return(draw)
}





#' Auto-regressive linear model for Bayesian Analysis of Rank-Order data with entities' Covariates. Full condtional z Sampler.
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARBayesRankCov_fullcond <- function(pair.comp.ten,
                                    X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                    X.test = matrix(NA, nrow =0, ncol = 0),
                                    tau2.alpha = 5^2,
                                    nu.alpha = 3,
                                    tau2.beta = 5^2,
                                    nu.beta = 3,
                                    n.item = dim(pair.comp.ten)[1],
                                    n.rankerbytime = dim(pair.comp.ten)[3],
                                    n.ranker,
                                    n.time,
                                    p.cov = ncol(X.train),
                                    iter.max = 5000,
                                    para.expan = TRUE,
                                    print.opt = 100,
                                    initial.list = NULL,
                                    n.trees = 50L,
                                    n.burn = 0L,
                                    n.samples = 1L,
                                    n.thin = 1L,
                                    n.chains = 1,
                                    n.threads = guessNumCores(),
                                    printEvery = 100L,
                                    printCutoffs = 0L,
                                    rngKind = "default",
                                    rngNormalKind = "default",
                                    rngSeed = NA_integer_,
                                    updateState = FALSE,
                                    num_lags = 1,
                                    diff_num_test_rankers = 0,
                                    num_test_periods = 0,
                                    keep_zmat = FALSE,
                                    noise_in_pred = 0,
                                    seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }
  if(num_lags >1){
    stop("Current implementation only allows for 1 lag of the latent outcome.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  length_mu <- 1

  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }


  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(p.cov + num_lags, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    mu_noZgamma = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    gamcoef = rep(NA, iter.max),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(nrow(X.test) >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
    draw$mu_noZgamma_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }

  }




  ###### Initialize Values ############

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(nrow(X.test) >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )


      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")





        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <-  cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }




    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, p.cov + num_lags)
    mu = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train) %*% beta )
    mu_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test) %*% beta )


    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )
    mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta

    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")



    # draw$Z.mat[,,1] <- Z.mat
    # draw$alpha[,1] = alpha
    # draw$beta[,1] = beta
    # draw$mu[,1] <- mu
    # draw$sigma2.alpha[1] = sigma2.alpha
    # draw$sigma2.beta[1] = sigma2.beta


    ## store initial value
    if(keep_zmat==TRUE){
      draw$Z.mat[,,1] = Z.mat
    }


    draw$alpha[,1] = alpha
    draw$beta[,1] = beta
    draw$mu[,1] = mu
    draw$mu_test[,1] = mu_test
    draw$sigma2.alpha[1] = sigma2.alpha
    draw$sigma2.beta[1] = sigma2.beta

    draw$mu_noZgamma[,1] = mu_noZgamma
    draw$mu_noZgamma_test[,1] = mu_noZgamma_test
    draw$gamcoef[1] = gamcoef




  }# ending  if statement if is null initial list




  if( nrow(X.test) > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA,
                                nrow = n.item*n.ranker,
                                ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- rep(alpha, n.ranker) + temp_test_mat %*% beta   #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] ,
                                      as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

        }else{
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                      as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ############# Begin Gibbs sampler#########################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
                                           weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){

        # if(seq_z_draws==1){
        for(t in 1:n.time){




          # update mu for period t-1

          #Zlag always zero in period t==0

          # Z in period 0 is unaffected since set to zero by default
          #therefore mu unaffected in period 0 (can draw anyway for now)

          Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat


          if(t==1){
            # mu[1:(n.item*n.ranker)] <- (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta ))  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])

            for(indiv in 1:n.ranker){

              tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]


              # tempmu <- mu[1:(n.item*n.ranker)]
              # tempmu_noZgamma <- mu_noZgamma[1:(n.item*n.ranker)]
              #
              # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]


              tempmu <- mu[(t-1)*(n.item*n.ranker) +
                             n.item*(indiv-1) +
                             1:(n.item)]

              tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                               n.item*(indiv-1) +
                                               1:(n.item)]


              tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                                 n.item*(indiv-1) +
                                 1:(n.item)]

              tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                   n.item*(indiv-1) +
                                                   1:(n.item)]

              tempz <- Z.mat[,(t-1)*n.ranker + indiv]

              tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]

              # draw item by item

              # calculate mean
              # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
              tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma  )/((gamcoef^2)*(1+gamcoef^2)+1)

              # calculate variance
              tempvar <- (gamcoef^2)*(1+gamcoef^2)+1

              for(item_ind in 1:n.item){
                # temp_z_i <- tempz[item_ind]
                temprank_i <- tempranks[item_ind]

                # find bounds for truncated normal distribution
                # need observed ranks for this
                if(temprank_i==1){
                  templower <- -Inf
                }else{
                  templower <- max(tempz[tempranks < temprank_i])
                }

                if(temprank_i==n.item){
                  tempupper <- Inf
                }else{
                  tempupper <- min(tempz[tempranks > temprank_i])
                }
                # # calculate mean
                # # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                # tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1[item_ind]-tempmu_noZgamma_tp1[item_ind]) +tempmu_noZgamma[item_ind]  )/((gamcoef^2)*(1+gamcoef^2)+1)
                #
                # # calculate variance
                # tempvar <- (gamcoef^2)*(1+gamcoef^2)+1


                temp_z_i <- rtruncnorm(n = 1,
                                       a = templower,
                                       b = tempupper,
                                       mean = tempmean[item_ind],
                                       sd = tempvar)

                tempz[item_ind] <- temp_z_i
                Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                # Is it then necessary to update z_tm1 and z_tm1*gamma in mu calcalcutions for draw of z in next period (t=2)?
                # Check also ARROBART code for this
                # Z.mat updated, therefore z_tm1 will be the updated values in next iteration over t
                # therefore all is fine as long as use noZgamma mu values

              }
            }

          }else{
            if(t==n.time){
              # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])
              for(indiv in 1:n.ranker){
                tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

                # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

                tempmu <- mu[(t-1)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

                tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

                tempz <- Z.mat[,(t-1)*n.ranker + indiv]

                # tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
                tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

                # draw item by item

                # calculate mean
                # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                tempmean <- tempmu_noZgamma + gamcoef*tempz_tm1

                # calculate variance
                tempvar <- 1

                for(item_ind in 1:n.item){
                  # temp_z_i <- tempz[item_ind]
                  temprank_i <- tempranks[item_ind]

                  # find bounds for truncated normal distribution
                  # need observed ranks for this
                  if(temprank_i==1){
                    templower <- -Inf
                  }else{
                    templower <- max(tempz[tempranks < temprank_i])
                  }

                  if(temprank_i==n.item){
                    tempupper <- Inf
                  }else{
                    tempupper <- min(tempz[tempranks > temprank_i])
                  }

                  temp_z_i <- rtruncnorm(n = 1,
                                         a = templower,
                                         b = tempupper,
                                         mean = tempmean[item_ind],
                                         sd = tempvar)

                  tempz[item_ind] <- temp_z_i
                  Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                }

              } # end loop over individuals
            }else{
              # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

              for(indiv in 1:n.ranker){
                tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

                # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
                # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

                tempmu <- mu[(t-1)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

                tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

                tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                                   n.item*(indiv-1) +
                                   1:(n.item)]

                tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                     n.item*(indiv-1) +
                                                     1:(n.item)]

                tempz <- Z.mat[,(t-1)*n.ranker + indiv]

                tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
                tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

                # draw item by item

                # calculate mean
                # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
                tempmean <- (  gamcoef*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma + gamcoef*tempz_tm1 )/(1+gamcoef^2)

                # calculate variance
                tempvar <- 1+gamcoef^2

                for(item_ind in 1:n.item){
                  # temp_z_i <- tempz[item_ind]
                  temprank_i <- tempranks[item_ind]

                  # find bounds for truncated normal distribution
                  # need observed ranks for this
                  if(temprank_i==1){
                    templower <- -Inf
                  }else{
                    templower <- max(tempz[tempranks < temprank_i])
                  }

                  if(temprank_i==n.item){
                    tempupper <- Inf
                  }else{
                    tempupper <- min(tempz[tempranks > temprank_i])
                  }

                  temp_z_i <- rtruncnorm(n = 1,
                                         a = templower,
                                         b = tempupper,
                                         mean = tempmean[item_ind],
                                         sd = tempvar)

                  tempz[item_ind] <- temp_z_i
                  Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

                }


              } # end loop over individuals

            } #end else statement (for t value not 1 or n.time)
          } # end else statement (for t value not 1)


          # Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
          #                                                                         Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
          #                                                                         mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
          #                                                                         weight.vec = rep(1, n.ranker),
          #                                                                         n.ranker = n.ranker,
          #                                                                         n.item = n.item)

          #update mu for period t to be used as lag for next period
          #require that this is consistent with the tree structure


          # mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
          #                                            weight.vec = rep(1, n.ranker*n.time),
          #                                            sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
          #                                            n.ranker = n.ranker*n.time,
          #                                            n.item = n.item,
          #                                            p.cov = p.cov+num_lags,
          #                                            para.expan = para.expan)


          # NOT REALLY NECESSARY TO UPDATE Z MATRIX WITHIN LOOP OVER T BUT KEEPING IT HERE ANYWAY
          # MAYBE CODE CAN BE MADE MORE EFFICIENT

          ### for check only
          # Z.mat = Z.mat/mean.para.update$theta

          Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

          for(t1 in 1:num_lags){
            init_Z_t0 <- rep(0, t1*n.item*n.ranker)
            # init_Z_t0 <- rnorm(t*n.item*n.ranker)

            Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

          }


          #update predictor matrix


        }#end of loop over t

        #end of seq_z_draws==1 code
        # }else{
        #
        #
        #   Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
        #                                             Z.mat = Z.mat,
        #                                             mu = mu,
        #                                             weight.vec = rep(1, n.ranker*n.time),
        #                                             n.ranker = n.ranker*n.time,
        #                                             n.item = n.item )
        #
        #   mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
        #                                              weight.vec = rep(1, n.ranker*n.time),
        #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
        #                                              n.ranker = n.ranker*n.time,
        #                                              n.item = n.item,
        #                                              p.cov = p.cov+num_lags,
        #                                              para.expan = para.expan)
        #
        #   ### for check only
        #   Z.mat = Z.mat/mean.para.update$theta
        #
        # }



      }else{
        #stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }
    } # end else statement checking number of rows of X.train





    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }


    Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat
    # Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test

    mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                               weight.vec = rep(1, n.ranker*n.time),
                                               sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                               n.ranker = n.ranker*n.time,
                                               n.item = n.item,
                                               p.cov = p.cov+num_lags,
                                               para.expan = para.expan)




    # create Z lag test matrix




    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( rep(alpha, n.ranker*n.time) + (Xmat.train) %*% beta )
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )

    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    }









    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta


    draw$mu_noZgamma[,iter] = mu_noZgamma
    draw$gamcoef[iter] = gamcoef


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }



    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }
      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      # temp_test_mat <- as.data.frame(temp_test_mat)
      # colnames(temp_test_mat) <- colnames(Xmat.test)


      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- rep(alpha, n.ranker) + as.matrix(temp_test_mat) %*% beta  #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){

          if(num_lags ==1){
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] ,
                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

          }else{
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

          }
        }

        # colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,iter] <- temp_mu_test
      mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)] )
      draw$mu_noZgamma_test[,iter] = mu_noZgamma_test

      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )
    # draw$mu_test[,iter] = mutest


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # # print iteration number
    # if(iter %% print.opt == 0){
    #   print(paste("Gibbs Iteration", iter))
    #   # print(c(sigma2.alpha, sigma2.beta))
    # }

  }
  return(draw)
}





#' Auto-regressive linear model for Bayesian Analysis of Rank-Order data with entities' Covariates
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARBayesRankCovSimpInds <- function(pair.comp.ten,
                                   X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                   X.test = matrix(NA, nrow =0, ncol = 0),
                                   tau2.alpha = 5^2,
                                   nu.alpha = 3,
                                   tau2.beta = 5^2,
                                   nu.beta = 3,
                                   n.item = dim(pair.comp.ten)[1],
                                   n.rankerbytime = dim(pair.comp.ten)[3],
                                   n.ranker,
                                   n.time,
                                   p.cov = ncol(X.train),
                                   iter.max = 5000,
                                   para.expan = TRUE,
                                   print.opt = 100,
                                   initial.list = NULL,
                                   n.trees = 50L,
                                   n.burn = 0L,
                                   n.samples = 1L,
                                   n.thin = 1L,
                                   n.chains = 1,
                                   n.threads = guessNumCores(),
                                   printEvery = 100L,
                                   printCutoffs = 0L,
                                   rngKind = "default",
                                   rngNormalKind = "default",
                                   rngSeed = NA_integer_,
                                   updateState = FALSE,
                                   num_lags = 1,
                                   diff_num_test_rankers = 0,
                                   num_test_periods = 0,
                                   keep_zmat = FALSE,
                                   noise_in_pred = 0,
                                   seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  length_mu <- 1

  if(nrow(X.train)==n.item){
    stop("nrow(X.train) not equal to n.item*n.rankerbytime")

    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.rankerbytime){
      length_mu <- n.item*n.rankerbytime
    }else{
      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- 1


  if(nrow(X.test) >0 ){


    if(diff_num_test_rankers==1){
      stop("Code not yet written for test data with different rankers to training data.")
    }else{

      if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
        stop("nrow(X.test) != n.item*n.ranker*num_test_periods")

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }


    }



    #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.



    # if(diff_num_test_rankers==1){
    #   length_mu_test <- nrow(X.test)
    # }else{
    #   if(nrow(X.train)==n.item){
    #     length_mu_test <- n.item*n.ranker
    #
    #   }else{
    #     length_mu_test <- nrow(X.test)
    #
    #   }
    # }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(p.cov + num_lags, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(nrow(X.test) >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }

  }






  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(nrow(X.test) >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){

      stop("nrow(X.train) not equal to n.item*n.rankerbytime")
      #this part of the code needs to be rewritten if code
      #edited to allow for nrow(X.train)==n.item
      #currently the dimensions of the traiinng and test matrices defined below do not agree with this option

      Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
                                                                                  ncol =  ncol(X.train) + num_lags ,
                                                                                  byrow = TRUE ))
      )


      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
        #so as.vector is NOT applied here to Zlag.mat.test.

        Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
                                                                 ncol =  ncol(X.test) , byrow = TRUE ) )
        )
        #colnames(Xmat.test) <- c("x","z","w")





        #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.


      }
    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){
        Xmat.train <-  cbind(Zlag.mat, X.train)

        # print(colnames(Xmat.train))

        if(nrow(X.test)>0 ){
          Xmat.test  <- cbind( Zlag.mat.test, X.test )

          #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }




    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, p.cov + num_lags)
    mu = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train) %*% beta )
    mu_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test) %*% beta )

    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta

    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")



    # draw$Z.mat[,,1] <- Z.mat
    # draw$alpha[,1] = alpha
    # draw$beta[,1] = beta
    # draw$mu[,1] <- mu
    # draw$sigma2.alpha[1] = sigma2.alpha
    # draw$sigma2.beta[1] = sigma2.beta


    ## store initial value
    if(keep_zmat==TRUE){
      draw$Z.mat[,,1] = Z.mat
    }


    draw$alpha[,1] = alpha
    draw$beta[,1] = beta
    draw$mu[,1] = mu
    draw$mu_test[,1] = mu_test
    draw$sigma2.alpha[1] = sigma2.alpha
    draw$sigma2.beta[1] = sigma2.beta


  }# ending  if statement if is null initial list




  if( nrow(X.test) > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA,
                                nrow = n.item*n.ranker,
                                ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- rep(alpha, n.ranker) + temp_test_mat %*% beta   #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] ,
                                      as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

        }else{
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                      as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ############ Begin Gibbs sampler####################
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      stop("nrow(X.train) not equal to n.item*n.ranker*n.time")

      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
                                           weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker*n.time){

        if(seq_z_draws==1){
          for(t in 1:n.time){

            # update mu for period t-1

            #Zlag always zero in period t==0

            # Z in period 0 is unaffected since set to zero by default
            #therefore mu unaffected in period 0 (can draw anyway for now)

            Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat


            if(t==1){

              # print("t = ")
              # print(t)
              # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
              # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])

              mu[1:(n.item*n.ranker)] <- (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta ))  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])
              # Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
              #                                                                             ncol =  ncol(X.train) + num_lags ,
              #                                                                             byrow = TRUE )))
              # mu[1:(n.item*n.ranker)] <- sampler$predict(Xmat.train[1:(n.item*n.ranker),])

            }else{
              mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

              # Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
              #                                                                             ncol =  ncol(X.train) + num_lags ,
              #                                                                             byrow = TRUE )))
              # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(Xmat.train[1:(n.item*n.ranker),])
            }



            Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
                                                                                    Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
                                                                                    mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
                                                                                    weight.vec = rep(1, n.ranker),
                                                                                    n.ranker = n.ranker,
                                                                                    n.item = n.item)

            #update mu for period t to be used as lag for next period
            #require that this is consistent with the tree structure


            mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                                       weight.vec = rep(1, n.ranker*n.time),
                                                       sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                                       n.ranker = n.ranker*n.time,
                                                       n.item = n.item,
                                                       p.cov = p.cov+num_lags,
                                                       para.expan = para.expan)

            ### for check only
            Z.mat = Z.mat/mean.para.update$theta

            Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

            for(t1 in 1:num_lags){
              init_Z_t0 <- rep(0, t1*n.item*n.ranker)
              # init_Z_t0 <- rnorm(t*n.item*n.ranker)

              Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

            }


            #update predictor matrix


          }#end of loop over t

          #end of seq_z_draws==1 code
        }else{


          Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
                                                    Z.mat = Z.mat,
                                                    mu = mu,
                                                    weight.vec = rep(1, n.ranker*n.time),
                                                    n.ranker = n.ranker*n.time,
                                                    n.item = n.item )

          mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                                     weight.vec = rep(1, n.ranker*n.time),
                                                     sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                                     n.ranker = n.ranker*n.time,
                                                     n.item = n.item,
                                                     p.cov = p.cov+num_lags,
                                                     para.expan = para.expan)

          ### for check only
          Z.mat = Z.mat/mean.para.update$theta

        }



      }else{
        #stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
      }
    }





    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }









    # create Z lag test matrix


    Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat
    # Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test

    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( rep(alpha, n.ranker*n.time) + (Xmat.train) %*% beta )
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )

    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    }









    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }



    if( nrow(X.test) > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }
      }

      temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
                                                                           (num_lags+1):ncol(Xmat.test)])

      # temp_test_mat <- as.data.frame(temp_test_mat)
      # colnames(temp_test_mat) <- colnames(Xmat.test)


      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- rep(alpha, n.ranker) + as.matrix(temp_test_mat) %*% beta  #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){

          if(num_lags ==1){
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] ,
                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

          }else{
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,
                                      as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ))

          }
        }

        # colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(nrow(X.test) >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )
    # draw$mu_test[,iter] = mutest


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # # print iteration number
    # if(iter %% print.opt == 0){
    #   print(paste("Gibbs Iteration", iter))
    #   # print(c(sigma2.alpha, sigma2.beta))
    # }

  }
  return(draw)
}




#' Auto-regressive linear model for Bayesian Analysis of Rank-Order data with entities' Covariates. Full conditional z sampler.
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARBayesRank_NoCovars_partial <- function(pair.comp.ten,
                                         # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                         # X.test = matrix(NA, nrow =0, ncol = 0),
                                         tau2.alpha = 5^2,
                                         nu.alpha = 3,
                                         tau2.beta = 5^2,
                                         nu.beta = 3,
                                         n.item = dim(pair.comp.ten)[1],
                                         n.rankerbytime = dim(pair.comp.ten)[3],
                                         n.ranker,
                                         n.time,
                                      # p.cov = ncol(X.train),
                                      iter.max = 5000,
                                      para.expan = TRUE,
                                      print.opt = 100,
                                      initial.list = NULL,
                                      n.trees = 50L,
                                      n.burn = 0L,
                                      n.samples = 1L,
                                      n.thin = 1L,
                                      n.chains = 1,
                                      n.threads = guessNumCores(),
                                      printEvery = 100L,
                                      printCutoffs = 0L,
                                      rngKind = "default",
                                      rngNormalKind = "default",
                                      rngSeed = NA_integer_,
                                      updateState = FALSE,
                                      num_lags = 1,
                                      diff_num_test_rankers = 0,
                                      num_test_periods = 0,
                                      keep_zmat = FALSE,
                                      noise_in_pred = 0,
                                      seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }
  if(num_lags >1){
    stop("Current implementation only allows for 1 lag of the latent outcome.")
  }
  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime
  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  length_mu_test <- 1
  num_test_rankers <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #       num_test_rankers <- length_mu_test/n.item
  #       if(num_test_rankers%%1 !=0){
  #         print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
  #       }
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  length_mu_test <- n.item*n.ranker*num_test_periods
  num_test_rankers <- length_mu_test/n.item
  if(num_test_rankers%%1 !=0){
    print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
  }


  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(num_lags, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    mu_noZgamma = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    gamcoef = rep(NA, iter.max),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(num_test_periods >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
    draw$mu_noZgamma_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }

  }




  ####### initialize values #############

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      # tempsort <- sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE )

      # Z.mat[ tempsort$ix , j] <-
      #   qnorm(  tempsort$x   /(n.item+1)) +
      #   rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(num_test_periods >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    Xmat.train <- Zlag.mat

    # print(colnames(Xmat.train))

    if(nrow(Zlag.mat.test)>0 ){
      Xmat.test  <- Zlag.mat.test

      #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

    }

    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #
    #
    #
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #
    #   }
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <-  cbind(Zlag.mat, X.train)
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- cbind( Zlag.mat.test, X.test )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }




    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, num_lags)
    mu = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train) %*% beta )
    mu_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test) %*% beta )


    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) #+ as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )
    mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) #+ as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    sigma2.beta = tau2.beta

    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")



    # draw$Z.mat[,,1] <- Z.mat
    # draw$alpha[,1] = alpha
    # draw$beta[,1] = beta
    # draw$mu[,1] <- mu
    # draw$sigma2.alpha[1] = sigma2.alpha
    # draw$sigma2.beta[1] = sigma2.beta


    ## store initial value
    if(keep_zmat==TRUE){
      draw$Z.mat[,,1] = Z.mat
    }


    draw$alpha[,1] = alpha
    draw$beta[,1] = beta
    draw$mu[,1] = mu
    draw$mu_test[,1] = mu_test
    draw$sigma2.alpha[1] = sigma2.alpha
    draw$sigma2.beta[1] = sigma2.beta

    draw$mu_noZgamma[,1] = mu_noZgamma
    draw$mu_noZgamma_test[,1] = mu_noZgamma_test
    draw$gamcoef[1] = gamcoef

  }# ending  if statement if is null initial list




  if( num_test_periods > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA,
                                nrow = n.item*n.ranker,
                                ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- rep(alpha, n.ranker) + temp_test_mat %*% beta   #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] #,
                                      # as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
          )

        }else{
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] #,
                                      # as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
          )

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(num_test_periods >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ######### Begin Gibbs sampler ##############
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    # if(nrow(X.train)==n.item){
    #   stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #   Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                        weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #   if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){

    # if(seq_z_draws==1){
    for(t in 1:n.time){




      # update mu for period t-1

      #Zlag always zero in period t==0

      # Z in period 0 is unaffected since set to zero by default
      #therefore mu unaffected in period 0 (can draw anyway for now)

      Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat


      if(t==1){
        # mu[1:(n.item*n.ranker)] <- (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta ))  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])

        for(indiv in 1:n.ranker){

          # tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

          temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

          # tempmu <- mu[1:(n.item*n.ranker)]
          # tempmu_noZgamma <- mu_noZgamma[1:(n.item*n.ranker)]
          #
          # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]


          tempmu <- mu[(t-1)*(n.item*n.ranker) +
                         n.item*(indiv-1) +
                         1:(n.item)]

          tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                           n.item*(indiv-1) +
                                           1:(n.item)]


          tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                             n.item*(indiv-1) +
                             1:(n.item)]

          tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                               n.item*(indiv-1) +
                                               1:(n.item)]

          tempz <- Z.mat[,(t-1)*n.ranker + indiv]

          tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]

          # draw item by item

          # calculate mean
          # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
          tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma  )/((gamcoef^2)*(1+gamcoef^2)+1)

          # calculate variance
          tempvar <- (gamcoef^2)*(1+gamcoef^2)+1

          for(item_ind in 1:n.item){

            set1 = which( temppaircomps[item_ind, ] == 1)
            set0 = which( temppaircomps[item_ind, ] == 0)

            if(length(set1) > 0){
              tempupper = min(tempz[set1])
            }else{
              tempupper = Inf
            }

            if(length(set0) > 0){
              templower = max(tempz[set0])
            }else{
              templower = -Inf
            }



            # # temp_z_i <- tempz[item_ind]
            # temprank_i <- tempranks[item_ind]
            #
            # # find bounds for truncated normal distribution
            # # need observed ranks for this
            # if(temprank_i==1){
            #   templower <- -Inf
            # }else{
            #   templower <- max(tempz[tempranks < temprank_i])
            # }
            #
            # if(temprank_i==n.item){
            #   tempupper <- Inf
            # }else{
            #   tempupper <- min(tempz[tempranks > temprank_i])
            # }




            # # calculate mean
            # # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            # tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1[item_ind]-tempmu_noZgamma_tp1[item_ind]) +tempmu_noZgamma[item_ind]  )/((gamcoef^2)*(1+gamcoef^2)+1)
            #
            # # calculate variance
            # tempvar <- (gamcoef^2)*(1+gamcoef^2)+1


            temp_z_i <- rtruncnorm(n = 1,
                                   a = templower,
                                   b = tempupper,
                                   mean = tempmean[item_ind],
                                   sd = tempvar)

            tempz[item_ind] <- temp_z_i
            Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            # Is it then necessary to update z_tm1 and z_tm1*gamma in mu calcalcutions for draw of z in next period (t=2)?
            # Check also ARROBART code for this
            # Z.mat updated, therefore z_tm1 will be the updated values in next iteration over t
            # therefore all is fine as long as use noZgamma mu values

          }
        }

      }else{
        if(t==n.time){
          # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])
          for(indiv in 1:n.ranker){
            # tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]


            temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]


            # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

            tempmu <- mu[(t-1)*(n.item*n.ranker) +
                           n.item*(indiv-1) +
                           1:(n.item)]

            tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                             n.item*(indiv-1) +
                                             1:(n.item)]

            tempz <- Z.mat[,(t-1)*n.ranker + indiv]

            # tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
            tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

            # draw item by item

            # calculate mean
            # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            tempmean <- tempmu_noZgamma + gamcoef*tempz_tm1

            # calculate variance
            tempvar <- 1

            for(item_ind in 1:n.item){


              set1 = which( temppaircomps[item_ind, ] == 1)
              set0 = which( temppaircomps[item_ind, ] == 0)

              if(length(set1) > 0){
                tempupper = min(tempz[set1])
              }else{
                tempupper = Inf
              }

              if(length(set0) > 0){
                templower = max(tempz[set0])
              }else{
                templower = -Inf
              }


              # # temp_z_i <- tempz[item_ind]
              # temprank_i <- tempranks[item_ind]
              #
              # # find bounds for truncated normal distribution
              # # need observed ranks for this
              # if(temprank_i==1){
              #   templower <- -Inf
              # }else{
              #   templower <- max(tempz[tempranks < temprank_i])
              # }
              #
              # if(temprank_i==n.item){
              #   tempupper <- Inf
              # }else{
              #   tempupper <- min(tempz[tempranks > temprank_i])
              # }

              temp_z_i <- rtruncnorm(n = 1,
                                     a = templower,
                                     b = tempupper,
                                     mean = tempmean[item_ind],
                                     sd = tempvar)

              tempz[item_ind] <- temp_z_i
              Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            }

          } # end loop over individuals
        }else{
          # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

          for(indiv in 1:n.ranker){
            # tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]
            temppaircomps <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

            # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

            tempmu <- mu[(t-1)*(n.item*n.ranker) +
                           n.item*(indiv-1) +
                           1:(n.item)]

            tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                             n.item*(indiv-1) +
                                             1:(n.item)]

            tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

            tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

            tempz <- Z.mat[,(t-1)*n.ranker + indiv]

            tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
            tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

            # draw item by item

            # calculate mean
            # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            tempmean <- (  gamcoef*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma + gamcoef*tempz_tm1 )/(1+gamcoef^2)

            # calculate variance
            tempvar <- 1+gamcoef^2

            for(item_ind in 1:n.item){

              set1 = which( temppaircomps[item_ind, ] == 1)
              set0 = which( temppaircomps[item_ind, ] == 0)

              if(length(set1) > 0){
                tempupper = min(tempz[set1])
              }else{
                tempupper = Inf
              }

              if(length(set0) > 0){
                templower = max(tempz[set0])
              }else{
                templower = -Inf
              }



              # # temp_z_i <- tempz[item_ind]
              # temprank_i <- tempranks[item_ind]
              #
              # # find bounds for truncated normal distribution
              # # need observed ranks for this
              # if(temprank_i==1){
              #   templower <- -Inf
              # }else{
              #   templower <- max(tempz[tempranks < temprank_i])
              # }
              #
              # if(temprank_i==n.item){
              #   tempupper <- Inf
              # }else{
              #   tempupper <- min(tempz[tempranks > temprank_i])
              # }

              temp_z_i <- rtruncnorm(n = 1,
                                     a = templower,
                                     b = tempupper,
                                     mean = tempmean[item_ind],
                                     sd = tempvar)

              tempz[item_ind] <- temp_z_i
              Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            }


          } # end loop over individuals

        } #end else statement (for t value not 1 or n.time)
      } # end else statement (for t value not 1)


      # Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
      #                                                                         Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
      #                                                                         mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
      #                                                                         weight.vec = rep(1, n.ranker),
      #                                                                         n.ranker = n.ranker,
      #                                                                         n.item = n.item)

      #update mu for period t to be used as lag for next period
      #require that this is consistent with the tree structure


      # mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
      #                                            weight.vec = rep(1, n.ranker*n.time),
      #                                            sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
      #                                            n.ranker = n.ranker*n.time,
      #                                            n.item = n.item,
      #                                            p.cov = p.cov+num_lags,
      #                                            para.expan = para.expan)


      # NOT REALLY NECESSARY TO UPDATE Z MATRIX WITHIN LOOP OVER T BUT KEEPING IT HERE ANYWAY
      # MAYBE CODE CAN BE MADE MORE EFFICIENT

      ### for check only
      # Z.mat = Z.mat/mean.para.update$theta

      Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

      for(t1 in 1:num_lags){
        init_Z_t0 <- rep(0, t1*n.item*n.ranker)
        # init_Z_t0 <- rnorm(t*n.item*n.ranker)

        Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

      }


      #update predictor matrix


    }#end of loop over t

    #end of seq_z_draws==1 code
    # }else{
    #
    #
    #   Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                             Z.mat = Z.mat,
    #                                             mu = mu,
    #                                             weight.vec = rep(1, n.ranker*n.time),
    #                                             n.ranker = n.ranker*n.time,
    #                                             n.item = n.item )
    #
    #   mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
    #                                              weight.vec = rep(1, n.ranker*n.time),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker*n.time,
    #                                              n.item = n.item,
    #                                              p.cov = num_lags,
    #                                              para.expan = para.expan)
    #
    #   ### for check only
    #   Z.mat = Z.mat/mean.para.update$theta
    #
    # }



    #   }else{
    #     #stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    # }





    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }









    # create Z lag test matrix


    Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat
    # Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test

    mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                               weight.vec = rep(1, n.ranker*n.time),
                                               sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                               n.ranker = n.ranker*n.time,
                                               n.item = n.item,
                                               p.cov = num_lags,
                                               para.expan = para.expan)


    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( rep(alpha, n.ranker*n.time) + (Xmat.train) %*% beta )
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )

    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) #+ as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)








    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta


    draw$mu_noZgamma[,iter] = mu_noZgamma
    draw$gamcoef[iter] = gamcoef


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }



    if( num_test_periods > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]

          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]/mean.para.update$theta
          # temp_test_preds[ , t1] <- mean.para.update$theta*testpredvec #+ rnorm( n.item*n.ranker )

        }
      }

      # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
      #                                                                      (num_lags+1):ncol(Xmat.test)])

      # temp_test_mat <- as.data.frame(temp_test_mat)
      # colnames(temp_test_mat) <- colnames(Xmat.test)


      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- rep(alpha, n.ranker) + as.matrix(temp_test_mat) %*% beta  #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- testpredvec/mean.para.update$theta #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){

          if(num_lags ==1){
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] #,
                                      # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
            )

          }else{
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] #,
                                      # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
            )

          }
        }

        # colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(num_test_periods >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]
      mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) # + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
      )
      draw$mu_noZgamma_test[,iter] = mu_noZgamma_test


      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )
    # draw$mu_test[,iter] = mutest


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # # print iteration number
    # if(iter %% print.opt == 0){
    #   print(paste("Gibbs Iteration", iter))
    #   # print(c(sigma2.alpha, sigma2.beta))
    # }

  }
  return(draw)
}





#' Auto-regressive linear model for Bayesian Analysis of Rank-Order data with entities' Covariates. Full conditional z sampler.
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARBayesRank_NoCovars_topk <- function(ranks_mat,
                                          # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                          # X.test = matrix(NA, nrow =0, ncol = 0),
                                          tau2.alpha = 5^2,
                                          nu.alpha = 3,
                                          tau2.beta = 5^2,
                                          nu.beta = 3,
                                          n.item = dim(ranks_mat)[1],
                                          n.rankerbytime = dim(ranks_mat)[2],
                                          n.ranker,
                                          n.time,
                                          # p.cov = ncol(X.train),
                                          iter.max = 5000,
                                          para.expan = TRUE,
                                          print.opt = 100,
                                          initial.list = NULL,
                                          n.trees = 50L,
                                          n.burn = 0L,
                                          n.samples = 1L,
                                          n.thin = 1L,
                                          n.chains = 1,
                                          n.threads = guessNumCores(),
                                          printEvery = 100L,
                                          printCutoffs = 0L,
                                          rngKind = "default",
                                          rngNormalKind = "default",
                                          rngSeed = NA_integer_,
                                          updateState = FALSE,
                                          num_lags = 1,
                                          diff_num_test_rankers = 0,
                                          num_test_periods = 0,
                                          keep_zmat = FALSE,
                                          noise_in_pred = 0,
                                          seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }
  if(num_lags >1){
    stop("Current implementation only allows for 1 lag of the latent outcome.")
  }
  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime
  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  length_mu_test <- 1
  num_test_rankers <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #       num_test_rankers <- length_mu_test/n.item
  #       if(num_test_rankers%%1 !=0){
  #         print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
  #       }
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  length_mu_test <- n.item*n.ranker*num_test_periods
  num_test_rankers <- length_mu_test/n.item
  if(num_test_rankers%%1 !=0){
    print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
  }


  # ranks_mat <- matrix(NA,
  #                     ncol = n.ranker*n.time,
  #                     nrow = n.item )
  #
  #
  # #n.item by n.item
  #
  # for(t in 1:n.time){
  #
  #   for(indiv in 1:n.ranker){
  #     pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]
  #
  #     # 1 corresponding to "highest rank" . i.e. highest utility ite,
  #     # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1
  #
  #     # 1 corresponding to "lowest rank". i.e. lowest utility item
  #
  #     up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)
  #
  #
  #     ranks_mat[, (t-1)*n.ranker + indiv] <- up.order
  #
  #   }
  # }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(num_lags, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    mu_noZgamma = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    gamcoef = rep(NA, iter.max),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(num_test_periods >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
    draw$mu_noZgamma_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }

  }




  ####### initialize values #############

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      tempsort <- sort(ranks_mat[,j], decreasing = TRUE, index.return = TRUE )

      Z.mat[ tempsort$ix , j] <-
        qnorm(  tempsort$x   /(n.item+1)) +
        rnorm(n = 1, mean = 0, sd = 0.01) # add some noise to prevent splitting issues

      # Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(num_test_periods >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    Xmat.train <- Zlag.mat

    # print(colnames(Xmat.train))

    if(nrow(Zlag.mat.test)>0 ){
      Xmat.test  <- Zlag.mat.test

      #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

    }

    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #
    #
    #
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #
    #   }
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <-  cbind(Zlag.mat, X.train)
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- cbind( Zlag.mat.test, X.test )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }




    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, num_lags)
    mu = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train) %*% beta )
    mu_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test) %*% beta )


    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) #+ as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )
    mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) #+ as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    sigma2.beta = tau2.beta

    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")



    # draw$Z.mat[,,1] <- Z.mat
    # draw$alpha[,1] = alpha
    # draw$beta[,1] = beta
    # draw$mu[,1] <- mu
    # draw$sigma2.alpha[1] = sigma2.alpha
    # draw$sigma2.beta[1] = sigma2.beta


    ## store initial value
    if(keep_zmat==TRUE){
      draw$Z.mat[,,1] = Z.mat
    }


    draw$alpha[,1] = alpha
    draw$beta[,1] = beta
    draw$mu[,1] = mu
    draw$mu_test[,1] = mu_test
    draw$sigma2.alpha[1] = sigma2.alpha
    draw$sigma2.beta[1] = sigma2.beta

    draw$mu_noZgamma[,1] = mu_noZgamma
    draw$mu_noZgamma_test[,1] = mu_noZgamma_test
    draw$gamcoef[1] = gamcoef

  }# ending  if statement if is null initial list




  if( num_test_periods > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA,
                                nrow = n.item*n.ranker,
                                ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- rep(alpha, n.ranker) + temp_test_mat %*% beta   #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] #,
                                      # as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
          )

        }else{
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] #,
                                      # as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
          )

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(num_test_periods >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ######### Begin Gibbs sampler ##############
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    # if(nrow(X.train)==n.item){
    #   stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #   Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                        weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #   if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){

    # if(seq_z_draws==1){
    for(t in 1:n.time){




      # update mu for period t-1

      #Zlag always zero in period t==0

      # Z in period 0 is unaffected since set to zero by default
      #therefore mu unaffected in period 0 (can draw anyway for now)

      Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat


      if(t==1){
        # mu[1:(n.item*n.ranker)] <- (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta ))  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])

        for(indiv in 1:n.ranker){

          tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]


          # tempmu <- mu[1:(n.item*n.ranker)]
          # tempmu_noZgamma <- mu_noZgamma[1:(n.item*n.ranker)]
          #
          # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]


          tempmu <- mu[(t-1)*(n.item*n.ranker) +
                         n.item*(indiv-1) +
                         1:(n.item)]

          tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                           n.item*(indiv-1) +
                                           1:(n.item)]


          tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                             n.item*(indiv-1) +
                             1:(n.item)]

          tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                               n.item*(indiv-1) +
                                               1:(n.item)]

          tempz <- Z.mat[,(t-1)*n.ranker + indiv]

          tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]

          # draw item by item

          # calculate mean
          # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
          tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma  )/((gamcoef^2)*(1+gamcoef^2)+1)

          # calculate variance
          tempvar <- (gamcoef^2)*(1+gamcoef^2)+1

          for(item_ind in 1:n.item){
            # temp_z_i <- tempz[item_ind]
            temprank_i <- tempranks[item_ind]

            # find bounds for truncated normal distribution
            # need observed ranks for this
            if(temprank_i==1){
              templower <- -Inf
            }else{
              templower <- max(tempz[tempranks < temprank_i])
            }

            if(temprank_i==n.item){
              tempupper <- Inf
            }else{
              tempupper <- min(tempz[tempranks > temprank_i])
            }
            # # calculate mean
            # # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            # tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1[item_ind]-tempmu_noZgamma_tp1[item_ind]) +tempmu_noZgamma[item_ind]  )/((gamcoef^2)*(1+gamcoef^2)+1)
            #
            # # calculate variance
            # tempvar <- (gamcoef^2)*(1+gamcoef^2)+1


            temp_z_i <- rtruncnorm(n = 1,
                                   a = templower,
                                   b = tempupper,
                                   mean = tempmean[item_ind],
                                   sd = tempvar)

            tempz[item_ind] <- temp_z_i
            Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            # Is it then necessary to update z_tm1 and z_tm1*gamma in mu calcalcutions for draw of z in next period (t=2)?
            # Check also ARROBART code for this
            # Z.mat updated, therefore z_tm1 will be the updated values in next iteration over t
            # therefore all is fine as long as use noZgamma mu values

          }
        }

      }else{
        if(t==n.time){
          # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])
          for(indiv in 1:n.ranker){
            tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

            # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

            tempmu <- mu[(t-1)*(n.item*n.ranker) +
                           n.item*(indiv-1) +
                           1:(n.item)]

            tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                             n.item*(indiv-1) +
                                             1:(n.item)]

            tempz <- Z.mat[,(t-1)*n.ranker + indiv]

            # tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
            tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

            # draw item by item

            # calculate mean
            # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            tempmean <- tempmu_noZgamma + gamcoef*tempz_tm1

            # calculate variance
            tempvar <- 1

            for(item_ind in 1:n.item){
              # temp_z_i <- tempz[item_ind]
              temprank_i <- tempranks[item_ind]

              # find bounds for truncated normal distribution
              # need observed ranks for this
              if(temprank_i==1){
                templower <- -Inf
              }else{
                templower <- max(tempz[tempranks < temprank_i])
              }

              if(temprank_i==n.item){
                tempupper <- Inf
              }else{
                tempupper <- min(tempz[tempranks > temprank_i])
              }

              temp_z_i <- rtruncnorm(n = 1,
                                     a = templower,
                                     b = tempupper,
                                     mean = tempmean[item_ind],
                                     sd = tempvar)

              tempz[item_ind] <- temp_z_i
              Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            }

          } # end loop over individuals
        }else{
          # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

          for(indiv in 1:n.ranker){
            tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

            # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

            tempmu <- mu[(t-1)*(n.item*n.ranker) +
                           n.item*(indiv-1) +
                           1:(n.item)]

            tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                             n.item*(indiv-1) +
                                             1:(n.item)]

            tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

            tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

            tempz <- Z.mat[,(t-1)*n.ranker + indiv]

            tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
            tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

            # draw item by item

            # calculate mean
            # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            tempmean <- (  gamcoef*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma + gamcoef*tempz_tm1 )/(1+gamcoef^2)

            # calculate variance
            tempvar <- 1+gamcoef^2

            for(item_ind in 1:n.item){
              # temp_z_i <- tempz[item_ind]
              temprank_i <- tempranks[item_ind]

              # find bounds for truncated normal distribution
              # need observed ranks for this
              if(temprank_i==1){
                templower <- -Inf
              }else{
                templower <- max(tempz[tempranks < temprank_i])
              }

              if(temprank_i==n.item){
                tempupper <- Inf
              }else{
                tempupper <- min(tempz[tempranks > temprank_i])
              }

              temp_z_i <- rtruncnorm(n = 1,
                                     a = templower,
                                     b = tempupper,
                                     mean = tempmean[item_ind],
                                     sd = tempvar)

              tempz[item_ind] <- temp_z_i
              Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            }


          } # end loop over individuals

        } #end else statement (for t value not 1 or n.time)
      } # end else statement (for t value not 1)


      # Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
      #                                                                         Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
      #                                                                         mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
      #                                                                         weight.vec = rep(1, n.ranker),
      #                                                                         n.ranker = n.ranker,
      #                                                                         n.item = n.item)

      #update mu for period t to be used as lag for next period
      #require that this is consistent with the tree structure


      # mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
      #                                            weight.vec = rep(1, n.ranker*n.time),
      #                                            sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
      #                                            n.ranker = n.ranker*n.time,
      #                                            n.item = n.item,
      #                                            p.cov = p.cov+num_lags,
      #                                            para.expan = para.expan)


      # NOT REALLY NECESSARY TO UPDATE Z MATRIX WITHIN LOOP OVER T BUT KEEPING IT HERE ANYWAY
      # MAYBE CODE CAN BE MADE MORE EFFICIENT

      ### for check only
      # Z.mat = Z.mat/mean.para.update$theta

      Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

      for(t1 in 1:num_lags){
        init_Z_t0 <- rep(0, t1*n.item*n.ranker)
        # init_Z_t0 <- rnorm(t*n.item*n.ranker)

        Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

      }


      #update predictor matrix


    }#end of loop over t

    #end of seq_z_draws==1 code
    # }else{
    #
    #
    #   Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                             Z.mat = Z.mat,
    #                                             mu = mu,
    #                                             weight.vec = rep(1, n.ranker*n.time),
    #                                             n.ranker = n.ranker*n.time,
    #                                             n.item = n.item )
    #
    #   mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
    #                                              weight.vec = rep(1, n.ranker*n.time),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker*n.time,
    #                                              n.item = n.item,
    #                                              p.cov = num_lags,
    #                                              para.expan = para.expan)
    #
    #   ### for check only
    #   Z.mat = Z.mat/mean.para.update$theta
    #
    # }



    #   }else{
    #     #stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    # }





    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }









    # create Z lag test matrix


    Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat
    # Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test

    mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                               weight.vec = rep(1, n.ranker*n.time),
                                               sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                               n.ranker = n.ranker*n.time,
                                               n.item = n.item,
                                               p.cov = num_lags,
                                               para.expan = para.expan)


    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( rep(alpha, n.ranker*n.time) + (Xmat.train) %*% beta )
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )

    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) #+ as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)








    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta


    draw$mu_noZgamma[,iter] = mu_noZgamma
    draw$gamcoef[iter] = gamcoef


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }



    if( num_test_periods > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]

          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]/mean.para.update$theta
          # temp_test_preds[ , t1] <- mean.para.update$theta*testpredvec #+ rnorm( n.item*n.ranker )

        }
      }

      # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
      #                                                                      (num_lags+1):ncol(Xmat.test)])

      # temp_test_mat <- as.data.frame(temp_test_mat)
      # colnames(temp_test_mat) <- colnames(Xmat.test)


      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- rep(alpha, n.ranker) + as.matrix(temp_test_mat) %*% beta  #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- testpredvec/mean.para.update$theta #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){

          if(num_lags ==1){
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] #,
                                      # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
            )

          }else{
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] #,
                                      # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
            )

          }
        }

        # colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(num_test_periods >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]
      mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) # + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
      )
      draw$mu_noZgamma_test[,iter] = mu_noZgamma_test


      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )
    # draw$mu_test[,iter] = mutest


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # # print iteration number
    # if(iter %% print.opt == 0){
    #   print(paste("Gibbs Iteration", iter))
    #   # print(c(sigma2.alpha, sigma2.beta))
    # }

  }
  return(draw)
}



#' Auto-regressive linear model for Bayesian Analysis of Rank-Order data with entities' Covariates. Full conditional z sampler.
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARBayesRank_NoCovars_fullcond <- function(pair.comp.ten,
                                          # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                          # X.test = matrix(NA, nrow =0, ncol = 0),
                                          tau2.alpha = 5^2,
                                          nu.alpha = 3,
                                          tau2.beta = 5^2,
                                          nu.beta = 3,
                                          n.item = dim(pair.comp.ten)[1],
                                          n.rankerbytime = dim(pair.comp.ten)[3],
                                          n.ranker,
                                          n.time,
                                          # p.cov = ncol(X.train),
                                          iter.max = 5000,
                                          para.expan = TRUE,
                                          print.opt = 100,
                                          initial.list = NULL,
                                          n.trees = 50L,
                                          n.burn = 0L,
                                          n.samples = 1L,
                                          n.thin = 1L,
                                          n.chains = 1,
                                          n.threads = guessNumCores(),
                                          printEvery = 100L,
                                          printCutoffs = 0L,
                                          rngKind = "default",
                                          rngNormalKind = "default",
                                          rngSeed = NA_integer_,
                                          updateState = FALSE,
                                          num_lags = 1,
                                          diff_num_test_rankers = 0,
                                          num_test_periods = 0,
                                          keep_zmat = FALSE,
                                          noise_in_pred = 0,
                                          seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }
  if(num_lags >1){
    stop("Current implementation only allows for 1 lag of the latent outcome.")
  }
  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime
  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  length_mu_test <- 1
  num_test_rankers <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #       num_test_rankers <- length_mu_test/n.item
  #       if(num_test_rankers%%1 !=0){
  #         print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
  #       }
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  length_mu_test <- n.item*n.ranker*num_test_periods
  num_test_rankers <- length_mu_test/n.item
  if(num_test_rankers%%1 !=0){
    print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
  }


  ranks_mat <- matrix(NA,
                      ncol = n.ranker*n.time,
                      nrow = n.item )


  #n.item by n.item

  for(t in 1:n.time){

    for(indiv in 1:n.ranker){
      pair.comp <- pair.comp.ten[, , (t-1)*n.ranker + indiv]

      # 1 corresponding to "highest rank" . i.e. highest utility ite,
      # up.order = rowSums( pair.comp, na.rm = TRUE ) + 1

      # 1 corresponding to "lowest rank". i.e. lowest utility item

      up.order = rank(-rowSums( pair.comp, na.rm = TRUE ) + 1)


      ranks_mat[, (t-1)*n.ranker + indiv] <- up.order

    }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(num_lags, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    mu_noZgamma = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    gamcoef = rep(NA, iter.max),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(num_test_periods >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
    draw$mu_noZgamma_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }

  }




  ####### initialize values #############

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(num_test_periods >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    Xmat.train <- Zlag.mat

    # print(colnames(Xmat.train))

    if(nrow(Zlag.mat.test)>0 ){
      Xmat.test  <- Zlag.mat.test

      #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

    }

    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #
    #
    #
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #
    #   }
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <-  cbind(Zlag.mat, X.train)
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- cbind( Zlag.mat.test, X.test )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }




    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, num_lags)
    mu = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train) %*% beta )
    mu_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test) %*% beta )


    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) #+ as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )
    mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) #+ as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    sigma2.beta = tau2.beta

    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")



    # draw$Z.mat[,,1] <- Z.mat
    # draw$alpha[,1] = alpha
    # draw$beta[,1] = beta
    # draw$mu[,1] <- mu
    # draw$sigma2.alpha[1] = sigma2.alpha
    # draw$sigma2.beta[1] = sigma2.beta


    ## store initial value
    if(keep_zmat==TRUE){
      draw$Z.mat[,,1] = Z.mat
    }


    draw$alpha[,1] = alpha
    draw$beta[,1] = beta
    draw$mu[,1] = mu
    draw$mu_test[,1] = mu_test
    draw$sigma2.alpha[1] = sigma2.alpha
    draw$sigma2.beta[1] = sigma2.beta

    draw$mu_noZgamma[,1] = mu_noZgamma
    draw$mu_noZgamma_test[,1] = mu_noZgamma_test
    draw$gamcoef[1] = gamcoef

  }# ending  if statement if is null initial list




  if( num_test_periods > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA,
                                nrow = n.item*n.ranker,
                                ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- rep(alpha, n.ranker) + temp_test_mat %*% beta   #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] #,
                                      # as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
          )

        }else{
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] #,
                                      # as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
          )

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(num_test_periods >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  ######### Begin Gibbs sampler ##############
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    # if(nrow(X.train)==n.item){
    #   stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #   Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                        weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #   if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){

    # if(seq_z_draws==1){
    for(t in 1:n.time){




      # update mu for period t-1

      #Zlag always zero in period t==0

      # Z in period 0 is unaffected since set to zero by default
      #therefore mu unaffected in period 0 (can draw anyway for now)

      Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat


      if(t==1){
        # mu[1:(n.item*n.ranker)] <- (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta ))  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])

        for(indiv in 1:n.ranker){

          tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]


          # tempmu <- mu[1:(n.item*n.ranker)]
          # tempmu_noZgamma <- mu_noZgamma[1:(n.item*n.ranker)]
          #
          # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]


          tempmu <- mu[(t-1)*(n.item*n.ranker) +
                         n.item*(indiv-1) +
                         1:(n.item)]

          tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                           n.item*(indiv-1) +
                                           1:(n.item)]


          tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                             n.item*(indiv-1) +
                             1:(n.item)]

          tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                               n.item*(indiv-1) +
                                               1:(n.item)]

          tempz <- Z.mat[,(t-1)*n.ranker + indiv]

          tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]

          # draw item by item

          # calculate mean
          # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
          tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma  )/((gamcoef^2)*(1+gamcoef^2)+1)

          # calculate variance
          tempvar <- (gamcoef^2)*(1+gamcoef^2)+1

          for(item_ind in 1:n.item){
            # temp_z_i <- tempz[item_ind]
            temprank_i <- tempranks[item_ind]

            # find bounds for truncated normal distribution
            # need observed ranks for this
            if(temprank_i==1){
              templower <- -Inf
            }else{
              templower <- max(tempz[tempranks < temprank_i])
            }

            if(temprank_i==n.item){
              tempupper <- Inf
            }else{
              tempupper <- min(tempz[tempranks > temprank_i])
            }
            # # calculate mean
            # # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            # tempmean <- (gamcoef*(1+gamcoef^2)*(tempz_tp1[item_ind]-tempmu_noZgamma_tp1[item_ind]) +tempmu_noZgamma[item_ind]  )/((gamcoef^2)*(1+gamcoef^2)+1)
            #
            # # calculate variance
            # tempvar <- (gamcoef^2)*(1+gamcoef^2)+1


            temp_z_i <- rtruncnorm(n = 1,
                                   a = templower,
                                   b = tempupper,
                                   mean = tempmean[item_ind],
                                   sd = tempvar)

            tempz[item_ind] <- temp_z_i
            Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            # Is it then necessary to update z_tm1 and z_tm1*gamma in mu calcalcutions for draw of z in next period (t=2)?
            # Check also ARROBART code for this
            # Z.mat updated, therefore z_tm1 will be the updated values in next iteration over t
            # therefore all is fine as long as use noZgamma mu values

          }
        }

      }else{
        if(t==n.time){
          # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])
          for(indiv in 1:n.ranker){
            tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

            # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

            tempmu <- mu[(t-1)*(n.item*n.ranker) +
                           n.item*(indiv-1) +
                           1:(n.item)]

            tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                             n.item*(indiv-1) +
                                             1:(n.item)]

            tempz <- Z.mat[,(t-1)*n.ranker + indiv]

            # tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
            tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

            # draw item by item

            # calculate mean
            # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            tempmean <- tempmu_noZgamma + gamcoef*tempz_tm1

            # calculate variance
            tempvar <- 1

            for(item_ind in 1:n.item){
              # temp_z_i <- tempz[item_ind]
              temprank_i <- tempranks[item_ind]

              # find bounds for truncated normal distribution
              # need observed ranks for this
              if(temprank_i==1){
                templower <- -Inf
              }else{
                templower <- max(tempz[tempranks < temprank_i])
              }

              if(temprank_i==n.item){
                tempupper <- Inf
              }else{
                tempupper <- min(tempz[tempranks > temprank_i])
              }

              temp_z_i <- rtruncnorm(n = 1,
                                     a = templower,
                                     b = tempupper,
                                     mean = tempmean[item_ind],
                                     sd = tempvar)

              tempz[item_ind] <- temp_z_i
              Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            }

          } # end loop over individuals
        }else{
          # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

          for(indiv in 1:n.ranker){
            tempranks <- ranks_mat[, (t-1)*n.ranker + indiv]

            # tempmu <- mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)]
            # tempz <- Z.mat[,(t-1)*n.ranker + 1:n.ranker]

            tempmu <- mu[(t-1)*(n.item*n.ranker) +
                           n.item*(indiv-1) +
                           1:(n.item)]

            tempmu_noZgamma <- mu_noZgamma[(t-1)*(n.item*n.ranker) +
                                             n.item*(indiv-1) +
                                             1:(n.item)]

            tempmu_tp1 <- mu[(t)*(n.item*n.ranker) +
                               n.item*(indiv-1) +
                               1:(n.item)]

            tempmu_noZgamma_tp1 <- mu_noZgamma[(t)*(n.item*n.ranker) +
                                                 n.item*(indiv-1) +
                                                 1:(n.item)]

            tempz <- Z.mat[,(t-1)*n.ranker + indiv]

            tempz_tp1 <- Z.mat[,(t)*n.ranker + indiv]
            tempz_tm1 <- Z.mat[,(t-2)*n.ranker + indiv]

            # draw item by item

            # calculate mean
            # note: not including z0 (latent score in time 0) prior mean in calculation because prior mean set to zero
            tempmean <- (  gamcoef*(tempz_tp1-tempmu_noZgamma_tp1) +tempmu_noZgamma + gamcoef*tempz_tm1 )/(1+gamcoef^2)

            # calculate variance
            tempvar <- 1+gamcoef^2

            for(item_ind in 1:n.item){
              # temp_z_i <- tempz[item_ind]
              temprank_i <- tempranks[item_ind]

              # find bounds for truncated normal distribution
              # need observed ranks for this
              if(temprank_i==1){
                templower <- -Inf
              }else{
                templower <- max(tempz[tempranks < temprank_i])
              }

              if(temprank_i==n.item){
                tempupper <- Inf
              }else{
                tempupper <- min(tempz[tempranks > temprank_i])
              }

              temp_z_i <- rtruncnorm(n = 1,
                                     a = templower,
                                     b = tempupper,
                                     mean = tempmean[item_ind],
                                     sd = tempvar)

              tempz[item_ind] <- temp_z_i
              Z.mat[item_ind,(t-1)*n.ranker + indiv] <- temp_z_i

            }


          } # end loop over individuals

        } #end else statement (for t value not 1 or n.time)
      } # end else statement (for t value not 1)


      # Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
      #                                                                         Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
      #                                                                         mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
      #                                                                         weight.vec = rep(1, n.ranker),
      #                                                                         n.ranker = n.ranker,
      #                                                                         n.item = n.item)

      #update mu for period t to be used as lag for next period
      #require that this is consistent with the tree structure


      # mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
      #                                            weight.vec = rep(1, n.ranker*n.time),
      #                                            sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
      #                                            n.ranker = n.ranker*n.time,
      #                                            n.item = n.item,
      #                                            p.cov = p.cov+num_lags,
      #                                            para.expan = para.expan)


      # NOT REALLY NECESSARY TO UPDATE Z MATRIX WITHIN LOOP OVER T BUT KEEPING IT HERE ANYWAY
      # MAYBE CODE CAN BE MADE MORE EFFICIENT

      ### for check only
      # Z.mat = Z.mat/mean.para.update$theta

      Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

      for(t1 in 1:num_lags){
        init_Z_t0 <- rep(0, t1*n.item*n.ranker)
        # init_Z_t0 <- rnorm(t*n.item*n.ranker)

        Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

      }


      #update predictor matrix


    }#end of loop over t

    #end of seq_z_draws==1 code
    # }else{
    #
    #
    #   Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
    #                                             Z.mat = Z.mat,
    #                                             mu = mu,
    #                                             weight.vec = rep(1, n.ranker*n.time),
    #                                             n.ranker = n.ranker*n.time,
    #                                             n.item = n.item )
    #
    #   mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
    #                                              weight.vec = rep(1, n.ranker*n.time),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker*n.time,
    #                                              n.item = n.item,
    #                                              p.cov = num_lags,
    #                                              para.expan = para.expan)
    #
    #   ### for check only
    #   Z.mat = Z.mat/mean.para.update$theta
    #
    # }



    #   }else{
    #     #stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    # }





    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }









    # create Z lag test matrix


    Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat
    # Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test

    mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                               weight.vec = rep(1, n.ranker*n.time),
                                               sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                               n.ranker = n.ranker*n.time,
                                               n.item = n.item,
                                               p.cov = num_lags,
                                               para.expan = para.expan)


    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( rep(alpha, n.ranker*n.time) + (Xmat.train) %*% beta )
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )

    mu_noZgamma = as.vector( rep(alpha, n.ranker*n.time) #+ as.matrix(Xmat.train)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
    )

    #coefficient of the lag of the latent variable
    gamcoef = beta[1]
    # gamcoef = beta[1:num_lags]


    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)








    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta


    draw$mu_noZgamma[,iter] = mu_noZgamma
    draw$gamcoef[iter] = gamcoef


    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }



    if( num_test_periods > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]

          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]/mean.para.update$theta
          # temp_test_preds[ , t1] <- mean.para.update$theta*testpredvec #+ rnorm( n.item*n.ranker )

        }
      }

      # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
      #                                                                      (num_lags+1):ncol(Xmat.test)])

      # temp_test_mat <- as.data.frame(temp_test_mat)
      # colnames(temp_test_mat) <- colnames(Xmat.test)


      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- rep(alpha, n.ranker) + as.matrix(temp_test_mat) %*% beta  #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- testpredvec/mean.para.update$theta #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){

          if(num_lags ==1){
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] #,
                                      # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
            )

          }else{
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] #,
                                      # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
            )

          }
        }

        # colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(num_test_periods >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]
      mu_noZgamma_test = as.vector( rep(alpha, n.ranker*num_test_periods) # + as.matrix(Xmat.test)[,-c(1:num_lags)] %*% beta[-c(1:num_lags)]
      )
      draw$mu_noZgamma_test[,iter] = mu_noZgamma_test


      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )
    # draw$mu_test[,iter] = mutest


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # # print iteration number
    # if(iter %% print.opt == 0){
    #   print(paste("Gibbs Iteration", iter))
    #   # print(c(sigma2.alpha, sigma2.beta))
    # }

  }
  return(draw)
}






#' Auto-regressive linear model for Bayesian Analysis of Rank-Order data with entities' Covariates
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{MT} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers and \eqn{T} time periods, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific or time-specific covariate values, then the matrix should have N*MT rows where MT is the number of rankers multiplied by the number of time periods. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param num_lags Number of lags of the latent vairable to use as splitting variables.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data.
#' @param num_test_periods Number of time periods to predict ranks in the test data
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @param noise_in_pred If equal to 1, keep noise in test prediction calculations
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
ARBayesRankCovSimpIndsNoCovars <- function(pair.comp.ten,
                                           # X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                           # X.test = matrix(NA, nrow =0, ncol = 0),
                                           tau2.alpha = 5^2,
                                           nu.alpha = 3,
                                           tau2.beta = 5^2,
                                           nu.beta = 3,
                                           n.item = dim(pair.comp.ten)[1],
                                           n.rankerbytime = dim(pair.comp.ten)[3],
                                           n.ranker,
                                           n.time,
                                           # p.cov = ncol(X.train),
                                           iter.max = 5000,
                                           para.expan = TRUE,
                                           print.opt = 100,
                                           initial.list = NULL,
                                           n.trees = 50L,
                                           n.burn = 0L,
                                           n.samples = 1L,
                                           n.thin = 1L,
                                           n.chains = 1,
                                           n.threads = guessNumCores(),
                                           printEvery = 100L,
                                           printCutoffs = 0L,
                                           rngKind = "default",
                                           rngNormalKind = "default",
                                           rngSeed = NA_integer_,
                                           updateState = FALSE,
                                           num_lags = 1,
                                           diff_num_test_rankers = 0,
                                           num_test_periods = 0,
                                           keep_zmat = FALSE,
                                           noise_in_pred = 0,
                                           seq_z_draws = 1){
  ## store MCMC draws

  # print("begin function")

  if(!is.integer(num_lags)){
    stop("num_lags must be an integer.")
  }
  if(num_lags <1){
    stop("num_lags must be an integer greater than or equal to 1.")
  }

  if(n.rankerbytime!=n.ranker*n.time ){
    stop("n.rankerbytime != n.ranker*n.time")
  }


  # length_mu <- 1
  length_mu <- n.item*n.rankerbytime
  # if(nrow(X.train)==n.item){
  #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #
  #   length_mu <- n.item
  # }else{
  #   if(nrow(X.train)==n.item*n.rankerbytime){
  #     length_mu <- n.item*n.rankerbytime
  #   }else{
  #     stop("nrow(X.train) not equal to n.item*n.rankerbytime")
  #   }
  #
  # }


  length_mu_test <- 1
  num_test_rankers <- 1


  # if(nrow(X.test) >0 ){
  #
  #
  #   if(diff_num_test_rankers==1){
  #     stop("Code not yet written for test data with different rankers to training data.")
  #   }else{
  #
  #     if(nrow(X.test) != n.item*n.ranker*num_test_periods ){
  #       stop("nrow(X.test) != n.item*n.ranker*num_test_periods")
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #       num_test_rankers <- length_mu_test/n.item
  #       if(num_test_rankers%%1 !=0){
  #         print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
  #       }
  #     }
  #
  #
  #   }
  #
  #
  #
  #   #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
  #
  #
  #
  #   # if(diff_num_test_rankers==1){
  #   #   length_mu_test <- nrow(X.test)
  #   # }else{
  #   #   if(nrow(X.train)==n.item){
  #   #     length_mu_test <- n.item*n.ranker
  #   #
  #   #   }else{
  #   #     length_mu_test <- nrow(X.test)
  #   #
  #   #   }
  #   # }
  # }



  length_mu_test <- n.item*n.ranker*num_test_periods
  num_test_rankers <- length_mu_test/n.item
  if(num_test_rankers%%1 !=0){
    print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c( num_lags, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker*n.time, iter.max))
  }

  if(num_test_periods >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))

    if(keep_zmat==TRUE){
      draw$Z.mat.test <- array(NA, dim = c(n.item, n.ranker*num_test_periods, iter.max))
    }

  }






  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker*n.time)
    for(j in 1:(n.ranker*n.time)){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #create time period 1 initial values for all items and all rankers
    #[actually these vlaues are not updated at al]
    #one possibility is all zeros, although then all T1 observations fall in one branc if split on Z
    # init_Z_t0 <- rep(0, n.item*n.ranker)
    #another possibility is normally distributed initial values
    # init_Z_t0 <- rnorm(n.item*n.ranker)

    # with initial value create vector of Z lags
    # Zlag.1.mat <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-1)*n.item*n.ranker)])

    #must do something similar if extend to two period lags, three period lags etc.

    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }

    #it is also necessary to create initial values for the test data

    Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

    if(num_test_periods >0 ){
      for(t in 1:num_lags){
        # if(t==1){
        #   #repeating the last period values
        #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
        #
        #   #other option is to set all unobservable values to zero
        #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
        #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
        #
        #
        # }else{

        if(num_test_periods > t ){
          #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                 rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                     (num_test_periods-t) )  )

          # #other option is to set all unobservable values to zero
          # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))

        }else{
          #nothing to fill in if num_test_periods <= t
          Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

        }


        # }
      }
    }


    Xmat.train <- Zlag.mat

    # print(colnames(Xmat.train))

    if(nrow(Zlag.mat.test)>0 ){
      Xmat.test  <- Zlag.mat.test

      #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.

    }

    # #must repeat x matrix if only n.item by the number of covaraites
    # #otherwise, the matrix has ranking specific covariates
    # if(nrow(X.train)==n.item){
    #
    #   stop("nrow(X.train) not equal to n.item*n.rankerbytime")
    #   #this part of the code needs to be rewritten if code
    #   #edited to allow for nrow(X.train)==n.item
    #   #currently the dimensions of the traiinng and test matrices defined below do not agree with this option
    #
    #   Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
    #                                                                               ncol =  ncol(X.train) + num_lags ,
    #                                                                               byrow = TRUE ))
    #   )
    #
    #
    #   #colnames(Xmat.train) <- c("y", "x","z","w")
    #
    #   if(nrow(X.test) >0 ){
    #     # print("nrow(X.test) = ")
    #     # print(nrow(X.test))
    #
    #     #Note: Zlag.mat.test already contains vecotrs. Each lag is correctly a separate vector
    #     #so as.vector is NOT applied here to Zlag.mat.test.
    #
    #     Xmat.test <- data.frame(x = cbind(Zlag.mat.test, matrix( rep( t( X.test ) , n.ranker ) ,
    #                                                              ncol =  ncol(X.test) , byrow = TRUE ) )
    #     )
    #     #colnames(Xmat.test) <- c("x","z","w")
    #
    #
    #
    #
    #
    #     #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #
    #   }
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){
    #     Xmat.train <-  cbind(Zlag.mat, X.train)
    #
    #     # print(colnames(Xmat.train))
    #
    #     if(nrow(X.test)>0 ){
    #       Xmat.test  <- cbind( Zlag.mat.test, X.test )
    #
    #       #must create predictions for future time periods using covariates for one period ahead, two periods ahead etc.
    #
    #     }
    #   }else{
    #     stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
    #   }
    #
    # }




    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, num_lags)
    mu = as.vector( rep(alpha, n.ranker*n.time) + as.matrix(Xmat.train) %*% beta )
    mu_test = as.vector( rep(alpha, n.ranker*num_test_periods) + as.matrix(Xmat.test) %*% beta )

    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta

    # print(colnames(Xmat.train))
    # print(colnames(Xmat.test))

    # print("begin dbarts")



    # draw$Z.mat[,,1] <- Z.mat
    # draw$alpha[,1] = alpha
    # draw$beta[,1] = beta
    # draw$mu[,1] <- mu
    # draw$sigma2.alpha[1] = sigma2.alpha
    # draw$sigma2.beta[1] = sigma2.beta


    ## store initial value
    if(keep_zmat==TRUE){
      draw$Z.mat[,,1] = Z.mat
    }


    draw$alpha[,1] = alpha
    draw$beta[,1] = beta
    draw$mu[,1] = mu
    draw$mu_test[,1] = mu_test
    draw$sigma2.alpha[1] = sigma2.alpha
    draw$sigma2.beta[1] = sigma2.beta


  }# ending  if statement if is null initial list




  if( num_test_periods > 0 ){


    if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)


      temp_test_mat <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,])  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA,
                                nrow = n.item*n.ranker,
                                ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      # print("colnames(temp_test_mat) = ")

      # print(colnames(temp_test_mat))

      for(t1 in 1:num_test_periods){
        #produce a prediction

        # print("t1 = ")
        # print(t1)
        #
        #
        # print("colnames(temp_test_mat) = ")
        # print(colnames(temp_test_mat))

        testpredvec <- rep(alpha, n.ranker) + temp_test_mat %*% beta   #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise
        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        if(num_lags ==1){
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] #,
                                      # as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
          )

        }else{
          temp_test_mat <-    cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] #,
                                      # as.matrix(Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
          )

        }

        colnames(temp_test_mat) <- colnames(Xmat.test)

        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(num_test_periods >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            # print("as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)]")
            # print(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)])
            #
            # print("as.vector(temp_test_mat)")
            # print(as.vector(as.matrix(temp_test_mat)))
            #
            # print("as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ]")
            # print(as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ])

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,1] <- temp_mu_test

      # draw$mu_test[,1] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,1]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

    }else{
      draw$mu_test[,1] <- initial.list$mu_test
    }

  }

  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////
  #//////////////////////////////////////////////////////////////////////////

  # Begin Gibbs sampler
  #//////////////////////////////////////////////////////////////////////////
  ## Gibbs iteration
  for(iter in 2:iter.max){


    # if(nrow(X.train)==n.item){
    #   stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #
    #   #each n.ranker values of u should be equal,
    #   #so just take one mu value from each of these
    #   #this keeps the dimension of mu equal to n.item
    #   #so a new Gibbs sampler update does not have to be written for Z
    #   Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
    #                                        weight.vec = rep(1, n.ranker), n.ranker = n.ranker )
    #
    #   if(any(is.na(Z.mat))){stop("NA in Z.mat")}
    #
    # }else{
    #   if(nrow(X.train)==n.item*n.ranker*n.time){

    if(seq_z_draws==1){
      for(t in 1:n.time){

        # update mu for period t-1

        #Zlag always zero in period t==0

        # Z in period 0 is unaffected since set to zero by default
        #thereofre mu unaffected in period 0 (can draw anyway for now)

        Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat


        if(t==1){

          # print("t = ")
          # print(t)
          # print("mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] = ")
          # print(mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)])

          mu[1:(n.item*n.ranker)] <- (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta ))  #sampler$predict(Xmat.train[1:(n.item*n.ranker),])
          # Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
          #                                                                             ncol =  ncol(X.train) + num_lags ,
          #                                                                             byrow = TRUE )))
          # mu[1:(n.item*n.ranker)] <- sampler$predict(Xmat.train[1:(n.item*n.ranker),])

        }else{
          mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  (as.vector( rep(alpha, n.ranker) + as.matrix(Xmat.train[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker) , ]) %*% beta )) # sampler$predict(Xmat.train[1:(n.item*n.ranker),])

          # Xmat.train <- data.frame(y = as.vector(Z.mat), x = cbind(Zlag.mat , matrix( rep( t( X.train ) , n.ranker ) ,
          #                                                                             ncol =  ncol(X.train) + num_lags ,
          #                                                                             byrow = TRUE )))
          # mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)] <-  sampler$predict(Xmat.train[1:(n.item*n.ranker),])
        }



        Z.mat[,(t-1)*n.ranker + 1:n.ranker] <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten[, , (t-1)*n.ranker + 1:n.ranker],
                                                                                Z.mat = Z.mat[,(t-1)*n.ranker + 1:n.ranker],
                                                                                mu = mu[(t-1)*(n.item*n.ranker) + 1:(n.item*n.ranker)],
                                                                                weight.vec = rep(1, n.ranker),
                                                                                n.ranker = n.ranker,
                                                                                n.item = n.item)

        #update mu for period t to be used as lag for next period
        #require that this is consistent with the tree structure


        mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                                   weight.vec = rep(1, n.ranker*n.time),
                                                   sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                                   n.ranker = n.ranker*n.time,
                                                   n.item = n.item,
                                                   p.cov = num_lags,
                                                   para.expan = para.expan)

        ### for check only
        Z.mat = Z.mat/mean.para.update$theta

        Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

        for(t1 in 1:num_lags){
          init_Z_t0 <- rep(0, t1*n.item*n.ranker)
          # init_Z_t0 <- rnorm(t*n.item*n.ranker)

          Zlag.mat[,t1] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t1)*n.item*n.ranker)])

        }


        #update predictor matrix


      }#end of loop over t

      #end of seq_z_draws==1 code
    }else{


      Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten,
                                                Z.mat = Z.mat,
                                                mu = mu,
                                                weight.vec = rep(1, n.ranker*n.time),
                                                n.ranker = n.ranker*n.time,
                                                n.item = n.item )

      mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                                 weight.vec = rep(1, n.ranker*n.time),
                                                 sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                                 n.ranker = n.ranker*n.time,
                                                 n.item = n.item,
                                                 p.cov = num_lags,
                                                 para.expan = para.expan)

      ### for check only
      Z.mat = Z.mat/mean.para.update$theta

    }



    #   }else{
    #     #stop("nrow(X.train) not equal to n.item*n.ranker*n.time")
    #   }
    # }





    # update training and test data Z values

    #training data update is straightforward, just use new draws of Z.mat
    Zlag.mat <- matrix(NA, nrow = n.time*n.ranker*n.item, ncol = num_lags)

    for(t in 1:num_lags){
      init_Z_t0 <- rep(0, t*n.item*n.ranker)
      # init_Z_t0 <- rnorm(t*n.item*n.ranker)

      Zlag.mat[,t] <- c(init_Z_t0, as.vector(Z.mat)[1:((n.time-t)*n.item*n.ranker)])

    }



    #update test data later in code?

    #test data update requires predictions of mu in test data and noise added to these predictions.
    #in addition to using the new Zmat values

    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #
    #   #two options
    #   #use predictions of unobservable Z lag values from previous iteration
    #   #or iterate through to obtain new predictions.
    #   draw$mu_test[,iter-1]
    #
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                                  (num_test_periods-t) )  )
    #
    #       #other option is to set all unobservable values to zero
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }

    # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))
    #
    # temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)
    #
    # temp_mu_test <- rep(NA,  nrow(Xmat.test) )
    #
    # for(t1 in 1:num_test_periods){
    #   #produce a prediction
    #   testpredvec <- sampler$predict(as.data.frame(temp_test_mat))
    #
    #   #fill in temp_test_preds with noise
    #   temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
    #
    #
    #   #update temp_test_mat
    #   #shift z columns to the right and fill in leftmost column
    #
    #   #need to rewrite this if want to allow for no observed covariates
    #
    #   temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
    #
    #
    #
    #   #fill in temp_mu_test without noise
    #   temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec
    #
    #
    # }
    #
    # #also update Zlag.mat.test ?
    # #perhaps this is unnecessary here?
    #
    #
    # Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)
    #
    # if(nrow(X.test) >0 ){
    #   for(t in 1:num_lags){
    #     # if(t==1){
    #     #   #repeating the last period values
    #     #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
    #     #
    #     #   #other option is to set all unobservable values to zero
    #     #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #     #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
    #     #
    #     #
    #     # }else{
    #
    #     if(num_test_periods > t ){
    #       #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data
    #
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
    #                              as.vector(temp_test_mat)[1:((num_test_periods - t)*(n.item*n.ranker))  ] )
    #
    #
    #
    #     }else{
    #       #nothing to fill in if num_test_periods <= t
    #       Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )
    #
    #     }
    #
    #
    #     # }
    #   }
    # }









    # create Z lag test matrix


    Xmat.train[,1:ncol(Zlag.mat)] <- Zlag.mat
    # Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test

    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( rep(alpha, n.ranker*n.time) + (Xmat.train) %*% beta )
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )

    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    # if(p.cov > 0){
    #   sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    # }

    sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)








    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }

    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    # draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }



    if( num_test_periods > 0 ){


      # if(is.null(initial.list)){
      # print("samplestemp$test[,1] = ")
      # print(samplestemp$test[,1])

      # mupreds <- sampler$predict(Xmat.train)

      # Xmat.test[,1:num_lags] <-  Zlag.mat.test


      temp_test_mat <- matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      for(t  in 1:num_lags){
        # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        if(noise_in_pred ==1){
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
        }else{
          # temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]
          temp_test_mat[,t] <- as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]

          # temp_test_mat[,t] <- as.vector(mu)[((n.time-t)*n.item*n.ranker+1):((n.time-t +1) *n.item*n.ranker)]/mean.para.update$theta
          # temp_test_preds[ , t1] <- mean.para.update$theta*testpredvec #+ rnorm( n.item*n.ranker )

        }
      }

      # temp_test_mat[, (num_lags+1):ncol(Xmat.test)] <- as.matrix(Xmat.test[1:(n.item*n.ranker) ,
      #                                                                      (num_lags+1):ncol(Xmat.test)])

      # temp_test_mat <- as.data.frame(temp_test_mat)
      # colnames(temp_test_mat) <- colnames(Xmat.test)


      # temp_test_mat <- Xmat.test[1:(n.item*n.ranker) ,]  #  matrix(NA, nrow = n.item*n.ranker,ncol = ncol(Xmat.test))

      temp_test_preds <- matrix(NA, nrow = n.item*n.ranker,ncol = num_test_periods)

      temp_mu_test <- rep(NA,  nrow(Xmat.test) )

      for(t1 in 1:num_test_periods){
        #produce a prediction
        testpredvec <- rep(alpha, n.ranker) + as.matrix(temp_test_mat) %*% beta  #sampler$predict(temp_test_mat)

        #fill in temp_test_preds with noise

        if(noise_in_pred ==1){
          temp_test_preds[ , t1] <- testpredvec + rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- rnorm( n.item*n.ranker )
        }else{
          temp_test_preds[ , t1] <- testpredvec #+ rnorm( n.item*n.ranker )
          # temp_test_preds[ , t1] <- testpredvec/mean.para.update$theta #+ rnorm( n.item*n.ranker )
        }

        #update temp_test_mat
        #shift z columns to the right and fill in leftmost column

        #need to rewrite this if want to allow for no observed covariates

        # temp_test_mat <-  data.frame( x= cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] ,Xmat.test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] ) )

        if(t1 != num_test_periods){

          if(num_lags ==1){
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] #,
                                      # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
            )

          }else{
            temp_test_mat <-  cbind(  temp_test_preds[ , t1] , temp_test_mat[,1:(num_lags-1)] #,
                                      # as.matrix(Xmat.test[(t1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ,(num_lags+1):(ncol(Xmat.test))] )
            )

          }
        }

        # colnames(temp_test_mat) <- colnames(Xmat.test)


        #fill in temp_mu_test without noise
        temp_mu_test[(t1-1)*(n.item*n.ranker)  +  1:(n.item*n.ranker) ] <- testpredvec


      }

      #also update Zlag.mat.test ?
      #perhaps this is unnecessary here?


      Zlag.mat.test <- matrix(NA, nrow = num_test_periods*n.ranker*n.item, ncol = num_lags)

      if(num_test_periods >0 ){
        for(t in 1:num_lags){
          # if(t==1){
          #   #repeating the last period values
          #   Zlag.mat.test[,t] <- rep(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],num_test_periods )
          #
          #   #other option is to set all unobservable values to zero
          #   # Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-1)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
          #   #                        rep(0,(num_test_periods-t)*n.item*n.ranker ))
          #
          #
          # }else{

          if(num_test_periods > t ){
            #up to t time periods ahead can be filled in. Rest of test time periods filled in using repeated values of last observation in training data

            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):(n.time*n.item*n.ranker)],
                                   as.vector(as.matrix(temp_test_mat))[1:((num_test_periods - t)*(n.item*n.ranker))  ] )



          }else{
            #nothing to fill in if num_test_periods <= t
            Zlag.mat.test[,t] <- c(as.vector(Z.mat)[((n.time-t)*n.item*n.ranker+1):((n.time-(t - num_test_periods) )*n.item*n.ranker)]  )

          }


          # }
        }
      }




      draw$mu_test[,iter] <- temp_mu_test
      # draw$mu_test[,iter] <- samplestemp$test[,1]

      if(keep_zmat==TRUE){
        draw$Z.mat.test[,,iter]  <- matrix(data = as.vector(temp_test_preds), nrow = n.item, ncol = n.ranker*num_test_periods)
      }

      # draw$mu_test[,1] <- samplestemp$test[,1]

      # }else{
      #   draw$mu_test[,1] <- initial.list$mu_test
      # }

    }

    Xmat.test[,1:ncol(Zlag.mat.test)] <- Zlag.mat.test
    # mutest = as.vector( rep(alpha, n.ranker) + Xmat.test %*% beta )
    # draw$mu_test[,iter] = mutest


    # if( nrow(X.test) >0 ){
    #   draw$mu_test[,iter] <- samplestemp$test[,1]
    # }


    # # print iteration number
    # if(iter %% print.opt == 0){
    #   print(paste("Gibbs Iteration", iter))
    #   # print(c(sigma2.alpha, sigma2.beta))
    # }

  }
  return(draw)
}






#' Linear model for Bayesian Analysis of Rank-Order data with entities' Covariates. Includes test data and ranker-item specific variables.
#'
#' Implement the Bayesian model for rank-order data with ranked entities' covariates information and lags of the latent variable.
#' @import truncnorm
#' @import mvtnorm
#' @import dbarts
#' @param pair.comp.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates. If there are ranker-specific covariate values, then the matrix should have N*M rows where M is the number of rankers. The first N rows correspond to ranker 1, the next N rows correspond to ranker 2, and so on.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan ?unused? Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @param print.opt Print every print.optnumber of Gibbsa samples.
#' @param initial.list List of initial values for the Gibbs sample. If not null, must contain elements named Z.mat and mu.
#' @param n.trees (dbarts option) A positive integer giving the number of trees used in the sum-of-trees formulation.
#' @param n.chains (dbarts option) A positive integer detailing the number of independent chains for the dbarts sampler to use (more than one chain is unlikely to improve speed because only one sample for each call to dbarts).
#' @param n.threads  (dbarts option) A positive integer controlling how many threads will be used for various internal calculations, as well as the number of chains. Internal calculations are highly optimized so that single-threaded performance tends to be superior unless the number of observations is very large (>10k), so that it is often not necessary to have the number of threads exceed the number of chains.
#' @param printEvery (dbarts option)If verbose is TRUE, every printEvery potential samples (after thinning) will issue a verbal statement. Must be a positive integer.
#' @param printCutoffs (dbarts option) A non-negative integer specifying how many of the decision rules for a variable are printed in verbose mode
#' @param rngKind (dbarts option) Random number generator kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads.
#' @param rngNormalKind (dbarts option) Random number generator normal kind, as used in set.seed. For type "default", the built-in generator will be used if possible. Otherwise, will attempt to match the built-in generator’s type. Success depends on the number of threads and the rngKind
#' @param rngSeed (dbarts option) Random number generator seed, as used in set.seed. If the sampler is running single-threaded or has one chain, the behavior will be as any other sequential algorithm. If the sampler is multithreaded, the seed will be used to create an additional pRNG object, which in turn will be used sequentially seed the threadspecific pRNGs. If equal to NA, the clock will be used to seed pRNGs when applicable.
#' @param updateState (dbarts option) Logical setting the default behavior for many sampler methods with regards to the immediate updating of the cached state of the object. A current, cached state is only useful when saving/loading the sampler.
#' @param diff_num_test_rankers Equal to 1 if there is a different number of rankers in the test data than in the training data. (assumes no structure to input data)
#' @param keep_zmat Boolean. If equal to TRUE output the draws of Zmat for training data and test data
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
BayesRankCovSimpInds <- function(pair.comp.ten,
                                 X.train = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                 X.test = matrix(NA, nrow =0, ncol = 0),
                                 tau2.alpha = 5^2,
                                 nu.alpha = 3,
                                 tau2.beta = 5^2,
                                 nu.beta = 3,
                                 n.item = dim(pair.comp.ten)[1],
                                 n.ranker = dim(pair.comp.ten)[3],
                                 p.cov = ncol(X.train),
                                 iter.max = 5000,
                                 para.expan = TRUE,
                                 print.opt = 100,
                                 initial.list = NULL,
                                 n.trees = 50L,
                                 n.burn = 0L,
                                 n.samples = 1L,
                                 n.thin = 1L,
                                 n.chains = 1,
                                 n.threads = guessNumCores(),
                                 printEvery = 100L,
                                 printCutoffs = 0L,
                                 rngKind = "default",
                                 rngNormalKind = "default",
                                 rngSeed = NA_integer_,
                                 updateState = FALSE,
                                 num_lags = 1,
                                 diff_num_test_rankers = 0,
                                 keep_zmat = FALSE){
  ## store MCMC draws

  # print("begin function")

  length_mu <- 1

  if(nrow(X.train)==n.item){
    length_mu <- n.item
  }else{
    if(nrow(X.train)==n.item*n.ranker){
      length_mu <- n.item*n.ranker
    }else{
      stop("nrow(X.train) not equal to n.item or n.ranker")
    }

  }


  length_mu_test <- 1
  num_test_rankers <- 1


  if(nrow(X.test) >0 ){
    if(diff_num_test_rankers==1){
      length_mu_test <- nrow(X.test)
      num_test_rankers <- length_mu_test/n.item
      if(num_test_rankers%%1 !=0){
        print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
      }
    }else{
      if(nrow(X.train)==n.item){
        length_mu_test <- n.item*n.ranker

      }else{
        length_mu_test <- nrow(X.test)
        num_test_rankers <- length_mu_test/n.item
        if(num_test_rankers%%1 !=0){
          print("number of test data observations must be an integer multiple of number of items for number of test data rankers to be an integer.")
        }
      }
    }
  }



  draw = list(
    # Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(p.cov, iter.max)),
    #if the x values do not vary over rankers, then there will only be n.item unique x values
    mu = array(NA, dim = c(length_mu, iter.max)),
    #
    #
    #can have mu of dimension n.item*n.ranker to operationalize rnanker-specific mu values, then need to edit gibbs update of Z
    #mu = array(NA, dim = c(n.item*n.ranker, iter.max))#,
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(keep_zmat==TRUE){
    draw$Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max))
  }

  if(nrow(X.test) >0 ){
    draw$mu_test <- array(NA, dim = c(length_mu_test, iter.max))
  }






  if(is.null(initial.list)){
    ## initial values for Z
    # Z.mat = matrix(NA, nrow = n.item, ncol = n.ranker)
    # for(j in 1:n.ranker){
    #   Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] = (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    # }




    ## initial values for Z
    Z.mat <- matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] <- (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values
    # alpha = rep(0, n.item)
    # beta = rep(0, p.cov)

    # print("create data matrices for dbarts")

    #must repeat x matrix if only n.item by the number of covaraites
    #otherwise, the matrix has ranking specific covariates
    if(nrow(X.train)==n.item){
      Xmat.train <- matrix( rep( t( X.train ) , n.ranker ) , ncol =  ncol(X.train) , byrow = TRUE )

      #colnames(Xmat.train) <- c("y", "x","z","w")

      if(nrow(X.test) >0 ){
        # print("nrow(X.test) = ")
        # print(nrow(X.test))

        Xmat.test <- matrix( rep( t( X.test ) , n.ranker ) , ncol =  ncol(X.test) , byrow = TRUE )
        #colnames(Xmat.test) <- c("x","z","w")
      }
    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Xmat.train <-  X.train
        if(nrow(X.test)>0 ){
          Xmat.test  <- X.test
        }
      }else{
        stop("nrow(X.train) not equal to n.item or n.item*n.ranker")
      }

    }



    # print("ncol(Xmat.train) = ")
    # print(ncol(Xmat.train))
    # print("nrow(Xmat.train) = ")
    # print(nrow(Xmat.train))
    # print("n.ranker = ")
    # print(n.ranker)
    # print("n.item = ")
    # print(n.item)

    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, p.cov)
    mu = as.vector( rep(alpha, n.ranker) + Xmat.train %*% beta )
    mu_test = as.vector( rep(alpha, num_test_rankers) + Xmat.test %*% beta )

    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta

  }else{
    Z.mat = initial.list$Z.mat
    alpha = initial.list$alpha
    beta = initial.list$beta
    mu = as.vector( rep(alpha, n.ranker) + Xmat.train %*% beta )
    mu_test = as.vector( rep(alpha, num_test_rankers) + Xmat.test %*% beta )

    sigma2.alpha = initial.list$sigma2.alpha
    sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  if(keep_zmat==TRUE){
    draw$Z.mat[,,1] = Z.mat
  }

  draw$alpha[,1] = alpha
  draw$beta[,1] = beta
  draw$mu[,1] = mu
  draw$mu_test[,1] = mu_test
  draw$sigma2.alpha[1] = sigma2.alpha
  draw$sigma2.beta[1] = sigma2.beta



  ## Gibbs iteration
  for(iter in 2:iter.max){


    if(nrow(X.train)==n.item){
      #each n.ranker values of u should be equal,
      #so just take one mu value from each of these
      #this keeps the dimension of mu equal to n.item
      #so a new Gibbs sampler update does not have to be written for Z
      Z.mat <- GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu,
                                           weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

      if(any(is.na(Z.mat))){stop("NA in Z.mat")}

    }else{
      if(nrow(X.train)==n.item*n.ranker){
        Z.mat <- GibbsUpLatentGivenRankindividual(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu, weight.vec = rep(1, n.ranker), n.ranker = n.ranker,
                                                  n.item = n.item )
      }else{
        #stop("nrow(X.train) not equal to n.item or n.ranker")
      }
    }


    # mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = Xmat.train,
    #                                              weight.vec = rep(1, n.ranker),
    #                                              sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
    #                                              n.ranker = n.ranker, n.item = n.item, p.cov = p.cov,
    #                                              para.expan = para.expan)

    mean.para.update = GibbsUpMuGivenLatentInd(Z.mat = Z.mat, X.mat = Xmat.train,
                                               weight.vec = rep(1, n.ranker),
                                               sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta,
                                               n.ranker = n.ranker,
                                               n.item = n.item,
                                               p.cov = p.cov,
                                               para.expan = para.expan)



    ### for check only
    Z.mat = Z.mat/mean.para.update$theta

    alpha = mean.para.update$alpha
    beta = mean.para.update$beta

    # print("ncol(Xmat.train) = ")
    # print(ncol(Xmat.train))
    # print("nrow(Xmat.train) = ")
    # print(nrow(Xmat.train))
    # print("n.ranker = ")
    # print(n.ranker)
    # print("n.item = ")
    # print(n.item)

    mu = as.vector( rep(alpha, n.ranker) + Xmat.train %*% beta )
    mu_test = as.vector( rep(alpha, num_test_rankers) + Xmat.test %*% beta )

    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    }


    # store value at this iteration
    if(keep_zmat==TRUE){
      draw$Z.mat[,,iter] = Z.mat
    }
    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    draw$mu_test[,iter] = mu_test
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }
  return(draw)
}





#' Bayesian Analysis of Rank data with entities' Covariates. Includes test data.
#'
#' Implement the Bayesian model for rand data with ranked entities' covariates information.
#' @import truncnorm
#' @import mvtnorm
#' @param pair.com.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
BayesRankCovSimpTest <- function(pair.comp.ten,
                                 X.mat = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                 X.test = matrix(NA, nrow =0, ncol = 0),
                                 tau2.alpha = 5^2, nu.alpha = 3,
                                 tau2.beta = 5^2, nu.beta = 3,
                                 n.item = dim(pair.comp.ten)[1], n.ranker = dim(pair.comp.ten)[3], p.cov = ncol(X.mat),
                                 iter.max = 5000, para.expan = TRUE, print.opt = 100,
                                 initial.list = NULL){


  # length_mu_test <- 1
  #
  #
  # if(nrow(X.test) >0 ){
  #   if(diff_num_test_rankers==1){
  #     length_mu_test <- nrow(X.test)
  #   }else{
  #     if(nrow(X.train)==n.item){
  #       length_mu_test <- n.item*n.ranker
  #
  #     }else{
  #       length_mu_test <- nrow(X.test)
  #
  #     }
  #   }
  # }



  ## store MCMC draws
  draw = list(
    Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(p.cov, iter.max)),
    mu = array(NA, dim = c(n.item, iter.max)),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )


  if(nrow(X.test) >0 ){
    draw$mu_test <- array(NA, dim = c(n.item, iter.max))
  }



  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat = matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] = (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, p.cov)
    mu = as.vector( alpha + X.mat %*% beta )
    mutest = as.vector( alpha + X.test %*% beta )

    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta

  }else{
    Z.mat = initial.list$Z.mat
    alpha = initial.list$alpha
    beta = initial.list$beta
    mu = as.vector( alpha + X.mat %*% beta )
    mutest = as.vector( alpha + X.test %*% beta )

    sigma2.alpha = initial.list$sigma2.alpha
    sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  draw$Z.mat[,,1] = Z.mat
  draw$alpha[,1] = alpha
  draw$beta[,1] = beta
  draw$mu[,1] = mu
  draw$mu_test[,1] = mu_test
  draw$sigma2.alpha[1] = sigma2.alpha
  draw$sigma2.beta[1] = sigma2.beta

  ## Gibbs iteration
  for(iter in 2:iter.max){

    # update Z.mat given (alpha, beta) or equivalently mu
    Z.mat = GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu, weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

    # update (alpha, beta) or equivalently mu
    mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker), sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta, n.ranker = n.ranker, n.item = n.item, p.cov = p.cov, para.expan = para.expan)

    ### for check only
    Z.mat = Z.mat/mean.para.update$theta

    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( alpha + X.mat %*% beta )
    mutest = as.vector( alpha + X.test %*% beta )

    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    }


    # store value at this iteration
    draw$Z.mat[,,iter] = Z.mat
    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    draw$mutest[,iter] = mutest
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }
  return(draw)
}






#' Bayesian Analysis of Rank data with entities' Covariates
#'
#' Implement the Bayesian model for rand data with ranked entities' covariates information.
#' @import truncnorm
#' @import mvtnorm
#' @param pair.com.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
BayesRankCovSimp <- function(pair.comp.ten, X.mat = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                             tau2.alpha = 5^2, nu.alpha = 3,
                             tau2.beta = 5^2, nu.beta = 3,
                             n.item = dim(pair.comp.ten)[1], n.ranker = dim(pair.comp.ten)[3], p.cov = ncol(X.mat),
                             iter.max = 5000, para.expan = TRUE, print.opt = 100,
                             initial.list = NULL){
  ## store MCMC draws
  draw = list(
    Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(p.cov, iter.max)),
    mu = array(NA, dim = c(n.item, iter.max)),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat = matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] = (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, p.cov)
    mu = as.vector( alpha + X.mat %*% beta )

    ## initial values for sigma2.alpha and sigma2.beta
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta

  }else{
    Z.mat = initial.list$Z.mat
    alpha = initial.list$alpha
    beta = initial.list$beta
    mu = as.vector( alpha + X.mat %*% beta )
    sigma2.alpha = initial.list$sigma2.alpha
    sigma2.beta = initial.list$sigma2.beta
  }



  ## store initial value
  draw$Z.mat[,,1] = Z.mat
  draw$alpha[,1] = alpha
  draw$beta[,1] = beta
  draw$mu[,1] = mu
  draw$sigma2.alpha[1] = sigma2.alpha
  draw$sigma2.beta[1] = sigma2.beta

  ## Gibbs iteration
  for(iter in 2:iter.max){

    # update Z.mat given (alpha, beta) or equivalently mu
    Z.mat = GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu, weight.vec = rep(1, n.ranker), n.ranker = n.ranker )

    # update (alpha, beta) or equivalently mu
    mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = rep(1, n.ranker), sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta, n.ranker = n.ranker, n.item = n.item, p.cov = p.cov, para.expan = para.expan)

    ### for check only
    Z.mat = Z.mat/mean.para.update$theta

    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( alpha + X.mat %*% beta )

    # update hyper para sigma2.alpha and sigma2.beta
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    }


    # store value at this iteration
    draw$Z.mat[,,iter] = Z.mat
    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(c(sigma2.alpha, sigma2.beta))
    }

  }
  return(draw)
}



### BARCW model

#' Bayesian Analysis of Rank data with entities' Covariates and rankers' Weights.
#'
#' Implement the Bayesian model for rand data with ranked entities' covariates information and rankers' with varying qualities or weights.
#' @import truncnorm
#' @import mvtnorm
#' @param pair.com.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param weight.prior.value A vector for the support of the discrete prior on weight parameter.
#' @param weight.prior.prob A vector for the probability mass of the discrete prior on weight parameter.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
BayesRankCovWeight <- function(pair.comp.ten, X.mat = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                               tau2.alpha = 5^2, nu.alpha = 3,
                               tau2.beta = 5^2, nu.beta = 3,
                               weight.prior.value = c(0.5, 1, 2), weight.prior.prob = rep(1/length(weight.prior.value), length(weight.prior.value)),
                               n.item = dim(pair.comp.ten)[1], n.ranker = dim(pair.comp.ten)[3], p.cov = ncol(X.mat),
                               iter.max = 5000, para.expan = TRUE, print.opt = 100,
                               initial.list = NULL){
  ## store MCMC draws
  draw = list(
    Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    alpha = array(NA, dim = c(n.item, iter.max)),
    beta = array(NA, dim = c(p.cov, iter.max)),
    mu = array(NA, dim = c(n.item, iter.max)),
    weight.vec = array(NA, dim = c(n.ranker, iter.max) ),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max)
  )

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat = matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] = (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values for alpha, beta and thus mu
    alpha = rep(0, n.item)
    beta = rep(0, p.cov)
    mu = as.vector( alpha + X.mat %*% beta )

    ## initial values for weights
    weight.vec = rep(1, n.ranker)

    ## initial values for sigma2
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta
  }else{

    Z.mat = initial.list$Z.mat
    alpha = initial.list$alpha
    beta = initial.list$beta
    mu = as.vector( alpha + X.mat %*% beta )
    weight.vec = initial.list$weight.vec
    sigma2.alpha = initial.list$sigma2.alpha
    sigma2.beta = initial.list$sigma2.beta

  }

  ## store initial value
  draw$Z.mat[,,1] = Z.mat
  draw$alpha[,1] = alpha
  draw$beta[,1] = beta
  draw$mu[,1] = mu
  draw$weight.vec[,1] = weight.vec

  ## Gibbs iteration
  for(iter in 2:iter.max){

    # update Z.mat given (alpha, beta) or equivalently mu
    Z.mat = GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten, Z.mat = Z.mat, mu = mu, weight.vec = weight.vec, n.ranker = n.ranker )

    # update (alpha, beta) or equivalently mu
    mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat, X.mat = X.mat, weight.vec = weight.vec, sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta, n.ranker = n.ranker, n.item = n.item, p.cov = p.cov, para.expan = para.expan)

    ### for check only
    Z.mat = Z.mat/mean.para.update$theta

    alpha = mean.para.update$alpha
    beta = mean.para.update$beta
    mu = as.vector( alpha + X.mat %*% beta )

    ### update weight
    weight.vec = GibbsUpWeightGroup(Z.mat = Z.mat, mu = mu, weight.prior.value = weight.prior.value, weight.prior.prob = weight.prior.prob, n.item = n.item, n.ranker = n.ranker)

    ### update sigma2
    sigma2.alpha = GibbsUpsigma2(alpha, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta, nu.beta, tau2.beta)
    }

    # store value at this iteration
    draw$Z.mat[,,iter] = Z.mat
    draw$alpha[,iter] = alpha
    draw$beta[,iter] = beta
    draw$mu[,iter] = mu
    draw$weight.vec[, iter] = weight.vec
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(table(weight.vec))
      # print(c(sigma2.alpha, sigma2.beta))
    }
  }
  return(draw)
}




### BARCM model
#' Bayesian Analysis of Rank data with Covariates of entities and Mixture of rankers with different opinion
#'
#' Implement the Bayesian model for rand data with ranked entities' covariates information and mixture of rankers with different ranking opinions.
#' @import truncnorm
#' @import mvtnorm
#' @param pair.com.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param gamma.a The shape parameter for the Gamma prior on the concentration parameter of Dirichlet process.
#' @param gamma.b The rate parameter for the Gamma prior on the concentration parameter of Dirichlet process.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
BayesRankCovMix <- function(pair.comp.ten, X.mat = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                            tau2.alpha = 5^2, nu.alpha = 3,
                            tau2.beta = 5^2, nu.beta = 3,
                            gamma.a = 2, gamma.b = NULL,
                            n.item = dim(pair.comp.ten)[1], n.ranker = dim(pair.comp.ten)[3], p.cov = ncol(X.mat),
                            iter.max = 5000, para.expan = TRUE, print.opt = 100,
                            initial.list = NULL){
  ## store MCMC draws
  draw = list(
    Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    alpha = array(NA, dim = c(n.item, n.ranker, iter.max)),
    beta = array(NA, dim = c(p.cov, n.ranker, iter.max)),
    mu = array(NA, dim = c(n.item, n.ranker, iter.max)),
    cluster = array(NA, dim = c(n.ranker, iter.max)),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max),
    gamma = rep(NA, iter.max)
  )

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat = matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] = (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values for alpha, beta and thus mu
    alpha = array(0, dim = c(n.item, n.ranker))
    beta = array(0, dim = c(p.cov, n.ranker))
    mu = alpha + X.mat %*% beta

    ## initial value for cluster indicator
    # cluster = rep(1, n.ranker)
    cluster = sample(c(1:ceiling(log(n.ranker))), n.ranker, replace = TRUE )

    ## initial value for hyper para of DP
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta
    if(is.null(gamma.b)){
      gamma = gamma.a
    }else{
      gamma = gamma.a/gamma.b
    }

  }else{
    Z.mat = initial.list$Z.mat
    alpha = initial.list$alpha
    beta = initial.list$beta
    mu = alpha + X.mat %*% beta
    cluster = initial.list$cluster
    sigma2.alpha = initial.list$sigma2.alpha
    sigma2.beta = initial.list$sigma2.beta
    gamma = initial.list$gamma
  }

  ## store initial value
  draw$Z.mat[,,1] = Z.mat
  draw$alpha[,,1] = alpha
  draw$beta[,,1] = beta
  draw$mu[,,1] = mu
  draw$cluster[, 1] = cluster
  draw$sigma2.alpha[1] = sigma2.alpha
  draw$sigma2.beta[1] = sigma2.beta
  draw$gamma[1] = gamma

  c.max = max(cluster)

  ## Gibbs iteration
  for(iter in 2:iter.max){
    ### Gibbs update for each clsuter
    alpha.all = c()
    beta.all = c()
    for(c in unique( cluster ) ){
      # update (alpha, beta) or equivalently mu
      mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat[, cluster == c, drop=FALSE], X.mat = X.mat, weight.vec = rep(1, sum(cluster==c)), sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta, n.ranker = sum(cluster==c), n.item = n.item, p.cov = p.cov, para.expan = para.expan)

      alpha.c = mean.para.update$alpha
      beta.c = mean.para.update$beta
      mu.c = as.vector( alpha.c + X.mat %*% beta.c )

      alpha[, cluster==c] = alpha.c
      beta[, cluster==c] = beta.c
      mu[, cluster==c] = mu.c

      alpha.all = c(alpha.all, alpha.c)
      beta.all = c(beta.all, beta.c)

      ### for check only
      Z.mat[, cluster == c] = Z.mat[, cluster == c]/mean.para.update$theta

      # update Z.mat given (alpha, beta) or equivalently mu
      # mu.c = mu[, cluster==c, drop=FALSE][,1]
      Z.mat[, cluster == c] = GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten[,,cluster==c, drop=FALSE], Z.mat = Z.mat[, cluster==c, drop=FALSE], mu = mu.c, weight.vec = rep(1, sum(cluster==c)), n.ranker = sum(cluster==c) )
    }

    ### Gibbs update for hyper parameters of DP
    sigma2.alpha = GibbsUpsigma2(alpha.all, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta.all, nu.beta, tau2.beta)
    }
    if(!is.null(gamma.b)){
      gamma = GibbsUpDPgamma( gamma = gamma, c.vec = cluster, a = gamma.a, b = gamma.b, n = n.ranker )
    }

    ### Gibbs update for the cluster label
    # for(i in 1:n.ranker){
    for(i in sample(c(1:n.ranker)) ){
      candidate = c( unique( cluster[-i] ), c.max+1 )
      logp = rep(NA, length(candidate))
      for(c in candidate){
        if( sum(cluster[-i] == c) > 0 ){
          set = setdiff( which(cluster == c), i )
          logp[candidate==c] = log( sum(cluster[-i] == c) ) + LogMargDensity(Z.mat = Z.mat[, c(set, i), drop=FALSE], X.mat = X.mat, sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta) - LogMargDensity(Z.mat = Z.mat[, set, drop=FALSE], X.mat = X.mat, sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta)
        }else{
          logp[candidate==c] = log(gamma) + LogMargDensity(Z.mat = Z.mat[, i, drop=FALSE], X.mat = X.mat, sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta)
        }
      }
      logp = logp - max(logp)
      cluster[i] = candidate[which( as.vector( rmultinom(1, 1, prob = exp(logp)) ) == 1 )]
      if(cluster[i] == ( c.max+1)){
        c.max = c.max + 1
      }
    }

    ### store vlaues
    draw$Z.mat[,,iter] = Z.mat
    draw$alpha[,,iter] = alpha
    draw$beta[,,iter] = beta
    draw$mu[,,iter] = mu
    draw$cluster[, iter] = cluster
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta
    draw$gamma[iter] = gamma

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(table(cluster))
      # print(c(sigma2.alpha, sigma2.beta))
      # print(gamma)
    }
  }
  return(draw)
}


### BARCMW model
#' Bayesian Analysis of Rank data with Covariates of entities and Mixture of rankers with different opinions and Weight
#'
#' Implement the Bayesian model for rand data with ranked entities' covariates information and mixture of rankers with different ranking opinions, where the rankers can also have different qualities or weights.
#' @import truncnorm
#' @import mvtnorm
#' @param pair.com.ten An \eqn{N} by \eqn{N} by \eqn{M} pairwise comparison tensor for all \eqn{N} entities and \eqn{M} rankers, where the (\eqn{i},\eqn{j},\eqn{m}) element equals 1 if \eqn{i} is ranked higher than \eqn{j} by ranker \eqn{m}, 0 if \eqn{i} is ranker lower than \eqn{j}, and NA if the relation between \eqn{i} and \eqn{j} is missing. Note that the diagonal elements (\eqn{i},\eqn{i},\eqn{m})'s for all rankers should be set to NA as well.
#' @param X.mat An \eqn{N} by \eqn{L} covariate matrix for the \eqn{N} entities with \eqn{L} covariates.
#' @param tau2.alpha The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param nu.alpha The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_alpha}.
#' @param tau2.beta The scale parameter for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param nu.beta The d.f. for the scaled inverse chi-squared prior on \eqn{\sigma^2_beta}.
#' @param gamma.a The shape parameter for the Gamma prior on the concentration parameter of Dirichlet process.
#' @param gamma.b The rate parameter for the Gamma prior on the concentration parameter of Dirichlet process.
#' @param weight.prior.value A vector for the support of the discrete prior on weight parameter.
#' @param weight.prior.prob A vector for the probability mass of the discrete prior on weight parameter.
#' @param iter.max Number of iterations for Gibbs sampler.
#' @param para.expan Logical variable for whether using parameter expansion in the Gibbs sampler.
#' @return A list containing posterior samples of all the missing evaluation scores for all rankers and all the model parameters.
#' @export
BayesRankCovMixWeight <- function(pair.comp.ten, X.mat = matrix(NA, nrow =dim(pair.comp.ten)[1], ncol = 0),
                                  tau2.alpha = 5^2, nu.alpha = 3,
                                  tau2.beta = 5^2, nu.beta = 3,
                                  gamma.a = 2, gamma.b = NULL,
                                  weight.prior.value = c(0.5, 1, 2), weight.prior.prob = rep(1/length(weight.prior.value), length(weight.prior.value)),
                                  n.item = dim(pair.comp.ten)[1], n.ranker = dim(pair.comp.ten)[3], p.cov = ncol(X.mat),
                                  iter.max = 5000, para.expan = TRUE, print.opt = 100,
                                  initial.list = NULL){
  ## store MCMC draws
  draw = list(
    Z.mat = array(NA, dim = c(n.item, n.ranker, iter.max)),
    alpha = array(NA, dim = c(n.item, n.ranker, iter.max)),
    beta = array(NA, dim = c(p.cov, n.ranker, iter.max)),
    mu = array(NA, dim = c(n.item, n.ranker, iter.max)),
    cluster = array(NA, dim = c(n.ranker, iter.max)),
    weight.vec = array(NA, dim = c(n.ranker, iter.max) ),
    sigma2.alpha = rep(NA, iter.max),
    sigma2.beta = rep(NA, iter.max),
    gamma = rep(NA, iter.max)
  )

  if(is.null(initial.list)){
    ## initial values for Z
    Z.mat = matrix(NA, nrow = n.item, ncol = n.ranker)
    for(j in 1:n.ranker){
      Z.mat[sort( rowSums( pair.comp.ten[,,j], na.rm = TRUE ), decreasing = FALSE, index.return = TRUE )$ix, j] = (c(n.item : 1) - (1+n.item)/2)/sd(c(n.item : 1))
    }

    ## initial values for alpha, beta and thus mu
    alpha = array(0, dim = c(n.item, n.ranker))
    beta = array(0, dim = c(p.cov, n.ranker))
    mu = alpha + X.mat %*% beta

    ## initial value for cluster indicator
    # cluster = rep(1, n.ranker)
    cluster = sample(c(1:ceiling(log(n.ranker))), n.ranker, replace = TRUE )

    ## initial values for weights
    weight.vec = rep(1, n.ranker)

    ## initial values for hyper para of DP
    sigma2.alpha = tau2.alpha
    sigma2.beta = tau2.beta
    if(is.null(gamma.b)){
      gamma = gamma.a
    }else{
      gamma = gamma.a/gamma.b
    }
  }else{

    Z.mat = initial.list$Z.mat
    alpha = initial.list$alpha
    beta = initial.list$beta
    mu = alpha + X.mat %*% beta
    cluster = initial.list$cluster
    weight.vec = initial.list$weight.vec
    sigma2.alpha = initial.list$sigma2.alpha
    sigma2.beta = initial.list$sigma2.beta
    gamma = initial.list$gamma

  }



  ## store initial value
  draw$Z.mat[,,1] = Z.mat
  draw$alpha[,,1] = alpha
  draw$beta[,,1] = beta
  draw$mu[,,1] = mu
  draw$cluster[, 1] = cluster
  draw$weight.vec[, 1] = weight.vec
  draw$sigma2.alpha[1] = sigma2.alpha
  draw$sigma2.beta[1] = sigma2.beta
  draw$gamma[1] = gamma

  c.max = max(cluster)

  ## Gibbs iteration
  for(iter in 2:iter.max){
    ### Gibbs update for each clsuter
    alpha.all = c()
    beta.all = c()
    for(c in unique( cluster ) ){
      # update (alpha, beta) or equivalently mu
      mean.para.update = GibbsUpMuGivenLatentGroup(Z.mat = Z.mat[, cluster == c, drop=FALSE], X.mat = X.mat, weight.vec = weight.vec[cluster==c], sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta, n.ranker = sum(cluster==c), n.item = n.item, p.cov = p.cov, para.expan = para.expan)

      alpha.c = mean.para.update$alpha
      beta.c = mean.para.update$beta
      mu.c = as.vector( alpha.c + X.mat %*% beta.c )

      alpha[, cluster==c] = alpha.c
      beta[, cluster==c] = beta.c
      mu[, cluster==c] = mu.c

      alpha.all = c(alpha.all, alpha.c)
      beta.all = c(beta.all, beta.c)

      ### for check only
      Z.mat[, cluster == c] = Z.mat[, cluster == c]/mean.para.update$theta

      # update Z.mat given (alpha, beta) or equivalently mu
      # mu.c = mu[, cluster==c, drop=FALSE][,1]
      Z.mat[, cluster == c] = GibbsUpLatentGivenRankGroup(pair.comp.ten = pair.comp.ten[,,cluster==c, drop=FALSE], Z.mat = Z.mat[, cluster==c, drop=FALSE], mu = mu.c, weight.vec = weight.vec[cluster==c], n.ranker = sum(cluster==c) )
    }

    ### Gibbs update for weights
    for(i in 1:n.ranker){
      weight.vec[i] = GibbsUpWeightInd(Z = Z.mat[, i], mu[, i], weight.prior.value = weight.prior.value, weight.prior.prob = weight.prior.prob, n.item = n.item )
    }

    ### Gibbs update for hyper parameters of DP
    sigma2.alpha = GibbsUpsigma2(alpha.all, nu.alpha, tau2.alpha)
    if(p.cov > 0){
      sigma2.beta = GibbsUpsigma2(beta.all, nu.beta, tau2.beta)
    }
    if(!is.null(gamma.b)){
      gamma = GibbsUpDPgamma( gamma = gamma, c.vec = cluster, a = gamma.a, b = gamma.b, n = n.ranker )
    }

    ### Gibbs update for the cluster label
    # for(i in 1:n.ranker){
    for(i in sample(c(1:n.ranker)) ){
      candidate = c( unique( cluster[-i] ), c.max+1 )
      logp = rep(NA, length(candidate))
      for(c in candidate){
        if( sum(cluster[-i] == c) > 0 ){
          set = setdiff( which(cluster == c), i )
          logp[candidate==c] = log( sum(cluster[-i] == c) ) + LogMargDensity(Z.mat = Z.mat[, c(set, i), drop=FALSE], X.mat = X.mat, sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta, weight.vec = weight.vec[c(set, i)]) - LogMargDensity(Z.mat = Z.mat[, set, drop=FALSE], X.mat = X.mat, sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta, weight.vec = weight.vec[set])
        }else{
          logp[candidate==c] = log(gamma) + LogMargDensity(Z.mat = Z.mat[, i, drop=FALSE], X.mat = X.mat, sigma2.alpha = sigma2.alpha, sigma2.beta = sigma2.beta, weight.vec = weight.vec[i])
        }
      }
      logp = logp - max(logp)
      cluster[i] = candidate[which( as.vector( rmultinom(1, 1, prob = exp(logp)) ) == 1 )]
      if(cluster[i] == ( c.max+1)){
        c.max = c.max + 1
      }
    }

    ### store vlaues
    draw$Z.mat[,,iter] = Z.mat
    draw$alpha[,,iter] = alpha
    draw$beta[,,iter] = beta
    draw$mu[,,iter] = mu
    draw$cluster[, iter] = cluster
    draw$weight.vec[, iter] = weight.vec
    draw$sigma2.alpha[iter] = sigma2.alpha
    draw$sigma2.beta[iter] = sigma2.beta
    draw$gamma[iter] = gamma

    # print iteration number
    if(iter %% print.opt == 0){
      print(paste("Gibbs Iteration", iter))
      # print(table(cluster))
      # print(table(weight.vec))
      # print(c(sigma2.alpha, sigma2.beta))
      # print(gamma)
    }
  }
  return(draw)
}


